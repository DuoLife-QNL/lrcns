[{"author": ["\ufeffPalash Goyal", "Sujit Rokka Chhetri", "Arquimedes Canedo"], "title": "dyngraph2vec: Capturing Network Dynamics using Dynamic Graph Representation Learning", "journal": "Knowledge-Based Systems", "year": 2019, "DOI": "10.1016/j.knosys.2019.06.024", "month": 7, "citations(google scholar)": 13, "abstract": "Learning graph representations is a fundamental task aimed at capturing various properties of graphs in vector space. The most recent methods learn such representations for static networks. However, real-world networks evolve over time and have varying dynamics. Capturing such evolution is key to predicting the properties of unseen networks. To understand how the network dynamics a\u000bect the prediction performance, we propose an embedding approach which learns the structure of evolution in dynamic graphs and can predict unseen links with higher precision. Our model, dyngraph2vec, learns the temporal transitions in the network using a deep architecture composed of dense and recurrent layers. We motivate the need for capturing dynamics for the prediction on a toy data set created using stochastic block models. We then demonstrate the e\u000ecacy of dyngraph2vec over existing state-ofthe-art methods on two real-world data sets. We observe that learning dynamics can improve the quality of embedding.", "keywords": ["Graph embedding techniques", "Graph embedding applications", "Python Graph Embedding Methods GEM Library"], "reference_count": 39, "ccfClass": "C", "important": true, "references": [{"ref": "[1] J. Gehrke, P. Ginsparg, J. Kleinberg, Overview of the 2003 kdd cup, ACM SIGKDD Explorations 5 (2)."}, {"ref": "[2] L. C. Freeman, Visualizing social networks, Journal of social structure 1 (1) (2000) 4."}, {"ref": "[3] A. Theocharidis, S. Van Dongen, A. Enright, T. Freeman, Network visualization and analysis of gene expression data using biolayout express3d, Nature protocols 4 (2009) 1535\u20131550."}, {"ref": "[4] P. Goyal, A. Sapienza, E. Ferrara, Recommending teammates with deep neural networks, in: Proceedings of the 29th on Hypertext and Social Media, ACM, 2018, pp. 57\u201361."}, {"ref": "[5] G. A. Pavlopoulos, A.-L. Wegener, R. Schneider, A survey of visualization tools for biological network analysis, Biodata mining 1 (1) (2008) 12."}, {"ref": "[6] S. Wasserman, K. Faust, Social network analysis: Methods and applications, Vol. 8, Cambridge university press, 1994."}, {"ref": "[7] P. Goyal, E. Ferrara, Graph embedding techniques, applications, and performance: A survey, Knowledge-Based Systems doi:https://doi.org/10.1016/j.knosys.2018.03.022. URL http://www.sciencedirect.com/science/article/pii/ S0950705118301540"}, {"ref": "[8] A. Grover, J. Leskovec, node2vec: Scalable feature learning for networks, in: Proceedings of the 22nd International Conference on Knowledge Discovery and Data Mining, ACM, 2016, pp. 855\u2013864."}, {"ref": "[9] M. Ou, P. Cui, J. Pei, Z. Zhang, W. Zhu, Asymmetric transitivity preserving graph embedding, in: Proc. of ACM SIGKDD, 2016, pp. 1105\u20131114."}, {"ref": "[10] A. Ahmed, N. Shervashidze, S. Narayanamurthy, V. Josifovski, A. J. Smola, Distributed large-scale natural graph factorization, in: Proceedings of the 22nd international conference on World Wide Web, ACM, 2013, pp. 37\u201348."}, {"ref": "[11] B. Perozzi, R. Al-Rfou, S. Skiena, Deepwalk: Online learning of social representations, in: Proceedings 20th international conference on Knowledge discovery and data mining, 2014, pp. 701\u2013710."}, {"ref": "[12] S. Cao,W. Lu, Q. Xu, Grarep: Learning graph representations with global structural information, in: KDD15, 2015, pp. 891\u2013900."}, {"ref": "[13] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, Q. Mei, Line: Large-scale information network embedding, in: Proceedings 24th International Conference on World Wide Web, 2015, pp. 1067\u20131077."}, {"ref": "[14] P. Goyal, H. Hosseinmardi, E. Ferrara, A. Galstyan, Embedding networks with edge attributes, in: Proceedings of the 29th on Hypertext and Social Media, ACM, 2018, pp. 38\u201342."}, {"ref": "[15] L. Zhou, Y. Yang, X. Ren, F. Wu, Y. Zhuang, Dynamic Network Embedding by Modelling Triadic Closure Process, in: AAAI, 2018."}, {"ref": "[16] P. Goyal, N. Kamra, X. He, Y. Liu, Dyngem: Deep embedding method for dynamic graphs, arXiv preprint arXiv:1805.11273."}, {"ref": "[17] Z. Zhang, P. Cui, J. Pei, X. Wang, W. Zhu, Timers: Error-bounded svd restart on dynamic networks, arXiv preprint arXiv:1711.09541."}, {"ref": "[18] M. Belkin, P. Niyogi, Laplacian eigenmaps and spectral techniques for embedding and clustering, in: NIPS, Vol. 14, 2001, pp. 585\u2013591."}, {"ref": "[19] D. Wang, P. Cui, W. Zhu, Structural deep network embedding, in: Proceedings of the 22nd International Conference on Knowledge Discovery and Data Mining, ACM, 2016, pp. 1225\u20131234."}, {"ref": "[20] S. Cao, W. Lu, Q. Xu, Deep neural networks for learning graph representations, in: Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI Press, 2016, pp. 1145\u20131152."}, {"ref": "[21] T. N. Kipf, M. Welling, Variational graph auto-encoders, arXiv preprint arXiv:1611.07308."}, {"ref": "[22] T. N. Kipf, M. Welling, Semi-supervised classification with graph convolutional networks, arXiv preprint arXiv:1609.02907."}, {"ref": "[23] J. Bruna,W. Zaremba, A. Szlam, Y. LeCun, Spectral networks and locally connected networks on graphs, arXiv preprint arXiv:1312.6203."}, {"ref": "[24] M. Hena\u000b, J. Bruna, Y. LeCun, Deep convolutional networks on graphstructured data, arXiv preprint arXiv:1506.05163."}, {"ref": "[25] L. Zhu, D. Guo, J. Yin, G. Ver Steeg, A. Galstyan, Scalable temporal latent space inference for link prediction in dynamic social networks, IEEE Transactions on Knowledge and Data Engineering 28 (10) (2016) 2765\u2013 2777."}, {"ref": "[26] P. Goyal, N. Kamra, X. He, Y. Liu, Dyngem: Deep embedding method for dynamic graphs, in: IJCAI International Workshop on Representation Learning for Graphs, 2017."}, {"ref": "[27] M. Rahman, T. K. Saha, M. A. Hasan, K. S. Xu, C. K. Reddy, Dylink2vec: E\u000bective feature representation for link prediction in dynamic networks, arXiv preprint arXiv:1804.05755."}, {"ref": "[28] P. Sarkar, D. Chakrabarti, M. Jordan, Nonparametric link prediction in dynamic networks, arXiv preprint arXiv:1206.6394."}, {"ref": "[29] S. Yang, T. Khot, K. Kersting, S. Natarajan, Learning continuous-time bayesian networks in relational domains: A non-parametric approach, in: Thirtieth AAAI Conference on Artificial Intelligence, 2016."}, {"ref": "[30] D. M. Dunlavy, T. G. Kolda, E. Acar, Temporal link prediction using matrix and tensor factorizations, ACM Transactions on Knowledge Discovery from Data (TKDD) 5 (2) (2011) 10."}, {"ref": "[31] X. Ma, P. Sun, Y. Wang, Graph regularized nonnegative matrix factorization for temporal link prediction in dynamic networks, Physica A: Statistical mechanics and its applications 496 (2018) 121\u2013136."}, {"ref": "[32] N. Talasu, A. Jonnalagadda, S. S. A. Pillai, J. Rahul, A link prediction based approach for recommendation systems, in: 2017 international conference on advances in computing, communications and informatics (ICACCI), IEEE, 2017, pp. 2059\u20132062."}, {"ref": "[33] J. Li, K. Cheng, L. Wu, H. Liu, Streaming link prediction on dynamic attributed networks, in: Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, ACM, 2018, pp. 369\u2013377."}, {"ref": "[34] Y. J.Wang, G. Y.Wong, Stochastic blockmodels for directed graphs, Journal of the American Statistical Association 82 (397) (1987) 8\u201319."}, {"ref": "[35] D. E. Rumelhart, G. E. Hinton, R. J. Williams, Neurocomputing: Foundations of research, JA Anderson and E. Rosenfeld, Eds (1988) 696\u2013699."}, {"ref": "[36] D. Kingma, J. Ba, Adam: A method for stochastic optimization, arXiv preprint arXiv:1412.6980."}, {"ref": "[37] J. Leskovec, J. Kleinberg, C. Faloutsos, Graphs over time: densification laws, shrinking diameters and possible explanations, in: Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining, ACM, 2005, pp. 177\u2013187."}, {"ref": "[38] M. Ou, P. Cui, J. Pei, Z. Zhang, W. Zhu, Asymmetric transitivity preserving graph embedding, in: Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, 2016, pp. 1105\u20131114."}, {"ref": "[39] M. Brand, Fast low-rank modifications of the thin singular value decomposition, Linear algebra and its applications 415 (1) (2006) 20\u201330."}]}, {"author": ["\ufeffNeil Shah", "Danai Koutra", "Tianmin Zou", "Brian Gallagher", "Christos Faloutsos"], "title": "TimeCrunch: Interpretable Dynamic Graph Summarization", "journal": "KDD", "year": 2015, "DOI": "10.1145/2783258.2783321", "month": 8, "citations(google scholar)": 68, "abstract": "How can we describe a large, dynamic graph over time? Is it random? If not, what are the most apparent deviations from randomness -- a dense block of actors that persists over time, or perhaps a star with many satellite nodes that appears with some fixed periodicity? In practice, these deviations indicate patterns -- for example, botnet attackers forming a bipartite core with their victims over the duration of an attack, family members bonding in a clique-like fashion over a difficult period of time, or research collaborations forming and fading away over the years. Which patterns exist in real-world dynamic graphs, and how can we find and rank them in terms of importance? These are exactly the problems we focus on in this work. Our main contributions are (a) formulation: we show how to formalize this problem as minimizing the encoding cost in a data compression paradigm, (b) algorithm: we propose TIMECRUNCH, an effective, scalable and parameter-free method for finding coherent, temporal patterns in dynamic graphs and (c) practicality: we apply our method to several large, diverse real-world datasets with up to 36 million edges and 6.3 million nodes. We show that TIMECRUNCH is able to compress these graphs by summarizing important temporal structures and finds patterns that agree with intuition.", "keywords": ["dynamic graph", "network", "clustering", "summarization", "compression"], "reference_count": 28, "ccfClass": "A", "important": true, "references": [{"ref": "[1] DBLP network dataset. konect.uni-koblenz.de/networks/dblp_coauthor, July 2014."}, {"ref": "[2] C. C. Aggarwal and S. Y. Philip. Online analysis of community evolution in data streams. SIAM."}, {"ref": "[3] C. J. Alpert, A. B. Kahng, and S.-Z. Yao. Spectral partitioning with multiple eigenvectors. Discrete Applied Mathematics, 90(1):3\u201326, 1999."}, {"ref": "[4] M. Araujo, S. Papadimitriou, S. G\u00fcnnemann, C. Faloutsos, P. Basu, A. Swami, E. E. Papalexakis, and D. Koutra. Com2: Fast automatic discovery of temporal (\"comet\") communities. In PAKDD, pages 271\u2013283. Springer, 2014."}, {"ref": "[5] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10):P10008, 2008."}, {"ref": "[6] D. Chakrabarti, S. Papadimitriou, D. S. Modha, and C. Faloutsos. Fully automatic cross-associations. In KDD, pages 79\u201388. ACM, 2004."}, {"ref": "[7] D. J. Cook and L. B. Holder. Substructure discovery using minimum description length and background knowledge. arXiv preprint cs/9402102, 1994."}, {"ref": "[8] T. M. Cover and J. A. Thomas. Elements of information theory. John Wiley & Sons, 2012."}, {"ref": "[9] I. S. Dhillon, S. Mallela, and D. S. Modha. Information-theoretic co-clustering. In Proc. 9th KDD, pages 89\u201398, 2003."}, {"ref": "[10] J. Ferlez, C. Faloutsos, J. Leskovec, D. Mladenic, and M. Grobelnik. Monitoring network evolution using MDL. ICDE, 2008."}, {"ref": "[11] R. Jin, C. Wang, D. Polshakov, S. Parthasarathy, and G. Agrawal. Discovering frequent topological structures from graph datasets. In KDD, pages 606\u2013611, 2005."}, {"ref": "[12] U. Kang and C. Faloutsos. Beyond\u2019caveman communities\u2019: Hubs and spokes for graph compression and mining. In ICDM, pages 300\u2013309. IEEE, 2011."}, {"ref": "[13] G. Karypis and V. Kumar. Multilevel k-way hypergraph partitioning. VLSI design, 11(3):285\u2013300, 2000."}, {"ref": "[14] J. M. Kleinberg, R. Kumar, P. Raghavan, S. Rajagopalan, and A. S. Tomkins. The web as a graph: measurements, models, and methods. In Computing and combinatorics, pages 1\u201317. Springer, 1999."}, {"ref": "[15] D. Koutra, U. Kang, J. Vreeken, and C. Faloutsos. Vog: Summarizing and understanding large graphs."}, {"ref": "[16] D. Koutra, T.-Y. Ke, U. Kang, D. H. P. Chau, H.-K. K. Pao, and C. Faloutsos. Unifying guilt-by-association approaches: Theorems and fast algorithms. In ECML/PKDD, pages 245\u2013260. Springer, 2011."}, {"ref": "[17] B. Kulis and Y. Guan. Graclus - efficient graph clustering software for normalized cut and ratio association on undirected graphs, 2008. 2010."}, {"ref": "[18] M. Li and P. M. Vit\u00e1nyi. An introduction to Kolmogorov complexity and its applications. Springer Science & Business Media, 2009."}, {"ref": "[19] M. E. Newman and M. Girvan. Finding and evaluating community structure in networks. Physical review E, 69(2):026113, 2004."}, {"ref": "[20] E. E. Papalexakis, N. D. Sidiropoulos, and R. Bro. From k-means to higher-way co-clustering: Multilinear decomposition with sparse latent factors. IEEE TSP, 61(2):493\u2013506, 2013."}, {"ref": "[21] J. Pei, D. Jiang, and A. Zhang. On mining cross-graph quasi-cliques. In KDD, pages 228\u2013238, 2005."}, {"ref": "[22] J. Rissanen. Modeling by shortest data description. Automatica, 14(5):465\u2013471, 1978."}, {"ref": "[23] N. Shah, A. Beutel, B. Gallagher, and C. Faloutsos. Spotting suspicious link behavior with fbox: An adversarial perspective. In ICDM. 2014."}, {"ref": "[24] J. Shetty and J. Adibi. The enron email dataset database schema and brief statistical report. Inf. sciences inst. TR, USC, 4, 2004."}, {"ref": "[25] J. Sun, C. Faloutsos, S. Papadimitriou, and P. S. Yu. Graphscope: parameter-free mining of large time-evolving graphs. In KDD, pages 687\u2013696. ACM, 2007."}, {"ref": "[26] H. Toivonen, F. Zhou, A. Hartikainen, and A. Hinkka. Compression of weighted graphs. In KDD, pages 965\u2013973. ACM, 2011."}, {"ref": "[27] K. S. Xu, M. Kliger, and A. O. Hero III. Tracking communities in dynamic social networks. In SBP, pages 219\u2013226. Springer, 2011."}, {"ref": "[28] Yahoo! Webscope. webscope.sandbox.yahoo.com."}]}, {"author": ["\ufeffTaisong Li", "Jiawei Zhang", "Philip S. Yu", "Yan Zhang", "Yonghong Yan"], "title": "Deep Dynamic Network Embedding for Link Prediction", "journal": "IEEE Access", "year": 2018, "DOI": "10.1109/access.2018.2839770", "month": 6, "citations(google scholar)": 14, "abstract": "Network embedding task aims at learning low-dimension latent representations of vertices while preserving the structure of a network simultaneously. Most existing network embedding methods mainly focus on static networks, which extract and condense the network information without temporal information. However, in the real world, networks keep evolving, where the linkage states between the same vertex pairs at consequential timestamps have very close correlations. In this paper, we propose to study the network embedding problem and focus on modeling the linkage evolution in the dynamic network setting. To address this problem, we propose a deep dynamic network embedding method. More specifically, the method utilizes the historical information obtained from the network snapshots at past timestamps to learn latent representations of the future network. In the proposed embedding method, the objective function is carefully designed to incorporate both the network internal and network dynamic transition structures. Extensive empirical experiments prove the effectiveness of the proposed model on various categories of real-world networks, including a human contact network, a bibliographic network, and e-mail networks. Furthermore, the experimental results also demonstrate the significant advantages of the method compared with both the state-of-the-art embedding techniques and several existing baseline methods.", "keywords": ["Social network analysis", "network embedding", "link prediction", "deep learning."], "reference_count": 29, "ccfClass": "", "important": true, "references": [{"ref": "[1] M. Spiliopoulou, ''Evolution in social networks: A survey,'' in Social Network Data Analytics. Boston, MA, USA: Springer, 2011, pp. 149\u0015175."}, {"ref": "[2] J. Leskovec, J. Kleinberg, and C. Faloutsos, ''Graph evolution: Densi\u001ccation and shrinking diameters,'' ACM Trans. Knowl. Discovery Data, vol. 1, no. 1, pp. 1\u001540, 2007."}, {"ref": "[3] X. Li, N. Du, H. Li, K. Li, J. Gao, and A. Zhang, ''Adeep learning approach to link prediction in dynamic networks,'' in Proc. SIAM Int. Conf. Data Mining, 2014, pp. 289\u0015297."}, {"ref": "[4] L. Tang, H. Liu, J. Zhang, and Z. Nazeri, ''Community evolution in dynamic multi-mode networks,'' in Proc. 14th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2008, pp. 677\u0015685."}, {"ref": "[5] J. B. Tenenbaum, V. de Silva, and J. C. Langford, ''A global geometric framework for nonlinear dimensionality reduction,'' Science, vol. 290, no. 5500, pp. 2319\u00152323, Dec. 2000."}, {"ref": "[6] M. Belkin and P. Niyogi, ''Laplacian eigenmaps for dimensionality reduction and data representation,'' Neural Comput., vol. 15, no. 6, pp. 1373\u00151396, 2003."}, {"ref": "[7] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei, ''Line: Large-scale information network embedding,'' in Proc. 24th Int. Conf. World Wide Web Int. World Wide Web Conf. Steering Committee, 2015, pp. 1067\u00151077."}, {"ref": "[8] D. Luo, C. H. Q. Ding, F. Nie, and H. Huang, ''Cauchy graph embedding,'' in Proc. 28th Int. Conf. Mach. Learn. (ICML), 2011, pp. 553\u0015560."}, {"ref": "[9] D. Wang, P. Cui, and W. Zhu, ''Structural deep network embedding,'' in Proc. 22nd ACMSIGKDD Int. Conf. Knowl. Discovery Data Mining, 2016, pp. 1225\u00151234."}, {"ref": "[10] A. Grover and J. Leskovec, ''Node2vec: Scalable feature learning for networks,'' in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2016, pp. 855\u0015864."}, {"ref": "[11] B. Perozzi, R. Al-Rfou, and S. Skiena, ''Deepwalk: Online learning of social representations,'' in Proc. 20th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2014, pp. 701\u0015710."}, {"ref": "[12] G. W. Taylor, G. E. Hinton, and S. T. Roweis, ''Modeling human motion using binary latent variables,'' in Proc. Adv. Neural Inf. Process. Syst., 2007, pp. 1345\u00151352."}, {"ref": "[13] D. Bahdanau, K. Cho, and Y. Bengio. (2014). ''Neural machine translation by jointly learning to align and translate.'' [Online]. Available: https://arxiv.org/abs/1409.0473"}, {"ref": "[14] I. Sutskever, O. Vinyals, and Q. V. Le, ''Sequence to sequence learning with neural networks,'' in Proc. Adv. Neural Inf. Process. Syst., 2014, pp. 3104\u00153112."}, {"ref": "[15] K. Cho et al. (2014). ''Learning phrase representations using RNN encoder-decoder for statistical machine translation.'' [Online]. Available: https://arxiv.org/abs/1406.1078"}, {"ref": "[16] (2015). Understanding LSTM Networks. [Online]. Available: http://colah.github.io/posts/2015-08-Understanding-LSTMs"}, {"ref": "[17] K. Cho, B. van Merri?nboer, D. Bahdanau, and Y. Bengio. (2014). ''On the properties of neural machine translation: Encoder-decoder approaches.'' [Online]. Available:https://arxiv.org/abs/1409.1259"}, {"ref": "[18] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio. (2014). ''Empirical evaluation of gated recurrent neural networks on sequence modeling.'' [Online]. Available: https://arxiv.org/abs/1412.3555"}, {"ref": "[19] M. D. Zeiler. (2012). ''ADADELTA: An adaptive learning rate method.'' [Online]. Available: https://arxiv.org/abs/1212.5701"}, {"ref": "[20] (Oct. 2016). Arxiv Hep-Ph Network Dataset\u0015KONECT. [Online]. Available: http://konect.uni-koblenz.de/networks/ca-cit-HepPh"}, {"ref": "[21] (Oct. 2016). Enron Network Dataset\u0015KONECT. [Online]. Available: http://konect.uni-koblenz.de/networks/enron"}, {"ref": "[22] B. Klimt and Y. Yang, ''The Enron corpus: A new dataset for email classi\u001ccation research,'' in Proc. Eur. Conf. Mach. Learn., 2004, pp. 217\u0015226."}, {"ref": "[23] (Oct. 2016). Manufacturing Emails Network Dataset\u0015KONECT. [Online]. Available: http://konect.uni-koblenz.de/networks/radoslaw_email"}, {"ref": "[24] R. Michalski, S. Palus, and P. Kazienko, ''Matching organizational structure and social network extracted from email communication,'' in Business Information Systems (Lecture Notes in Business Information Processing), vol. 87. Berlin, Germany: Springer, 2011, pp. 197\u0015206."}, {"ref": "[25] (Oct. 2016). Haggle Network Dataset\u0015KONECT. [Online]. Available: http://konect.uni-koblenz.de/networks/contact"}, {"ref": "[26] A. Chaintreau, P. Hui, J. Crowcroft, C. Diot, R. Gass, and J. Scott, ''Impact of human mobility on opportunistic forwarding algorithms,'' IEEE Trans. Mobile Comput., vol. 6, no. 6, pp. 606\u0015620, Jun. 2007."}, {"ref": "[27] L. Katz, ''A new status index derived from sociometric analysis,'' Psychometrika, vol. 18, no. 1, pp. 39\u001543, 1953."}, {"ref": "[28] P. Goyal and E. Ferrara. (2017). ''Graph embedding techniques, applications, and performance: A survey.'' [Online]. Available: https://arxiv.org/abs/1705.02801"}, {"ref": "[29] F. Pedregosa et al., ''Scikit-learn: Machine learning in Python,'' J. Mach. Learn. Res., vol. 12, pp. 2825\u00152830, Oct. 2011."}]}, {"author": ["\ufeffSrijan Kumar", "Xikun Zhang", "Jure Leskovec"], "title": "Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks", "journal": "KDD : proceedings. International Conference on Knowledge Discovery & Data Mining", "year": 2019, "DOI": "10.1145/3292500.3330895", "month": 8, "citations(google scholar)": 1, "abstract": "Modeling sequential interactions between users and items/products is crucial in domains such as e-commerce, social networking, and education. Representation learning presents an attractive opportunity to model the dynamic evolution of users and items, where each user/item can be embedded in a Euclidean space and its evolution can be modeled by an embedding trajectory in this space. However, existing dynamic embedding methods generate embeddings only when users take actions and do not explicitly model the future trajectory of the user/item in the embedding space. Here we propose JODIE, a coupled recurrent neural network model that learns the embedding trajectories of users and items. JODIE employs two recurrent neural networks to update the embedding of a user and an item at every interaction. Crucially, JODIE also models the future embedding trajectory of a user/item. To this end, it introduces a novel projection operator that learns to estimate the embedding of the user at any time in the future. These estimated embeddings are then used to predict future user-item interactions. To make the method scalable, we develop a t-Batch algorithm that creates time-consistent batches and leads to 9x faster training. We conduct six experiments to validate JODIE on two prediction tasks---future interaction prediction and state change prediction---using four real-world datasets. We show that JODIE outperforms six state-of-the-art algorithms in these tasks by at least 20% in predicting future interactions and 12% in state change prediction.", "keywords": ["Dynamic Embedding", "Temporal Interaction Networks"], "reference_count": 52, "ccfClass": "", "important": true, "references": [{"ref": "[1] Kdd cup 2015. https://biendata.com/competition/kddcup2015/data/."}, {"ref": "[2] Reddit data dump. http://files.pushshift.io/reddit/."}, {"ref": "[3] Wikipedia edit history dump. https://meta.wikimedia.org/wiki/Data_dumps."}, {"ref": "[4] D. Agrawal, C. Budak, A. El Abbadi, T. Georgiou, and X. Yan. Big data in online social networks: user interaction analysis to model user behavior in social networks. In DNIS, 2014."}, {"ref": "[5] T. Arnoux, L. Tabourier, and M. Latapy. Combining structural and dynamic information to predict activity in link streams. In ASONAM, 2017."}, {"ref": "[6] T. Arnoux, L. Tabourier, and M. Latapy. Predicting interactions between individuals with structural and dynamical information. CoRR, 2018."}, {"ref": "[7] I. M. Baytas, C. Xiao, X. Zhang, F.Wang, A. K. Jain, and J. Zhou. Patient subtyping via time-aware lstm networks. In KDD, 2017."}, {"ref": "[8] A. Beutel, P. Covington, S. Jain, C. Xu, J. Li, V. Gatto, and E. H. Chi. Latent cross: Making use of context in recurrent recommender systems. In WSDM, 2018."}, {"ref": "[9] J. Cheng, M. Bernstein, C. Danescu-Niculescu-Mizil, and J. Leskovec. Anyone can become a troll: Causes of trolling behavior in online discussions. In CSCW, 2017."}, {"ref": "[10] J. Cheng, C. Lo, and J. Leskovec. Predicting intent using activity logs: How goal specificity and temporal range affect user behavior. In WWW, 2017."}, {"ref": "[11] H. Dai, Y. Wang, R. Trivedi, and L. Song. Deep coevolutionary network: Embedding user and item features for recommendation. arXiv:1609.03675, 2016."}, {"ref": "[12] N. Du, H. Dai, R. Trivedi, U. Upadhyay, M. Gomez-Rodriguez, and L. Song. Recurrent marked temporal point processes: Embedding event history to vector. In KDD, 2016."}, {"ref": "[13] M. Farajtabar, Y. Wang, M. Gomez-Rodriguez, S. Li, H. Zha, and L. Song. COEVOLVE: A joint point process model for information diffusion and network co-evolution. In NeurIPS, 2015."}, {"ref": "[14] P. Goyal and E. Ferrara. Graph embedding techniques, applications, and performance: A survey. Knowledge Based Systems, 151:78\u201394, 2018."}, {"ref": "[15] P. Goyal, N. Kamra, X. He, and Y. Liu. Dyngem: Deep embedding method for dynamic graphs. arXiv:1805.11273, 2018."}, {"ref": "[16] A. Grover and J. Leskovec. node2vec: Scalable feature learning for networks. In KDD, 2016."}, {"ref": "[17] W. L. Hamilton, R. Ying, and J. Leskovec. Representation learning on graphs: Methods and applications. IEEE Data Engineering Bulletin, 40(3):52\u201374, 2017."}, {"ref": "[18] B. Hidasi and D. Tikk. Fast als-based tensor factorization for context-aware recommendation from implicit feedback. In ECML, 2012."}, {"ref": "[19] T. Iba, K. Nemoto, B. Peters, and P. A. Gloor. Analyzing the creative editing behavior of wikipedia editors: Through dynamic social network analysis. Procedia- Social and Behavioral Sciences, 2(4):6441\u20136456, 2010."}, {"ref": "[20] S. J. Julier and J. K. Uhlmann. New extension of the kalman filter to nonlinear systems. In Signal processing, sensor fusion, and target recognition VI, volume 3068, pages 182\u2013194, 1997."}, {"ref": "[21] R. R. Junuthula, M. Haghdan, K. S. Xu, and V. K. Devabhaktuni. The block point process model for continuous-time event-based dynamic networks. CoRR, 2017."}, {"ref": "[22] R. R. Junuthula, K. S. Xu, and V. K. Devabhaktuni. Leveraging friendship networks for dynamic link prediction in social interaction networks. In ICWSM, 2018."}, {"ref": "[23] M. Kloft, F. Stiehler, Z. Zheng, and N. Pinkwart. Predicting mooc dropout over weeks using machine learning methods. In EMNLP, 2014."}, {"ref": "[24] S. Kumar, W. L. Hamilton, J. Leskovec, and D. Jurafsky. Community interaction and conflict on the web. In The World Wide Web Conference, 2018."}, {"ref": "[25] S. Kumar, B. Hooi, D. Makhija, M. Kumar, C. Faloutsos, and V. Subrahmanian. Rev2: Fraudulent user prediction in rating platforms. In WSDM, 2018."}, {"ref": "[26] S. Kumar, F. Spezzano, and V. Subrahmanian. Vews: A wikipedia vandal early warning system. In KDD, 2015."}, {"ref": "[27] J. Leskovec, A. Rajaraman, and J. D. Ullman. Mining of massive datasets. Cambridge university press, 2014."}, {"ref": "[28] J. Li, H. Dani, X. Hu, J. Tang, Y. Chang, and H. Liu. Attributed network embedding for learning in a dynamic environment. In CIKM, 2017."}, {"ref": "[29] T. Li, J. Zhang, P. S. Yu, Y. Zhang, and Y. Yan. Deep dynamic network embedding for link prediction. IEEE Access, 6:29219\u201329230, 2018."}, {"ref": "[30] X. Li, N. Du, H. Li, K. Li, J. Gao, and A. Zhang. A deep learning approach to link prediction in dynamic networks. In SDM, 2014."}, {"ref": "[31] T. R. Liyanagunawardena, A. A. Adams, and S. A. Williams. Moocs: A systematic study of the published literature 2008-2012. The International Review of Research in Open and Distributed Learning, 14(3):202\u2013227, 2013."}, {"ref": "[32] Y. Ma, Z. Guo, Z. Ren, Y. E. Zhao, J. Tang, and D. Yin. Dynamic graph neural networks. CoRR, abs/1810.10627, 2018."}, {"ref": "[33] G. H. Nguyen, J. B. Lee, R. A. Rossi, N. K. Ahmed, E. Koh, and S. Kim. Continuoustime dynamic network embeddings. In WWW BigNet workshop, 2018."}, {"ref": "[34] R. P\u00e1lovics, A. A. Bencz\u00far, L. Kocsis, T. Kiss, and E. Frig\u00f3. Exploiting temporal influence in online recommendation. In RecSys, 2014."}, {"ref": "[35] J. W. Pennebaker, M. E. Francis, and R. J. Booth. Linguistic inquiry and word count: Liwc 2001. Mahway: Lawrence Erlbaum Associates, 71(2001):2001, 2001."}, {"ref": "[36] J. Qiu, Y. Dong, H. Ma, J. Li, K. Wang, and J. Tang. Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec. In WSDM, 2018."}, {"ref": "[37] V. Raghavan, G. Ver Steeg, A. Galstyan, and A. G. Tartakovsky. Modeling temporal activity patterns in dynamic social networks. IEEE TCSS, 1(1):89\u2013107, 2014."}, {"ref": "[38] M. Rahman, T. K. Saha, M. A. Hasan, K. S. Xu, and C. K. Reddy. Dylink2vec: Effective feature representation for link prediction in dynamic networks. CoRR, 2018."}, {"ref": "[39] S. Sajadmanesh, J. Zhang, and H. R. Rabiee. Continuous-time relationship prediction in dynamic heterogeneous information networks. CoRR, 2017."}, {"ref": "[40] S. Sedhain, S. Sanner, L. Xie, R. Kidd, K. Tran, and P. Christen. Social affinity filtering: recommendation through fine-grained analysis of user interactions and activities. In COSN, 2013."}, {"ref": "[41] R. Trivedi, H. Dai, Y. Wang, and L. Song. Know-evolve: Deep temporal reasoning for dynamic knowledge graphs. In ICML, 2017."}, {"ref": "[42] R. Trivedi, M. Farajtbar, P. Biswal, and H. Zha. Representation learning over dynamic graphs. arXiv:1803.04051, 2018."}, {"ref": "[43] P. B. Walker, S. G. Fooshee, and I. Davidson. Complex interactions in social and event network analysis. In SBP-BRiMS, 2015."}, {"ref": "[44] Y. Wang, N. Du, R. Trivedi, and L. Song. Coevolutionary latent feature processes for continuous-time user-item interactions. In NeurIPS, 2016."}, {"ref": "[45] C.-Y. Wu, A. Ahmed, A. Beutel, A. J. Smola, and H. Jing. Recurrent recommender networks. In WSDM, 2017."}, {"ref": "[46] D. Yang, T. Sinha, D. Adamson, and C. P. Ros\u00e9. Turn on, tune in, drop out: Anticipating student dropouts in massive open online courses. In NeurIPS Datadriven education workshop, 2013."}, {"ref": "[47] J. You, Y. Wang, A. Pal, P. Eksombatchai, C. Rosenburg, and J. Leskovec. Hierarchical temporal convolutional networks for dynamic recommender systems. In The World Wide Web Conference, 2019."}, {"ref": "[48] S. Zhang, L. Yao, and A. Sun. Deep learning based recommender system: A survey and new perspectives. arXiv:1707.07435, 2017."}, {"ref": "[49] Y. Zhang, Y. Xiong, X. Kong, and Y. Zhu. Learning node embeddings in interaction graphs. In CIKM, 2017."}, {"ref": "[50] L.-k. Zhou, Y. Yang, X. Ren, F. Wu, and Y. Zhuang. Dynamic network embedding by modeling triadic closure process. In AAAI, 2018."}, {"ref": "[51] L. Zhu, D. Guo, J. Yin, G. Ver Steeg, and A. Galstyan. Scalable temporal latent space inference for link prediction in dynamic social networks. IEEE TKDE, 28(10):2765\u20132777, 2016."}, {"ref": "[52] Y. Zhu, H. Li, Y. Liao, B. Wang, Z. Guan, H. Liu, and D. Cai. What to do next: modeling user behaviors by time-lstm. In IJCAI, 2017."}]}, {"author": ["\ufeffJundong Li", "Kewei Cheng", "Liang Wu", "Huan Liu"], "title": "Streaming Link Prediction on Dynamic Attributed Networks", "journal": "WSDM", "year": 2018, "DOI": "10.1145/3159652.3159674", "month": 2, "citations(google scholar)": 17, "abstract": "Link prediction targets to predict the future node interactions mainly based on the current network snapshot. It is a key step in understanding the formation and evolution of the underlying networks; and has practical implications in many real-world applications, ranging from friendship recommendation, click through prediction to targeted advertising. Most existing efforts are devoted to plain networks and assume the availability of network structure in memory before link prediction takes place. However, this assumption is untenable as many real-world networks are affiliated with rich node attributes, and often, the network structure and node attributes are both dynamically evolving at an unprecedented rate. Even though recent studies show that node attributes have an added value to network structure for accurate link prediction, it still remains a daunting task to support link prediction in an online fashion on such dynamic attributed networks. As changes in the dynamic attributed networks are often transient and can be endless, link prediction algorithms need to be efficient by making only one pass of the data with limited memory overhead. To tackle these challenges, we study a novel problem of streaming link prediction on dynamic attributed networks and present a novel framework - SLIDE. Methodologically, SLIDE maintains and updates a low-rank sketching matrix to summarize all observed data, and we further leverage the sketching matrix to infer missing links on the fly. The whole procedure is theoretically guaranteed, and empirical experiments on real-world dynamic attributed networks validate the effectiveness and efficiency of the proposed framework.", "keywords": ["Dynamic Attributed Networks\uff0cLink Prediction"], "reference_count": 57, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Charu Aggarwal and Karthik Subbian. 2014. Evolutionary network analysis: A survey. CSUR (2014)."}, {"ref": "[2] Charu C Aggarwal. 2011. On Classification of Graph Streams. In SDM."}, {"ref": "[3] Charu C Aggarwal, Yuchen Zhao, and S Yu Philip. 2011. Outlier Detection in Graph Streams. In ICDE."}, {"ref": "[4] Charu C Aggarwal, Yuchen Zhao, and Philip S Yu. 2010. On Clustering Graph Streams. In SDM."}, {"ref": "[5] Mohammad Al Hasan and Mohammed J Zaki. 2011. A Survey of Link Prediction in Social Networks. In Social Network Data Analytics."}, {"ref": "[6] Lars Backstrom and Jure Leskovec. 2011. Supervised Random Walks: Predicting and Recommending Links in Social Networks. In WSDM."}, {"ref": "[7] Nicola Barbieri, Francesco Bonchi, and Giuseppe Manco. 2014. Who to Follow and Why: Link Prediction with Explanations. In KDD."}, {"ref": "[8] Shiyu Chang, Guo-Jun Qi, Charu C Aggarwal, Jiayu Zhou, Meng Wang, and Thomas S Huang. 2014. Factorized Similarity Learning in Networks. In ICDM."}, {"ref": "[9] Shiyu Chang, Yang Zhang, Jiliang Tang, Dawei Yin, Yi Chang, Mark A Hasegawa- Johnson, and Thomas S Huang. 2016. Positive-Unlabeled Learning in Streaming Networks. In KDD."}, {"ref": "[10] Chen Chen and Hanghang Tong. 2015. Fast Eigen-Functions Tracking on Dynamic Graphs. In SDM."}, {"ref": "[11] Chen Chen, Hanghang Tong, Lei Xie, Lei Ying, and Qing He. 2016. FASCINATE: Fast Cross-Layer Dependency Inference on Multi-Layered Networks. In KDD."}, {"ref": "[12] Lorenzo De Stefani, Alessandro Epasto, Matteo Riondato, and Eli Upfal. 2016. TRI\u00e8ST: Counting Local and Global Triangles in Fully-Dynamic Streams with Fixed Memory Size. In KDD."}, {"ref": "[13] Liang Duan, Charu Aggarwal, Shuai Ma, Renjun Hu, and Jinpeng Huai. 2016. Scaling up Link Prediction with Ensembles. In WSDM."}, {"ref": "[14] Daniel M Dunlavy, Tamara G Kolda, and Evrim Acar. 2011. Temporal Link Prediction using Matrix and Tensor Factorizations. TKDD (2011)."}, {"ref": "[15] Joan Feigenbaum, Sampath Kannan, Andrew McGregor, Siddharth Suri, and Jian Zhang. 2005. On Graph Problems in a Semi-Streaming Model. TCS (2005)."}, {"ref": "[16] Huiji Gao, Xufei Wang, Jiliang Tang, and Huan Liu. 2013. Network Denoising in Social Media. In ASONAM."}, {"ref": "[17] Lise Getoor and Christopher P Diehl. 2005. Link Mining: A Survey. SIGKDD Explorations (2005)."}, {"ref": "[18] Mina Ghashami, Amey Desai, and JeffMPhillips. 2014. Improved Practical Matrix Sketching with Guarantees. In ESA."}, {"ref": "[19] Mina Ghashami and Jeff M Phillips. 2014. Relative Errors for Deterministic Low-Rank Matrix Approximations. In SODA."}, {"ref": "[20] Neil Zhenqiang Gong, Ameet Talwalkar, Lester Mackey, Ling Huang, Eui Chul Richard Shin, Emil Stefanov, Elaine Runting Shi, and Dawn Song. 2014. Joint Link Prediction and Attribute Inference using a Social-Attribute Network. TIST (2014)."}, {"ref": "[21] Ting Guo, Lianhua Chi, and Xingquan Zhu. 2013. Graph Hashing and Factorization for Fast Graph Stream Classification. In CIKM."}, {"ref": "[22] Chin-Chi Hsu, Yi-An Lai, Wen-Hao Chen, Ming-Han Feng, and Shou-De Lin. 2017. Unsupervised Ranking using Graph Structures and Node Attributes. In WSDM."}, {"ref": "[23] Hao Huang and Shiva Prasad Kasiviswanathan. 2015. Streaming Anomaly Detection Using Randomized Matrix Sketching. VLDB (2015)."}, {"ref": "[24] Hao Huang, Shinjae Yoo, and Shiva Prasad Kasiviswanathan. 2015. Unsupervised Feature Selection on Data Streams. In CIKM."}, {"ref": "[25] Ling Jian, Jundong Li, and Huan Liu. 2017. Toward Online Node Classification on Streaming Networks. DMKD (2017)."}, {"ref": "[26] Takuya Kitazawa. 2017. Sketching Dynamic User-Item Interactions for Online Item Recommendation. In CHIIR."}, {"ref": "[27] J\u00e9r?me Kunegis and Andreas Lommatzsch. 2009. Learning Spectral Graph Transformations for Link Prediction. In ICML."}, {"ref": "[28] Timothy La Fond and Jennifer Neville. 2010. Randomization Tests for Distinguishing Social Influence and Homophily Effects. In WWW."}, {"ref": "[29] Jundong Li, Harsh Dani, Xia Hu, and Huan Liu. 2017. Radar: Residual Analysis for Anomaly Detection in Attributed Networks. IJCAI (2017)."}, {"ref": "[30] Jundong Li, Harsh Dani, Xia Hu, Jiliang Tang, Yi Chang, and Huan Liu. 2017. Attributed Network Embedding for Learning in a Dynamic Environment. In CIKM."}, {"ref": "[31] Jundong Li, Xia Hu, Ling Jian, and Huan Liu. 2016. Toward Time-Evolving Feature Selection on Dynamic Networks. In ICDM."}, {"ref": "[32] Jundong Li, Xia Hu, LiangWu, and Huan Liu. 2016. Robust Unsupervised Feature Selection on Networked Data. In SDM."}, {"ref": "[33] Jundong Li, Jiliang Tang, Yilin Wang, Yali Wan, Yi Chang, and Huan Liu. 2017. Understanding and Predicting Delay in Reciprocal Relations. arXiv preprint arXiv:1703.01393 (2017)."}, {"ref": "[34] Jundong Li, LiangWu, Osmar R Za?ane, and Huan Liu. 2017. Toward Personalized Relational Learning. In SDM."}, {"ref": "[35] Lihong Li, Wei Chu, John Langford, and Robert E Schapire. 2010. A Contextual- Bandit Approach to Personalized News Article Recommendation. In WWW."}, {"ref": "[36] Yanen Li, Jia Hu, ChengXiang Zhai, and Ye Chen. 2010. Improving One-Class Collaborative Filtering by Incorporating Rich User Information. In CIKM."}, {"ref": "[37] David Liben-Nowell and Jon Kleinberg. 2007. The Link Prediction Problem for Social Networks. JASIST (2007)."}, {"ref": "[38] Edo Liberty. 2013. Simple and Deterministic Matrix Sketching. In KDD."}, {"ref": "[39] Ryan N Lichtenwalter, Jake T Lussier, and Nitesh V Chawla. 2010. New Perspectives and Methods in Link Prediction. In KDD."}, {"ref": "[40] Chih-Jen Lin. 2007. Projected Gradient Methods for Nonnegative Matrix Factorization. Neural Computation (2007)."}, {"ref": "[41] Andrew McGregor. 2005. Finding Graph Matchings in Data Streams. In APPROXRANDOM."}, {"ref": "[42] Andrew McGregor. 2014. Graph Stream Algorithms: A Survey. ACM SIGMOD Record (2014)."}, {"ref": "[43] Miller McPherson, Lynn Smith-Lovin, and JamesMCook. 2001. Birds of a Feather: Homophily in Social Networks. Annual Review of Sociology (2001)."}, {"ref": "[44] Aditya Menon and Charles Elkan. 2011. Link Prediction via Matrix Factorization. ECMLPKDD (2011)."}, {"ref": "[45] Rong Pan, Yunhong Zhou, Bin Cao, Nathan N Liu, Rajan Lukose, Martin Scholz, and Qiang Yang. 2008. One-class Collaborative Filtering. In ICDM."}, {"ref": "[46] Steffen Rendle. 2010. Factorization Machines. In ICDM."}, {"ref": "[47] Gilbert W Stewart. 1990. Matrix Perturbation Theory. (1990)."}, {"ref": "[48] Yizhou Sun, Jiawei Han, Charu C Aggarwal, and Nitesh V Chawla. 2012. When Will It Happen?: Relationship Prediction in Heterogeneous Information Networks. In WWW."}, {"ref": "[49] Hanghang Tong, Christos Faloutsos, and Jia-yu Pan. 2006. Fast Random Walk with Restart and Its Applications. In ICDM."}, {"ref": "[50] Alexey Tsymbal. 2004. The Problem of Concept Drift: Definitions and Related Work. Computer Science Department, Trinity College Dublin (2004)."}, {"ref": "[51] Xiaokai Wei, Linchuan Xu, Bokai Cao, and Philip S Yu. 2017. Cross View Link Prediction by Learning Noise-resilient Representation Consensus. In WWW."}, {"ref": "[52] Qingyun Wu, Huazheng Wang, Quanquan Gu, and Hongning Wang. 2016. Contextual Bandits in A Collaborative Environment. In SIGIR."}, {"ref": "[53] Zhijun Yin, Manish Gupta, Tim Weninger, and Jiawei Han. 2010. A Unified Framework for Link Recommendation Using Random Walks. In ASONAM."}, {"ref": "[54] Peixiang Zhao, Charu Aggarwal, and Gewen He. 2016. Link Prediction in Graph Streams. In ICDE."}, {"ref": "[55] Tong Zhao, H Vicky Zhao, and Irwin King. 2015. Exploiting Game Theoretic Analysis for Link Recommendation in Social Networks. In CIKM."}, {"ref": "[56] Yuchen Zhao and Philip S Yu. 2013. On Graph Stream Clustering with Side Information. In SDM."}, {"ref": "[57] Linhong Zhu, Dong Guo, Junming Yin, Greg Ver Steeg, and Aram Galstyan. 2016. Scalable Temporal Latent Space Inference for Link Prediction in Dynamic Social Networks. TKDE (2016)."}]}, {"author": ["\ufeffTaisong Li", "Bing Wang", "Yasong Jiang", "Yan Zhang", "Yonghong Yan"], "title": "Restricted Boltzmann Machine-Based Approaches for Link Prediction in Dynamic Networks", "journal": "IEEE Access", "year": 2018, "DOI": "10.1109/access.2018.2840054", "month": 5, "citations(google scholar)": 3, "abstract": "Link prediction in dynamic networks aims to predict edges according to historical linkage status. It is inherently difficult because of the linear/non-linear transformation of underlying structures. The problem of efficiently performing dynamic link inference is extremely challenging due to the scale of networks and different evolving patterns. Most previous approaches for link prediction are based on members\u2019 similarity and supervised learning methods. However, research work on investigating hidden patterns of dynamic social networks is rarely conducted. In this paper, we propose a novel framework that incorporates a deep learning method, i.e., temporal restricted Boltzmann machine, and a machine learning approach, i.e., gradient boosting decision tree. The proposed model is capable of modeling each link\u2019s evolving patterns. We also propose a novel transformation for input matrix, which significantly reduces the computational complexity and makes our algorithm scalable to large networks. Extensive experiments demonstrate that the proposed method outperforms the existing state-of-the-art algorithms on real-world dynamic networks.", "keywords": ["Link prediction", "social network analysis", "deep learning"], "reference_count": 38, "ccfClass": "", "important": true, "references": [{"ref": "[1] D. Liben-Nowell J. Kleinberg \"The link-prediction problem for social networks\" J. Amer. Soc. Inf. Sci. Technol. vol. 58 pp. 1019-1031 2007."}, {"ref": "[2] P. Wang B. Xu Y. Wu X. Zhou \"Link prediction in social networks: The state-of-the-art\" Sci. China Inf. Sci. vol. 58 no. 1 pp. 1-38 2015."}, {"ref": "[3] M. E. J. Newman \"Clustering and preferential attachment in growing networks\" Phys. Rev. E Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top. vol. 64 no. 2 pp. 025102 2001."}, {"ref": "[4] L. Katz \"A new status index derived from sociometric analysis\" Psychometrika vol. 18 no. 1 pp. 39-43 1953."}, {"ref": "[5] A.-L. Barab\u00e1si H. Jeong Z. N\u00e9da E. Ravasz A. Schubert T. Vicsek \"Evolution of the social network of scientific collaborations\" Phys. A Stat. Mech. Appl. vol. 311 no. 3 pp. 590-614 2002."}, {"ref": "[6] Y. Sun J. Han C. C. Aggarwal N. V. Chawla \"When will it happen?: Relationship prediction in heterogeneous information networks\" Proc. 5th ACM Int. Conf. Web Search Data Mining pp. 663-672 2012."}, {"ref": "[7] Z. Lu B. Savas W. Tang I. S. Dhillon \"Supervised link prediction using multiple sources\" Proc. IEEE 10th Int. Conf. Data Mining (ICDM) pp. 923-928 Dec. 2010."}, {"ref": "[8] M. Rowe M. Stankovic H. Alani \"Who will follow whom? Exploiting semantics for link prediction in attention-information networks\" Proc. Int. Semantic Web Conf. pp. 476-491 2012."}, {"ref": "[9] F. Liu B. Liu C. Sun M. Liu X. Wang \"Deep learning approaches for link prediction in social network services\" Proc. Int. Conf. Neural Inf. Process. pp. 425-432 2013."}, {"ref": "[10] X. Li N. Du H. Li K. Li J. Gao A. Zhang \"A deep learning approach to link prediction in dynamic networks\" Proc. SIAM Int. Conf. Data Mining pp. 289-297 2013."}, {"ref": "[11] A. Clauset C. Moore M. E. Newman \"Hierarchical structure and the prediction of missing links in networks\" Nature vol. 453 no. 7191 pp. 98-101 2008."}, {"ref": "[12] R. Guimer\u00e0 M. Sales-Pardo \"Missing and spurious interactions and the reconstruction of complex networks\" Proc. Nat. Acad. Sci. USA vol. 106 no. 52 pp. 22073-22078 2009."}, {"ref": "[13] C. Wang V. Satuluri S. Parthasarathy \"Local probabilistic models for link prediction\" Proc. 7th IEEE Int. Conf. Data Mining (ICDM) pp. 322-331 Oct. 2007."}, {"ref": "[14] N. M. Ahmed L. Chen \"An efficient algorithm for link prediction in temporal uncertain social networks\" Inf. Sci. vol. 331 pp. 120-136 Apr. 2016."}, {"ref": "[15] C. A. Bliss M. R. Frank C. M. Danforth P. S. Dodds \"An evolutionary algorithm approach to link prediction in dynamic social networks\" J. Comput. Sci. vol. 5 no. 5 pp. 750-764 2014."}, {"ref": "[16] L. Zhu D. Guo J. Yin G. Ver Steeg A. Galstyan \"Scalable temporal latent space inference for link prediction in dynamic social networks\" IEEE Trans. Knowl. Data Eng. vol. 28 no. 10 pp. 2765-2777 Oct. 2016."}, {"ref": "[17] M. W. Berry M. Browne A. N. Langville V. P. Pauca R. J. Plemmons \"Algorithms and applications for approximate nonnegative matrix factorization\" Comput. Statist. Data Anal. vol. 52 no. 1 pp. 155-173 2007."}, {"ref": "[18] P. Tseng S. Yun \"A coordinate gradient descent method for nonsmooth separable minimization\" Math. Program. vol. 117 no. 1 pp. 387-423 2009."}, {"ref": "[19] G. E. Hinton R. R. Salakhutdinov \"Reducing the dimensionality of data with neural networks\" Science vol. 313 no. 5786 pp. 504-507 2006."}, {"ref": "[20] G. E. Hinton \"Training products of experts by minimizing contrastive divergence\" Neural Comput. vol. 14 no. 8 pp. 1771-1800 2002."}, {"ref": "[21] G. W. Taylor G. E. Hinton S. T. Roweis \"Modeling human motion using binary latent variables\" Proc. Adv. Neural Inf. Process. Syst. pp. 1345-1352 2006."}, {"ref": "[22] T. Li J. Wang M. Tu Y. Zhang Y. Yan \"Enhancing link prediction using gradient boosting features\" Proc. Int. Conf. Intell. Comput. pp. 81-92 2016."}, {"ref": "[23] C. D. Manning P. Raghavan H. Sch\u00fctze Introduction to Information Retrieval Cambridge U.K.:Cambridge Univ. Press vol. 1 pp. 496 2008."}, {"ref": "[24] L. A. Adamic E. Adar \"Friends and neighbors on the Web\" Soc. Netw. vol. 25 no. 3 pp. 211-230 2003."}, {"ref": "[25] T. Zhou L. L\u00fc Y.-C. Zhang \"Predicting missing links via local information\" Eur. Phys. J. B vol. 71 no. 4 pp. 623-630 2009."}, {"ref": "[26] E. A. Leicht P. Holme M. E. J. Newman \"Vertex similarity in networks\" Phys. Rev. E Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top. vol. 73 no. 2 pp. 026120 2006."}, {"ref": "[27] J. H. Friedman \"Greedy function approximation: A gradient boosting machine\" Ann. Statist. vol. 29 no. 5 pp. 1189-1232 2001."}, {"ref": "[28] T. K. Ho \"Random decision forests\" Proc. 3rd Int. Conf. Document Anal. Recognit. vol. 1 pp. 278-282 Aug. 1995."}, {"ref": "[29] D. Yin L. Hong B. D. Davison \"Structural link analysis and prediction in microblogs\" Proc. 20th ACM Int. Conf. Inf. Knowl. Manage. pp. 1163-1168 2011."}, {"ref": "[30] Arxiv Hep-Ph Network Dataset\u2014KONECT Oct. 2016 [online] Available: http://konect.uni-koblenz.de/networks/ca-cit-HepPh."}, {"ref": "[31] J. Leskovec J. Kleinberg C. Faloutsos \"Graph evolution: Densification and shrinking diameters\" ACM Trans. Knowl. Discovery Data vol. 1 no. 1 2007."}, {"ref": "[32] Enron Network Dataset\u2014KONECT Oct. 2016 [online] Available: http://konect.uni-koblenz.de/networks/enron."}, {"ref": "[33] B. Klimt Y. Yang \"The enron corpus: A new dataset for email classification research\" Proc. Eur. Conf. Mach. Learn. pp. 217-226 2004."}, {"ref": "[34] Manufacturing Emails Network Dataset\u2014KONECT Oct. 2016 [online] Available: http://konect.uni-koblenz.de/networks/radoslaw_email."}, {"ref": "[35] R. Michalski S. Palus P. Kazienko \"Matching organizational structure and social network extracted from email communication\" Proc. Int. Conf. Bus. Inf. Syst. vol. 87 pp. 197-206 2011."}, {"ref": "[36] Haggle Network Dataset\u2014KONECT Oct. 2016 [online] Available: http://konect.uni-koblenz.de/networks/contact."}, {"ref": "[37] A. Chaintreau P. Hui J. Crowcroft C. Diot R. Gass J. Scott \"Impact of human mobility on opportunistic forwarding algorithms\" IEEE Trans. Mobile Comput. vol. 6 no. 6 pp. 606-620 Jun. 2007."}, {"ref": "[38] H. R. De S\u00e1 R. B. Prud\u00eancio \"Supervised link prediction in weighted networks\" Proc. Int. Joint Conf. Neural Netw. (IJCNN) pp. 2281-2288 Jul./Aug. 2011."}]}, {"author": ["\ufeffYujing Zhou", "Weile Liu", "Yang Pei", "Lei Wang", "Daren Zha", "Tianshu Fu"], "title": "Dynamic Network Embedding by Semantic Evolution", "journal": "2019 International Joint Conference on Neural Networks (IJCNN)", "year": 2019, "DOI": "10.1109/IJCNN.2019.8852247", "month": 7, "citations(google scholar)": 27, "abstract": "Network embedding, which aims to learn the low-dimensional representations of nodes, has attracted increasing attention in various fields such as social networks, paper citation networks and knowledge graphs. At present, most of the network embedding works are based on static networks, that is, the evolution of networks over time is not taken into account. It is more realistic to consider temporal information in network embedding and it could also make the embedding get more abundant information. In this paper, we propose a dynamic network embedding model DynSEM with semantic evolution, to train node embeddings in a sequence of networks over time. The advantage of our method is that it presents an effective inheritance of historical information. Our method uses nonrandom initialization and orthogonal procrustes method to align the node embeddings into common space which makes node embedding able to inheritance information. In particular, in the common space, we train a model to capture the dynamics information of the networks and smooth temporal node embeddings. We evaluate our method comparing it with other methods on three real-world datasets. The experimental results prove the effectiveness of dynamic network embeddings generated by DynSEM model.", "keywords": ["Dynamic Network", "Semantic Evolution", "Nonrandom Initialization", "Network Embedding"], "reference_count": 34, "ccfClass": "C", "important": true, "references": [{"ref": "[1] Le-kui Zhou Yang Yang Xiang Ren Fei Wu Yueting Zhuang Dynamic Network Embedding by Modeling Triadic Closure Process AAAI pp. 571-578 2018."}, {"ref": "[2] B Perozzi R Alrfou S Skiena DeepWalk: online learning of social representations[J] pp. 701-710 2014."}, {"ref": "[3] A Grover J Leskovec node2vec: Scalable Feature Learning for Networks[J] vol. 2016 pp. 855-864 2016."}, {"ref": "[4] D Wang P Cui W Zhu \"Structural Deep Network Embedding[C]\" Acm Sigkdd International Conference on Knowledge Discovery &amp; Data Mining 2016."}, {"ref": "[5] Li J Dani H Hu X et al. \"Attributed network embedding for learning in a dynamic environment[C]\" Proceedings of the 2017 ACM on Conference on Information and Knowledge Management pp. 387-396 2017."}, {"ref": "[6] D Zhu P Cui Z Zhang et al. \"High-order Proximity Preserved Embedding For Dynamic Networks[J]\" IEEE Transactions on Knowledge &amp; Data Engineering vol. PP no. 99 pp. 1-1 2018."}, {"ref": "[7] Lun Du et al. Dynamic Network Embedding: An Extended Approach for Skip-gram based Network Embedding IJCAI 2018."}, {"ref": "[8] P Goyal N Kamra X He et al. \"DynGEM: Deep Embedding Method for Dynamic Graphs[J]\" arXiv preprint arXiv:1805.11273 2018."}, {"ref": "[9] Palash Goyal Sujit Rokka Chhetri Arquimedes Canedo \"dyngraph2vec: Capturing Network Dynamics using Dynamic Graph Representation Learning\" arXiv preprint arXiv:1809.02657 2018."}, {"ref": "[10] GD Rosin K Radinsky E Adar Learning Word Relatedness over Time[J] 2017."}, {"ref": "[11] Z Yao Y Sun W Ding et al. Dynamic Word Embeddings for Evolving Semantic Discovery[J] 2017."}, {"ref": "[12] R Bamler S Mandt Dynamic Word Embeddings[J] 2017."}, {"ref": "[13] Y Bengio JS Senecal \"Adaptive importance sampling to accelerate training of a neural probabilistic language model.[J]\" IEEE Transactions on Neural Networks vol. 19 no. 4 pp. 713 2008."}, {"ref": "[14] Mikolov T Chen K Corrado G et al. \"Efficient Estimation of Word Representations in Vector Space[J]\" Computer Science 2013."}, {"ref": "[15] J Pennington R Socher C Manning \"Glove: Global Vectors for Word Representation[C]\" Conference on Empirical Methods in Natural Language Processing pp. 1532-1543 2014."}, {"ref": "[16] O Levy Y Goldberg \"Neural word embedding as implicit matrix factorization[J]\" Advances in Neural Information Processing Systems vol. 3 pp. 2177-2185 2014."}, {"ref": "[17] S.T. Roweis \"Nonlinear Dimensionality Reduction by Locally Linear Embedding[J]\" Science vol. 290 no. 5500 pp. 2323-2326 2000."}, {"ref": "[18] M Belkin P Niyogi TG Dietterich et al. \"Laplacian eigenmaps and spectral techniques for embedding and clustering.[J]\" Advances in Neural Information Processing Systems vol. 14 no. 6 pp. 585-591 2001."}, {"ref": "[19] L Tang H Liu \"Leveraging social media networks for classification[J]\" Data Mining and Knowledge Discovery vol. 23 no. 3 pp. 447-478 2011."}, {"ref": "[20] T Chen Q Yang X Tang et al. \"Directed graph embedding[C]\" International Joint Conference on Artifical Intelligence 2007."}, {"ref": "[21] L Tang H Liu \"Relational learning via latent social dimensions[C]\" Acm Sigkdd International Conference on Knowledge Discovery &amp; Data Mining. DBLP 2009."}, {"ref": "[22] Zhang M Tang J Qu M et al. LINE: Large-scale Information Network Embedding[J] vol. 2 no. 2 pp. 1067-1077 2015."}, {"ref": "[23] D Wang P Cui W Zhu \"Structural Deep Network Embedding[C]\" ACM SIGKDD International Conference on Knowledge Discovery and Data Mining pp. 2016-1234."}, {"ref": "[24] C Yang Z Liu D Zhao et al. \"Network Representation Learning with Rich Text Information[C]\" International Conference on Artificial Intelligence 2015."}, {"ref": "[25] CC Tu WC Zhang ZY Liu et al. \"Max-Margin DeepWalk: discriminative learning of network representation\" Proceedings of International Joint Conference on Artificial Intelligence (IJCAI) 2016."}, {"ref": "[26] S Cao W Lu Q Xu \"GraRep: Learning Graph Representations with Global Structural Information[C]\" Acm International on Conference on Information &amp; Knowledge Management 2015."}, {"ref": "[27] V Kulkarni R Alrfou B Perozzi et al. Statistically Significant Detection of Linguistic Change[J] 2014."}, {"ref": "[28] Terrence Szymanski \"Temporal Word Analogies: Identifying Lexical Replacement with Diachronic Word Embeddings\" ACL no. 2 pp. 448-453 2017."}, {"ref": "[29] M Rudolph D Blei Dynamic Bernoulli Embeddings for Language Evolution[J] 2017."}, {"ref": "[30] T Mikolov I Sutskever K Chen et al. \"Distributed Representations of Words and Phrases and their Compositionality[J]\" Advances in Neural Information Processing Systems vol. 26 pp. 3111-3119 2013."}, {"ref": "[31] Y Kim Y Chiu K Hanaki et al. \"Temporal Analysis of Language through Neural Language Models[J]\" Computer Science vol. 6 no. 3 pp. 153-178 2014."}, {"ref": "[32] LVD Maaten G Hinton \"Visualizing Data using t-SNE[J]\" Journal of Machine Learning Research vol. 9 no. 2605 pp. 2579-2605 2008."}, {"ref": "[33] L Zhu D Guo J Yin et al. \"Scalable Temporal Latent Space Inference for Link Prediction in Dynamic Social Networks[J]\" IEEE Transactions on Knowledge &amp; Data Engineering vol. 28 no. 10 pp. 2765-2777 2016."}, {"ref": "[34] J Tang J Zhang L Yao et al. \"ArnetMiner: extraction and mining of academic social networks[C]\" Acm Sigkdd International Conference on Knowledge Discovery &amp; Data Mining. DBLP 2008."}]}, {"author": ["\ufeffJianxin Ma", "Peng Cui", "Wenwu Zhu"], "title": "DepthLGP: Learning Embeddings of Out-of-Sample Nodes in Dynamic Networks", "journal": "AAAI", "year": 2018, "DOI": "CannotFind", "month": 2, "citations(google scholar)": 29, "abstract": "Network embedding algorithms to date are primarily designed for static networks, where all nodes are known before learning. How to infer embeddings for out-of-sample nodes, i.e. nodes that arrive after learning, remains an open problem. The problem poses great challenges to existing methods, since the inferred embeddings should preserve intricate network properties such as high-order proximity, share similar characteristics (i.e. be of a homogeneous space) with in-sample node embeddings, and be of low computational cost. To overcome these challenges, we propose a Deeply Transformed High-order Laplacian Gaussian Process (DepthLGP) method to infer embeddings for out-of-sample nodes. DepthLGP combines the strength of nonparametric probabilistic modeling and deep learning. In particular, we design a high-order Laplacian Gaussian process (hLGP) to encode network properties, which permits fast and scalable inference. In order to further ensure homogeneity, we then employ a deep neural network to learn a nonlinear transformation from latent states of the hLGP to node embeddings. DepthLGP is general, in that it is applicable to embeddings learned by any network embedding algorithms. We theoretically prove the expressive power of DepthLGP, and conduct extensive experiments on real-world networks. Empirical results demonstrate that our approach can achieve significant performance gain over existing approaches.", "keywords": ["None"], "reference_count": 40, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Belkin, M.; Niyogi, P.; and Sindhwani, V. 2006. Manifold regularization: A geometric framework for learning from labeled and unlabeled examples. JMLR."}, {"ref": "[2] Breitkreutz, B.-J.; Stark, C.; Reguly, T.; Boucher, L.; Breitkreutz, A.; Livstone, M.; Oughtred, R.; Lackner, D. H.;"}, {"ref": "[3] Bhler, J.; Wood, V.; Dolinski, K.; and Tyers, M. 2008. The biogrid interaction database: 2008 update. Nucleic Acids Research."}, {"ref": "[4] Cao, S.; Lu, W.; and Xu, Q. 2015. Grarep: Learning graph representations with global structural information. In Proceedings of CIKM 2015."}, {"ref": "[5] Chapelle, O.; Schlkopf, B.; and Zien, A. 2010. SemiSupervised Learning. The MIT Press."}, {"ref": "[6] Chen, L.; Tsang, I. W.; and Xu, D. 2012. Laplacian embedded regression for scalable manifold regularization. IEEE Transactions on Neural Networks and Learning Systems."}, {"ref": "[7] Chu, W.; Sindhwani, V.; Ghahramani, Z.; and Keerthi, S. S. 2006. Relational learning with gaussian processes. In Proceedings of NIPS 2006."}, {"ref": "[8] Cybenko, G. 1989. Approximation by superpositions of a sigmoidal function. Mathematics of Control, Signals and Systems."}, {"ref": "[9] Delalleau, O.; Bengio, Y.; and Roux, N. L. 2005. Efficient non-parametric function induction in semi-supervised learning. In Proceedings of AISTATS 2005."}, {"ref": "[10] Dong, Y.; Chawla, N. V.; and Swami, A. 2017. Metapath2vec: Scalable representation learning for heterogeneous networks. In Proceedings of KDD 2017."}, {"ref": "[11] Dreyfus, S. 1962. The numerical solution of variational problems. Journal of Mathematical Analysis and Applications."}, {"ref": "[12] Grover, A., and Leskovec, J. 2016. Node2vec: Scalable feature learning for networks. In Proceedings of KDD 2016."}, {"ref": "[13] He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep residual learning for image recognition. In Proceedings of CVPR 2016."}, {"ref": "[14] Hornik, K. 1991. Approximation capabilities of multilayer feedforward networks. Neural Networks."}, {"ref": "[15] Joachims, T. 2003. Transductive learning via spectral graph partitioning. In Proceedings of ICML 2003."}, {"ref": "[16] Karlen, M.; Weston, J.; Erkan, A.; and Collobert, R. 2008. Large scale manifold transduction. In Proceedings of ICML 2008."}, {"ref": "[17] Kingma, D., and Ba, J. 2015. Adam: A method for stochastic optimization. In Proceedings of ICLR 2015."}, {"ref": "[18] Ou, M.; Cui, P.; Wang, F.; Wang, J.; and Zhu, W. 2015. Non-transitive hashing with latent similarity components. In Proceedings of KDD 2015."}, {"ref": "[19] Ou, M.; Cui, P.; Pei, J.; Zhang, Z.; and Zhu, W. 2016. Asymmetric transitivity preserving graph embedding. In Proceedings of KDD 2016."}, {"ref": "[20] Perozzi, B.; Al-Rfou, R.; and Skiena, S. 2014. Deepwalk: Online learning of social representations. In Proceedings of  KDD 2014."}, {"ref": "[21] Rasmussen, C. E., and Williams, C. K. I. 2005. Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning). The MIT Press."}, {"ref": "[22] Rumelhart, D. E.; Hinton, G. E.; and Williams, R. J. 1988. Learning representations by back-propagating errors. In Neurocomputing: Foundations of Research. The MIT Press."}, {"ref": "[23] Silva, R.; Chu, W.; and Ghahramani, Z. 2007. Hidden common cause relations in relational learning. In Proceedings of NIPS 2007."}, {"ref": "[24] Smola, A. J., and Kondor, R. 2003. Kernels and regularization on graphs. In Proceedings of COLT 2003."}, {"ref": "[25] Stoyanov, V.; Ropson, A.; and Eisner, J. 2011. Empirical risk minimization of graphical model parameters given approximate inference, decoding, and model structure. In Proceedings of AISTATS 2011."}, {"ref": "[26] Subramanya, A., and Bilmes, J. 2008. Soft-supervised learning for text classification. In Proceedings of EMNLP 2008."}, {"ref": "[27] Szummer, M., and Jaakkola, T. 2001. Partially labeled classification with markov random walks. In Proceedings of NIPS 2001."}, {"ref": "[28] Tang, L., and Liu, H. 2009. Relational learning via latent social dimensions. In Proceedings of KDD 2009."}, {"ref": "[29] Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, Q. 2015. Line: Large-scale information network embedding. In Proceedings of WWW 2015."}, {"ref": "[30] Tomar, V. S., and Rose, R. C. 2014. Manifold regularized deep neural networks. In Proceedings of INTERSPEECH 2014."}, {"ref": "[31] Wang, S.; Tang, J.; Aggarwal, C.; Chang, Y.; and Liu, H. 2017a. Signed network embedding in social media. In Proceedings of SDM 2017."}, {"ref": "[32] Wang, X.; Cui, P.; Wang, J.; Pei, J.; Zhu, W.; and Yang, S. 2017b. Community preserving network embedding. In Proceedings of AAAI 2017."}, {"ref": "[33] Wang, D.; Cui, P.; and Zhu, W. 2016. Structural deep network embedding. In Proceedings of KDD 2016."}, {"ref": "[34] Yang, C.; Liu, Z.; Zhao, D.; Sun, M.; and Chang, E. Y. 2015. Network representation learning with rich text information. In Proceedings of IJCAI 2015."}, {"ref": "[35] Yu, K., and Chu, W. 2007. Gaussian process models for link analysis and transfer learning. In Proceedings of NIPS 2007."}, {"ref": "[36] Yu, K.; Chu, W.; Yu, S.; Tresp, V.; and Xu, Z. 2006. Stochastic relational models for discriminative link prediction. In Proceedings of NIPS 2006."}, {"ref": "[37] Zheng, Q., and Skillicorn, D. 2015. Spectral embedding of signed networks. In Proceedings of SDM 2015."}, {"ref": "[38] Zhu, X., and Ghahramani, Z. 2002. Learning from labeled and unlabeled data with label propagation. Technical report, Carnegie Mellon University."}, {"ref": "[39] Zhu, X.; Ghahramani, Z.; and Lafferty, J. 2003. Semisupervised learning using gaussian fields and harmonic functions. In Proceedings of ICML 2003."}, {"ref": "[40] Zhu, X. 2005. Semi-supervised Learning with Graphs.Ph.D. Dissertation, Carnegie Mellon University."}]}, {"author": ["\ufeffUriel Singer", "Ido Guy", "Kira Radinsky"], "title": "Node Embedding over Temporal Graphs", "journal": "IJCAI", "year": 2019, "DOI": "10.24963/ijcai.2019/640", "month": 4, "citations(google scholar)": 1, "abstract": "In this work, we present a method for node embedding in temporal graphs. We propose an algorithm that learns the evolution of a temporal graph's nodes and edges over time and incorporates this dynamics in a temporal node embedding framework for different graph prediction tasks. We present a joint loss function that creates a temporal embedding of a node by learning to combine its historical temporal embeddings, such that it optimizes per given task (e.g., link prediction). The algorithm is initialized using static node embeddings, which are then aligned over the representations of a node at different time points, and eventually adapted for the given task in a joint optimization. We evaluate the effectiveness of our approach over a variety of temporal graphs for the two fundamental tasks of temporal link prediction and multi-label node classification, comparing to competitive baselines and algorithmic alternatives. Our algorithm shows performance improvements across many of the datasets and baselines and is found particularly effective for graphs that are less cohesive, with a lower clustering coefficient.", "keywords": ["Node Embedding", "Temporal Graphs"], "reference_count": 59, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Leman Akoglu, Hanghang Tong, and Danai Koutra. 2015. Graph based anomaly detection and description: a survey. Data Mining and Knowledge Discovery 29, 3 (2015), 626\u2013688."}, {"ref": "[2] Mohammad Al Hasan, Vineet Chaoji, Saeed Salem, and Mohammed Zaki. 2006. Link prediction using supervised learning. In Proc. of SDM06: workshop on link analysis, counter-terrorism and security."}, {"ref": "[3] Albert-Laszlo Barabasi and Reka Albert. 1999. Emergence of Scaling in Random Networks. Science 286, 5439 (1999), 509\u2013512."}, {"ref": "[4] Mikhail Belkin and Partha Niyogi. 2002. Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering. In Advances in Neural Information Processing Systems 14. 585\u2013591."}, {"ref": "[5] Paul J Besl and Neil D McKay. 1992. Method for registration of 3-D shapes. In Sensor Fusion IV: Control Paradigms and Data Structures, Vol. 1611. 586\u2013607."}, {"ref": "[6] Justin Cheng, Lada Adamic, P. Alex Dow, Jon Michael Kleinberg, and Jure Leskovec. 2014. Can Cascades Be Predicted?. In Proc. of WWW. 925\u2013936."}, {"ref": "[7] Peng Cui, Xiao Wang, Jian Pei, and Wenwu Zhu. 2018. A survey on network embedding. IEEE Transactions on Knowledge and Data Engineering (2018)."}, {"ref": "[8] Zhiyong Cui, Kristian Henrickson, Ruimin Ke, and Yinhai Wang. 2018. HighOrder Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting. arXiv preprint abs/1802.07007 (2018)."}, {"ref": "[9] Lun Du, Yun Wang, Guojie Song, Zhicong Lu, and Junshan Wang. 2018. Dynamic Network Embedding: An Extended Approach for Skip-gram based Network Embedding.. In IJCAI. 2086\u20132092."}, {"ref": "[10] Daniel M Dunlavy, Tamara G Kolda, and Evrim Acar. 2011. Temporal link prediction using matrix and tensor factorizations. ACM Transactions on Knowledge Discovery from Data (TKDD) 5, 2 (2011), 10."}, {"ref": "[11] Jie Feng, Yong Li, Chao Zhang, Funing Sun, Fanchao Meng, Ang Guo, and Depeng Jin. 2018. DeepMove: Predicting Human Mobility with Attentional Recurrent Networks. In Proc. of WWW. 1459\u20131468."}, {"ref": "[12] Palash Goyal and Emilio Ferrara. 2018. Graph embedding techniques, applications, and performance: A survey. Knowledge-Based Systems 151 (2018), 78\u201394."}, {"ref": "[13] Palash Goyal, Nitin Kamra, Xinran He, and Yan Liu. 2017. DynGEM: Deep Embedding Method for Dynamic Graphs. arXiv preprint abs/1805.11273 (2017)."}, {"ref": "[14] Aditya Grover and Jure Leskovec. 2016. Node2Vec: Scalable Feature Learning for Networks. In Proc. of KDD. 855\u2013864."}, {"ref": "[15] William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Representation learning on graphs: Methods and applications. arXiv preprint abs/1709.05584 (2017)."}, {"ref": "[16] Alan G Hawkes. 1971. Spectra of some self-exciting and mutually exciting point processes. Biometrika 58, 1 (1971), 83\u201390."}, {"ref": "[17] Derek LG Hill, Philipp G Batchelor, Mark Holden, and David J Hawkes. 2001. Medical image registration. Physics in medicine & biology 46, 3 (2001), R1."}, {"ref": "[18] Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735\u20131780."}, {"ref": "[19] John R Hurley and Raymond B Cattell. 1962. The Procrustes program: Producing direct rotation to test a hypothesized factor structure. Systems Research and Behavioral Science 7, 2 (1962), 258\u2013262."}, {"ref": "[20] Ashesh Jain, Amir R Zamir, Silvio Savarese, and Ashutosh Saxena. 2016. Structural-RNN: Deep learning on spatio-temporal graphs. In Proc. of CVPR. 5308\u20135317."}, {"ref": "[21] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint abs/1412.6980 (2014)."}, {"ref": "[22] Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint abs/1609.02907 (2016)."}, {"ref": "[23] Andrey Kupavskii, Liudmila Ostroumova, Alexey Umnov, Svyatoslav Usachev, Pavel Serdyukov, Gleb Gusev, and Andrey Kustarev. 2012. Prediction of Retweet Cascade Size over Time. In Proc. of CIKM. 2335\u20132338."}, {"ref": "[24] Jure Leskovec, Lars Backstrom, Ravi Kumar, and Andrew Tomkins. 2008. Microscopic Evolution of Social Networks. In Proc. of KDD. 462\u2013470."}, {"ref": "[25] Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. 2005. Graphs over Time: Densification Laws, Shrinking Diameters and Possible Explanations. In Proc. of KDD. 177\u2013187."}, {"ref": "[26] Jundong Li, Harsh Dani, Xia Hu, Jiliang Tang, Yi Chang, and Huan Liu. 2017. Attributed network embedding for learning in a dynamic environment. In Proc. of CIKM. 387\u2013396."}, {"ref": "[27] Taisong Li, Jiawei Zhang, S Yu Philip, Yan Zhang, and Yonghong Yan. 2018. Deep Dynamic Network Embedding for Link Prediction. IEEE Access (2018)."}, {"ref": "[28] Xiaoyi Li, Nan Du, Hui Li, Kang Li, Jing Gao, and Aidong Zhang. 2014. A Deep Learning Approach to Link Prediction in Dynamic Networks. In Proc. of SDM. 289\u2013297."}, {"ref": "[29] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. 2015. Gated graph sequence neural networks. arXiv preprint abs/1511.05493 (2015)."}, {"ref": "[30] David Liben-Nowell and Jon Kleinberg. 2007. The Link-prediction Problem for Social Networks. J. Am. Soc. Inf. Sci. Technol. 58, 7 (May 2007), 1019\u20131031."}, {"ref": "[31] Linyuan L\u00fc and Tao Zhou. 2011. Link prediction in complex networks: A survey. Physica A: statistical mechanics and its applications 390, 6 (2011), 1150\u20131170."}, {"ref": "[32] Aditya Krishna Menon and Charles Elkan. 2011. Link prediction via matrix factorization. In Proc. of ECML PKDD. 437\u2013452."}, {"ref": "[33] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. arXiv preprint abs/1301.3781 (2013)."}, {"ref": "[34] Giang Hoang Nguyen, John Boaz Lee, Ryan A Rossi, Nesreen K Ahmed, Eunyee Koh, and Sungchul Kim. 2018. Continuous-time dynamic network embeddings. In Proc. of WWW Companion. 969\u2013976."}, {"ref": "[35] Hamid Palangi, Li Deng, Yelong Shen, Jianfeng Gao, Xiaodong He, Jianshu Chen, Xinying Song, and Rabab K. Ward. 2015. Deep Sentence Embedding Using the Long Short Term Memory Network: Analysis and Application to Information Retrieval. (2015)."}, {"ref": "[36] Gergely Palla, Imre Der??nyi, Ill??s Farkas, and Tam??s Vicsek. 2005. Uncovering the overlapping community structure of complex networks in nature and society. Nature 435, 7043 (June 2005), 814\u2013818."}, {"ref": "[37] Ashwini Patil and Haruki Nakamura. 2005. HINT: a database of annotated protein-protein interactions and their homologs. Biophysics 1 (2005), 21\u201324."}, {"ref": "[38] Yulong Pei, Jianpeng Zhang, George HL Fletcher, and Mykola Pechenizkiy. 2016. Node classification in dynamic social networks. In Proc. of AALTD (ECML/PKDD Workshop). 8."}, {"ref": "[39] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: Online Learning of Social Representations. In Proc. of KDD. 701\u2013710."}, {"ref": "[40] F. Radicchi, C. Castellano, F. Cecconi, V. Loreto, and D. Parisi. 2004. Defining and identifying communities in networks. Proceedings of the National Academy of Sciences 101, 9 (2004), 2658."}, {"ref": "[41] Ryan A. Rossi and Nesreen K. Ahmed. 2015. Role Discovery in Networks. IEEE Trans. Knowl. Data Eng. 27, 4 (2015), 1112\u20131131."}, {"ref": "[42] Sam T. Roweis and Lawrence K. Saul. 2000. Nonlinear dimensionality reduction by locally linear embedding. SCIENCE 290 (2000), 2323\u20132326."}, {"ref": "[43] Peter H Sch?nemann. 1966. A generalized solution of the orthogonal procrustes problem. Psychometrika 31, 1 (1966), 1\u201310."}, {"ref": "[44] Peter H Sch?nemann and Robert M Carroll. 1970. Fitting one matrix to another under choice of a central dilation and a rigid motion. Psychometrika 35, 2 (1970), 245\u2013255."}, {"ref": "[45] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale Information Network Embedding. In Proc. of WWW. 1067\u20131077."}, {"ref": "[46] Joshua B. Tenenbaum, Vin de Silva, and John C. Langford. 2000. A Global Geometric Framework for Nonlinear Dimensionality Reduction. Science 290 (2000), 2319."}, {"ref": "[47] Rakshit Trivedi, Hanjun Dai, Yichen Wang, and Le Song. 2017. Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs. In Proc. of ICML. 3462\u20133471."}, {"ref": "[48] Rakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, and Hongyuan Zha. 2018. Representation Learning over Dynamic Graphs. arXiv preprint abs/1803.04051 (2018)."}, {"ref": "[49] Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural Deep Network Embedding. In Proc. of KDD. 1225\u20131234."}, {"ref": "[50] Hongjian Wang and Zhenhui Li. 2017. Region Representation Learning via Mobility Flow. In Proc. of CIKM. 237\u2013246."}, {"ref": "[51] Stanley Wasserman and Katherine Faust. 1994. Social network analysis: Methods and applications. Vol. 8. Cambridge university press."}, {"ref": "[52] Sijie Yan, Yuanjun Xiong, and Dahua Lin. 2018. Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition. In Proc. of AAAI. 3482\u20133489."}, {"ref": "[53] Shuicheng Yan, Dong Xu, Benyu Zhang, Hong-Jiang Zhang, Qiang Yang, and Stephen Lin. 2007. Graph Embedding and Extensions: A General Framework for Dimensionality Reduction. IEEE Trans. Pattern Anal. Mach. Intell. 29, 1 (2007), 40\u201351."}, {"ref": "[54] Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2017. Spatio-temporal Graph Convolutional Neural Network: A Deep Learning Framework for Traffic Forecasting. arXiv preprint abs/1709.04875 (2017)."}, {"ref": "[55] Wenchao Yu, Charu C. Aggarwal, and Wei Wang. 2017. Temporally Factorized Network Modeling for Evolutionary Network Analysis. In Proc. of WSDM (WSDM \u201917). 455\u2013464."}, {"ref": "[56] Le-kui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. 2018. Dynamic Network Embedding by Modeling Triadic Closure Process. In Proc. of AAAI. 571\u2013578."}, {"ref": "[57] Dingyuan Zhu, Peng Cui, Ziwei Zhang, Jian Pei, and Wenwu Zhu. 2018. Highorder Proximity Preserved Embedding For Dynamic Networks. IEEE Transactions on Knowledge and Data Engineering (2018), 2134\u20132144."}, {"ref": "[58] Linhong Zhu, Dong Guo, Junming Yin, Greg Ver Steeg, and Aram Galstyan. 2016. Scalable temporal latent space inference for link prediction in dynamic social networks. IEEE Transactions on Knowledge and Data Engineering 28, 10 (2016), 2765\u20132777."}, {"ref": "[59] Yuan Zuo, Guannan Liu, Hao Lin, Jia Guo, Xiaoqian Hu, and Junjie Wu. 2018. Embedding Temporal Network via Neighborhood Formation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 2857\u20132866."}]}, {"author": ["\ufeffCarter Chiu", "Justin Zhan"], "title": "Deep Learning for Link Prediction in Dynamic Networks Using Weak Estimators", "journal": "IEEE Access", "year": 2018, "DOI": "10.1109/access.2018.2845876", "month": 6, "citations(google scholar)": 12, "abstract": "Link prediction is the task of evaluating the probability that an edge exists in a network, and it has useful applications in many domains. Traditional approaches rely on measuring the similarity between two nodes in a static context. Recent research has focused on extending link prediction to a dynamic setting, predicting the creation and destruction of links in networks that evolve over time. Though a difficult task, the employment of deep learning techniques has shown to make notable improvements to the accuracy of predictions. To this end, we propose the novel application of weak estimators in addition to the utilization of traditional similarity metrics to inexpensively build an effective feature vector for a deep neural network. Weak estimators have been used in a variety of machine learning algorithms to improve model accuracy, owing to their capacity to estimate the changing probabilities in dynamic systems. Experiments indicate that our approach results in increased prediction accuracy on several real-world dynamic networks.", "keywords": ["Deep learning", "link prediction", "dynamic networks", "weak estimators", "similarity metrics"], "reference_count": 52, "ccfClass": "", "important": true, "references": [{"ref": "[1] D. Liben-Nowell and J. Kleinberg, \"The link-prediction problem for social networks,\" J. Am. Soc. Inf. Sci. Technol., vol. 58, no. 7, pp. 1019\u20131031, May 2007."}, {"ref": "[2] L. A. Adamic and E. Adar, \"Friends and neighbors on the web,\" Social Networks, vol. 25, no. 3, pp. 211\u2013230, 2003."}, {"ref": "[3] L. Katz, \"A new status index derived from sociometric analysis,\" Psychometrika, vol. 18, no. 1, pp. 39\u201343, Mar 1953."}, {"ref": "[4] L. Yao, L. Wang, L. Pan, and K. Yao, \"Link prediction based on common-neighbors for dynamic social network,\" Procedia Computer Science, vol. 83, no. Supplement C, pp. 82 \u2013 89, 2016, Workshops."}, {"ref": "[5] M. Kaya, M. Jawed, E. But\u00a8 un, and R. Alhajj, \u00a8 Unsupervised Link Prediction Based on Time Frames in Weighted\u2013Directed Citation Networks. Cham: Springer International Publishing, 2017, pp. 189\u2013205."}, {"ref": "[6] H. Wang, W. Hu, Z. Qiu, and B. Du, \"Nodes\u2019 evolution diversity and link prediction in social networks,\" IEEE Transactions on Knowledge and Data Engineering, vol. 29, no. 10, pp. 2263\u20132274, Oct 2017."}, {"ref": "[7] H. A. Deylami and M. Asadpour, \"Link prediction in social networks using hierarchical community detection,\" in 2015 7th Conference on Information and Knowledge Technology (IKT), May 2015, pp. 1\u20135."}, {"ref": "[8] W. Hu, H. Wang, C. Peng, H. Liang, and B. Du, \"An event detection method for social networks based on link prediction,\" Information Systems, vol. 71, pp. 16 \u2013 26, 2017. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0306437917303976"}, {"ref": "[9] W. Hu, H. Wang, Z. Qiu, C. Nie, L. Yan, and B. Du, \"An event detection method for social networks based on hybrid link prediction and quantum swarm intelligent,\" World Wide Web, vol. 20, no. 4, pp. 775\u2013795, Jul 2017. [Online]. Available: https://doi.org/10.1007/s11280-016-0416-y"}, {"ref": "[10] L. Zhang, F. Zhuo, C. Bai, and H. Xu, \"Analytical model for predictable contact in intermittently connected cognitive radio ad hoc networks,\" International Journal of Distributed Sensor Networks,  vol. 12, no. 7, p. 1550147716659426, 2016. [Online]. Available: https://doi.org/10.1177/1550147716659426"}, {"ref": "[11] M. A. Hasan, V. Chaoji, S. Salem, and M. Zaki, \"Link prediction using supervised learning,\" in In Proc. of SDM 06 workshop on Link Analysis, Counterterrorism and Security, 2006."}, {"ref": "[12] N. Benchettara, R. Kanawati, and C. Rouveirol, \"Supervised machine learning applied to link prediction in bipartite social networks,\" in 2010 International Conference on Advances in Social Networks Analysis and Mining, Aug 2010, pp. 326\u2013330."}, {"ref": "[13] J. R. Doppa, J. Yu, P. Tadepalli, and L. Getoor, Learning Algorithms for Link Prediction Based on Chance Constraints. Berlin, Heidelberg: Springer Berlin Heidelberg, 2010, pp. 344\u2013360."}, {"ref": "[14] X. Li, N. Du, H. Li, K. Li, J. Gao, and A. Zhang, A Deep Learning Approach to Link Prediction in Dynamic Networks, pp. 289\u2013297."}, {"ref": "[15] C. Zhang, H. Zhang, D. Yuan, and M. Zhang, \"Deep learning based link prediction with social pattern and external attribute knowledge in bibliographic networks,\" in 2016 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData), Dec 2016, pp. 815\u2013821."}, {"ref": "[16] M. Rahman and M. A. Hasan, Link Prediction in Dynamic Networks Using Graphlet. Cham: Springer International Publishing, 2016, pp. 394\u2013409."}, {"ref": "[17] T. D. Bui, S. Ravi, and V. Ramavajjala, \"Neural graph machines: Learning neural networks using graphs,\" CoRR, vol. abs/1703.04818, 2017."}, {"ref": "[18] R. A. Rossi, R. Zhou, and N. K. Ahmed, \"Deep feature learning for graphs,\" in arXiv:1704.08829, 2017, pp. 1\u201311."}, {"ref": "[19] I. Fras-Blanco, J. d. Campo-vila, G. Ramos-Jimnez, R. MoralesBueno, A. Ortiz-Daz, and Y. Caballero-Mota, \"Online and nonparametric drift detection methods based on hoeffding\u2019s bounds,\" IEEE Transactions on Knowledge and Data Engineering, vol. 27, no. 3, pp. 810\u2013823, March 2015."}, {"ref": "[20] M. Bhaduri, J. Zhan, C. Chiu, and F. Zhan, \"A novel online and non-parametric approach for drift detection in big data,\" IEEE Access, vol. 5, pp. 15 883\u201315 892, 2017."}, {"ref": "[21] H. Wang and Z. Abraham, \"Concept drift detection for streaming data,\" in 2015 International Joint Conference on Neural Networks (IJCNN), 07 2015, pp. 1\u20139."}, {"ref": "[22] H.-K. Song, \"A channel estimation using sliding window approach and tuning algorithm for mlse,\" IEEE Communications Letters, vol. 3, no. 7, pp. 211\u2013213, July 1999."}, {"ref": "[23] M. M. Lazarescu, S. Venkatesh, and H. H. Bui, \"Using multiple windows to track concept drift,\" Intell. Data Anal., vol. 8, no. 1, pp. 29\u201359, Jan. 2004."}, {"ref": "[24] B. J. Oommen and L. Rueda, On Utilizing Stochastic Learning Weak Estimators for Training and Classification of Patterns with Nonstationary Distributions. Berlin, Heidelberg: Springer Berlin Heidelberg, 2005, pp. 107\u2013120."}, {"ref": "[25] \u2014\u2014, \"Stochastic learning-based weak estimation of multinomial random variables and its applications to pattern recognition in non-stationary environments,\" Pattern Recognition, vol. 39, no. 3, pp. 328 \u2013 341, 2006."}, {"ref": "[26] J. Zhan, B. J. Oommen, and J. Crisostomo, \"Anomaly detection in dynamic systems using weak estimators,\" ACM Trans. Internet Technol., vol. 11, no. 1, pp. 3:1\u20133:16, Jul. 2011."}, {"ref": "[27] M. Bhaduri, J. Zhan, and C. Chiu, \"A novel weak estimator for dynamic systems,\" IEEE Access, vol. PP, no. 99, pp. 1\u20131, 2017."}, {"ref": "[28] N. B. Silva, I. R. Tsang, G. D. C. Cavalcanti, and I. J. Tsang, \"A graph-based friend recommendation system using genetic algorithm,\" in IEEE Congress on Evolutionary Computation, July 2010, pp. 1\u20137."}, {"ref": "[29] P. Wang, B. Xu, Y. Wu, and X. Zhou, \"Link prediction in social networks: the state-of-the-art,\" CoRR, vol. abs/1411.5118, 2014."}, {"ref": "[30] A. Lebedev, J. Lee, V. Rivera, and M. Mazzara, \"Link prediction using top-k shortest distances,\" CoRR, vol. abs/1705.02936, 2017."}, {"ref": "[31] J. Leskovec and A. Krevl, \"SNAP Datasets: Stanford large network dataset collection,\" http://snap.stanford.edu/data, Jun. 2014."}, {"ref": "[32] D. P. Kingma and J. Ba, \"Adam: A method for stochastic optimization,\" CoRR, vol. abs/1412.6980, 2014."}, {"ref": "[33] P. Ezatpoor, J. Zhan, J. Wu, and C. Chiu, \"Finding top-k dominance on incomplete big data using mapreduce framework,\" IEEE Access, vol. 6, pp. 7872\u20137887, 2018."}, {"ref": "[34] P. Chopade and J. Zhan, \"Towards a framework for community detection in large networks using game-theoretic modeling,\" IEEE Transaction on Big Data, vol. 3, no. 3, pp. 276\u2013288, 2017."}, {"ref": "[35] M. Bhaduri, J. Zhan, and C. Chiu, \"A weak estimator for dynamic systems,\" IEEE Access, vol. 5, no. 1, pp. 27 354\u201327 365, 2017."}, {"ref": "[36] M. Bhaduri, J. Zhan, C. Chiu, and F. Zhan, \"A novel online and non-parametric approach for drift detection in big data,\" IEEE Access, vol. 5, no. 1, pp. 15 883\u201315 892, 2017."}, {"ref": "[37] C. Chiu, J. Zhan, and F. Zhan, \"Uncovering suspicious activity from partially paired and incomplete multimodal data,\" IEEE Access, vol. 5, no. 1, pp. 13 689 \u2013 13 698, 2017."}, {"ref": "[38] R. Ahn and J. Zhan, \"Using proxies for node immunization identification on large graphs,\" IEEE Access, vol. 5, no. 1, pp. 13 046\u2013 13 053, 2017."}, {"ref": "[39] M. Wu, J. Zhan, and J. Lin, \"Ant colony system sanitization approach to hiding sensitive itemsets,\" IEEE Access, vol. 14, no. 8, 2017."}, {"ref": "[40] J. Zhan and B. Dahal, \"Using deep learning for short text understanding,\" Journal of Big Data, vol. 4, no. 34, pp. 1\u201315, 2017."}, {"ref": "[41] W. Gan, J. Lin, P. Fournier-Viger, H. Chao, J. Zhan, and J. Zhang, \"Exploiting highly qualified pattern with frequency and weight occupancy,\" Knowledge and Information Systems, In Press, 3 October 2017."}, {"ref": "[42] J. Lin, T.-P. Hong, P. Fournier-Viger, Q. Liu, J.-W. Wong, and J. Zhan, \"Efficient hiding of confidential high-utility itemsets with minimal side effects,\" Journal of Experimental and Theoretical Artificial Intelligence, vol. 0, no. 0, pp. 1\u201321, 2017."}, {"ref": "[43] J. Zhan, S. Gurung, and S. P. K. Parsa, \"Identification of top-k nodes in large networks using katz centrality,\" Journal of Big Data, vol. 4, no. 16, 2017."}, {"ref": "[44] J. C.-W. Lin, W. Gan, P. Fournier-Viger, H.-C. Chao, J. M.-T. Wu, and J. Zhan, \"Extracting recent weighted-based patterns from uncertain temporal databases,\" International Scientific Journal Engineering Applications of Artificial Intelligence, vol. 61, pp. 161\u2013172, 2017."}, {"ref": "[45] J. Zhan, T. Rafalski, G. Stashkevich, and E. Verenich, \"Vaccination allocation in large dynamic networks,\" Journal of Big Data, vol. 4, no. 2, 2017."}, {"ref": "[46] W. Gan, C.-W. Lin, H.-C. Chao, and Z. Justin, \"Data mining in distributed environment: A survey, wires data mining and knowledge discovery,\" 2017 (accepted)."}, {"ref": "[47] W. Gan, J. C.-W. Lin, P. Fournier-Viger, H. C. Chao, and J. Zhan, \"Mining of frequent patterns with multiple minimum supports,\" Engineering Applications of Artificial Intelligence, 2017."}, {"ref": "[48] J. M.-T. Wu, J. Zhan, and J. C.-W. Lin, \"An aco-based approach to mine high-utility itemsets,\" Knowledge-Based Systems, vol. 116, pp. 102\u2013113, 2017."}, {"ref": "[49] M. Pirouz, J. Zhan, and S. Tayeb, \"An optimized approach for community detection and ranking,\" Journal of Big Data, vol. 3, no. 22, 2016."}, {"ref": "[50] J. C.-W. Lin, W. Gan, P. Fournier-Viger, T.-P. Hong, and J. Zhan, \"Efficient mining of high-utility itemsets using multiple minimum utility thresholds,\" Knowledge-Based Systems, vol. 113, pp. 100\u2013115, 2016."}, {"ref": "[51] J. C.-W. Lin, T. Li, P. Fournier-Viger, T.-P. Hong, J. M.-T. Wu, and J. Zhan, \"Efficient mining of multiple fuzzy frequent itemsets,\" International Journal of Fuzzy Systems, pp. 1\u20139, 2016."}]}]