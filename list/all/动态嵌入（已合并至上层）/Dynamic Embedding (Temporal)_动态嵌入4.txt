[{"author": ["Xiaodong Jiang", "Pengsheng Ji", "Sheng Li"], "title": "CensNet: Convolution with Edge-Node Switching in Graph Neural Networks", "journal": "International Joint Conference on Artificial Intelligence", "year": 2019, "DOI": "10.24963/ijcai.2019/369", "month": 8, "citations(google scholar)": 0, "abstract": "In this paper, we present CensNet, Convolution with Edge-Node Switching graph neural network, for semi-supervised classification and regression in graph-structured data with both node and edge features. CensNet is a general graph embedding framework, which embeds both nodes and edges to a latent feature space. By using line graph of the original undirected graph, the role of nodes and edges are switched, and two novel graph convolution operations are proposed for feature propagation. Experimental results on real-world academic citation networks and quantum chemistry graphs show that our approach has achieved or matched the state-of-the-art performance.", "keywords": ["Relational Learning", "Semi-Supervised Learning", "Deep Learning", "Other Applications"], "reference_count": 25, "ccfClass": "A", "important": true, "references": [{"ref": "[Bronstein et al., 2017] Michael M Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre Vandergheynst. Geometric deep learning: going beyond euclidean data. IEEE Signal Processing Magazine, 34(4):18\u201342, 2017."}, {"ref": "[Defferrard et al., 2016a] Michae \u0308l Defferrard, Xavier Bres- son, and Pierre Vandergheynst. Convolutional neural net- works on graphs with fast localized spectral filtering. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Information Pro- cessing Systems 29, pages 3844\u20133852. Curran Associates, Inc., 2016."}, {"ref": "[Defferrard et al., 2016b] Michae \u0308l Defferrard, Xavier Bres- son, and Pierre Vandergheynst. Convolutional neural net- works on graphs with fast localized spectral filtering. In NIPS, 2016."}, {"ref": "[Hamilton et al., 2017] William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In NIPS, 2017."}, {"ref": "[Harary and Norman, 1960] Frank Harary and Robert Z. Norman. Some properties of line digraphs. Rendiconti del Circolo Matematico di Palermo, 1960."}, {"ref": "[He et al., 2016] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog- nition. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770\u2013778, 2016."}, {"ref": "[Ji and Jin, 2016] Pengsheng Ji and Jiashun Jin. Coauthor- ship and citation networks for statisticians. The Annals of Applied Statistics, 10(4):1779\u20131812, 2016."}, {"ref": "[Kingma and Ba, 2014] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014."}, {"ref": "[Kipf and Welling, 2017] Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Rep- resentations, 2017."}, {"ref": "[Krizhevsky et al., 2012] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In Proceedings of the 25th International Conference on Neural Information Process- ing Systems - Volume 1, NIPS\u201912, pages 1097\u20131105, USA, 2012. Curran Associates Inc."}, {"ref": "[LeCun et al., 2015] Yann LeCun, Yoshua Bengio, and Ge- offrey Hinton. Deep learning. Nature, 521(7553):436\u2013 444, 5 2015."}, {"ref": "[Li and Fu, 2015] Sheng Li and Yun Fu. Learning balanced and unbalanced graphs via low-rank coding. IEEE Trans- actions on Knowledge and Data Engineering, 27(5):1274\u2013 1287, 2015."}, {"ref": "[Li et al., 2017] Sheng Li, Hongfu Liu, Zhiqiang Tao, and Yun Fu. Multi-view graph learning with adaptive label propagation. In IEEE International Conference on Big Data, pages 110\u2013115. IEEE, 2017."}, {"ref": "[Liao et al., 2019] Renjie Liao, Zhizhen Zhao, Raquel Urta- sun, and Richard Zemel. Lanczosnet: Multi-scale deep graph convolutional networks. In International Confer- ence on Learning Representations, 2019."}, {"ref": "[Monti et al., 2017] Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodola, Jan Svoboda, and Michael M. Bronstein. Geometric deep learning on graphs and manifolds using mixture model cnns. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017."}, {"ref": "[Namata et al., 2012] Galileo Mark Namata, Ben London, Lise Getoor, and Bert Huang. Query-driven active survey- ing for collective classification. In Workshop on Mining and Learning with Graphs (MLG), 2012."}, {"ref": "[Paszke et al., 2017] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary De- Vito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. NIPS- W, 2017."}, {"ref": "[Pedregosa et al., 2011] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blon- del, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825\u20132830, 2011."}, {"ref": "[Scarselli et al., 2009] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini. The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61\u201380, Jan 2009."}, {"ref": "[Schlichtkrull et al., 2018] Michael Sejr Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. In ESWC, 2018."}, {"ref": "[Sen et al., 2008] Prithviraj Sen, Galileo Mark Namata, Mustafa Bilgic, Lise Getoor, Brian Gallagher, and Tina Eliassi-Rad. Collective classification in network data. AI Magazine, 29(3):93\u2013106, 2008."}, {"ref": "[Shchur et al., 2018] Oleksandr Shchur, Maximil- ian Mumme, Aleksandar Bojchevski, and Stephan Gu \u0308nnemann. Pitfalls of graph neural network evaluation. CoRR, abs/1811.05868, 2018."}, {"ref": "[Velic\u02c7kovic \u0301 et al., 2018] Petar Velic\u02c7kovic \u0301, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio`, and Yoshua Bengio. Graph attention networks. In Interna- tional Conference on Learning Representations, 2018."}, {"ref": "[Wu et al., 2018] Zhenqin Wu, Bharath Ramsundar, Evan N. Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S. Pappu, Karl Leswing, and Vijay Pande. Moleculenet: a benchmark for molecular machine learning. Chem. Sci., 9:513\u2013530, 2018."}, {"ref": "[Zhou et al., 2018] Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, and Maosong Sun. Graph neural networks: A review of methods and applications. CoRR, abs/1812.08434, 2018."}]}, {"author": ["Yuan Zuo", "Guannan Liu", "Hao Lin", "Jia Guo", "Xiaoqian Hu", "Junjie Wu"], "title": "Embedding Temporal Network via Neighborhood Formation", "journal": "ACM Knowledge Discovery and Data Mining", "year": 2018, "DOI": "10.1145/3219819.3220054", "month": 8, "citations(google scholar)": 15, "abstract": "Given the rich real-life applications of network mining as well as the surge of representation learning in recent years, network embedding has become the focal point of increasing research interests in both academic and industrial domains. Nevertheless, the complete temporal formation process of networks characterized by sequential interactive events between nodes has yet seldom been modeled in the existing studies, which calls for further research on the so-called temporal network embedding problem. In light of this, in this paper, we introduce the concept of neighborhood formation sequence to describe the evolution of a node, where temporal excitation effects exist between neighbors in the sequence, and thus we propose a Hawkes process based Temporal Network Embedding (HTNE) method. HTNE well integrates the Hawkes process into network embedding so as to capture the influence of historical neighbors on the current neighbors. In particular, the interactions of low-dimensional vectors are fed into the Hawkes process as base rate and temporal influence, respectively. In addition, attention mechanism is also integrated into HTNE to better determine the influence of historical neighbors on current neighbors of a node. Experiments on three large-scale real-life networks demonstrate that the embeddings learned from the proposed HTNE model achieve better performance than state-of-the-art methods in various tasks including node classification, link prediction, and embedding visualization. In particular, temporal recommendation based on arrival rate inferred from node embeddings shows excellent predictive power of the proposed model.", "keywords": ["Temporal Network", "Network Embedding", "Learning Representation", "Hawkes Process"], "reference_count": 30, "ccfClass": "A", "important": true, "references": [{"ref": "[1] AmrAhmed,NinoShervashidze,ShravanNarayanamurthy,VanjaJosifovski,and Alexander J. Smola. 2013. Distributed Large-scale Natural Graph Factorization. In WWW. ACM, New York, NY, USA, 37\u201348."}, {"ref": "[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural ma- chine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473."}, {"ref": "[3] Mikhail Belkin and Partha Niyogi. 2001. Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering. In NIPS. MIT Press, Cambridge, MA, USA, 585\u2013591."}, {"ref": "[4] HongYun Cai, Vincent W. Zheng, and Kevin Chen-Chuan Chang. 2017. A Com- prehensive Survey of Graph Embedding: Problems, Techniques and Applications. CoRR abs/1709.07604 (2017)."}, {"ref": "[5] SandroCavallari,VincentW.Zheng,HongyunCai,KevinChen-ChuanChang, and Erik Cambria. 2017. Learning Community Embedding with Community Detection and Node Embedding on Graphs. In CIKM. 377\u2013386."}, {"ref": "[6] Quanyu Dai, Qiang Li, Jian Tang, and Dan Wang. 2017. Adversarial Network Embedding. CoRR abs/1711.07838 (2017)."}, {"ref": "[7] Nan Du, Yichen Wang, Niao He, and Le Song. 2015. Time-sensitive Recommen- dation from Recurrent User Activities. In NIPS. 3492\u20133500."}, {"ref": "[8] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde- Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative Adversarial Nets. In NIPS. MIT Press, Cambridge, MA, USA, 2672\u20132680."}, {"ref": "[9] Aditya Grover and Jure Leskovec. 2016. Node2Vec: Scalable Feature Learning for Networks. In SIGKDD. ACM, New York, NY, USA, 855\u2013864."}, {"ref": "[10] William L. Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. CoRR abs/1706.02216 (2017)."}, {"ref": "[11] Alan G Hawkes. 1971. Spectra of some self-exciting and mutually exciting point processes. Biometrika 58, 1 (1971), 83\u201390."}, {"ref": "[12] Petter Holme and Jari Saram\u00c3\u010fki. 2012. Temporal networks. Physics Reports 519, 3 (2012), 97 \u2013 125."}, {"ref": "[13] Joseph B Kruskal and Myron Wish. 1978. Multidimensional Scaling. CRC press. 875\u2013878 pages."}, {"ref": "[14] R\u00c3\u013emi Lemonnier, Kevin Scaman, and Argyris Kalogeratos. 2017. Multivariate Hawkes Processes for Large-Scale Inference. In AAAI."}, {"ref": "[15] Remi Lemonnier and Nicolas Vayatis. 2014. Nonparametric Markovian Learning of Triggering Kernels for Mutually Exciting and Mutually Inhibiting Multivariate Hawkes Processes. In Machine Learning and Knowledge Discovery in Databases. 161\u2013176."}, {"ref": "[16] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. CoRR abs/1301.3781 (2013)."}, {"ref": "[17] TomasMikolov,IlyaSutskever,KaiChen,GregCorrado,andJeffreyDean.2013. Distributed Representations of Words and Phrases and Their Compositionality. In NIPS. Curran Associates Inc., USA, 3111\u20133119."}, {"ref": "[18] TomasMikolov,IlyaSutskever,KaiChen,GregSCorrado,andJeffDean.2013. Distributed Representations of Words and Phrases and their Compositionality. In NIPS. 3111\u20133119."}, {"ref": "[19] Shirui Pan, Jia Wu, Xingquan Zhu, Chengqi Zhang, and Yang Wang. 2016. Tri- party Deep Network Representation. In IJCAI. AAAI Press, 1895\u20131901."}, {"ref": "[20] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: Online Learn- ing of Social Representations. In SIGKDD. ACM, New York, NY, USA, 701\u2013710."}, {"ref": "[21] Sam T. Roweis and Lawrence K. Saul. 2000. Nonlinear Dimensionality Reduction by Locally Linear Embedding. Science 290, 5500 (2000), 2323\u20132326."}, {"ref": "[22] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale Information Network Embedding. In WWW. International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, 1067\u20131077."}, {"ref": "[23] Joshua B. Tenenbaum, Vin de Silva, and John C. Langford. 2000. A Global Geometric Framework for Nonlinear Dimensionality Reduction. Science 290, 5500 (2000), 2319\u20132323."}, {"ref": "[24] Laurens van der Maaten and Geoffrey E. Hinton. 2008. Visualizing High- Dimensional Data Using t-SNE. JMLR 9 (2008), 2579\u20132605."}, {"ref": "[25] Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural Deep Network Em- bedding. In SIGKDD. ACM, New York, NY, USA, 1225\u20131234."}, {"ref": "[26] Hongwei Wang, Jia Wang, Jialin Wang, Miao Zhao, Weinan Zhang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2017. GraphGAN: Graph Representation Learning with Generative Adversarial Nets. CoRR abs/1711.08267 (2017)."}, {"ref": "[27] JingyuanWang,FeiGao,PengCui,ChaoLi,andZhangXiong.2014.Discovering urban spatio-temporal structure from time-evolving traffic networks. In Proceed- ings of the 16th Asia-Pacific Web Conference. Springer International Publishing, 93\u2013104."}, {"ref": "[28] XiaoWang,PengCui,JingWang,JianPei,WenwuZhu,andShiqiangYang.2017. Community Preserving Network Embedding."}, {"ref": "[29] Lekui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. 2018. Dy- namic Network Embedding by Modeling Triadic Closure Process. In The AAAI Conference on Artificial Intelligence."}, {"ref": "[30] L. Zhu, D. Guo, J. Yin, G. V. Steeg, and A. Galstyan. 2016. Scalable Temporal Latent Space Inference for Link Prediction in Dynamic Social Networks. IEEE Transactions on Knowledge and Data Engineering 28, 10 (Oct 2016), 2765\u20132777."}]}, {"author": ["Franco Manessi", "Alessandro Rozza", "Mario Manzo"], "title": "Dynamic graph convolutional networks", "journal": "Pattern Recognition", "year": 2019, "DOI": "10.1016/j.patcog.2019.107000", "month": 8, "citations(google scholar)": 17, "abstract": "In many different classification tasks it is required to manage structured data, which are usually mod- eled as graphs. Moreover, these graphs can be dynamic, meaning that the vertices/edges of each graph may change over time. The goal is to exploit existing neural network architectures to model datasets that are best represented with graph structures that change over time. To the best of the authors\u2019 knowl- edge, this task has not been addressed using these kinds of architectures. Two novel approaches are pro- posed, which combine Long Short-Term Memory networks and Graph Convolutional Networks to learn long short-term dependencies together with graph structure. The advantage provided by the proposed methods is confirmed by the results achieved on four real world datasets: an increase of up to 12 per- centage points in Accuracy and F1 scores for vertex-based semi-supervised classification and up to 2 percentage points in Accuracy and F1 scores for graph-based supervised classification.", "keywords": ["Long Short-Term Memory", "Graph Convolutional Networks", "classification"], "reference_count": 41, "ccfClass": "B", "important": true, "references": [{"ref": "[1] F. Scarselli, M. Gori, A.C. Tsoi, M. Hagenbuchner, G. Monfardini, The graph neu- ral network model, IEEE Trans. Neural Netw. 20 (1) (2009) 61\u201380."}, {"ref": "[2] M. Bianchini, M. Maggini, L. Sarti, F. Scarselli, Recursive neural networks learn to localize faces, Pattern Recognit. Lett. 26 (12) (2005) 1885\u20131895."}, {"ref": "[3] J. Liu, M. Li, Q. Liu, H. Lu, S. Ma, Image annotation via graph learning, Pattern Recognit. 42 (2) (2009) 218\u2013228."}, {"ref": "[4] A. Srinivasan, S. Muggleton, R.D. King, M.J. Sternberg, Mutagenesis: ILP experi- ments in a non-determinate biological domain, in: Proceedings of the 4th In- ternational Workshop on Inductive Logic Programming, vol. 237, Citeseer, 1994, pp. 217\u2013232."}, {"ref": "[5] A. Jain, A.R. Zamir, S. Savarese, A. Saxena, Structural-RNN: deep learning on spatio-temporal graphs, in: CVPR, IEEE, 2016, pp. 5308\u20135317."}, {"ref": "[6] Y. Yuan, X. Liang, X. Wang, D.-Y. Yeung, A. Gupta, Temporal dynamic graph LSTM for action-driven video object detection, in: Proceedings of the IEEE In- ternational Conference on Computer Vision, 2017, pp. 1801\u20131810."}, {"ref": "[7] A. Rozza, M. Manzo, A. Petrosino, A novel graph-based fisher kernel method for semi-supervised learning, in: ICPR, 2014, pp. 3786\u20133791."}, {"ref": "18 F. Manessi, A. Rozza and M. Manzo/Pattern Recognition 97 (2020) 107000"}, {"ref": "[8] H. Xu, Y. Yang, L. Wang, W. Liu, Node classification in social network via a factor graph model, in: PAKDD, 2013, pp. 213\u2013224."}, {"ref": "[9] Y. Zhao, G. Wang, P.S. Yu, S. Liu, S. Zhang, Inferring social roles and statuses in social networks, in: ACM SIGKDD, ACM, 2013, pp. 695\u2013703."}, {"ref": "[10] Y. Dong, Y. Yang, J. Tang, Y. Yang, N.V. Chawla, Inferring user demographics and social strategies in mobile social networks, in: KDD \u201914, ACM, 2014, pp. 15\u201324."}, {"ref": "[11] J. Bruna, W. Zaremba, A. Szlam, Y. LeCun, Spectral networks and locally connected networks on graphs, ICLR, 2013."}, {"ref": "[12] M. Defferrard, X. Bresson, P. Vandergheynst, Convolutional neural networks on graphs with fast localized spectral filtering, NIPS, 2016."}, {"ref": "[13] D.K. Duvenaud, D. Maclaurin, J. Iparraguirre, R. Bombarell, T. Hirzel, A. Aspu-ru-Guzik, R.P. Adams, Convolutional networks on graphs for learning molecular fingerprints, NIPS, 2015."}, {"ref": "[14] T.N. Kipf, M. Welling, Semi-supervised classification with graph convolutional networks, ICLR, 2017."}, {"ref": "[15] Y. Li, D. Tarlow, M. Brockschmidt, R.S. Zemel, Gated graph sequence neural networks, ICLR, 2016."}, {"ref": "[16] S. Hochreiter, J. Schmidhuber, Long short-term memory, Neural Comput. 9 (8)(1997) 1735\u20131780."}, {"ref": "[17] L.C. Jain, L.R. Medsker, Recurrent Neural Networks: Design and Applications,1st ed., CRC Press, Inc., 1999."}, {"ref": "[18] Y. Lecun, L. Bottou, Y. Bengio, P. Haffner, Gradient-based learning applied to document recognition, in: Proceedings of the IEEE, 1998, pp. 2278\u20132324."}, {"ref": "[19] X. Zhu, Z. Ghahramani, J. Lafferty, et al., Semi-supervised learning using gaussian fields and harmonic functions, in: ICML, vol. 3, 2003, pp. 912\u2013919."}, {"ref": "[20] Y. Boykov, O. Veksler, R. Zabih, Fast approximate energy minimization via graph cuts, IEEE Trans. Pattern Anal. Mach. Intell. 23 (11) (2001) 1222\u20131239."}, {"ref": "[21] B. Wang, J. Tsotsos, Dynamic label propagation for semi-supervised multi-class multi-label classification, Pattern Recognit. 52 (2016) 75\u201384."}, {"ref": "[22] A. Grover, J. Leskovec, node2vec: Scalable feature learning for networks, in:ACM SIGKDD, ACM, 2016, pp. 855\u2013864."}, {"ref": "[23] B. Perozzi, R. Al-Rfou, S. Skiena, DeepWalk: online learning of social representations, in: ACM SIGKDD, ACM, 2014, pp. 701\u2013710."}, {"ref": "[24] F.B. Silva, R.d.O. Werneck, S. Goldenstein, S. Tabbone, R.d.S. Torres, Graph-based bag-of-words for classification, Pattern Recognit. 74 (2018) 266\u2013285."}, {"ref": "[25] K. Li, S. Guo, N. Du, J. Gao, A. Zhang, Learning, analyzing and predicting object roles on dynamic networks, in: IEEE ICDM, 2013, pp. 428\u2013437."}, {"ref": "[26] Y. Yao, L. Holder, Scalable SVM-based classification in dynamic graphs, in: IEEE ICDM, 2014, pp. 650\u2013659."}, {"ref": "[27] Y. Pei, J. Zhang, G.H. Fletcher, M. Pechenizkiy, Node classification in dynamic social networks, in: AALTD 2016: 2nd ECML-PKDD International Workshop on Advanced Analytics and Learning on Temporal Data, 2016, pp. 54\u201393."}, {"ref": "[28] M. Gori, G. Monfardini, F. Scarselli, A new model for learning in graph domains, in: Proceedings of the 2005 IEEE International Joint Conference on Neural Networks, vol. 2, 2005, pp. 729\u2013734."}, {"ref": "[29] K. Cho, B. van Merrie\u0308nboer, C\u0327. Gu\u0308lc\u0327ehre, D. Bahdanau, F. Bougares, H. Schwenk,Y. Bengio, Learning phrase representations using RNN encoder\u2013decoder for statistical machine translation, in: EMNLP, 2014, pp. 1724\u20131734."}, {"ref": "[30] D.K. Hammond, P. Vandergheynst, R. Gribonval, Wavelets on graphs via spectral graph theory, Appl. Comput. Harmon. Anal. 30 (2) (2011) 129\u2013150."}, {"ref": "[31] Y. Seo, M. Defferrard, P. Vandergheynst, X. Bresson, Structured sequence mod- eling with graph convolutional recurrent networks, in: International Confer- ence on Neural Information Processing, Springer, 2018, pp. 362\u2013373."}, {"ref": "[32] F. Monti, M. Bronstein, X. Bresson, Geometric matrix completion with recur- rent multi-graph neural networks, in: NIPS 30, 2017, pp. 3697\u20133707."}, {"ref": "[33] I. Goodfellow, Y. Bengio, A. Courville, Deep Learning, MIT Press, 2016."}, {"ref": "[34] M. Defferrard, X. Bresson, P. Vandergheynst, Convolutional neural networks on graphs with fast localized spectral filtering, in: NIPS, 2016, pp. 3844\u20133852. [35] M. Ge\u0301nois, C.L. Vestergaard, J. Fournet, A. Panisson, I. Bonmarin, A. Barrat, Data on face-to-face contacts in an office building suggest a low-cost vaccination strategy based on community linkers, Netw. Sci. 3 (2015) 326\u2013347."}, {"ref": "[36] M. Hashemian, W. Qian, K.G. Stanley, N.D. Osgood, Temporal aggregation im- pacts on epidemiological simulations employing microcontact data, BMC Med.Inf. Decis. Making 12 (1) (2012) 132."}, {"ref": "[37] H.S. Koppula, R. Gupta, A. Saxena, Learning human activities and object affordances from RGB-D videos, Int. J. Rob. Res. 32 (8) (2013) 951\u2013970."}, {"ref": "[38] D.G. Lowe, Object recognition from local scale-invariant features, in: ICCV,IEEE, 1999, pp. 1150\u20131157."}, {"ref": "[39] M. Mu\u0308ller, T. Ro\u0308der, M. Clausen, B. Eberhardt, B. Kru\u0308ger, A. Weber, Documentation Mocap Database HDM05, Technical Report, Universita\u0308t Bonn, 2007."}, {"ref": "[40] D. Kingma, J. Ba, Adam: a method for stochastic optimization, ICLR, 2015."}, {"ref": "[41] F. Manessi, A. Rozza, S. Bianco, P. Napoletano, R. Schettini, Automated pruning for deep neural network compression, in: Proceedings of the 24th International Conference on Pattern Recognition, 2018, pp. 657\u2013664."}]}, {"author": ["Lekui Zhou", "Yang Yang", "Xiang Ren", "Fei Wu", "Yueting Zhuang"], "title": "Dynamic Network Embedding by Modeling Triadic Closure Process", "journal": "AAAI Conference on Artificial Intelligence", "year": 2018, "DOI": "", "month": 4, "citations(google scholar)": 59, "abstract": "Network embedding, which aims to learn the low-dimensional representations of vertices, is an important task and has attracted considerable research efforts recently. In real world, networks, like social network and biological networks, are dynamic and evolving over time. However, almost all the existing network embedding methods focus on static networks while ignore network dynamics. In this paper, we present a novel representation learning approach, DynamicTriad, to preserve both structural information and evolution patterns of a given network. The general idea of our approach is to impose triad, which is a group of three vertices and is one of the basic units of networks. In particular, we model how a closed triad, which consists of three vertices connected with each other, develops from an open triad that has two of three vertices not connected with each other. This triadic closure process is a fundamental mechanism in the formation and evolution of networks, thereby makes our model being able to capture the network dynamics and to learn representation vectors for each vertex at different time steps. Experimental results on three real-world networks demonstrate that, compared with several state-of-the-art techniques, DynamicTriad achieves substantial gains in several application scenarios. For example, our approach can effectively be applied and help to identify telephone frauds in a mobile network, and to predict whether a user will repay her loans or not in a loan network.", "keywords": ["Network Embedding", "Dynamic Network\u00df", "Triad Closure Process"], "reference_count": 30, "ccfClass": "A", "important": true, "references": [{"ref": "Belkin, M., and Niyogi, P. 2001. Laplacian eigenmaps and spectral techniques for embedding and clustering. In NIPS, volume 14, 585\u2013591."}, {"ref": "Coleman, J. S. 1994. Foundations of social theory. American Political Science Review 85(1):263."}, {"ref": "Dempster, A. P.; Laird, N. M.; and Rubin, D. B. 1977. Maxi- mum likelihood from incomplete data via the em algorithm. JOURNAL OF THE ROYAL STATISTICAL SOCIETY, SE- RIES B 39(1):1\u201338."}, {"ref": "Dong, Y.; Chawla, N. V.; and Swami, A. 2017. metap- ath2vec: Scalable representation learning for heterogeneous networks. In Proceedings of the 23rd ACM SIGKDD In- ternational Conference on Knowledge Discovery and Data Mining, 135\u2013144. ACM."}, {"ref": "Duchi, J.; Hazan, E.; and Singer, Y. 2011. Adaptive subgra- dient methods for online learning and stochastic optimiza- tion. Journal of Machine Learning Research 12(Jul):2121\u2013 2159."}, {"ref": "Erds, D.; Gemulla, R.; and Terzi, E. 2014. Reconstruct- ing graphs from neighborhood data. ACM Transactions on Knowledge Discovery From Data 8(4):23."}, {"ref": "Grover, A., and Leskovec, J. 2016. node2vec: Scalable fea- ture learning for networks. In KDD\u201916, 855\u2013864."}, {"ref": "Ho, Q.; Yin, J.; and Xing, E. P. 2016. Latent space inference of internet-scale networks. Journal of Machine Learning Research 17(78):1\u201341."}, {"ref": "Hoff, P. D.; Raftery, A. E.; and Handcock, M. S. 2012. La- tent space approaches to social network analysis. Journal of the American Statistical Association 97(460):1090\u20131098."}, {"ref": "Huang, H.; Tang, J.; Liu, L.; Luo, J.; and Fu, X. 2015. Tri- adic closure pattern analysis and prediction in social net- works. IEEE Transactions on Knowledge and Data Engi- neering 27(12):3374\u20133389."}, {"ref": "Jolliffe, I. 2002. Principal component analysis. Wiley On- line Library."}, {"ref": "Kossinets, G., and Watts, D. J. 2006. Empirical analysis of an evolving social network. science 311(5757):88\u201390."}, {"ref": "Kruskal, J. B. 1964. Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis. Psychometrika 29(1):1\u201327."}, {"ref": "Maaten, L. v. d., and Hinton, G. 2008. Visualizing data using t-sne. Journal of Machine Learning Research 9(Nov):2579\u2013 2605."}, {"ref": "Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; and Dean, J. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems, 3111\u20133119."}, {"ref": "Perozzi, B.; Al-Rfou, R.; and Skiena, S. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD International Conference on Knowl- edge Discovery and Data Mining, KDD \u201914, 701\u2013710. New York, NY, USA: ACM."}, {"ref": "Qi, G.; Aggarwal, C. C.; and Huang, T. S. 2013. Link pre- diction across networks by biased cross-network sampling. In ECML/PKDD\u201913, 793\u2013804."}, {"ref": "Roweis, S. T., and Saul, L. K. 2000. Nonlinear dimen- sionality reduction by locally linear embedding. science 290(5500):2323\u20132326."}, {"ref": "Sarkar, P., and Moore, A. W. 2005. Dynamic social network analysis using latent space models. ACM SIGKDD Explo- rations Newsletter 7(2):31\u201340."}, {"ref": "Sun, J.; Faloutsos, C.; Papadimitriou, S.; and Yu, P. S. 2007. Graphscope: parameter-free mining of large time-evolving graphs. In Proceedings of the 13th ACM SIGKDD interna- tional conference on Knowledge discovery and data mining, 687\u2013696. ACM."}, {"ref": "Tang, J.; Zhang, J.; Yao, L.; Li, J.; Zhang, L.; and Su, Z. 2008. Arnetminer: extraction and mining of academic so- cial networks. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, 990\u2013998. ACM."}, {"ref": "Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, Q. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web, 1067\u20131077. ACM."}, {"ref": "Tantipathananandh, C.; Berger-Wolf, T.; and Kempe, D. 2007. A framework for community identification in dynamic social networks. In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining, 717\u2013726. ACM."}, {"ref": "Tenenbaum, J. B.; De Silva, V.; and Langford, J. C. 2000. A global geometric framework for nonlinear dimensionality reduction. science 290(5500):2319\u20132323."}, {"ref": "Wang, Z.; Zhang, J.; Feng, J.; and Chen, Z. 2014. Knowl- edge graph embedding by translating on hyperplanes. In AAAI, 1112\u20131119. Citeseer."}, {"ref": "Wang, D.; Cui, P.; and Zhu, W. 2016. Structural deep net- work embedding. In KDD\u201916, 1225\u20131234."}, {"ref": "Zhang, T.; Cui, P.; Faloutsos, C.; Lu, Y.; Ye, H.; Zhu, W.; and Yang, S. 2016. Come-and-go patterns of group evolu- tion: A dynamic model. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discov- ery and Data Mining, 1355\u20131364. ACM."}, {"ref": "Zhu, L.; Guo, D.; Yin, J.; Steeg, G. V.; and Galstyan, A. 2014. Scalable link prediction in dynamic net- works via non-negative matrix factorization. arXiv preprint arXiv:1411.3675."}, {"ref": "Zhu, L.; Guo, D.; Yin, J.; Ver Steeg, G.; and Galstyan, A. 2016. Scalable temporal latent space inference for link pre- diction in dynamic social networks. IEEE Transactions on Knowledge and Data Engineering 28(10):2765\u20132777."}, {"ref": "Zhuang, H.; Sun, Y.; Tang, J.; Zhang, J.; and Sun, X. 2013. Influence maximization in dynamic social networks. In Data Mining (ICDM), 2013 IEEE 13th International Conference on, 1313\u20131318. IEEE."}]}, {"author": ["Xi Liu", "Ping-Chun Hsieh", "Nick Duffield", "Rui Chen", "Muhe Xie", "Xidao Wen"], "title": "Real-Time Streaming Graph Embedding Through Local Actions", "journal": "International World Wide Web Conferences", "year": 2019, "DOI": "10.1145/3308560.3316585", "month": 5, "citations(google scholar)": 1, "abstract": "Recently, considerable research attention has been paid to graph embedding, a popular approach to construct representations of vertices in latent space. Due to the curse of dimensionality and sparsity in graphical datasets, this approach has become indispensable for machine learning tasks over large networks. The majority of the existing literature has considered this technique under the assumption that the network is static. However, networks in many applications, including social networks, collaboration networks, and recommender systems, nodes, and edges accrue to a growing network as streaming. A small number of very recent results have addressed the problem of embedding for dynamic networks. However, they either rely on knowledge of vertex attributes, suffer high-time complexity or need to be re-trained without closed-form expression. Thus the approach of adapting the existing methods designed for static networks or dynamic networks to the streaming environment faces non-trivial technical challenges.These challenges motivate developing new approaches to the problems of streaming graph embedding. In this paper, we propose a new framework that is able to generate latent representations for new vertices with high efficiency and low complexity under specified iteration rounds. We formulate a constrained optimization problem for the modification of the representation resulting from a stream arrival. We show this problem has no closed-form solution and instead develop an online approximation solution. Our solution follows three steps: (1) identify vertices affected by newly arrived ones, (2) generating latent features for new vertices, and (3) updating the latent features of the most affected vertices. The new representations are guaranteed to be feasible in the original constrained optimization problem. Meanwhile, the solution only brings about a small change to existing representations and only slightly changes the value of the objective function. Multi-class classification and clustering on five real-world networks demonstrate that our model can efficiently update vertex representations and simultaneously achieve comparable or even better performance compared with model retraining.", "keywords": ["Streaming Graph Embedding", "Local Actions", "latent representations"], "reference_count": 30, "ccfClass": "A", "important": true, "references": [{"ref": "[1] William L Hamilton, Rex Ying, and Jure Leskovec. Representation learning on graphs: Methods and applications. IEEE Data Engineering Bulletin, 2017."}, {"ref": "[2] Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for net- works. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 855\u2013864, 2016."}, {"ref": "[3] Ye Li, Chaofeng Sha, Xin Huang, and Yanchun Zhang. Community detection in attributed graphs: An embedding approach. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, pages 338\u2013345, 2018."}, {"ref": "[4] Zhu Cao, Linlin Wang, and Gerard de Melo. Link prediction via subgraph embedding-based convex matrix completion. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, pages 2803\u20132810, 2018."}, {"ref": "[5] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. Line: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web, pages 1067\u20131077, 2015."}, {"ref": "[6] Daixin Wang, Peng Cui, and Wenwu Zhu. Structural deep network embedding. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1225\u20131234, 2016."}, {"ref": "[7] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 701\u2013710, 2014."}, {"ref": "[8] Leonardo FR Ribeiro, Pedro HP Saverese, and Daniel R Figueiredo. struc2vec: Learning node representations from structural identity. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 385\u2013394, 2017."}, {"ref": "[9] Claire Donnat, Marinka Zitnik, David Hallac, and Jure Leskovec. Learning structural node embeddings via diffusion wavelets. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1320\u20131329, 2018."}, {"ref": "[10] ShiyuChang,YangZhang,JiliangTang,DaweiYin,YiChang,MarkAHasegawa- Johnson, and Thomas S Huang. Positive-unlabeled learning in streaming net- works. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 755\u2013764, 2016."}, {"ref": "[11] Lun Du, Yun Wang, Guojie Song, Zhicong Lu, and Junshan Wang. Dynamic network embedding: An extended approach for skip-gram based network em- bedding. In Proceedings of the 17th International Joint Conferences on Artificial Intelligence, pages 2086\u20132092, 2018."}, {"ref": "[12] WillHamilton,ZhitaoYing,andJureLeskovec.Inductiverepresentationlearning on large graphs. In Advances in Neural Information Processing Systems, pages 1024\u20131034, 2017."}, {"ref": "[13] XiLiu,MuheXie,XidaoWen,RuiChen,YongGe,NickDuffield,andNaWang. A semi-supervised and inductive embedding model for churn prediction of large- scale mobile games. In IEEE International Conference on Data Mining (ICDM), 2018."}, {"ref": "[14] Jianxin Ma, Peng Cui, and Wenwu Zhu. Depthlgp: Learning embeddings of out-of-sample nodes in dynamic networks. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, pages 370\u2013377, 2018."}, {"ref": "[15] GiangHoangNguyen,JohnBoazLee,RyanARossi,NesreenKAhmed,Eunyee Koh, and Sungchul Kim. Continuous-time dynamic network embeddings. In Companion of the The Web Conference 2018 on The Web Conference 2018, pages 969\u2013976. International World Wide Web Conferences Steering Committee, 2018."}, {"ref": "[16] Qixiang Wang, Shanfeng Wang, Maoguo Gong, and Yue Wu. Feature hashing for network representation learning. In IJCAI, pages 2812\u20132818, 2018."}, {"ref": "[17] JundongLi,HarshDani,XiaHu,JiliangTang,YiChang,andHuanLiu.Attributed network embedding for learning in a dynamic environment. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, pages 387\u2013396, 2017."}, {"ref": "[18] Ling Jian, Jundong Li, and Huan Liu. Toward online node classification on streaming networks. Data Mining and Knowledge Discovery, 32(1):231\u2013257, 2018."}, {"ref": "[19] Dingyuan Zhu, Peng Cui, Ziwei Zhang, Jian Pei, and Wenwu Zhu. High-order proximity preserved embedding for dynamic networks. IEEE Transactions on Knowledge and Data Engineering, 2018."}, {"ref": "[20] Palash Goyal and Emilio Ferrara. Graph embedding techniques, applications, and performance: A survey. Knowledge-Based Systems, 151:78\u201394, 2018."}, {"ref": "[21] Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps and spectral techniques for embedding and clustering. In Advances in Neural Information Processing Systems, pages 585\u2013591, 2002."}, {"ref": "[22] Johann Paratte and Lionel Martin. Fast eigenspace approximation using random signals. EPFL-ARTICLE, 2017."}, {"ref": "[23] Zhiqiang Xu and Xin Gao. On truly block eigensolvers via riemannian optimization. In International Conference on Artificial Intelligence and Statistics, pages 168\u2013177, 2018."}, {"ref": "[24] HuikangLiu,WeijieWu,and Anthony Man-ChoSo.Quadratic optimization with orthogonality constraints: explicit \u0142ojasiewicz exponent and linear convergence of line-search methods. In Proceedings of the 33rd International Conference on International Conference on Machine Learning, pages 1158\u20131167, 2016."}, {"ref": "[25] SanchengPeng,YongmeiZhou,LihongCao,ShuiYu,JianweiNiu,andWeijiaJia. Influence analysis in social networks: a survey. Journal of Network and Computer Applications, pages 17\u201332, 2018."}, {"ref": "[26] YuanZhang,TianshuLyu,andYanZhang.Cosine:Community-preservingsocial network embedding from information diffusion cascades. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, pages 2620\u20132627, 2018."}, {"ref": "[27] Franco Manessi, Alessandro Rozza, and Mario Manzo. Dynamic graph convolu- tional networks. arXiv preprint arXiv:1704.06199, 2017."}, {"ref": "[28] Rakshit Trivedi, Mehrdad Farajtbar, Prasenjeet Biswal, and Hongyuan Zha. Rep- resentation learning over dynamic graphs. arXiv preprint arXiv:1803.04051, 2018. [29] Le-kui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. Dynamic network embedding by modeling triadic closure process. In Proceedings of the32nd AAAI Conference on Artificial Intelligence, pages 571\u2013578, 2018."}, {"ref": "[30] Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, and Jie Tang. Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec. In Proceedings of the 11th ACM International Conference on Web Search and Data Mining, pages 459\u2013467, 2018."}]}, {"author": ["Hogun Park", "Jennifer Neville"], "title": "Exploiting Interaction Links for Node Classification with Deep Graph Neural Networks", "journal": "International Joint Conference on Artificial Intelligence", "year": 2019, "DOI": "10.24963/ijcai.2019/447", "month": 8, "citations(google scholar)": 0, "abstract": "Node classification is an important problem in re- lational machine learning. However, in scenarios where graph edges represent interactions among the entities (e.g., over time), the majority of cur- rent methods either summarize the interaction in- formation into link weights or aggregate the links to produce a static graph. In this paper, we propose a neural network architecture that jointly captures both temporal and static interaction patterns, which we call Temporal-Static-Graph-Net (TSGNet). Our key insight is that leveraging both a static neigh- bor encoder, which can learn aggregate neighbor patterns, and a graph neural network-based recur- rent unit, which can capture complex interaction patterns, improve the performance of node clas- sification. In our experiments on node classifica- tion tasks, TSGNet produces significant gains com- pared to state-of-the-art methods\u2014reducing clas- sification error up to 24% and an average of 10% compared to the best competitor on four real-world networks and one synthetic dataset.", "keywords": ["Interaction Links", "Node Classification", "Deep Graph Neural Networks", "Temporal-Static-Graph-Net"], "reference_count": 22, "ccfClass": "A", "important": true, "references": [{"ref": "[Chen et al., 2018] Jie Chen, Tengfei Ma, and Cao Xiao. Fastgcn: fast learning with graph convolutional networks via importance sampling. In Proceedings of International Conference on Learning Representations (ICLR), 2018."}, {"ref": "[Grover and Leskovec, 2016] Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In Proceedings of SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 855\u2013864, 2016."}, {"ref": "[Hamilton et al., 2017] William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Proceedings of Conference on Neural Infor- mation Processing Systems (NeurIPS), pages 1024\u20131034, 2017."}, {"ref": "[Hochreiter and Schmidhuber, 1997] Sepp Hochreiter and Ju \u0308rgen Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735\u20131780, 1997."}, {"ref": "[Hornik, 1991] Kurt Hornik. Approximation capabilities of multilayer feedforward networks. Neural networks, 4(2):251\u2013257, 1991."}, {"ref": "[Jensen et al., 2004] David Jensen, Jennifer Neville, and Brian Gallagher. Why collective inference improves re- lational classification. In Proceedings of SIGKDD Inter- national Conference on Knowledge Discovery and Data Mining, pages 593\u2013598, 2004."}, {"ref": "[Kingma and Ba, 2014] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Proceed- ings of International Conference on Learning Representa- tions (ICLR), 2014."}, {"ref": "[Kipf and Welling, 2016] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In Proceedings of International Conference on Learning Representations (ICLR), 2016."}, {"ref": "[Liaoetal.,2018] LiziLiao,XiangnanHe,HanwangZhang, and Tat-Seng Chua. Attributed social network embedding. IEEE Transactions on Knowledge and Data Engineering, 30(12):2257\u20132270, 2018."}, {"ref": "[Lu and Getoor, 2003] Qing Lu and Lise Getoor. Link-based classification. In Proceedings of International Conference on Machine Learning (ICML), pages 496\u2013503, 2003."}, {"ref": "[Ma et al., 2018] Jianxin Ma, Peng Cui, and Wenwu Zhu. Depthlgp: learning embeddings of out-of-sample nodes in dynamic networks. In Proceedings of AAAI Conference on Artificial Intelligence, 2018."}, {"ref": "[Murphy et al., 2019] Ryan L Murphy, Balasubramaniam Srinivasan, Vinayak Rao, and Bruno Ribeiro. Janossy pooling: Learning deep permutation-invariant functions for variable-size inputs. In Proceedings of International Conference on Learning Representations (ICLR), 2019."}, {"ref": "[Nguyen et al., 2018] Giang Hoang Nguyen, John Boaz Lee, Ryan A Rossi, Nesreen K Ahmed, Eunyee Koh, and Sungchul Kim. Continuous-time dynamic network em- beddings. In Proceedings of BigNet Workshop in The Web Conference (WWW), 2018."}, {"ref": "[Park et al., 2017] Hogun Park, John Moore, and Jennifer Neville. Deep dynamic relational classifiers: Exploiting dynamic neighborhoods in complex networks. In Proceed- ings of MAISoN Workshop in International Conference on Web Search and Data Mining (WSDM), 2017."}, {"ref": "[Pfeiffer et al., 2015] Joseph J. Pfeiffer, III, Jennifer Neville, and Paul N. Bennett. Overcoming relational learning bi- ases to accurately predict preferences in large scale net- works. In Proceedings of International World Wide Web Conference (WWW), pages 853\u2013863, 2015."}, {"ref": "[Rossi and Neville, 2012] Ryan Rossi and Jennifer Neville. Time-evolving relational classification and ensemble methods. In Proceedings of Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), pages 1\u201313, 2012."}, {"ref": "[Sharan and Neville, 2008] Umang Sharan and Jennifer Neville. Temporal-relational classifiers for prediction in evolving domains. In Proceedings of International Con- ference on Data Mining (ICDM), pages 540\u2013549, 2008."}, {"ref": "[Xuetal.,2019] KeyuluXu,WeihuaHu,JureLeskovec,and Stefanie Jegelka. How powerful are graph neural net- works? In Proceedings of International Conference on Learning Representations (ICLR), 2019."}, {"ref": "[Yang et al., 2011] Tianbao Yang, Yun Chi, Shenghuo Zhu, Yihong Gong, and Rong Jin. Detecting communities and their evolutions in dynamic social networks \u2013 a bayesian approach. Machine learning, 82(2):157\u2013189, 2011."}, {"ref": "[Zhang et al., 2018] Ziwei Zhang, Peng Cui, Jian Pei, Xiao Wang, and Wenwu Zhu. Timers: Error-bounded svd restart on dynamic networks. In Proceedings of AAAI Conference on Artificial Intelligence, 2018."}, {"ref": "[Zhou et al., 2018] Lekui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. Dynamic network embedding by modeling triadic closure process. In Proceedings of AAAI Conference on Artificial Intelligence, 2018."}, {"ref": "[Zhu et al., 2018] Dingyuan Zhu, Peng Cui, Ziwei Zhang, Jian Pei, and Wenwu Zhu. High-order proximity pre- served embedding for dynamic networks. IEEE Transac- tions on Knowledge and Data Engineering, 30(11):2134\u2013 2144, 2018."}]}, {"author": ["Aynaz Taheri", "Kevin Gimpel", "Tanya Y. Berger-Wolf"], "title": "Learning to Represent the Evolution of Dynamic Graphs with Recurrent Models", "journal": "International World Wide Web Conferences", "year": 2019, "DOI": "10.1145/3308560.3316581", "month": 5, "citations(google scholar)": 0, "abstract": "Graph representation learning for static graphs is a well studied topic. Recently, a few studies have focused on learning temporal information in addition to the topology of a graph. Most of these studies have relied on learning to represent nodes and substructures in dynamic graphs. However, the representation learning problem for entire graphs in a dynamic context is yet to be addressed. In this paper, we propose an unsupervised representation learning architecture for dynamic graphs, designed to learn both the topological and temporal features of the graphs that evolve over time. The approach consists of a sequence-to-sequence encoder-decoder model embedded with gated graph neural networks (GGNNs) and long short-term memory networks (LSTMs). The GGNN is able to learn the topology of the graph at each time step, while LSTMs are leveraged to propagate the temporal information among the time steps. Moreover, an encoder learns the temporal dynamics of an evolving graph and a decoder reconstructs the dynamics over the same period of time using the encoded representation provided by the encoder. We demonstrate that our approach is capable of learning the representation of a dynamic graph through time by applying the embeddings to dynamic graph classification using a real world dataset of animal behaviour.", "keywords": ["dynamic graph", "representation learning", "recurrent models"], "reference_count": 42, "ccfClass": "A", "important": true, "references": [{"ref": "[1] B. Adhikari, Y. Zhang, N. Ramakrishnan, and B. A. Prakash. 2017. Distributed Representations of Subgraphs. In DaMNet."}, {"ref": "[2] Chainarong Amornbunchornvej, Ivan Brugere, Ariana Strandburg-Peshkin, Damien R. Farine, Margaret C. Crofoot, and Tanya Y. Berger-Wolf. 2018. Coordi- nation Event Detection and Initiator Identification in Time Series Data. ACM Trans. Knowl. Discov. Data 12, 5 (2018), 53:1\u201353:33."}, {"ref": "[3] Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2013. Spectral Networks and Locally Connected Networks on Graphs. CoRR (2013)."}, {"ref": "[4] Chih-ChungChangandChih-JenLin.2011.LIBSVM:alibraryforsupportvector machines. ACM TIST 2 (2011)."}, {"ref": "[5] Jinyin Chen, Xuanheng Xu, Yangyang Wu, and Haibin Zheng. 2018. GC-LSTM: Graph Convolution Embedded LSTM for Dynamic Link Prediction. arXiv preprint arXiv:1812.04206 (2018)."}, {"ref": "[6] Kyunghyun Cho, Bart Van Merrie\u0308nboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 (2014)."}, {"ref": "[7] MCCrofoot,RWKays,andWikelskiM.2015.Datafrom:Shareddecision-making drives collective movement in wild baboons. Movebank Data Repository (2015)."}, {"ref": "[8] Michae\u0308l Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convo- lutional neural networks on graphs with fast localized spectral filtering. arXiv (2016)."}, {"ref": "[9] LunDu,YunWang,GuojieSong,ZhicongLu,andJunshanWang.2018.Dynamic Network Embedding: An Extended Approach for Skip-gram based Network Embedding.. In IJCAI."}, {"ref": "[10] Nan Du, Hanjun Dai, Rakshit Trivedi, Utkarsh Upadhyay, Manuel Gomez- Rodriguez, and Le Song. 2016. Recurrent marked temporal point processes: Embedding event history to vector. In Proceedings of the 22nd ACM SIGKDD Inter- national Conference on Knowledge Discovery and Data Mining. ACM, 1555\u20131564."}, {"ref": "[11] DavidDuvenaud,DougalMaclaurin,JorgeIparraguirre,RafaelBombarell,Timo- thy Hirzel, Ala\u0301n Aspuru-Guzik, and Ryan P Adams. 2015. Convolutional networks on graphs for learning molecular fingerprints. In NIPS."}, {"ref": "[12] JustinGilmer,SamuelS.Schoenholz,PatrickF.Riley,OriolVinyals,andGeorgeE. Dahl. 2017. Neural Message Passing for Quantum Chemistry. CoRR (2017)."}, {"ref": "[13] JustinGilmer,SamuelSSchoenholz,PatrickFRiley,OriolVinyals,andGeorgeE Dahl. 2017. Neural message passing for quantum chemistry. arXiv preprint arXiv:1704.01212 (2017)."}, {"ref": "[14] Marco Gori, Gabriele Monfardini, and Franco Scarselli. [n. d.]. A new model for learning in graph domains. In Proceedings of the 2005 IEEE International Joint Conference on Neural Networks (IJCNN\u201905), Vol. 2. IEEE, 729\u2013734."}, {"ref": "[15] PalashGoyal,SujitRokkaChhetri,andArquimedesCanedo.2018.dyngraph2vec: Capturing network dynamics using dynamic graph representation learning. arXiv preprint arXiv:1809.02657 (2018)."}, {"ref": "[16] Palash Goyal, Nitin Kamra, Xinran He, and Yan Liu. 2017. DynGEM: Deep Embedding Method for Dynamic Graphs. CoRR abs/1805.11273 (2017)."}, {"ref": "[17] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In KDD."}, {"ref": "[18] M. Henaff, J. Bruna, and Y. LeCun. 2015. Deep convolutional networks on graph- structured data. arXiv (2015)."}, {"ref": "[19] Bala\u0301zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based recommendations with recurrent neural networks. In ICLR."}, {"ref": "[20] S. Hochreiter and J. Schmidhuber. 1997. Long short-term memory. Neural computation (1997)."}, {"ref": "[21] Petter Holme and Jari Sarama\u0308ki. 2012. Temporal networks. Physics reports 519, 3 (2012), 97\u2013125."}, {"ref": "[22] David Kempe, Jon Kleinberg, and Amit Kumar. 2002. Connectivity and inference problems for temporal networks. J. Comput. System Sci. 64, 4 (2002), 820\u2013842."}, {"ref": "[23] John Boaz Lee, Ryan Rossi, and Xiangnan Kong. 2018. Graph classification using structural attention. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 1666\u20131674."}, {"ref": "[24] Jia Li, Kaiser Asif, Hong Wang, Brian D Ziebart, and Tanya Y Berger-Wolf. 2016. Adversarial Sequence Tagging.. In IJCAI."}, {"ref": "[25] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. 2016. Gated graph sequence neural networks. In ICLR."}, {"ref": "[26] Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. JMLR (2008)."}, {"ref": "[27] AnnamalaiNarayanan,MahinthanChandramohan,LihuiChen,YangLiu,and Santhoshkumar Saminathan. 2016. subgraph2vec: Learning distributed represen- tations of rooted sub-graphs from large graphs. MLG (2016)."}, {"ref": "[28] AnnamalaiNarayanan,MahinthanChandramohan,RajasekarVenkatesan,Lihui Chen, Yang Liu, and Shantanu Jaiswal. 2017. graph2vec: Learning Distributed Representations of Graphs. In MLG."}, {"ref": "[29] GiangHoangNguyen,JohnBoazLee,RyanARossi,NesreenKAhmed,Eunyee Koh, and Sungchul Kim. 2018. Continuous-time dynamic network embeddings. In International Workshop on Learning Representations for Big Networks at The Web Conference."}, {"ref": "[30] Mathias Niepert, Mohamed Ahmed, and Konstantin Kutzkov. 2016. Learning Convolutional Neural Networks for Graphs. In ICML."}, {"ref": "[31] B. Perozzi, R. Al-Rfou, and S Skiena. 2014. DeepWalk: Online learning of social representations. In KDD."}, {"ref": "[32] Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, and Hao Yang. 2018. Dynamic Graph Representation Learning via Self-Attention Networks. arXiv preprint arXiv:1812.09430 (2018)."}, {"ref": "[33] FrancoScarselli,MarcoGori,AhChungTsoi,MarkusHagenbuchner,andGabriele Monfardini. 2009. The graph neural network model. IEEE Transactions on Neural Networks 20, 1 (2009), 61\u201380."}, {"ref": "[34] Ariana Strandburg-Peshkin, Damien R Farine, Iain D Couzin, and Margaret C Crofoot. 2015. Shared decision-making drives collective movement in wild baboons. Science 348, 6241 (2015), 1358\u20131361."}, {"ref": "[35] Aynaz Taheri, Kevin Gimpel, and Tanya Berger-Wolf. 2018. Learning Graph Representations with Recurrent Neural Network Autoencoders. In KDD Deep Learning Day."}, {"ref": "[36] Rakshit Trivedi, Hanjun Dai, Yichen Wang, and Le Song. 2017. Know-evolve: Deep temporal reasoning for dynamic knowledge graphs. In ICML."}, {"ref": "[37] Rakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, and Hongyuan Zha. 2019. DyRep: Learning Representations over Dynamic Graphs. In International Conference on Learning Representations."}, {"ref": "[38] PengyangWang,YanjieFu,JiaweiZhang,PengfeiWang,YuZheng,andCharu Aggarwal. 2018. You are how you drive: Peer and temporal-aware representation learning for driving behavior analysis. In KDD. ACM."}, {"ref": "[39] Quan Wang, Zhendong Mao, Bin Wang, and Li Guo. 2017. Knowledge graph embedding: A survey of approaches and applications. IEEE Transactions on Knowledge and Data Engineering 29, 12 (2017), 2724\u20132743."}, {"ref": "[40] Pinar Yanardag and SVN Vishwanathan. 2015. Deep graph kernels. In KDD."}, {"ref": "[41] Muhan Zhang, Zhicheng Cui, Marion Neumann, and Yixin Chen. 2018. An End-to-End Deep Learning Architecture for Graph Classification. In AAAI."}, {"ref": "[42] Le-kuiZhou,YangYang,XiangRen,FeiWu,andYuetingZhuang.2018.Dynamic Network Embedding by Modeling Triadic Closure Process.. In AAAI."}]}, {"author": ["Hong Huang", "Jie Tang", "Lu Liu", "Jarder Luo", "Xiaoming Fu"], "title": "Triadic Closure Pattern Analysis and Prediction in Social Networks", "journal": "IEEE Transactions on Knowledge and Data Engineering", "year": 2015, "DOI": "10.1109/TKDE.2015.2453956", "month": 12, "citations(google scholar)": 24, "abstract": "We study the problem of group formation in online social networks. In particular, we focus on one of the most important human groups-the triad-and try to understand how closed triads are formed in dynamic networks, by employing data from a large microblogging network as the basis of our study. We formally define the problem of triadic closure prediction and conduct a systematic investigation. The study reveals how user demographics, network characteristics, and social properties influence the formation of triadic closure. We also present a probabilistic graphical model to predict whether three persons will form a closed triad in a dynamic network. Different kernel functions are incorporated into the proposed graphical model to quantify the similarity between triads. Our experimental results with the large microblogging dataset demonstrate the effectiveness (+10 percent over alternative methods in terms of F1-Score) of the proposed model for the prediction of triadic closure formation.", "keywords": ["Social network services", "Predictive models", "Social factors", "Graphical models", "Probabilistic logic"], "reference_count": 46, "ccfClass": "A", "important": true, "references": [{"ref": "1. L. Backstrom, D. Huttenlocher, J. Kleinberg, X. Lan, \"Group formation in large social networks: Membership growth and evolution\", Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 44-54, 2006."}, {"ref": "2. J. Coleman, Foundations of Social Theory, Cambridge, MA, USA:Harvard, 1990."}, {"ref": "3. D. Easley, J. Kleinberg, Networks Crowds and Markets, Cambridge, U.K.:Cambridge Univ. Press, pp. 6-1, 2010."}, {"ref": "4. J. Leskovec, L. Backstrom, R. Kumar, A. Tomkins, \"Microscopic evolution of social networks\", Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 462-470, 2008."}, {"ref": "5. P. W. Holland, S. Leinhardt, \"Transitivity in structural models of small groups\", Comparative Group Stud., vol. 2, no. 2, pp. 107-124, 1971."}, {"ref": "6. S. Wasserman, Social Network Analysis: Methods and Applications, Cambridge, MA, USA:Cambridge Univ. Press, vol. 8, 1994."}, {"ref": "7. J.-P. Eckmann, E. Moses, \"Curvature of co-links uncovers hidden thematic layers in the world wide web\", Proc. Nat. Acad. Sci., vol. 99, no. 9, pp. 5825-5829, 2002."}, {"ref": "8. E. Zheleva, H. Sharara, L. Getoor, \"Co-evolution of social and affiliation networks\", Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 1007-1016, 2009."}, {"ref": "9. A. Sala, L. Cao, C. Wilson, R. Zablit, H. Zheng, B. Y. Zhao, \"Measurement-calibrated graph models for social network experiments\", Proc. Int. Conf. World Wide Web, pp. 861-870, 2010."}, {"ref": "10. N. Z. Gong, W. Xu, L. Huang, P. Mittal, E. Stefanov, V. Sekar, D. Song, \"Evolution of social-attribute networks: Measurements modeling and implications using google+\", Proc. ACM Conf. Internet Meas. Conf., pp. 131-144, 2012."}, {"ref": "11. R. Milo, S. Itzkovitz, N. Kashtan, R. Levitt, S. Shen-Orr, I. Ayzenshtat, M. Sheffer, U. Alon, \"Superfamilies of evolved and designed networks\", Science, vol. 303, no. 5663, pp. 1538-1542, 2004."}, {"ref": "12. R. Milo, S. Shen Orr, S. Itzkovitz, N. Kashtan, D. Chklovskii, U. Alon, \"Network motifs: Simple building blocks of complex networks\", Science, vol. 298, pp. 824-827, 2002."}, {"ref": "13. D. M. Romero, J. Kleinberg, \"The directed closure process in hybrid social-information networks with an analysis of link formation on twitter\", Statistics, vol. 1050, pp. 12, 2010."}, {"ref": "14. T. Lou, J. Tang, J. Hopcroft, Z. Fang, X. Ding, \"Learning to predict reciprocity and triadic closure in social networks\", ACM Trans. Knowl. Discovery Data, vol. 7, no. 2, pp. 5, 2013."}, {"ref": "15. H. Huang, J. Tang, S. Wu, L. Liu, X. Fu, \"Mining triadic closure patterns in social networks\", Proc. Companion Publication 23rd Int. Conf. World Wide Web Companion, pp. 499-504, 2014."}, {"ref": "16. H. Kwak, C. Lee, H. Park, S. Moon, Proc. 19th Int. Conf. World Wide Web, pp. 591-600, 2010."}, {"ref": "17. L. Page, S. Brin, R. Motwani, T. Winograd, \"The pagerank citation ranking: Bringing order to the web\", 1998."}, {"ref": "18. S. Wu, J. M. Hofman, W. A. Mason, D. J. Watts, \"Who says what to whom on twitter\", Proc. Int. Conf. World Wide Web, pp. 705-714, 2011."}, {"ref": "19. R. S. Burt, \"The social structure of competition\", Explorations Econ. Sociol., vol. 65, pp. 103, 1993."}, {"ref": "20. T. Lou, J. Tang, \"Mining structural hole spanners through information diffusion in social networks\", Proc. Int. Conf. World Wide Web, pp. 837-848, 2013."}, {"ref": "21. K. C. Cook, R. S. Burt, N. Lin, \"Structural holes versus network closure as social capital\" in Social Capital: Theory and Research, Piscataway, NJ, USA:Transaction Publishers, 2001."}, {"ref": "22. Z. Sasovova, A. Mehra, S. P. Borgatti, M. C. Schippers, \"Network churn: The effects of self-monitoring personality on brokerage dynamics\", Administ. Sci. Quart., vol. 55, no. 4, pp. 639-670, 2010."}, {"ref": "23. D. Obstfeld, \"Social networks the tertius iungens orientation and involvement in innovation\", Administ. Sci. Quart., vol. 50, no. 1, pp. 100-130, 2005."}, {"ref": "24. J. Leskovec, D. Huttenlocher, J. Kleinberg, \"Signed networks in social media\", Proc. SIGCHI Conf. Human Factors Comput. Syst., pp. 1361-1370, 2010."}, {"ref": "25. J. Zhang, B. Liu, J. Tang, T. Chen, J. Li, \"Social influence locality for modeling retweeting behaviors\", Proc. 23rd Int. Joint Conf. Artif. Intell., pp. 2761-2767, 2013."}, {"ref": "26. J. M. Hammersley, P. Clifford, \"Markov field on finite graphs and lattices\", 1971."}, {"ref": "27. J. Lafferty, A. McCallum, F. C. Pereira, \"Conditional random fields: Probabilistic models for segmenting and labeling sequence data\", Proc. Int. Conf. Mach. Learn., pp. 282-289, 2001."}, {"ref": "28. J. Shawe Taylor, N. Cristianini, Kernel Methods for Pattern Analysis, Cambridge, MA, USA:Cambridge Univ. Press, 2004."}, {"ref": "29. M.-H. Yang, \"Kernel eigenfaces vs. kernel fisherfaces: Face recognition using kernel methods\", Proc. 5th IEEE Int. Conf. Automatic Face Gesture Recog., pp. 0215-0215, 2002.Show Context View Article Full Text: PDF\t(336KB) Google Scholar"}, {"ref": "30. A. Ben-Hur, W. S. Noble, \"Kernel methods for predicting protein\u2013protein interactions\", Bioinformatics, vol. 21, no. suppl 1, pp. i38-i46, 2005."}, {"ref": "31. L. Wasserman, All of Statistics: A Concise Course in Statistical Inference, New York, NY, USA:Springer, 2004."}, {"ref": "32. B. Schweizer, A. Sklar, Probabilistic Metric Spaces, Mineola, NY, USA:Courier Dover Publications, 2011."}, {"ref": "33. M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, I. H. Witten, \"The weka data mining software: An update\", ACM SIGKDD Explorations Newslett., vol. 11, no. 1, pp. 10-18, 2009."}, {"ref": "34. J. Hopcroft, T. Lou, J. Tang, \"Who will follow you back?reciprocal relationship prediction\", Proc. ACM Conf. Inf. Knowl. Manage., pp. 1137-1146, 2011."}, {"ref": "35. P. Klimek, S. Thurner, \"Triadic closure dynamics drives scaling laws in social multiplex networks\", New J. Phys., vol. 15, no. 6, pp. 063008, 2013."}, {"ref": "36. M. Li, H. Zou, S. Guan, X. Gong, K. Li, Z. Di, C.-H. Lai, \"A coevolving model based on preferential triadic closure for social media networks\", Sci. Rep., vol. 3, pp. 2512, 2013."}, {"ref": "37. Y. Dong, J. Tang, S. Wu, J. Tian, N. V. Chawla, J. Rao, H. Cao, \"Link prediction and recommendation across heterogeneous social networks\", Proc. Int. Conf. Data Mining, pp. 181-190, 2012."}, {"ref": "38. Y. Dong, Y. Yang, J. Tang, Y. Yang, N. V. Chawla, \"Inferring user demographics and social strategies in mobile social networks\", Proc. 20th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 15-24, 2014."}, {"ref": "39. J. Zhang, Z. Fang, W. Chen, J. Tang, \"Diffusion of following links in microblogging networks\", IEEE trans. Knowl. Data Eng., 2015."}, {"ref": "40. M. Zignani, S. Gaito, G. P. Rossi, X. Zhao, H. Zheng, B. Y. Zhao, \"Link and triadic closure delay: Temporal metrics for social network dynamics\", Proc. 8th Int. AAAI Conf. Weblogs Social Media, pp. 564-573, 2014."}, {"ref": "41. M. E. Newman, \"Clustering and preferential attachment in growing networks\", Phys. Rev. E, vol. 64, no. 2, pp. 025102, 2001."}, {"ref": "42. L. Katz, \"A new status index derived from sociometric analysis\", Psychometrika, vol. 18, no. 1, pp. 39-43, 1953."}, {"ref": "43. R. N. Lichtenwalter, J. T. Lussier, N. V. Chawla, \"New perspectives and methods in link prediction\", Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 243-252, 2010."}, {"ref": "44. D. Liben-Nowell, J. Kleinberg, \"The link-prediction problem for social networks\", J. Amer. Soc. Inf. Sci. Technol., vol. 58, no. 7, pp. 1019-1031, 2007."}, {"ref": "45. L. Backstrom, J. Leskovec, \"Supervised random walks: Predicting and recommending links in social networks\", Proc. ACM Int. Conf. Web Search Data Mining, pp. 635-644, 2011."}, {"ref": "46. J. Leskovec, D. Huttenlocher, J. Kleinberg, \"Predicting positive and negative links in online social networks\", Proc. Int. Conf. World Wide Web, pp. 641-650, 2010."}]}, {"author": ["Yue Meng", "Peng Wang", "Junyan Xiao", "Xiaoyu Zhou"], "title": "NeLSTM: A New Model for Temporal Link Prediction in Social Networks", "journal": "ICSC", "year": 2019, "DOI": "10.1109/ICOSC.2019.8665664", "month": 1, "citations(google scholar)": 1, "abstract": "The dynamic nature of social networks has a huge impact on temporal link prediction problem, in which we are given snapshots of a network at different timestamps and need to predict the possible link between a node pair in the future or whether there are some missing links. The core issue is how to effectively use topology and timing information to improve performance. This paper proposes a model called NeLSTM combining network embedding with Long Short-Term Memory(LSTM) network to predict temporal network topology structure, which is represented by node vectors. First, to measure the impact of a past link on the future network, we add a time attenuation coefficient to the weight of a node pair. Then, network embedding is able to preserve the network topology information and based on its output, LSTM can characterize the continuous network evolution. Finally, NeLSTM obtains the similarity of a node pair via calculating the inner product, which exactly represents the possibility that a link occurs. Experimental results show that NeLSTM performs well in real world networks.", "keywords": ["Attenuation", "Predictive models", "Network topology", "Aging", "Facebook", "Task analysis"], "reference_count": 18, "ccfClass": "", "important": true, "references": [{"ref": "[1] GetoorL,DiehlCP.Linkmining:asurvey.ACMSIGKDD Explorations Newsletter. Vol 7, No. 2 . 2005. pp. 3-12."}, {"ref": "[2] Wang P, Xu B W, Wu Y R, et al. Link prediction in social networks: the state-of-the-art. Science China:Information Science. Vol 58, No. 1. 2015. pp. 1-38."}, {"ref": "[3] Liben-Nowell D, Kleinberg J. The link-prediction problem for social networks. Journal of the American Society for Information Science and Technology. Vol 58, No. 7. 2007. pp. 1019-1031."}, {"ref": "[4] Oyama S, Hayashi K, Kashima H. Cross-Temporal Link Prediction IEEE, International Conference on Data Mining. Proceedings of the 2011 IEEE 11th International Conference on Data Mining. Washington, DC, USA. 2011. pp. 1188-1193."}, {"ref": "[5] Dunlavy D M, Kolda T G, Acar E. Temporal Link Prediction Using Matrix and Tensor Factorizations. ACM Transactions on Knowledge Discovery from Data. Vol 5, No. 2. 2011. pp. 1-27."}, {"ref": "[6] Gao S, Denoyer L, Gallinari P. Temporal link prediction by integrating content and structure information. Proceedings of the 20th ACM international conference on Information and knowledge management. Glasgow, Scotland, UK. 2011. pp. 1169-1174."}, {"ref": "[7] XuHH,ZhangLJ.ApplicationofLinkPredictioninTemporalNetworks. Advanced Materials Research. Vol 756-759. 2013. pp. 2231-2236."}, {"ref": "[8] Munasinghe L, Ichise R. Time Score : A New Feature for Link Prediction in Social Networks. IEICE Transactions on Information and Systems.Vol 95, No. 3. 2012. pp. 821-828."}, {"ref": "[9] Jahanbakhsh K, King V, Shoja G C. Predicting missing contacts in mobile social networks. Pervasive and Mobile Computing. Vol 8, No. 5.2012. pp. 698-716."}, {"ref": "[10] Tylenda T, Angelova R, Bedathur S. Towards time-aware link prediction in evolving social networks. Proceedings of the 3rd Workshop on Social Network Mining and Analysis. Paris, France. 2009. pp. 1-10."}, {"ref": "[11] Richard E, Baskiotis N, Evgeniou T, et al. Link Discovery using Graph Feature Tracking. Advances in Neural Information Processing Systems. Vancouver, Canada. 2010. pp. 1966-1974."}, {"ref": "[12] Zhu L, Guo D, Yin J, et al. Scalable Temporal Latent Space Inference for Link Prediction in Dynamic Social Networks. IEEE Transactions on Knowledge and Data Engineering. Vol 28, No. 10. 2016. pp. 2765-2777."}, {"ref": "[13] Yu W, Cheng W, Aggarwal C C, et al. Link Prediction with Spatial and Temporal Consistency in Dynamic Networks. Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence. Melbourne, Australia. 2017. pp. 3343-3349."}, {"ref": "[14] Perozzi B, Al-Rfou R, Skiena S. 2014. Deepwalk: Online learning of social representations. Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. New York, New York, USA. 2014. pp. 701-710."}, {"ref": "[15] Tang J, Qu M, Wang M, et al. LINE: Large-scale Information Network Embedding. Proceedings of the 24th International Conference on World Wide Web. Florence, Italy. 2015. pp. 1067-1077."}, {"ref": "[16] Hochreiter S, Schmidhuber J. Long Short-Term Memory. Neural Com- putation. Vol 9, No.8. 1997. pp. 1735-1780."}, {"ref": "[17] Mueller J, Thyagarajan A. Siamese recurrent architectures for learning sentence similarity. Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. Phoenix, Arizona, USA. 2016. pp. 2786-2792."}, {"ref": "[18] Graves A. Supervised Sequence Labelling with Recurrent Neural Networks. Springer Press. Berlin, Heidelberg. 2012. behavioral networks. Journal of Theoretical Biology. Vol 271, No. 1. 2011. pp. 166-180."}]}, {"author": ["Aldo Pareja", "Giacomo Domeniconi", "Jian Jhen Chen", "Tengfei Ma", "Toyotaro Suzumura", "Hiroki Kanezashi", "Tim Kaler", "Charles E. Leisersen"], "title": "EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs", "journal": "ArXiv", "year": 2019, "DOI": "arXiv:1902.10191", "month": 9, "citations(google scholar)": 6, "abstract": "Graph representation learning resurges as a trending research subject owing to the widespread use of deep learning for Euclidean data, which inspire various creative designs of neural networks in the non-Euclidean domain, particularly graphs. With the success of these graph neural networks (GNN) in the static setting, we approach further practical scenarios where the graph dynamically evolves. For this case, combining the GNN with a recurrent neural network (RNN, broadly speaking) is a natural idea. Existing approaches typically learn one single graph model for all the graphs, by using the RNN to capture the dynamism of the output node embeddings and to implicitly regulate the graph model. In this work, we propose a different approach, coined EvolveGCN, that uses the RNN to evolve the graph model itself over time. This model adaptation approach is model oriented rather than node oriented, and hence is advantageous in the flexibility on the input. For example, in the extreme case, the model can handle at a new time step, a completely new set of nodes whose historical information is unknown, because the dynamism has been carried over to the GNN parameters. We evaluate the proposed approach on tasks including node classification, edge classification, and link prediction. The experimental results indicate a generally higher performance of EvolveGCN compared with related approaches.", "keywords": ["EvolveGCN", "RNN", "Node Classification"], "reference_count": 32, "ccfClass": "", "important": true, "references": [{"ref": "[Belkin and Niyogi 2002] Belkin, M., and Niyogi, P. 2002. Laplacian eigenmaps and spectral techniques for embedding and clustering. In NIPS."}, {"ref": "[Bruna et al. 2014] Bruna, J.; Zaremba, W.; Szlam, A.; and LeCun, Y. 2014. Spectral networks and locally connected networks on graphs. In ICLR."}, {"ref": "[Cangea et al. 2018] Cangea, C.; Velic\u02c7kovic \u0301, P.; Jovanovic \u0301, N.; and Thomas Kipf, P. L. 2018. Towards sparse hierar- chical graph classifiers. In NIPS Workshop on Relational Representation Learning."}, {"ref": "[Cao, Lu, and Xu 2015] Cao, S.; Lu, W.; and Xu, Q. 2015. GraRep: Learning graph representations with global struc- tural information. In CIKM."}, {"ref": "[Chen, Ma, and Xiao 2018] Chen, J.; Ma, T.; and Xiao, C. 2018. FastGCN: Fast learning with graph convolutional net- works via importance sampling. In ICLR."}, {"ref": "[Defferrard, Bresson, and Vandergheynst 2016] Defferrard, M.; Bresson, X.; and Vandergheynst, P. 2016. Convolu- tional neural networks on graphs with fast localized spectral filtering. In NIPS."}, {"ref": "[Duvenaud et al. 2015] Duvenaud, D.; Maclaurin, D.; Aguilera-Iparraguirre, J.; Go \u0301mez-Bombarelli, R.; Hirzel, T.; Aspuru-Guzik, A.; and Adams, R. P. 2015. Convolutional networks on graphs for learning molecular fingerprints. In NIPS."}, {"ref": "[Gao and Ji 2019] Gao, H., and Ji, S. 2019. Graph U-Nets. In ICML."}, {"ref": "[Gilmer et al. 2017] Gilmer, J.; Schoenholz, S. S.; Riley, P. F.; Vinyals, O.; and Dahl, G. E. 2017. Neural message passing for quantum chemistry. In ICML."}, {"ref": "[Goyal et al. 2017] Goyal, P.; Kamra, N.; He, X.; and Liu, Y. 2017. DynGEM: Deep embedding method for dynamic graphs. In IJCAI Workshop on Representation Learning for Graphs."}, {"ref": "[Goyal, Chhetri, and Canedo 2019] Goyal, P.; Chhetri, S. R.; and Canedo, A. 2019. dyngraph2vec: Capturing net- work dynamics using dynamic graph representation learn- ing. Knowledge-Based Systems."}, {"ref": "[Grover and Leskovec 2016] Grover, A., and Leskovec, J. 2016. node2vec: Scalable feature learning for networks. In KDD."}, {"ref": "[Hamilton, Ying, and Leskovec 2017] Hamilton, W. L.; Ying, R.; and Leskovec, J. 2017. Inductive representation learning on large graphs. In NIPS."}, {"ref": "[Jin et al. 2017] Jin, W.; Coley, C. W.; Barzilay, R.; and Jaakkola, T. 2017. Predicting organic reaction outcomes with Weisfeiler-Lehman network. In NIPS."}, {"ref": "[Kipf and Welling 2017] Kipf, T. N., and Welling, M. 2017. Semi-supervised classification with graph convolutional net- works. In ICLR."}, {"ref": "[Li et al. 2016] Li, Y.; Tarlow, D.; Brockschmidt, M.; and Zemel, R. 2016. Gated graph sequence neural networks. In ICLR."}, {"ref": "[Li et al. 2017] Li, J.; Dani, H.; Hu, X.; Tang, J.; Chang, Y.; and Liu, H. 2017. Attributed network embedding for learn- ing in a dynamic environment. In CIKM."}, {"ref": "[Manessia, Rozza, and Manzo 2017] Manessia, F.; Rozza, A.; and Manzo, M. 2017. Dynamic graph convolutional networks. arXiv:1704.06199."}, {"ref": "[Narayan and Roe 2018] Narayan, A., and Roe, P. H. O. 2018. Learning graph dynamics using deep neural networks. IFAC-PapersOnLine 51(2):433\u2013438."}, {"ref": "[Nguyen et al. 2018] Nguyen, G. H.; Lee, J. B.; Rossi, R. A.; Ahmed, N. K.; Koh, E.; and Kim, S. 2018. Continuous-time dynamic network embeddings. In WWW."}, {"ref": "[Ou et al. 2016] Ou, M.; Cui, P.; Pei, J.; Zhang, Z.; and Zhu, W. 2016. Asymmetric transitivity preserving graph embed- ding. In KDD."}, {"ref": "[Perozzi, Al-Rfou, and Skiena 2014] Perozzi, B.; Al-Rfou, R.; and Skiena, S. 2014. DeepWalk: Online learning of social representations. In KDD."}, {"ref": "[Roweis and Saul 2000] Roweis, S. T., and Saul, L. K. 2000. Nonlinear dimensionality reduction by locally linear embed- ding. Science 290(5500):2323\u20132326."}, {"ref": "[Seo et al. 2016] Seo, Y.; Defferrard, M.; Vandergheynst, P.; and Bresson, X. 2016. Structured sequence modeling with graph convolutional recurrent networks. arXiv:1612.07659."}, {"ref": "[Tang et al. 2015] Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, Q. 2015. LINE: Large-scale information network embedding. In WWW."}, {"ref": "[Trivedi et al. 2017] Trivedi, R.; Dai, H.; Wang, Y.; and Song, L. 2017. Know-Evolve: Deep temporal reasoning for dynamic knowledge graphs. In ICML."}, {"ref": "[Trivedi et al. 2018] Trivedi, R.; Farajtabar, M.; Biswal, P.; and Zha, H. 2018. Representation learning over dynamic graphs. arXiv:1803.04051."}, {"ref": "[Velic \u0306kovic \u0301 et al. 2018] Velic \u0306kovic \u0301, P.; Cucurull, G.; Casanova, A.; Romero, A.; Lio`, P.; and Bengio, Y. 2018. Graph attention networks. In ICLR."}, {"ref": "[Yu et al. 2018] Yu, W.; Cheng, W.; Aggarwal, C.; Zhang, K.; Chen, H.; and Wang, W. 2018. NetWalk: A flexible deep embedding approach for anomaly detection in dynamic networks. In KDD."}, {"ref": "[Yu, Yin, and Zhu 2018] Yu, B.; Yin, H.; and Zhu, Z. 2018. Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting. In IJCAI."}, {"ref": "[Zhou et al. 2018] Zhou, L.; Yang, Y.; Ren, X.; Wu, F.; and Zhuang, Y. 2018. Dynamic network embedding by model- ing triadic closure process. In AAAI."}, {"ref": "[Zuo et al. 2018] Zuo, Y.; Liu, G.; Lin, H.; Guo, J.; Hu, X.; and Wu, J. 2018. Embedding temporal network via neigh- borhood formation. In KDD."}]}]