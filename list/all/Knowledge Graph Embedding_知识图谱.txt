[{"author": ["Quan Wang", "Zhendong Mao", "Bin Wang", "Li Guo"], "title": "Knowledge Graph Embedding: A Survey of Approaches and Applications", "journal": "TKDE", "year": 2017, "DOI": "10.1109/TKDE.2017.2754499", "month": 9.0, "citations": 222, "abstract": "Knowledge graph (KG) embedding is to embed components of a KG including entities and relations into continuous vector spaces, so as to simplify the manipulation while preserving the inherent structure of the KG. It can benefit a variety of downstream tasks such as KG completion and relation extraction, and hence has quickly gained massive attention. In this article, we provide a systematic review of existing techniques, including not only the state-of-the-arts but also those with latest trends. Particularly, we make the review based on the type of information used in the embedding task. Techniques that conduct embedding using only facts observed in the KG are first introduced. We describe the overall framework, specific model design, typical training procedures, as well as pros and cons of such techniques. After that, we discuss techniques that further incorporate additional information besides facts. We focus specifically on the use of entity types, relation paths, textual descriptions, and logical rules. Finally, we briefly introduce how KG embedding can be applied to and benefit a wide variety of downstream tasks such as KG completion, relation extraction, question answering, and so forth.", "keywords": ["Statistical analysis", "Knowledge discovery", "Graphical models", "Matrix decomposition", "Systematics", "Market research", "Semantics"], "reference_count": 133, "ccf_class": "A", "is_important": 1.0, "references": [{"ref": "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor, \"Freebase: A collaboratively created graph database for structuring human knowledge,\" in Proc. ACM SIGMOD Int. Conf. Manage. Data, 2008, pp. 1247-1250."}, {"ref": "J. Lehmann, et al., \"DBpedia: A large-scale, multilingual knowledge base extracted from Wikipedia,\" Semantic Web J., vol. 6,no. 2, pp. 167-195, 2015."}, {"ref": "F. M. Suchanek, G. Kasneci, and G. Weikum, \"YAGO: A core of semantic knowledge,\" in Proc. 16th Int. Conf. World Wide Web, 2007, pp. 697-706."}, {"ref": "A. Carlson, J. Betteridge, B. Kisiel, B. Settles, E. R. Hruschka Jr., and T. M. Mitchell, \"Toward an architecture for never-ending language learning,\" in Proc. 24th AAAI Conf. Artif. Intell., 2010, pp. 1306-1313."}, {"ref": "J. Berant, A. Chou, R. Frostig, and P. Liang, \"Semantic parsing on freebase from question-answer pairs,\" in Proc. Conf. Empirical Methods Natural Language Process., 2013, pp. 1533-1544."}, {"ref": "L. P. Heck, D. Hakkani-Tur, and G. Tur, \"Leveraging knowledge graphs for web-scale unsupervised semantic parsing,\" in Proc. Annu. Conf. Int. Speech Commun. Assoc., 2013, pp. 1594-1598."}, {"ref": "D. Damljanovic and K. Bontcheva, \"Named entity disambiguation using linked data,\" in Proc. 9th Extended Semantic Web Conf., 2012."}, {"ref": "Z. Zheng, X. Si, F. Li, E. Y. Chang, and X. Zhu, \"Entity disambiguation with Freebase,\" in Proc. IEEE/WIC/ACM Int. Joint Conf. Web Intell. Intell. Agent Technol., 2012, pp. 82-89."}, {"ref": "R. Hoffmann, C. Zhang, X. Ling, L. Zettlemoyer, and D. S. Weld, \"Knowledge-based weak supervision for information extraction of overlapping relations,\" in Proc. 49th Annu. Meeting Assoc. Comput. Linguistics, 2011, pp. 541-550."}, {"ref": "J. Daiber, M. Jakob, C. Hokamp, and P. N. Mendes, \"Improving ef\ufb01ciency and accuracy in multilingual entity extraction,\" in Proc. 9th Int. Conf. Semantic Syst., 2013, pp. 121-124."}, {"ref": "A. Bordes, J. Weston, and N. Usunier, \"Open question answering with weakly supervised embedding models,\" in Proc. Joint Eur. Conf. Mach. Learn. Knowl. Discovery Databases, 2014, pp. 165-180."}, {"ref": "A. Bordes, S. Chopra, and J. Weston, \"Question answering with subgraph embeddings,\" in Proc. Conf. Empirical Methods Natural Language Process., 2014, pp. 615-620."}, {"ref": "M. Nickel, V. Tresp, and H.-P. Kriegel, \"A three-way model for collective learning on multi-relational data,\" in Proc. 28th Int. Conf. Mach. Learn., 2011, pp. 809-816."}, {"ref": "A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko, \"Translating embeddings for modeling multi-relational data,\" in Proc. Adv. Neural Inf. Process. Syst., 2013, pp. 2787-2795."}, {"ref": "Z. Wang, J. Zhang, J. Feng, and Z. Chen, \"Knowledge graph embedding by translating on hyperplanes,\" in Proc. 28th AAAI Conf. Artif. Intell., 2014, pp. 1112-1119."}, {"ref": "Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu, \"Learning entity and relation embeddings for knowledge graph completion,\" in Proc. 29th AAAI Conf. Artif. Intell., 2015, pp. 2181-2187."}, {"ref": "R. Jenatton, N. L. Roux, A. Bordes, and G. R. Obozinski, \"A latent factor model for highly multi-relational data,\" in Proc. Adv. Neural Inf. Process. Syst., 2012, pp. 3167-3175."}, {"ref": "A. Bordes, X. Glorot, J. Weston, and Y. Bengio, \"A semantic matching energy function for learning with multi-relational data,\" Mach. Learn., vol. 94, no. 2, pp. 233-259, 2014."}, {"ref": "R. Socher, D. Chen, C. D. Manning, and A. Y. Ng, \"Reasoning with neural tensor networks for knowledge base completion,\" in Proc. Adv. Neural Inf. Process. Syst., 2013, pp. 926-934."}, {"ref": "J. Weston, A. Bordes, O. Yakhnenko, and N. Usunier, \"Connecting language and knowledge bases with embedding models for relation extraction,\" in Proc. Conf. Empirical Methods Natural Language Process., 2013, pp. 1366-1371."}, {"ref": "S. Riedel, L. Yao, A. Mccallum, and B. M. Marlin, \"Relation extraction with matrix factorization and universal schemas,\" in Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics: Human Language Technol., 2013, pp. 74-84."}, {"ref": "M. Nickel, V. Tresp, and H.-P. Kriegel, \"Factorizing YAGO: Scalable machine learning for linked data,\" in Proc. 21st Int. Conf. World Wide Web, 2012, pp. 271-280."}, {"ref": "Q. Wang, B. Wang, and L. Guo, \"Knowledge base completion using embeddings and rules,\" in Proc. 24th Int. Joint Conf. Artif. Intell., 2015, pp. 1859-1865."}, {"ref": "Z. Wei, J. Zhao, K. Liu, Z. Qi, Z. Sun, and G. Tian, \"Large-scale knowledge base completion: Inferring via grounding network sampling over selected instances,\" in Proc. 24th ACM Int. Conf. Inf. Knowl. Manage., 2015, pp. 1331-1340."}, {"ref": "S. Guo, Q. Wang, L. Wang, B. Wang, and L. Guo, \"Semantically smooth knowledge graph embedding,\" in Proc. 53rd Annu. Meeting Assoc. Comput. Linguistics 7th Int. Joint Conf. Natural Language Process., 2015, pp. 84-94."}, {"ref": "R. Xie, Z. Liu, and M. Sun, \"Representation learning of knowledge graphs with hierarchical types,\" in Proc. 25th Int. Joint Conf. Artif. Intell., 2016, pp. 2965-2971."}, {"ref": "Y. Lin, Z. Liu, H. Luan, M. Sun, S. Rao, and S. Liu, \"Modeling relation paths for representation learning of knowledge bases,\" in Proc. Conf. Empirical Methods Natural Language Process., 2015, pp. 705-714."}, {"ref": "K. Guu, J. Miller, and P. Liang, \"Traversing knowledge graphs in vector space,\" in Proc. Conf. Empirical Methods Natural Language Process., 2015, pp. 318-327."}, {"ref": "K. Toutanova, V. Lin, W.-T. Yih, H. Poon, and C. Quirk, \"Compositional learning of embeddings for relation paths in knowledge base and text,\" in Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, 2016, pp. 1434-1444."}, {"ref": "Z. Wang, J. Zhang, J. Feng, and Z. Chen, \"Knowledge graph and text jointly embedding,\" in Proc. Conf. Empirical Methods Natural Language Process., 2014, pp. 1591-1601."}, {"ref": "H. Zhong, J. Zhang, Z. Wang, H. Wan, and Z. Chen, \"Aligning knowledge and text embeddings by entity descriptions,\" in Proc. Conf. Empirical Methods Natural Language Process., 2015, pp. 267-272."}, {"ref": "R. Xie, Z. Liu, J. Jia, H. Luan, and M. Sun, \"Representation learning of knowledge graphs with entity descriptions,\" in Proc. 30th AAAI Conf. Artif. Intell., 2016, pp. 2659-2665."}, {"ref": "Z. Wang and J. Li, \"Text-enhanced representation learning for knowledge graph,\" in Proc. 25th Int. Joint Conf. Artif. Intell., 2016, pp. 1293-1299."}, {"ref": "S. Guo, Q. Wang, L. Wang, B. Wang, and L. Guo, \"Jointly embedding knowledge graphs and logical rules,\" in Proc. Conf. Empirical Methods Natural Language Process., 2016, pp. 192-202."}, {"ref": "T. Rockt\u20acaschel, S. Singh, and S. Riedel, \"Injecting logical background knowledge into embeddings for relation extraction,\" in Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics: Human Language Technol., 2015, pp. 1119-1129."}, {"ref": "M. Nickel, K. Murphy, V. Tresp, and E. Gabrilovich, \"A review of relational machine learning for knowledge graphs,\" in Proc. IEEE, vol. 104, no. 1, pp. 11-33, Jan. 2016."}, {"ref": "N. Lao and W. W. Cohen, \"Relational retrieval using a combination of path-constrained random walks,\" Mach. Learn., vol. 81, no. 1, pp. 53-67, 2010."}, {"ref": "M. Gardner and T. Mitchell, \"Ef\ufb01cient and expressive knowledge base completion using subgraph feature extraction,\" in Proc. Conf. Empirical Methods Natural Language Process., 2015, pp. 1488-1498."}, {"ref": "Q. Wang, J. Liu, Y. Luo, B. Wang, and C.-Y. Lin, \"Knowledge base completion via coupled path ranking,\" in Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, 2016, pp. 1308-1318."}, {"ref": "M. Richardson and P. Domingos, \"Markov logic networks,\" Mach. Learn., vol. 62, no. 1/2, pp. 107-136, 2006."}, {"ref": "A. Kimmig, S. Bach, M. Broecheler, B. Huang, and L. Getoor, \"A short introduction to probabilistic soft logic,\" in Proc. NIPS Workshop Probab. Program.: Found. Appl., 2012, pp. 1-4."}, {"ref": "J. Pujara, H. Miao, L. Getoor, and W. W. Cohen, \"Using semantics and statistics to turn data into knowledge,\" AI Mag., vol. 36, no. 1, pp. 65-74, 2015."}, {"ref": "R. A. Horn, \"The Hadamard product,\" in Proc. Symp. Appl. Math., 1990, pp. 87-169."}, {"ref": "T. A. Plate, \"Holographic reduced representations,\" IEEE Trans. Neural Netw., vol. 6, no. 3, pp. 623-641, May 1995."}, {"ref": "S. He, K. Liu, G. Ji, and J. Zhao, \"Learning to represent knowledge graphs with Gaussian embedding,\" in Proc. 24th ACM Int. Conf. Inf. Knowl. Manage., 2015, pp. 623-632."}, {"ref": "H. Xiao, M. Huang, and X. Zhu, \"TransG: A generative model for knowledge graph embedding,\" in Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, 2016, pp. 2316-2325."}, {"ref": "T. Mikolov, W.-T. Yih, and G. Zweig, \"Linguistic regularities in continuous space word representations,\" in Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics: Human Language Technol., 2013, pp. 746-751."}, {"ref": "H.-G. Yoon, H.-J. Song, S.-B. Park, and S.-Y. Park, \"A translation-based knowledge graph embedding preserving logical property of relations,\" in Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics: Human Language Technol., 2016, pp. 907-916."}, {"ref": "D. Q. Nguyen, K. Sirts, L. Qu, and M. Johnson, \"STransE: A novel embedding model of entities and relationships in knowledge bases,\" in Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics: Human Language Technol., 2016, pp. 460-466."}, {"ref": "G. Ji, S. He, L. Xu, K. Liu, and J. Zhao, \"Knowledge graph embedding via dynamic mapping matrix,\" in Proc. 53rd Annu. Meeting Assoc. Comput. Linguistics 7th Int. Joint Conf. Natural Language Process., 2015, pp. 687-696."}, {"ref": "G. Ji, K. Liu, S. He, and J. Zhao, \"Knowledge graph completion with adaptive sparse transfer matrix,\" in Proc. 30th AAAI Conf. Artif. Intell., 2016, pp. 985-991."}, {"ref": "M. Fan, Q. Zhou, E. Chang, and T. F. Zheng, \"Transition-based knowledge graph embedding with relational mapping properties,\" in Proc. 28th Paci\ufb01c Asia Conf. Language Inf. Comput., 2014, pp. 328-337."}, {"ref": "H. Xiao, M. Huang, and X. Zhu, \"From one point to a manifold: Knowledge graph embedding for precise link prediction,\" in Proc. 25th Int. Joint Conf. Artif. Intell., 2016, pp. 1315-1321."}, {"ref": "J. Feng, M. Huang, M. Wang, M. Zhou, Y. Hao, and X. Zhu, \"Knowledge graph embedding by \ufb02exible translation,\" in Proc. 15th Int. Conf. Principles Knowl. Represent. Reasoning, 2015, pp. 557-560."}, {"ref": "H. Xiao, M. Huang, Y. Hao, and X. Zhu, \"TransA: An adaptive approach for knowledge graph embedding,\" arXiv preprint arXiv:1509.05490, 2015."}, {"ref": "A. Bordes, X. Glorot, J. Weston, and Y. Bengio, \"Joint learning of words and meaning representations for open-text semantic parsing,\" in Proc. 15th Int. Conf. Artif. Intell. Statist., 2012, pp. 127-135."}, {"ref": "A. Bordes, J. Weston, R. Collobert, and Y. Bengio, \"Learning structured embeddings of knowledge bases,\" in Proc. 25th AAAI Conf. Artif. Intell., 2011, pp. 301-306."}, {"ref": "S. Kullback, Information Theory and Statistics. North Chelmsford, MA, USA: Courier Corporation, 1997."}, {"ref": "T. Jebara, R. Kondor, and A. Howard, \"Probability product kernels,\" J. Mach. Learn. Res., vol. 5, pp. 819-844, 2004."}, {"ref": "D. J. Aldous, \"Exchangeability and related topics,\" in Ecole d\u2019Ete de Probabilites de Saint-Flour, XIII-1983, Berlin, Germany: Springer, 1985, pp. 1-198."}, {"ref": "D. M. Blei, T. L. Grif\ufb01ths, and M. I. Jordan, \"The nested Chinese restaurant process and Bayesian nonparametric inference of topic hierarchies,\" J. ACM, vol. 57, no. 2, pp. 7:1-7:30, 2010."}, {"ref": "M. Nickel, L. Rosasco, and T. Poggio, \"Holographic embeddings of knowledge graphs,\" in Proc. 30th AAAI Conf. Artif. Intell., 2016, pp. 1955-1961."}, {"ref": "Q. Liu, H. Jiang, A. Evdokimov, Z.-H. Ling, X. Zhu, S. Wei, and Y. Hu, \"Probabilistic reasoning via deep learning: Neural association models,\" arXiv preprint arXiv:1603.07704, 2016."}, {"ref": "A. Garc\u0131a-Duran, A. Bordes, and N. Usunier, \"Effective blending of two and three-way interactions for modeling multi-relational data,\" in Proc. Joint Eur. Conf. Mach. Learn. Knowl. Discovery Databases, 2014, pp. 434-449."}, {"ref": "B. Yang, W.-T. Yih, X. He, J. Gao, and L. Deng, \"Embedding entities and relations for learning and inference in knowledge bases,\" in Proc. Int. Conf. Learn. Representations, 2015."}, {"ref": "T. Trouillon, J. Welbl, S. Riedel, E. Gaussier, and G. Bouchard, \"Complex embeddings for simple link prediction,\" in Proc. 33rd Int. Conf. Mach. Learn., 2016, pp. 2071-2080."}, {"ref": "K. Hayashi and M. Shimbo, \"On the equivalence of holographic and complex embeddings for link prediction,\" in Proc. 55th Annu. Meeting Assoc. Comput. Linguistics, 2017, pp. 554-559."}, {"ref": "H. Liu, Y. Wu, and Y. Yang, \"Analogical inference for multi-relational embeddings,\" in Proc. 34th Int. Conf. Mach. Learn., 2017, pp. 2168-2178."}, {"ref": "X. Dong, et al., \"Knowledge vault: A web-scale approach to probabilistic knowledge fusion,\" in Proc. 20th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2014, pp. 601-610."}, {"ref": "T. G. Kolda and B. W. Bader, \"Tensor decompositions and applications,\" SIAM Rev., vol. 51, no. 3, pp. 455-500, 2009."}, {"ref": "G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov, \"Improving neural networks by preventing co-adaptation of feature detectors,\" arXiv preprint arXiv:1207.0580, 2012."}, {"ref": "L. Drumond, S. Rendle, and L. Schmidt-Thieme, \"Predicting RDF triples in incomplete knowledge bases with tensor factorization,\" in Proc. 27th Annu. ACM Symp. Appl.  Comput.,2012, pp. 326-331."}, {"ref": "G. Bouchard, S. Singh, and T. Trouillon, \"On approximate reasoning capabilities of low-rank vector spaces,\" in Proc. AAAI Spring Symp. Knowl. Representation Reasoning, 2015."}, {"ref": "H. Robbins and S. Monro, \"A stochastic approximation method,\" Ann. Math. Statist., vol. 22, pp. 400-407, 1951."}, {"ref": "J. Duchi, E. Hazan, and Y. Singer, \"Adaptive subgradient methods for online learning and stochastic optimization,\" J. Mach. Learn. Res., vol. 12, pp. 2121-2159, 2011."}, {"ref": "T. Long, R. Lowe, J. C. K. Cheung, and D. Precup, \"Leveraging lexical resources for learning entity embeddings in multi-relational data,\" in Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, 2016, pp. 112-117."}, {"ref": "D. Krompa\u00df, S. Baier, and V. Tresp, \"Type-constrained representation learning in knowledge graphs,\" in Proc. 14th Int. Semantic Web Conf., 2015, pp. 640-655."}, {"ref": "M. Nickel and V. Tresp, \"Logistic tensor factorization for multirelational data,\" in Proc. ICML Workshop Structured Learn.: Inferring Graphs Structured Unstructured Inputs, 2013."}, {"ref": "P. Miettinen, \"Boolean tensor factorizations,\" in Proc. 11th IEEE Int. Conf. Data Mining, 2011, pp. 447-456."}, {"ref": "D. Erdos and P. Miettinen, \"Discovering facts with Boolean tensor Tucker decomposition,\" in Proc. 22nd ACM Int. Conf. Inf.Knowl. Manage., 2013, pp. 1569-1572."}, {"ref": "J. D. Carroll and J.-J. Chang, \"Analysis of individual differences in multidimensional scaling via an N-way generalization of \"Eckart-Young\" decomposition,\" Psychometrika, vol. 35, no. 3, pp. 283-319, 1970."}, {"ref": "L. R. Tucker, \"Some mathematical notes on three-mode factor analysis,\" Psychometrika, vol. 31, no. 3, pp. 279-311, 1966."}, {"ref": "T. Franz, A. Schultz, S. Sizov, and S. Staab, \"TripleRank: Ranking semantic web data by tensor decomposition,\" in Proc. 8th Int. Semantic Web Conf., 2009, pp. 213-228."}, {"ref": "T. Van de Cruys, T. Poibeau, and A. Korhonen, \"A tensor-based factorization model of semantic compositionality,\" in Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics: Human Language Technol., 2013, pp. 1142-1151."}, {"ref": "K.-W. Chang, W.-T. Yih, and C. Meek, \"Multi-relational latent semantic analysis,\" in Proc. Conf. Empirical Methods Natural Language Process., 2013, pp. 1602-1612."}, {"ref": "R. West, E. Gabrilovich, K. Murphy, S. Sun, R. Gupta, and D. Lin, \"Knowledge base completion via search-based question answering,\" in Proc. 23rd Int. Conf. World Wide Web, 2014, pp. 515-526."}, {"ref": "S. Guo, Q. Wang, B. Wang, L. Wang, and L. Guo, \"SSE: Semantically smooth embedding for knowledge graphs,\" IEEE Trans. Knowl. Data Eng., vol. 29, no. 4, pp. 884-897, Apr. 2017."}, {"ref": "M. Fan, D. Zhao, Q. Zhou, Z. Liu, T. F. Zheng, and E. Y. Chang, \"Distant supervision for relation extraction with matrix completion,\" in Proc. 52nd Annu. Meeting Assoc. Comput. Linguistics, 2014, pp. 839-849."}, {"ref": "V. Tresp, Y. Huang, M. Bundschus, and A. Rettinger, \"Materializing and querying learned knowledge,\" in Proc. 1st ESWC Workshop Inductive Reasoning Mach. Learn. Semantic Web, 2009."}, {"ref": "Y. Huang, V. Tresp, M. Nickel, A. Rettinger, and H.-P. Kriegel, \"A scalable approach for statistical learning in semantic graphs,\" Semantic Web, vol. 5, no. 1, pp. 5-22, 2014."}, {"ref": "M. Belkin and P. Niyogi, \"Laplacian eigenmaps and spectral techniques for embedding and clustering,\" in Proc. Adv. Neural Inf. Process. Syst., 2001, pp. 585-591."}, {"ref": "S. T. Roweis and L. K. Saul, \"Nonlinear dimensionality reduction by locally linear embedding,\" Sci., vol. 290, no. 5500, pp. 2323-2326, 2000."}, {"ref": "K.-W. Chang, W.-T. Yih, B. Yang, and C. Meek, \"Typed tensor decomposition of knowledge bases for relation extraction,\" in Proc. Conf. Empirical Methods Natural Language Process., 2014, pp. 1568-1579."}, {"ref": "Z. Hu, P. Huang, Y. Deng, Y. Gao, and E. Xing, \"Entity hierarchy embedding,\" in Proc. 53rd Annu. Meeting Assoc. Comput. Linguistics 7th Int. Joint Conf. Natural Language Process., 2015, pp. 1292-1300."}, {"ref": "P. J. Werbos, \"Backpropagation through time: What it does and how to do it,\" in Proc. IEEE, vol. 78, no. 10, pp. 1550-1560, Oct. 1990."}, {"ref": "T. Zhou, J. Ren, M. Medo, and Y.-C. Zhang, \"Bipartite network projection and personal recommendation,\" Phys. Rev. E, vol. 76, no. 4, 2007, Art. no. 046115."}, {"ref": "A. Garc\u0131a-Duran, A. Bordes, and N. Usunier, \"Composing relationships with translations,\" in Proc. Conf. Empirical Methods Natural Language Process., 2015, pp. 286-290."}, {"ref": "A. Neelakantan, B. Roth, and A. McCallum, \"Compositional vector space models for knowledge base completion,\" in Proc. 53rd Annu. Meeting Assoc. Comput. Linguistics 7th Int. Joint Conf. Natural Language Process., 2015, pp. 156-166."}, {"ref": "R. Das, A. Neelakantan, D. Belanger, and A. McCallum, \"Chains of reasoning over entities, relations, and text using recurrent neural networks,\" in Proc. 15th Conf. Eur. Chapter Assoc. Comput. Linguistics, 2016, pp. 132-141."}, {"ref": "Y. Luo, Q. Wang, B. Wang, and L. Guo, \"Context-dependent knowledge graph embedding,\" in Proc. Conf. Empirical MethodsNatural Language Process., 2015, pp. 1656-1661."}, {"ref": "T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, \"Distributed representations of words and phrases and their compositionality,\" in Proc. Adv. Neural Inf. Process. Syst., 2013, pp. 3111-3119."}, {"ref": "D. Zhang, B. Yuan, D. Wang, and R. Liu, \"Joint semantic relevance learning with text data and graph knowledge,\" in Proc. 3rd Workshop Continuous Vector Space Models Compositionality, 2015, pp. 32-40."}, {"ref": "H. Xiao, M. Huang, and X. Zhu, \"SSP: Semantic space projection for knowledge graph embedding with text descriptions,\" in Proc. 31st AAAI Conf. Artif. Intell., 2017, pp. 3104-3110."}, {"ref": "M. Fan, Q. Zhou, T. F. Zheng, and R. Grishman, \"Distributed representation learning for knowledge graphs with entity descriptions,\" Pattern Recognit. Lett., vol. 93, pp. 31-37, 2017."}, {"ref": "J. Xu, K. Chen, X. Qiu, and X. Huang, \"Knowledge graph representation with jointly structural and textual encoding,\" arXiv preprint arXiv:1611.08661, 2016."}, {"ref": "L. Dehaspe and H. Toivonen, \"Discovery of frequent DATALOG patterns,\" Data Mining Knowl. Discovery, vol. 3, no. 1, pp. 7-36, 1999."}, {"ref": "S. Muggleton, \"Inverse entailment and Progol,\" New Generation Comput., vol. 13, no. 3, pp. 245-286, 1995."}, {"ref": "L. A. Gal\u0003arraga, C. Te\ufb02ioudi, K. Hose, and F. M. Suchanek, \"AMIE: Association rule mining under incomplete evidence in ontological knowledge bases,\" in Proc. 22nd Int. Conf. World Wide Web, 2013, pp. 413-422."}, {"ref": "L. A. Gal\u0003arraga, C. Te\ufb02ioudi, K. Hose, and F. M. Suchanek, \"Fast rule mining in ontological knowledge bases with AMIE+,\" VLDB J., vol. 24, no. 6, pp. 707-730, 2015."}, {"ref": "P. H\u0003ajek, The Metamathematics of Fuzzy Logic. Norwell, MA, USA: Kluwer, 1998."}, {"ref": "T. Demeester, T. Rockt\u20acaschel, and S. Riedel, \"Lifted rule injection for relation embeddings,\" in Proc. Conf. Empirical Methods Natural Language Process., 2016, pp. 1389-1399."}, {"ref": "T. Rockt\u20acaschel, M. Bo\u0004snjak, S. Singh, and S. Riedel, \"Low-dimensional embeddings of logic,\" in Proc. ACL Workshop Semantic Parsing, 2014, pp. 45-49."}, {"ref": "W. Y. Wang and W. W. Cohen, \"Learning \ufb01rst-order logic embeddings via matrix factorization,\" in Proc. 25th Int. Joint Conf. Artif. Intell., 2016, pp. 2132-2138."}, {"ref": "Y. Lin, Z. Liu, and M. Sun, \"Knowledge representation learning with entities, attributes and relations,\" in Proc. 25th Int. Joint Conf. Artif. Intell., 2016, pp. 2866-2872."}, {"ref": "T. Jiang, et al., \"Encoding temporal information for time-aware link prediction,\" in Proc. Conf. Empirical Methods Natural Language Process., 2016, pp. 2350-2354."}, {"ref": "C. Esteban, V. Tresp, Y. Yang, S. Baier, and D. Krompa\u00df, \"Predicting the co-evolution of event and knowledge graphs,\" in Proc. 19th Int. Conf. Inf. Fusion, 2016, pp. 98-105."}, {"ref": "R. Trivedi, H. Dai, Y. Wang, and L. Song, \"Know-evolve: Deep temporal reasoning for dynamic knowledge graphs,\" in Proc. 34th Int. Conf. Mach. Learn., 2017, pp. 3462-3471."}, {"ref": "D. R. Cox and P. A. W. Lewis, \"Multivariate point processes,\" in Proc. 6th Berkeley Symp., 1972, pp. 401-448."}, {"ref": "J. Feng, M. Huang, Y. Yang, and X. Zhu, \"GAKE: Graph aware knowledge embedding,\" in Proc. 26th Int. Conf. Comput. Linguistics, 2016, pp. 641-651."}, {"ref": "B. Perozzi, R. Al-Rfou, and S. Skiena, \"DeepWalk: Online learning of social representations,\" in Proc. 20th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2014, pp. 701-710."}, {"ref": "X. Jiang, V. Tresp, Y. Huang, and M. Nickel, \"Link prediction in multi-relational graphs using additive models,\" in Proc. Int. Conf. Semantic Technol. Meet Recommender Syst. Big Data, 2012, pp. 1-12."}, {"ref": "M. Nickel, X. Jiang, and V. Tresp, \"Reducing the rank in relational factorization models by including observable patterns,\" in Proc. Adv. Neural Inf. Process. Syst., 2014, pp. 1179-1187."}, {"ref": "H. Paulheim, \"Knowledge graph re\ufb01nement: A survey of approaches and evaluation methods,\" Semantic Web, vol. 8, no. 3, pp. 489-508, 2017."}, {"ref": "P. Singla and P. Domingos, \"Entity resolution with Markov logic,\" in Proc. 6th Int. Conf. Data Mining, 2006, pp. 572-582."}, {"ref": "M. Mintz, S. Bills, R. Snow, and D. Jurafsky, \"Distant supervision for relation extraction without labeled data,\" in Proc. Joint Conf. 47th Annu. Meeting ACL 4th Int. Joint Conf. Natural Language Process, 2009, pp. 1003-1011."}, {"ref": "S. Riedel, L. Yao, and A. McCallum, \"Modeling relations and their mentions without labeled text,\" in Proc. Eur. Conf. Mach. Learn. Knowl. Discovery Databases, 2010, pp. 148-163."}, {"ref": "X. Jiang, Q. Wang, P. Li, and B. Wang, \"Relation extraction with multi-instance multi-label convolutional neural networks,\" in Proc. 26th Int. Conf. Comput. Linguistics, 2016, pp. 1471-1480."}, {"ref": "E. J. Cand\u0005es and B. Recht, \"Exact matrix completion via convex optimization,\" Found. Comput. Math., vol. 9, no. 6, pp. 717-772, 2009."}, {"ref": "J. Berant, A. Chou, R. Frostig, and P. Liang, \"Semantic parsing on Freebase from question-answer pairs,\" in Proc. Conf. Empirical Methods Natural Language Process., 2013, pp. 1533-1544."}, {"ref": "A. Fader, L. Zettlemoyer, and O. Etzioni, \"Paraphrase-driven learning for open question answering,\" in Proc. 51st Annu. Meeting Assoc. Comput. Linguistics, 2013, pp. 1608-1618."}, {"ref": "Y. Koren, R. Bell, and C. Volinsky, \"Matrix factorization techniques for recommender systems,\" Comput., vol. 42, no. 8, pp. 30-37, 2009."}, {"ref": "X. Yu, et al., \"Personalized entity recommendation: A heterogeneous information network approach,\" in Proc. 7th ACM Int.Conf. Web Search Data Mining, 2014, pp. 283-292."}, {"ref": "F. Zhang, N. J. Yuan, D. Lian, X. Xie, and W.-Y. Ma, \"Collaborative knowledge base embedding for recommender systems,\" in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2016, pp. 353-362."}]}, {"author": ["Kurt Bollacker", "Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"], "title": "Freebase: A collaboratively created graph database for structuring human knowledge", "journal": "SIGMOD", "year": 2008, "DOI": "10.1145/1376616.1376746", "month": 6.0, "citations": 2557, "abstract": "Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.", "keywords": [""], "reference_count": 4, "ccf_class": "A", "is_important": 1.0, "references": [{"ref": "\"wikipedia (n.d.). wikipedia: The free encyclopedia. on the interne t. http://www.wikipedia.org."}, {"ref": "T. Berners-Lee, J. Hendler, and O. Lassila. \"the semantic web\". Scientific American, 284:34\u201343, 5 2001."}, {"ref": "K. Bollacker, P. Tufts, T. Pierce, and R. Cook. A Platform for Scalable, Collaborative, Structured Information Integration. In Sixth International Workshop on Information Integration on the Web. Association for the Advancement of Artificial Intelligence, July 2007."}, {"ref": "D. Flanagan. Developing Metaweb-enabled Web Applications. Metaweb Technologies, 2007."}]}, {"author": ["Jens Lehmann", "Robert Isele", "Max Jakob", "Anja Jentzsch", "Dimitris Kontokostas", "Pablo N. Mendes", "Sebastian Hellmann", "Mohamed Morsey", "Patrick van Kleef", "S\u00f6ren Auer and Christian Bizer"], "title": "DBpedia: A large-scale multilingual knowledge base extracted from Wikipedia", "journal": "JWS", "year": 2015, "DOI": "10.3233/SW-140134", "month": 0.0, "citations": 1484, "abstract": "The DBpedia community project extracts structured, multilingual knowledge from Wikipedia and makes it freely available on the Web using Semantic Web and Linked Data technologies. The project extracts knowledge from 111 different language editions of Wikipedia. The largest DBpedia knowledge base which is extracted from the English edition of Wikipedia consists of over 400 million facts that describe 3.7 million things. The DBpedia knowledge bases that are extracted from the other 110 Wikipedia editions together consist of 1.46 billion facts and describe 10 million additional things. The DBpedia project maps Wikipedia infoboxes from 27 different language editions to a single shared ontology consisting of 320 classes and 1,650 properties. The mappings are created via a world-wide crowd-sourcing effort and enable knowledge from the different Wikipedia editions to be combined. The project publishes releases of all DBpedia knowledge bases for download and provides SPARQL query access to 14 out of the 111 language editions via a global network of local DBpedia chapters. In addition to the regular releases, the project maintains a live knowledge base which is updated whenever a page in Wikipedia changes. DBpedia sets 27 million RDF links pointing into over 30 external data sources and thus enables data from these sources to be used together with DBpedia data. Several hundred data sets on the Web publish RDF links pointing to DBpedia themselves and make DBpedia one of the central interlinking hubs in the Linked Open Data (LOD) cloud. In this system report, we give an overview of the DBpedia community project, including its architecture, technical implementation, maintenance, internationalisation, usage statistics and applications.", "keywords": ["Knowledge extraction", "Wikipedia", "multilingual knowledge bases", "Linked Data", "RDF"], "reference_count": 49, "ccf_class": "B", "is_important": 1.0, "references": [{"ref": "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives, DBpedia: A nucleus for a web of open data, in: Proc. of the 6th International Semantic Web Conference (ISWC), Lecture Notes in Computer Science, Vol. 4825, Springer, 2008, pp. 722\u2013735."}, {"ref": "S. Auer and J. Lehmann, What have Innsbruck and Leipzig in common? Extracting semantics from wiki content, in: Proc. of the ESWC (2007), Lecture Notes in Computer Science, Vol. 4519, Springer, Berlin/Heidelberg, 2007, pp. 503\u2013517."}, {"ref": "C. Becker and C. Bizer, Exploring the geospatial Semantic Web with DBpedia Mobile, Journal of Web Semantics 7(4)(2009), 278\u2013286."}, {"ref": "D. Bikel, V. Castelli, R. Florian, and D.-J. Han, Entity linking and slot \ufb01lling through statistical processing and inference rules, in: Proc. TAC Workshop, 2009."}, {"ref": "C. Bizer, J. Lehmann, G. Kobilarov, S. Auer, C. Becker, R. Cyganiak, and S. Hellmann, DBpedia \u2013 a crystallization point for the Web of Data, Journal of Web Semantics 7(3) (2009), 154\u2013165."}, {"ref": "E. Cabrio, J. Cojan, A.P. Aprosio, B. Magnini, A. Lavelli, and F. Gandon, QAKiS: An open domain QA system based on relational patterns, in: ISWC-PD; International Semantic Web Conference (Posters & Demos), CEUR Workshop Proceedings, Vol. 914, CEUR-WS.org, 2012."}, {"ref": "D.V. Camarda, S. Mazzini, and A. Antonuccio, Lodlive, exploring the Web of Data, in: I-SEMANTICS 2012 \u2013 8th International Conference on Semantic Systems, ACM, 2012, pp. 197-200."}, {"ref": "S. Campinas, T.E. Perry, D. Ceccarelli, R. Delbru, and G. Tummarello, Introducing RDF graph summary with application to assisted SPARQL formulation, in: Database and Expert Systems Applications (DEXA), 2012 23rd International Workshop, IEEE, 2012, pp. 261\u2013266."}, {"ref": "D. Damljanovic, M. Agatonovic, and H. Cunningham, FREyA: An interactive way of querying linked data using natural language, in: The Semantic Web: ESWC 2011 Workshops, Vol. 7117, Springer, 2012, pp. 125\u2013138."}, {"ref": "O. Erling and I. Mikhailov, RDF support in the Virtuoso DBMS, in: CSSW, LNI, Vol. 113, GI, 2007, pp. 59\u201368."}, {"ref": "O. Etzioni, M. Cafarella, D. Downey, S. Kok, A.-M. Popescu, T. Shaked, S. Soderland, D.S. Weld, and A. Yates, Web-scale information extraction in KnowitAll, in: Proc. of the 13th International Conference on World Wide Web, ACM, 2004, pp. 100\u2013110."}, {"ref": "D. Ferrucci, E. Brown, J. Chu-Carroll, J. Fan, D. Gondek, A.A. Kalyanpur, A. Lally, J.W. Murdock, E. Nyberg, J. Prager, et al., Building Watson: An overview of the DeepQA project, AI magazine 31(3) (2010), 59\u201379."}, {"ref": "A. Garc\u00eda-Silva, M. Jakob, P.N. Mendes, and C. Bizer, Multipedia: Enriching DBpedia with multimedia information, in: Proc. of the Sixth International Conference on Knowledge Capture, K-CAP \u201911, New York, NY, USA, ACM, 2011, pp. 137\u2013144."}, {"ref": "A. Garc\u00eda-Silva, M. Szomszor, H. Alani, and O. Corcho, Preliminary results in tag disambiguation using DBpedia, in: 1st International Workshop in Collective Knowledage Capturing and Representation (CKCaR), California, USA, 2009."}, {"ref": "R. Hahn, C. Bizer, C. Sahnwaldt, C. Herta, S. Robinson, M. B\u00fcrgle, H. D\u00fcwiger, and U. Scheel, Faceted Wikipedia search, in: Business Information Systems, Proc. of 13th International Conference, BIS 2010, Berlin, Germany, May 3\u20135, 2010, W. Abramowicz and R. Tolksdorf, eds, Lecture Notes in Business Information Processing, Vol. 47, Springer, 2010, pp. 1\u201311."}, {"ref": "P. Heim, T. Ertl, and J. Ziegler, Facet Graphs: Complex semantic querying made easy, in: Proc. of the 7th Extended Semantic Web Conference (ESWC 2010), LNCS, Vol. 6088, Springer,Berlin/Heidelberg, 2010, pp. 288\u2013302."}, {"ref": "P. Heim, S. Hellmann, J. Lehmann, S. Lohmann, and T. Stegemann, RelFinder: Revealing relationships in RDF knowledge bases, in: Semantic Multimedia, Proc. of 4th International Conference on Semantic and Digital Media Technologies, SAMT 2009, Graz, Austria, December 2\u20134, 2009, Lecture Notes in Computer Science, Vol. 5887, Springer, 2009, pp. 182\u2013187."}, {"ref": "P. Heim, S. Lohmann, D. Tsendragchaa, and T. Ertl, SemLens: Visual analysis of semantic data with scatter plots and semantic lenses, in: Proc. the 7th International Conference on Semantic Systems, I-SEMANTICS 2011, Graz, Austria, September 7\u20139, 2011, ACM International Conference Proceeding Series, ACM, 2011, pp. 175\u2013178."}, {"ref": "S. Hellmann, J. Brekle, and S. Auer, Leveraging the crowdsourcing of lexical resources for bootstrapping a linguistic data cloud, in: Proc. of the Joint International Semantic Technology Conference (JIST), Vol. 7774, Springer, 2012, pp. 191\u2013206."}, {"ref": "S. Hellmann, C. Stadler, J. Lehmann, and S. Auer, DBpedia live extraction, in: Proc. of 8th International Conference on Ontologies, DataBases, and Applications of Semantics (ODBASE), Lecture Notes in Computer Science, Vol. 5871, 2009, pp. 1209\u20131223."}, {"ref": "J. Hoffart, F.M. Suchanek, K. Berberich, and G. Weikum, YAGO2: A spatially and temporally enhanced knowledge base from Wikipedia, Artif. Intell 194 (2013), 28\u201361."}, {"ref": "H. Ji, R. Grishman, H.T. Dang, K. Grif\ufb01tt, and J. Ellis, Overview of the TAC 2010 knowledge base population track, in: Third Text Analysis Conference (TAC 2010), 2010."}, {"ref": "G. Kobilarov, T. Scott, Y. Raimond, S. Oliver, C. Sizemore, M. Smethurst, C. Bizer, and R. Lee, Media meets Semantic Web \u2013 how the BBC uses DBpedia and linked data to make connections, in: The Semantic Web: Research and Applications, Proc. of 6th European Semantic Web Conference, ESWC, Springer, 2009, pp. 723\u2013737."}, {"ref": "D. Kontokostas, C. Bratsas, S. Auer, S. Hellmann, I. Antoniou, and G. Metakides, Internationalization of linked data: The case of the Greek DBpedia edition, Web Semantics: Science, Services and Agents on the World Wide Web 15 (2012), 51\u201361."}, {"ref": "D. Kontokostas, A. Zaveri, S. Auer, and J. Lehmann, Triplecheckmate: A tool for crowdsourcing the quality assessment of linked data, in: Knowledge Engineering and the Semantic Web \u2013 Proc. of 4th International Conference, KESW, Communications in Computer and Information Science, Vol. 394, Springer, 2013, pp. 265\u2013272."}, {"ref": "P. Kreis, Design of a quality assessment framework for the DBpedia knowledge base, Master\u2019s thesis, Freie Universit\u00e4t Berlin, 2011."}, {"ref": "C. Lagoze, H.V. de Sompel, M. Nelson, and S. Warner, The open archives initiative protocol for metadata harvesting, http://www.openarchives.org/OAI/openarchivesprotocol.html, 2008."}, {"ref": "J. Lehmann, S. Monahan, L. Nezda, A. Jung, and Y. Shi, LCC approaches to knowledge base population at TAC 2010, in: Proc. of the TAC Workshop, 2010."}, {"ref": "D.B. Lenat, CYC: A large-scale investment in knowledge infrastructure, Communications of the ACM 38(11) (1995), 33\u201338."}, {"ref": "C.-Y. Lin and E.H. Hovy, The automated acquisition of topic signatures for text summarization, in: Proc. of the 18th Conference on Computational linguistics, 2000, pp. 495\u2013501."}, {"ref": "V. Lopez, M. Fern\u00e1ndez, E. Motta, and N. Stieler, PowerAqua: Supporting users in querying and exploring the Semantic Web, Semantic Web 3(3) (2012), 249\u2013265."}, {"ref": "M. Martin, C. Stadler, P. Frischmuth, and J. Lehmann, Increasing the \ufb01nancial transparency of European Commission project funding, Semantic Web Journal, Special Call for Linked Dataset descriptions, 2013."}, {"ref": "P.N. Mendes, M. Jakob, and C. Bizer, DBpedia for NLP \u2013 a multilingual cross-domain knowledge base, in: Proc. of the International Conference on Language Resources and Evaluation (LREC), Istanbul, Turkey, 2012."}, {"ref": "P.N. Mendes, M. Jakob, A. Garc\u00eda-Silva, and C. Bizer, DBpedia Spotlight: Shedding light on the web of documents, in: Proc. of the 7th International Conference on Semantic Systems (I-Semantics), Graz, Austria, 2011."}, {"ref": "S.M. Meyer, J. Degener, J. Giannandrea, and B. Michener, Optimizing schema-last tuple-store queries in GraphD, in: SIGMOD Conference, A.K. Elmagarmid and D. Agrawal, eds, ACM, 2010, pp. 1047\u20131056."}, {"ref": "M. Morsey, J. Lehmann, S. Auer, C. Stadler, and S. Hellmann, DBpedia and the live extraction of structured data from Wikipedia, Program: Electronic Library and Information Systems 46 (2012), 27."}, {"ref": "K. Nakayama, M. Pei, M. Erdmann, M. Ito, M. Shirakawa, T. Hara, and S. Nishio, Wikipedia mining: Wikipedia as a corpus for knowledge extraction, in: Annual Wikipedia Conference (Wikimania), 2008."}, {"ref": "X. Niu, X. Sun, H. Wang, S. Rong, G. Qi, and Y. Yu, Zhishi.me: Weaving chinese linking open data, in: 10th International Conference on The Semantic Web \u2013 Volume Part II, SpringerVerlag, Berlin, Heidelberg, 2011, pp. 205\u2013220."}, {"ref": "E. Oren, R. Delbru, M. Catasta, R. Cyganiak, H. Stenzhorn, and G. Tummarello, Sindice.com: A document-oriented lookup index for open linked data, Int. J. of Metadata and Semantics and Ontologies 3 (2008), 37\u201352."}, {"ref": "S.P. Ponzetto and M. Strube, WikiTaxonomy: A large scale knowledge resource, in: ECAI, M. Ghallab, C.D. Spyropoulos, N. Fakotakis, and N.M. Avouris, eds, Frontiers in Arti\ufb01cial Intelligence and Applications, Vol. 178, IOS Press, 2008, pp. 751\u2013752."}, {"ref": "C. Stadler, J. Lehmann, K. H\u00f6ffner, and S. Auer, LinkedGeoData: A core for a web of spatial open data, Semantic Web Journal 3(4) (2012), 333\u2013354."}, {"ref": "F.M. Suchanek, G. Kasneci, and G. Weikum, Yago: A core of semantic knowledge, in: Proc. of the 16th International Conference on World Wide Web (WWW), ACM, 2007, pp. 697\u2013706."}, {"ref": "E. Tacchini, A. Schultz, and C. Bizer, Experiments with Wikipedia cross-language data fusion, in: Proc. of the 5th Workshop on Scripting and Development for the Semantic Web, co-located with ESWC, 2009."}, {"ref": "C. Unger, L. B\u00fchmann, J. Lehmann, A.-C. Ngonga Ngomo, D. Gerber, and P. Cimiano, Template-based question answering over RDF data, in: Proc. of the 21st International Conference on World Wide Web, 2012, pp. 639\u2013648."}, {"ref": "Z. Wang, J. Li, Z. Wang, and J. Tang, Cross-lingual knowledge linking across wiki knowledge bases, in: Proc. of the 21st International Conference on World Wide Web, New York, NY, USA, ACM, 2012, pp. 459\u2013468."}, {"ref": "F. Wu and D.S. Weld, Autonomously semantifying Wikipedia, in: Proc. of the 16th Conference on Information and Knowledge Management, ACM, 2007, pp. 41\u201350."}, {"ref": "F. Wu and D.S. Weld, Automatically re\ufb01ning the wikipedia infobox ontology, in: Proc. of the 17th International Conference on World Wide Web, WWW, ACM, 2008, pp. 635\u2013644."}, {"ref": "A. Zaveri, D. Kontokostas, M.A. Sherif, L. B\u00fchmann, M. Morsey, S. Auer, and J. Lehmann, User-driven quality evaluation of DBpedia, in: I-SEMANTICS \u2013 9th International Conference on Semantic Systems, ACM, 2013, pp. 97\u2013104."}, {"ref": "T. Zesch, C. M\u00fcller, and I. Gurevych, Extracting lexical semantic knowledge from Wikipedia and Wiktionary, in: Proc. of the 6th International Conference on Language Resources and Evaluation (LREC), Vol. 8, 2008, pp. 1646\u20131652."}]}, {"author": ["Fabian M. Suchanek", "Gjergji Kasneci", "Gerhard Weikum"], "title": "YAGO: A core of semantic knowledge", "journal": "WWW", "year": 2007, "DOI": "10.1145/1242572.1242667", "month": 5.0, "citations": 3039, "abstract": "We present YAGO, a light-weight and extensible ontology with high coverage and quality. YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts. This includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE). The facts have been automatically extracted from Wikipedia and unified with WordNet, using a carefully designed combination of rule-based and heuristic methods described in this paper. The resulting knowledge base is a major step beyond WordNet: in\u00a0quality\u00a0by adding knowledge about individuals like persons, organizations, products, etc. with their semantic relationships - and in\u00a0quantity\u00a0by increasing the number of facts by more than an order of magnitude. Our empirical evaluation of fact correctness shows an accuracy of about 95%. YAGO is based on a logically clean model, which is decidable, extensible, and compatible with RDFS. Finally, we show how YAGO can be further extended by state-of-the-art information extraction techniques.", "keywords": ["Wikipedia", "WordNet"], "reference_count": 28, "ccf_class": "A", "is_important": 1.0, "references": [{"ref": "E. Agichtein and L. Gravano. Snowball: extracting relations from large plain-text collections. In ICDL, 2000."}, {"ref": "F. Baader and T. Nipkow. Term rewriting and all that. Cambridge University Press, New York, NY, USA, 1998."}, {"ref": "R. C. Bunescu and M. Pasca. Using encyclopedic knowledge for named entity disambiguation. In EACL, 2006."}, {"ref": "M. J. Cafarella, D. Downey, S. Soderland, and O. Etzioni. KnowItNow: Fast, scalable information extraction from the web. In EMNLP, 2005."}, {"ref": "N. Chatterjee, S. Goyal, and A. Naithani. Resolving pattern ambiguity for english to hindi machine translation using WordNet. In Workshop on Modern Approaches in Translation Technologies, 2005."}, {"ref": "S. Chaudhuri, V. Ganti, and R. Motwani. Robust identi\ufb01cation of fuzzy duplicates. In ICDE, 2005."}, {"ref": "W. W. Cohen and S. Sarawagi. Exploiting dictionaries in named entity extraction: combining semi-markov extraction processes and data integration methods. In KDD, 2004."}, {"ref": "H. Cunningham, D. Maynard, K. Bontcheva, and V. Tablan. GATE: A framework and graphical development environment for robust NLP tools and applications. In ACL, 2002."}, {"ref": "O. Etzioni, M. J. Cafarella, D. Downey, S. Kok, A.-M. Popescu, T. Shaked, S. Soderland, D. S. Weld, and A. Yates. Web-scale information extraction in KnowItAll. In WWW, 2004."}, {"ref": "C. Fellbaum, editor. WordNet: An Electronic Lexical Database. MIT Press, 1998."}, {"ref": "J. Graupmann, R. Schenkel, and G. Weikum. The spheresearch engine for uni\ufb01ed ranked retrieval of heterogeneous XML and web documents. In VLDB, 2005."}, {"ref": "I. Horrocks, O. Kutz, and U. Sattler. The even more irresistible SROIQ. In KR, 2006."}, {"ref": "W. Hunt, L. Lita, and E. Nyberg. Gazetteers, wordnet, encyclopedias, and the web: Analyzing question answering resources. Technical Report CMU-LTI-04-188, Language Technologies Institute, Carnegie Mellon, 2004."}, {"ref": "G. Ifrim and G. Weikum. Transductive learning for text classi\ufb01cation using explicit knowledge models. In PKDD, 2006."}, {"ref": "D. Kinzler. WikiSense - Mining the Wiki. In Wikimania, 2005."}, {"ref": "S. Liu, F. Liu, C. Yu, and W. Meng. An e\ufb00ective approach to document retrieval via utilizing wordnet and recognizing phrases. In SIGIR, 2004."}, {"ref": "C. Matuszek, J. Cabral, M. Witbrock, and J. DeOliveira. An introduction to the syntax and content of Cyc. In AAAI Spring Symposium, 2006."}, {"ref": "I. Niles and A. Pease. Towards a standard upper ontology. In FOIS, 2001."}, {"ref": "N. F. Noy, A. Doan, and A. Y. Halevy. Semantic integration. AI Magazine, 26(1):7\u201310, 2005."}, {"ref": "P. Pantel and M. Pennacchiotti. Espresso: Leveraging generic patterns for automatically harvesting semantic relations. In ACL, 2006."}, {"ref": "M. Ruiz-Casado, E. Alfonseca, and P. Castells. Automatic extraction of semantic relationships for WordNet by means of pattern learning from Wikipedia. In NLDB, pages 67\u201379, 2006."}, {"ref": "S. Russell and P. Norvig. Arti\ufb01cial Intelligence: a Modern Approach. Prentice Hall, 2002."}, {"ref": "R. Snow, D. Jurafsky, and A. Y. Ng. Semantic taxonomy induction from heterogenous evidence. In ACL, 2006."}, {"ref": "S. Staab and R. Studer. Handbook on Ontologies. Springer, 2004."}, {"ref": "F. M. Suchanek, G. Ifrim, and G. Weikum. Combining linguistic and statistical analysis to extract relations from web documents. In KDD, 2006."}, {"ref": "F. M. Suchanek, G. Ifrim, and G. Weikum. LEILA: Learning to Extract Information by Linguistic Analysis. In Workshop on Ontology Population at ACL/COLING, 2006."}, {"ref": "M. Theobald, R. Schenkel, and G. Weikum. TopX and XXL at INEX 2005. In INEX, 2005."}, {"ref": "W3C. Sparql, 2005. retrieved from http://www.w3.org/TR/rdf-sparql-query/."}]}, {"author": ["Andrew Carlson", "Justin Betteridge", "Bryan Kisiel", "Burr Settles", "Estevam R. Hruschka", "Tom M. Mitchell"], "title": "Toward an architecture for never-ending language learning", "journal": "AAAI", "year": 2010, "DOI": "", "month": 7.0, "citations": 1445, "abstract": "We consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent.", "keywords": ["information extraction", "web mining", "semi-supervised learning"], "reference_count": 29, "ccf_class": "A", "is_important": 1.0, "references": [{"ref": "Anderson, J. R.; Byrne, M. D.; Douglass, S.; Lebiere, C.; and Qin, Y. 2004. An integrated theory of the mind. Psychological Review 111(4):1036\u20131050."}, {"ref": "Banko, M., and Etzioni, O. 2007. Strategies for lifelong knowledge extraction from the web. In Proc. of K-CAP. Blum, A., and Mitchell, T. 1998. Combining labeled and unlabeled data with co-training. In Proc. of COLT."}, {"ref": "Callan, J., and Hoy, M. 2009. Clueweb09 data set. http://boston.lti.cs.cmu.edu/Data/clueweb09/."}, {"ref": "Carbonell, J.; Etzioni, O.; Gil, Y.; Joseph, R.; Knoblock, C.; Minton, S.; and Veloso, M. 1991. PRODIGY: an integrated architecture for planning and learning. SIGART Bull. 2(4):51\u201355."}, {"ref": "Carlson, A.; Betteridge, J.; Wang, R. C.; Jr., E. R. H.; and Mitchell, T. M. 2010. Coupled semi-supervised learning for information extraction. In Proc. of WSDM."}, {"ref": "Caruana, R. 1997. Multitask learning. Machine Learning 28:41\u201375."}, {"ref": "Chang, M.-W.; Ratinov, L.-A.; and Roth, D. 2007. Guiding semi-supervision with constraint-driven learning. In Proc. of ACL."}, {"ref": "Collins, M., and Singer, Y. 1999. Unsupervised models for named entity classi\ufb01cation. In Proc. of EMNLP."}, {"ref": "Curran, J. R.; Murphy, T.; and Scholz, B. 2007. Minimising semantic drift with mutual exclusion bootstrapping. In Proc. of PACLING."}, {"ref": "Downey, D.; Etzioni, O.; and Soderland, S. 2005. A probabilistic model of redundancy in information extraction. In Proc. of IJCAI."}, {"ref": "Druck, G.; Settles, B.; and McCallum, A. 2009. Active learning by labeling features. In Proc. of EMNLP."}, {"ref": "Erman, L.; Hayes-Roth, F.; Lesser, V.; and Reddy, D. 1980. The HEARSAY-II speech-understanding system: Integrating knowledge to resolve uncertainty. Computing Surveys 12(2):213\u2013253."}, {"ref": "Etzioni, O.; Cafarella, M.; Downey, D.; Popescu, A.-M.; Shaked, T.; Soderland, S.; Weld, D. S.; and Yates, A. 2004. Methods for domain-independent information extraction from the web: an experimental comparison. In Proc. of AAAI."}, {"ref": "Hearst, M. A. 1992. Automatic acquisition of hyponyms from large text corpora. In Proc. of COLING."}, {"ref": "Laird, J.; Newell, A.; and Rosenbloom, P. 1987. SOAR: An architecture for general intelligence. Artif. Intel. 33:1\u201364."}, {"ref": "Langley, P.; McKusick, K. B.; Allen, J. A.; Iba, W. F.; and Thompson, K. 1991. A design for the ICARUS architecture. SIGART Bull. 2(4):104\u2013109."}, {"ref": "Lenat, D. B. 1983. Eurisko: A program that learns new heuristics and domain concepts. Artif. Intel. 21(1-2):61\u201398."}, {"ref": "Mitchell, T. M.; Allen, J.; Chalasani, P.; Cheng, J.; Etzioni, O.; Ringuette, M. N.; and Schlimmer, J. C. 1991. Theo: A framework for self-improving systems. Arch. for Intelligence 323\u2013356."}, {"ref": "Nahm, U. Y., and Mooney, R. J. 2000. A mutually bene\ufb01cial integration of data mining and information extraction. In Proc. of AAAI."}, {"ref": "Pas\u00b8ca, M.; Lin, D.; Bigham, J.; Lifchits, A.; and Jain, A. 2006. Names and similarities on the web: fact extraction in the fast lane. In Proc. of ACL."}, {"ref": "Pennacchiotti, M., and Pantel, P. 2009. Entity extraction via ensemble semantics. In Proc. of EMNLP."}, {"ref": "Quinlan, J. R., and Cameron-Jones, R. M. 1993. Foil: A midterm report. In Proc. of ECML."}, {"ref": "Riloff, E., and Jones, R. 1999. Learning dictionaries for information extraction by multi-level bootstrapping. In Proc. of AAAI."}, {"ref": "Settles, B. 2009. Active learning literature survey. Computer Sciences Technical Report 1648, University of WisconsinMadison."}, {"ref": "Thrun, S., and Mitchell, T. 1995. Lifelong robot learning. In Robotics and Autonomous Systems, volume 15, 25\u201346."}, {"ref": "Wang, R. C., and Cohen, W. W. 2009. Character-level analysis of semi-structured documents for set expansion. In Proc. of EMNLP."}, {"ref": "Yang, X.; Kim, S.; and Xing, E. 2009. Heterogeneous multitask learning with joint sparsity constraints. In NIPS 2009."}, {"ref": "Yangarber, R. 2003. Counter-training in discovery of semantic patterns. In Proc. of ACL."}, {"ref": "Yarowsky, D. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proc. of ACL."}]}, {"author": ["Antoine Bordes", "Jason Weston", "Nicolas Usunier"], "title": "Open question answering with weakly supervised embedding models", "journal": "ECML PKDD", "year": 2014, "DOI": "10.1007/978-3-662-44848-9_11", "month": 0.0, "citations": 192, "abstract": "Building computers able to answer questions on any subject is a long standing goal of artificial intelligence. Promising progress has recently been achieved by methods that learn to map questions to logical forms or database queries. Such approaches can be effective but at the cost of either large amounts of human-labeled data or by defining lexicons and grammars tailored by practitioners. In this paper, we instead take the radical approach of learning to map questions to vectorial feature representations. By mapping answers into the same space one can query any knowledge base independent of its schema, without requiring any grammar or lexicon. Our method is trained with a new optimization procedure combining stochastic gradient descent followed by a fine-tuning step using the weak supervision provided by blending automatically and collaboratively generated resources. We empirically demonstrate that our model can capture meaningful signals from its noisy supervision leading to major improvements over\u00a0paralex, the only existing method able to be trained on similar weakly labeled data.", "keywords": ["natural language processing", "\u00a0question answering", "\u00a0weak supervision", "\u00a0embedding models\u00a0"], "reference_count": 26, "ccf_class": "B", "is_important": "", "references": [{"ref": "Banko, M., Brill, E., Dumais, S., Lin, J.: Askmsr: Question answering using the worldwide web. In: Proceedings of 2002 AAAI Spring Symposium on Mining Answers from Texts and Knowledge Bases (2002)"}, {"ref": "Bengio, Y., Ducharme, R., Vincent, P., Jauvin, C.: A neural probabilistic language model. Journal of Machine Learning Research 3, 1137\u20131155 (2003)"}, {"ref": "Berant, J., Chou, A., Frostig, R., Liang, P.: Semantic parsing on Freebase from question-answer pairs. In: Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (October 2013)"}, {"ref": "Bollacker, K., Evans, C., Paritosh, P., Sturge, T., Taylor, J.: Freebase: a collaboratively created graph database for structuring human knowledge. In: Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data. ACM(2008)"}, {"ref": "Bordes, A., Glorot, X., Weston, J., Bengio, Y.: Joint learning of words and meaning representations for open-text semantic parsing. In: Proc. of the 15th Intern. Conf. on Artif. Intel. and Stat., vol. 22] JMLR W&CP (2012)"}, {"ref": "Cai, Q., Yates, A.: Large-scale semantic parsing via schema matching and lexicon extension. In: Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. Long Papers, vol. 1 (August 2013)"}, {"ref": "Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., Kuksa, P.: Natural language processing (almost) from scratch. Journal of Machine Learning Research 12, 2493\u20132537 (2011)"}, {"ref": "Duchi, J., Hazan, E., Singer, Y.: Adaptive subgradient methods for online learning and stochastic optimization. The Journal of Machine Learning Research 12 (2011)"}, {"ref": "Fader, A., Soderland, S., Etzioni, O.: Identifying relations for open information extraction. In: Proceedings of the Conference of Empirical Methods in Natural Language Processing (EMNLP 2011), Edinburgh, Scotland, UK, July 27-31 (2011)"}, {"ref": "Fader, A., Zettlemoyer, L., Etzioni, O.: Paraphrase-driven learning for open question answering. In: Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria, pp. 1608\u20131618 (2013)"}, {"ref": "Fader, A., Zettlemoyer, L., Etzioni, O.: Open question answering over curated and extracted knowledge bases. In: KDD (2014)"}, {"ref": "Hoffmann, R., Zhang, C., Ling, X., Zettlemoyer, L., Weld, D.S.: Knowledge-based weak supervision for information extraction of overlapping relations. In: Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, vol. 1 (2011)"}, {"ref": "Kwiatkowski, T., Choi, E., Artzi, Y., Zettlemoyer, L.: Scaling semantic parsers with on-the-fly ontology matching. In: Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (October 2013)"}, {"ref": "Kwok, C., Etzioni, O., Weld, D.S.: Scaling question answering to the web. ACM Transactions on Information Systems (TOIS) 19(3) (2001)"}, {"ref": "Lao, N., Subramanya, A., Pereira, F., Cohen, W.W.: Reading the web with learned syntactic-semantic inference rules. In: Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (2012)"}, {"ref": "Lehmann, J., Isele, R., Jakob, M., Jentzsch, A., Kontokostas, D., Mendes, P.N., Hellmann, S., Morsey, M., van Kleef, P., Auer, S., Bizer, C.: DBpedia - a largescale, multilingual knowledge base extracted from wikipedia. Semantic Web Journal (2014)"}, {"ref": "Mintz, M., Bills, S., Snow, R., Jurafsky, D.: Distant supervision for relation extraction without labeled data. In: Proc. of the Conference of the 47th Annual Meeting of ACL (2009)"}, {"ref": "Pomik\u00b4alek, J., Jakub\u00b4\u0131cek, M., Rychl`y, P.: Building a 70 billion word corpus of english from clueweb. In: LREC, pp. 502\u2013506 (2012)"}, {"ref": "Recht, B., R\u00b4e, C., Wright, S.J., Niu, F.: Hogwild!: A lock-free approach to parallelizing stochastic gradient descent. In: Advances in Neural Information Processing Systems (NIPS 24) (2011)"}, {"ref": "Riedel, S., Yao, L., McCallum, A., Marlin, B.M.: Relation extraction with matrix factorization and universal schemas. In: Proceedings of NAACL-HLT (2013)"}, {"ref": "Socher, R., Perelygin, A., Wu, J.Y., Chuang, J., Manning, C.D., Ng, A.Y., Potts, C.: Recursive deep models for semantic compositionality over a sentiment treebank. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP) (2013)"}, {"ref": "Unger, C., B\u00a8uhmann, L., Lehmann, J., Ngonga Ngomo, A.C., Gerber, D., Cimiano, P.: Template-based question answering over rdf data. In: Proceedings of the 21st International Consference on World Wide Web (2012)"}, {"ref": "Voorhees, E.M., Tice, D.M.: Building a question answering test collection. In: Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM (2000)"}, {"ref": "Weston, J., Bengio, S., Usunier, N.: Large scale image annotation: learning to rank with joint word-image embeddings. Machine Learning 81(1) (2010)"}, {"ref": "Weston, J., Bordes, A., Yakhnenko, O., Usunier, N.: Connecting language and knowledge bases with embedding models for relation extraction. In: Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pp. 1366\u20131371 (2013)"}, {"ref": "Yahya, M., Berberich, K., Elbassuoni, S., Ramanath, M., Tresp, V., Weikum, G.: Natural language questions for the web of data. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing (2012)"}]}, {"author": ["Antoine Bordes", "\u00a0Sumit Chopra", "\u00a0Jason Weston"], "title": "Question answering with subgraph embeddings", "journal": "EMNLP", "year": 2014, "DOI": "10.3115/v1/D14-1067", "month": 10.0, "citations": 361, "abstract": "This paper presents a system which learns to answer questions on a broad range of topics from a knowledge base using few hand-crafted features. Our model learns low-dimensional embeddings of words and knowledge base constituents; these representations are used to score natural language questions against candidate answers. Training our system using pairs of questions and structured representations of their answers, and pairs of question paraphrases, yields competitive results on a competitive benchmark of the literature.", "keywords": [""], "reference_count": 15, "ccf_class": "B", "is_important": "", "references": [{"ref": "Jonathan Berant and Percy Liang. 2014. Semantic parsing via paraphrasing. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL\u201914), Baltimore, USA."}, {"ref": "Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on Freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP\u201913), Seattle, USA."}, {"ref": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, Vancouver, Canada. ACM."}, {"ref": "Antoine Bordes, Sumit Chopra, and Jason Weston. 2014a. Question answering with subgraph embeddings. CoRR, abs/1406.3676."}, {"ref": "Antoine Bordes, Jason Weston, and Nicolas Usunier. 2014b. Open question answering with weakly supervised embedding models. In Proceedings of the 7th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD\u201914), Nancy, France. Springer."}, {"ref": "Anthony Fader, Luke Zettlemoyer, and Oren Etzioni. 2013. Paraphrase-driven learning for open question answering. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL\u201913), Sofia, Bulgaria."}, {"ref": "Anthony Fader, Luke Zettlemoyer, and Oren Etzioni. 2014. Open question answering over curated and extracted knowledge bases. In Proceedings of 20th SIGKDD Conference on Knowledge Discovery and Data Mining (KDD\u201914), New York City, USA. ACM."}, {"ref": "Oleksandr Kolomiyets and Marie-Francine Moens. 2011. A survey on question answering technology from an information retrieval perspective. Information Sciences, 181(24):5412\u20135434."}, {"ref": "Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke Zettlemoyer. 2013. Scaling semantic parsers with on-the-fly ontology matching. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP\u201913), Seattle, USA, October."}, {"ref": "Thomas Lin, Mausam, and Oren Etzioni. 2012. Entity linking at web scale. In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBCWEKEX\u201912), Montreal, Canada."}, {"ref": "Benjamin Recht, Christopher Re, Stephen J Wright, \u00b4 and Feng Niu. 2011. Hogwild!: A lock-free approach to parallelizing stochastic gradient descent. In Advances in Neural Information Processing Systems (NIPS 24)., Vancouver, Canada."}, {"ref": "Christina Unger, Lorenz Buhmann, Jens Lehmann, Axel-Cyrille Ngonga Ngomo, Daniel Gerber, and Philipp Cimiano. 2012. Template-based question"}, {"ref": "answering over RDF data. In Proceedings of the 21st international conference on World Wide Web (WWW\u201912), Lyon, France. ACM."}, {"ref": "Jason Weston, Samy Bengio, and Nicolas Usunier. 2010. Large scale image annotation: learning to rank with joint word-image embeddings. Machine learning, 81(1)."}, {"ref": "Xuchen Yao and Benjamin Van Durme. 2014. Information extraction over structured data: Question answering with freebase. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL\u201914), Baltimore, USA."}]}, {"author": [" Maximilian Nickel", "Volker Tresp", "Hans-Peter Kriegel"], "title": "A three-way model for collective learning on multi-relational data", "journal": "ICML", "year": 2011, "DOI": "", "month": 6.0, "citations": 725, "abstract": "Relational learning is becoming increasingly important in many areas of application. Here, we present a novel approach to relational learning based on the factorization of a three-way tensor. We show that unlike other tensor approaches, our method is able to perform collective learning via the latent components of the model and provide an efficient algorithm to compute the factorization. We substantiate our theoretical considerations regarding the collective learning capabilities of our model by the means of experiments on both a new dataset and a dataset commonly used in entity resolution. Furthermore, we show on common benchmark datasets that our approach achieves better or on-par results, if compared to current state-of-the-art relational learning solutions, while it is significantly faster to compute.", "keywords": [""], "reference_count": 15, "ccf_class": "A", "is_important": 1.0, "references": [{"ref": "Bader, Brett W. and Kolda, Tamara G. MATLAB tensor toolbox version 2.4, March 2010. URL http://csmr.ca.sandia.gov/~tgkolda/TensorToolbox/."}, {"ref": "Bader, Brett W., Harshman, Richard A., and Kolda, Tamara G. Temporal analysis of semantic graphs using ASALSAN. In Seventh IEEE International Conference on Data Mining (ICDM 2007), pp. 33\u201342, Omaha, NE, USA, 2007. doi: 10.1109/ICDM.2007.54. URL http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4470227."}, {"ref": "Franz, T., Schultz, A., Sizov, S., and Staab, S. Triplerank: Ranking semantic web data by tensor decomposition. The Semantic Web-ISWC 2009, pp. 213\u2013228, 2009."}, {"ref": "Friedman, N., Getoor, L., Koller, D., and Pfeffer, A. Learning probabilistic relational models. In International Joint Conference on Artificial Intelligence, volume 16, pp. 1300\u20131309, 1999."}, {"ref": "Getoor, L. and Taskar, B. Introduction to statistical relational learning. The MIT Press, 2007. ISBN 0262072882."}, {"ref": "Harshman, R. A. Models for analysis of asymmetrical relationships among n objects or stimuli. In First Joint Meeting of the Psychometric Society and the Society for Mathematical Psychology, McMaster University, Hamilton, Ontario, August, 1978."}, {"ref": "Harshman, R. A and Lundy, M. E. PARAFAC: parallel factor analysis. Computational Statistics & Data Analysis, 18(1): 39\u201372, 1994. ISSN 0167-9473."}, {"ref": "Horn, Roger A. and Johnson, Charles R. Topics in matrix analysis. Cambridge University Press, June 1994. ISBN 9780521467131."}, {"ref": "Huang, Yi, Tresp, Volker, Bundschus, Markus, and Rettinger, Achim. Multivariate structured prediction for learning on semantic web. In Proceedings of the 20th International Conference on Inductive Logic Programming (ILP), 2010."}, {"ref": "Kemp, C., Tenenbaum, J. B, Griffiths, T. L, Yamada, T., and Ueda, N. Learning systems of concepts with an infinite relational model. In Proceedings of the National Conference on Artificial Intelligence, volume 21, pp. 381, 2006."}, {"ref": "Kok, S. and Domingos, P. Statistical predicate invention. In Proceedings of the 24th international conference on Machine learning, pp. 433\u2013440, 2007."}, {"ref": "Kolda, Tamara G. and Bader, Brett W. Tensor decompositions and applications. SIAM Review, 51(3): 455\u2014500, 2009. ISSN 00361445. doi: 10.1137/"}, {"ref": "07070111X. URL http://link.aip.org/link/SIREAD/v51/i3/p455/s1&Agg=doi."}, {"ref": "Richardson, M. and Domingos, P. Markov logic networks. Machine Learning, 62(1):107\u2013136, 2006. ISSN 0885-6125."}, {"ref": "Sen, P., Namata, G., Bilgic, M., Getoor, L., Galligher, B., and Eliassi-Rad, T. Collective classification in network data. AI Magazine, 29(3):93, 2008. ISSN 0738-4602."}, {"ref": "Singh, A. P and Gordon, G. J. Relational learning via collective matrix factorization. In Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 650\u2013658, 2008."}, {"ref": "Singla, P. and Domingos, P. Entity resolution with markov logic. In Data Mining, 2006. ICDM\u201906. Sixth International Conference on, pp. 572\u2013582, 2007."}, {"ref": "Sun, J., Tao, D., and Faloutsos, C. Beyond streams and graphs: dynamic tensor analysis. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 374\u2013383, 2006. ISBN 1595933395."}, {"ref": "Sutskever, I., Salakhutdinov, R., and Tenenbaum, J. B. Modelling relational data using bayesian clustered tensor factorization. Advances in Neural Information Processing Systems, 22, 2009."}, {"ref": "Tucker, L. R. Some mathematical notes on three-mode factor analysis. Psychometrika, 31(3):279\u2013311, 1966. ISSN 0033-3123."}, {"ref": "Xu, Z., Tresp, V., Yu, K., and Kriegel, H. P. Infinite hidden relational models. In Proceedings of the 22nd International Conference on Uncertainty in Artificial Intelligence, 2006."}]}, {"author": ["Antoine Bordes", "Nicolas Usunier", "Alberto Garcia-Duran", "Jason Weston", "Oksana Yakhnenko"], "title": "Translating embeddings for modeling multi-relational data", "journal": "NeurIPS", "year": 2013, "DOI": "", "month": 0.0, "citations": 1478, "abstract": "We consider the problem of embedding entities and relationships of multi-relational data in low-dimensional vector spaces. Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large databases. Hence, we propose, TransE, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities. Despite its simplicity, this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. Besides, it can be successfully trained on a large scale data set with 1M entities, 25k relationships and more than 17M training samples.", "keywords": [""], "reference_count": 17, "ccf_class": "A", "is_important": 1.0, "references": [{"ref": "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, 2008."}, {"ref": "A. Bordes, X. Glorot, J. Weston, and Y. Bengio. A semantic matching energy function for learning with multi-relational data. Machine Learning, 2013."}, {"ref": "A. Bordes, J. Weston, R. Collobert, and Y. Bengio. Learning structured embeddings of knowledge bases. In Proceedings of the 25th Annual Conference on Arti\ufb01cial Intelligence (AAAI), 2011."}, {"ref": "X. Glorot and Y. Bengio. Understanding the dif\ufb01culty of training deep feedforward neural networks. In Proceedings of the International Conference on Arti\ufb01cial Intelligence and Statistics (AISTATS)., 2010."}, {"ref": "R. A. Harshman and M. E. Lundy. Parafac: parallel factor analysis. Computational Statistics & Data Analysis, 18(1):39\u201372, Aug. 1994."}, {"ref": "R. Jenatton, N. Le Roux, A. Bordes, G. Obozinski, et al. A latent factor model for highly multi-relational data. In Advances in Neural Information Processing Systems (NIPS 25), 2012."}, {"ref": "C. Kemp, J. B. Tenenbaum, T. L. Grif\ufb01ths, T. Yamada, and N. Ueda. Learning systems of concepts with an in\ufb01nite relational model. In Proceedings of the 21st Annual Conference on Arti\ufb01cial Intelligence (AAAI), 2006."}, {"ref": "T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems (NIPS 26), 2013."}, {"ref": "G. Miller. WordNet: a Lexical Database for English. Communications of the ACM, 38(11):39\u201341, 1995."}, {"ref": "K. Miller, T. Grif\ufb01ths, and M. Jordan. Nonparametric latent feature models for link prediction. In Advances in Neural Information Processing Systems (NIPS 22), 2009."}, {"ref": "M. Nickel, V. Tresp, and H.-P. Kriegel. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th International Conference on Machine Learning (ICML), 2011."}, {"ref": "M. Nickel, V. Tresp, and H.-P. Kriegel. Factorizing YAGO: scalable machine learning for linked data. In Proceedings of the 21st international conference on World Wide Web (WWW), 2012."}, {"ref": "A. P. Singh and G. J. Gordon. Relational learning via collective matrix factorization. In Proceedings of the 14th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2008."}, {"ref": "R. Socher, D. Chen, C. D. Manning, and A. Y. Ng. Learning new facts from knowledge bases with neural tensor networks and semantic word vectors. In Advances in Neural Information Processing Systems (NIPS 26), 2013."}, {"ref": "I. Sutskever, R. Salakhutdinov, and J. Tenenbaum. Modelling relational data using bayesian clustered tensor factorization. In Advances in Neural Information Processing Systems (NIPS 22), 2009."}, {"ref": "J. Weston, A. Bordes, O. Yakhnenko, and N. Usunier. Connecting language and knowledge bases with embedding models for relation extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2013."}, {"ref": "J. Zhu. Max-margin nonparametric latent feature models for link prediction. In Proceedings of the 29th International Conference on Machine Learning (ICML), 2012."}]}, {"author": ["Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen"], "title": "Knowledge graph embedding by translating on hyperplanes", "journal": "AAAI", "year": 2014, "DOI": "", "month": 6.0, "citations": 770, "abstract": "We deal with embedding a large scale knowledge graph composed of entities and relations into a continuous vector space. TransE is a promising method proposed recently, which is very efficient while achieving state-of-the-art predictive performance. We discuss some mapping properties of relations which should be considered in embedding, such as reflexive, one-to-many, many-to-one, and many-to-many. We note that TransE does not do well in dealing with these properties. Some complex models are capable of preserving these mapping properties but sacrifice efficiency in the process. To make a good trade-off between model capacity and efficiency, in this paper we propose TransH which models a relation as a hyperplane together with a translation operation on it. In this way, we can well preserve the above mapping properties of relations with almost the same model complexity of TransE. Additionally, as a practical knowledge graph is often far from completed, how to construct negative examples to reduce false negative labels in training is very important. Utilizing the one-to-many/many-to-one mapping property of a relation, we propose a simple trick to reduce the possibility of false negative labeling. We conduct extensive experiments on link prediction, triplet classification and fact extraction on benchmark datasets like WordNet and Freebase. Experiments show TransH delivers significant improvements over TransE on predictive accuracy with comparable capability to scale up.", "keywords": ["Knowledge Embedding", "Knowledge Graph", "TransH"], "reference_count": 17, "ccf_class": "A", "is_important": "", "references": [{"ref": "Ashburner, M.; Ball, C. A.; Blake, J. A.; Botstein, D.; Butler, H.; Cherry, J. M.; Davis, A. P.; Dolinski, K.; Dwight, S. S.; Eppig, J. T.; et al. 2000. Gene ontology: Tool for the unification of biology. Nature genetics 25(1):25\u201329."}, {"ref": "Bollacker, K.; Evans, C.; Paritosh, P.; Sturge, T.; and Taylor, J. 2008. Freebase: A collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, 1247\u20131250. ACM."}, {"ref": "Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning structured embeddings of knowledge bases. In Proceedings of the 25th AAAI Conference on Artificial Intelligence. 1118"}, {"ref": "Bordes, A.; Glorot, X.; Weston, J.; and Bengio, Y. 2012. A semantic matching energy function for learning with multirelational data. Machine Learning 1\u201327."}, {"ref": "Bordes, A.; Usunier, N.; Garcia-Duran, A.; Weston, J.; and Yakhnenko, O. 2013a. Irreflexive and hierarchical relations as translations. arXiv preprint arXiv:1304.7158."}, {"ref": "Bordes, A.; Usunier, N.; Garcia-Duran, A.; Weston, J.; and Yakhnenko, O. 2013b. Translating embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems 26. Curran Associates, Inc. 2787\u20132795."}, {"ref": "Chang, K.-W.; Yih, W.-t.; and Meek, C. 2013. Multirelational latent semantic analysis. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, 1602\u20131612. Seattle, Washington, USA: Association for Computational Linguistics."}, {"ref": "Collobert, R., and Weston, J. 2008. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the 25th Annual International Conference on Machine Learning (ICML 2008), 160\u2013167. Omnipress."}, {"ref": "Finkel, J. R.; Grenager, T.; and Manning, C. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, 363\u2013370. Association for Computational Linguistics."}, {"ref": "Hoffmann, R.; Zhang, C.; Ling, X.; Zettlemoyer, L. S.; and Weld, D. S. 2011. Knowledge-based weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting on Association for Computational Linguistics, 541\u2013550. Association for Computational Linguistics."}, {"ref": "Jenatton, R.; Roux, N. L.; Bordes, A.; and Obozinski, G. R. 2012. A latent factor model for highly multi-relational data. In Advances in Neural Information Processing Systems 25. Curran Associates, Inc. 3167\u20133175."}, {"ref": "Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; and Dean, J. 2013. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems 26. Curran Associates, Inc. 3111\u20133119."}, {"ref": "Miller, G. A. 1995. Wordnet: A lexical database for english. Communications of the ACM 38(11):39\u201341."}, {"ref": "Mintz, M.; Bills, S.; Snow, R.; and Jurafsky, D. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, 1003\u20131011. Association for Computational Linguistics."}, {"ref": "Nickel, M.; Tresp, V.; and Kriegel, H.-P. 2011. A threeway model for collective learning on multi-relational data. In Proceedings of the 28th International Conference on Machine Learning (ICML-11), ICML \u201911, 809\u2013816. New York, NY, USA: ACM."}, {"ref": "Riedel, S.; Yao, L.; and McCallum, A. 2010. Modeling relations and their mentions without labeled text. In Machine Learning and Knowledge Discovery in Databases. Springer. 148\u2013163."}, {"ref": "Socher, R.; Chen, D.; Manning, C. D.; and Ng, A. 2013. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems 26. Curran Associates, Inc. 926\u2013934."}, {"ref": "[]Surdeanu, M.; Tibshirani, J.; Nallapati, R.; and Manning, C. D. 2012. Multi-instance multi-label learning for relation extraction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, 455\u2013465. Association for Computational Linguistics."}, {"ref": "[]Sutskever, I.; Tenenbaum, J. B.; and Salakhutdinov, R. 2009. Modelling relational data using bayesian clustered tensor factorization. In Advances in Neural Information Processing Systems 22. Curran Associates, Inc. 1821\u20131828."}, {"ref": "[]Weston, J.; Bordes, A.; Yakhnenko, O.; and Usunier, N. 2013. Connecting language and knowledge bases with embedding models for relation extraction. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, 1366\u20131371. Seattle, Washington, USA: Association for Computational Linguistics."}]}, {"author": ["Yankai Lin", "Zhiyuan Liu", "Maosong Sun", "Yang Liu", "Xuan Zhu"], "title": "Learning entity and relation embeddings for knowledge graph completion", "journal": "AAAI", "year": 2015, "DOI": "10.1016/j.procs.2017.05.045", "month": 2.0, "citations": 828, "abstract": "Knowledge graph completion aims to perform link prediction between entities. In this paper, we consider the approach of knowledge graph embeddings. Recently, models such as TransE and TransH build entity and relation embeddings by regarding a relation as translation from head entity to tail entity. We note that these models simply put both entities and relations within the same semantic space. In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling. In this paper, we propose TransR to build entity and relation embeddings in separate entity space and relation spaces. Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. In experiments, we evaluate our models on three tasks including link prediction, triple classification and relational fact extraction. Experimental results show significant and consistent improvements compared to state-of-the-art baselines including TransE and TransH.", "keywords": ["knowledge graph embedding; knowledge graph completion; relation extraction; knolwedge representation"], "reference_count": 22, "ccf_class": "A", "is_important": 1.0, "references": [{"ref": "Bengio, Y.; Ducharme, R.; Vincent, P.; and Jauvin, C. 2003. A neural probabilistic language model. JMLR 3:1137\u20131155."}, {"ref": "Bollacker, K.; Evans, C.; Paritosh, P.; Sturge, T.; and Taylor, J. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of KDD, 1247\u20131250."}, {"ref": "Bordes, A.; Weston, J.; Collobert, R.; Bengio, Y.; et al. 2011. Learning structured embeddings of knowledge bases. In Proceedings of AAAI, 301\u2013306."}, {"ref": "Bordes, A.; Glorot, X.; Weston, J.; and Bengio, Y. 2012. Joint learning of words and meaning representations for open-text semantic parsing. In Proceedings of AISTATS, 127\u2013135."}, {"ref": "Bordes, A.; Usunier, N.; Garcia-Duran, A.; Weston, J.; and Yakhnenko, O. 2013. Translating embeddings for modeling multi-relational data. In Proceedings of NIPS, 2787\u20132795."}, {"ref": "Bordes, A.; Glorot, X.; Weston, J.; and Bengio, Y. 2014. A semantic matching energy function for learning with multirelational data. Machine Learning 94(2):233\u2013259."}, {"ref": "Hoffmann, R.; Zhang, C.; Ling, X.; Zettlemoyer, L.; and Weld, D. S. 2011. Knowledge-based weak supervision for information extraction of overlapping relations. In Proceedings of ACL-HLT, 541\u2013550."}, {"ref": "Jenatton, R.; Roux, N. L.; Bordes, A.; and Obozinski, G. R. 2012. A latent factor model for highly multi-relational data. In Proceedings of NIPS, 3167\u20133175."}, {"ref": "Mikolov, T.; Chen, K.; Corrado, G.; and Dean, J. 2013a. Efficient estimation of word representations in vector space. Proceedings of ICLR."}, {"ref": "Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; and Dean, J. 2013b. Distributed representations of words and phrases and their compositionality. In Proceedings of NIPS, 3111\u20133119."}, {"ref": "Mikolov, T.; Yih, W.-t.; and Zweig, G. 2013. Linguistic regularities in continuous space word representations. In Proceedings of HLT-NAACL, 746\u2013751."}, {"ref": "Miller, G. A. 1995. Wordnet: a lexical database for english. Communications of the ACM 38(11):39\u201341."}, {"ref": "Mintz, M.; Bills, S.; Snow, R.; and Jurafsky, D. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of ACL-IJCNLP, 1003\u20131011."}, {"ref": "Nickel, M.; Tresp, V.; and Kriegel, H.-P. 2011. A threeway model for collective learning on multi-relational data. In Proceedings of ICML, 809\u2013816."}, {"ref": "Nickel, M.; Tresp, V.; and Kriegel, H.-P. 2012. Factorizing yago: scalable machine learning for linked data. In Proceedings of WWW, 271\u2013280."}, {"ref": "Riedel, S.; Yao, L.; and McCallum, A. 2010. Modeling relations and their mentions without labeled text. In Machine Learning and Knowledge Discovery in Databases. 148\u2013163."}, {"ref": "Ritzema, H., et al. 1994. Drainage principles and applications."}, {"ref": "Socher, R.; Chen, D.; Manning, C. D.; and Ng, A. 2013. Reasoning with neural tensor networks for knowledge base completion. In Proceedings of NIPS, 926\u2013934."}, {"ref": "Surdeanu, M.; Tibshirani, J.; Nallapati, R.; and Manning, C. D. 2012. Multi-instance multi-label learning for relation extraction. In Proceedings of EMNLP, 455\u2013465."}, {"ref": "Sutskever, I.; Tenenbaum, J. B.; and Salakhutdinov, R. 2009. Modelling relational data using bayesian clustered tensor factorization. In Proceedings of NIPS, 1821\u20131828."}, {"ref": "Wang, Z.; Zhang, J.; Feng, J.; and Chen, Z. 2014. Knowledge graph embedding by translating on hyperplanes. In Proceedings of AAAI, 1112\u20131119."}, {"ref": "Weston, J.; Bordes, A.; Yakhnenko, O.; and Usunier, N. 2013. Connecting language and knowledge bases with embedding models for relation extraction. In Proceedings of EMNLP, 1366\u20131371."}]}, {"author": ["Rodolphe Jenatton", "Nicolas Le Roux", "Antoine Bordes", "Guillaume Obozinski"], "title": "A latent factor model for highly multi-relational data", "journal": "NeurIPS", "year": 2012, "DOI": "", "month": 3.0, "citations": 294, "abstract": "Many data such as social networks, movie preferences or knowledge bases are multi-relational, in that they describe multiple relations between entities. While there is a large body of work focused on modeling these data, modeling these multiple types of relations jointly remains challenging. Further, existing approaches tend to breakdown when the number of these types grows. In this paper, we propose a method for modeling large multi relational datasets, with possibly thousands of relations. Our model is based on a bilinear structure, which captures various orders of interaction of the data, and also shares sparse latent factors across different relations. We illustrate the performance of our approach on standard tensor-factorization datasets where we attain, or outperform, state-of-the-art results. Finally, a NLP application demonstrates our scalability and the ability of our model to learn efficient and semantically meaningful verb representations.", "keywords": ["large scale", "\u00a0sparsity", "\u00a0natural language processing", "\u00a0relational data", "\u00a0tensor factorization", "\u00a0low rank"], "reference_count": 28, "ccf_class": "A", "is_important": 0.0, "references": [{"ref": "F. Bach, R. Jenatton, J. Mairal, and G. Obozinski. Optimization with sparsity-inducing penalties. Foundations and Trends in Machine Learning, 4(1):1\u2013106, 2011."}, {"ref": "A. Bordes, X. Glorot, J. Weston, and Y. Bengio. A semantic matching energy function for learning with multi-relational data. Machine Learning, 2012. To appear."}, {"ref": "L. Bottou and Y. LeCun. Large scale online learning. In Advances in Neural Information Processing Systems, volume 16, pages 217\u2013224, 2004."}, {"ref": "W. Chu and Z. Ghahramani. Probabilistic models for incomplete multi-dimensional arrays. Journal of Machine Learning Research - Proceedings Track, 5:89\u201396, 2009."}, {"ref": "R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. Natural language processing (almost) from scratch. JMLR, 12:2493\u20132537, 2011."}, {"ref": "W. Denham. The detection of patterns in Alyawarra nonverbal behavior. PhD thesis, 1973."}, {"ref": "L. Getoor and B. Taskar. Introduction to Statistical Relational Learning (Adaptive Computation and Machine Learning). The MIT Press, 2007."}, {"ref": "R. A. Harshman and M. E. Lundy. Parafac: parallel factor analysis. Comput. Stat. Data Anal., 18(1):39\u201372, Aug. 1994."}, {"ref": "C. Kemp, J. B. Tenenbaum, T. L. Griffiths, T. Yamada, and N. Ueda. Learning systems of concepts with an infinite relational model. In Proc. of AAAI, pages 381\u2013388, 2006."}, {"ref": "S. Kok and P. Domingos. Statistical predicate invention. In Proceedings of the 24th international conference on Machine learning, pages 433\u2013440, 2007."}, {"ref": "A. Korhonen, Y. Krymolowski, and T. Briscoe. A large subcategorization lexicon for natural language processing applications. In Proceedings of LREC, 2006."}, {"ref": "A. T. McCray. An upper level ontology for the biomedical domain. Comparative and Functional Genomics, 4:80\u201388, 2003."}, {"ref": "G. Miller. WordNet: a Lexical Database for English. Communications of the ACM, 38(11):39\u201341, 1995."}, {"ref": "K. Miller, T. Griffiths, and M. Jordan. Nonparametric latent feature models for link prediction. In Advances in Neural Information Processing Systems 22, pages 1276\u20131284. 2009."}, {"ref": "M. Nickel, V. Tresp, and H.-P. Kriegel. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th Intl Conf. on Mach. Learn., pages 809\u2013816, 2011."}, {"ref": "M. Nickel, V. Tresp, and H.-P. Kriegel. Factorizing YAGO: scalable machine learning for linked data. In Proc. of the 21st intl conf. on WWW, pages 271\u2013280, 2012."}, {"ref": "K. Nowicki and T. A. B. Snijders. Estimation and prediction for stochastic blockstructures. Journal of the American Statistical Association, 96(455):1077\u20131087, 2001."}, {"ref": "A. Paccanaro and G. Hinton. Learning distributed representations of concepts using linear relational embedding. IEEE Trans. on Knowl. and Data Eng., 13:232\u2013244, 2001."}, {"ref": "T. Pedersen, S. Patwardhan, and J. Michelizzi. Wordnet:: Similarity: measuring the relatedness of concepts. In Demonstration Papers at HLT-NAACL 2004, pages 38\u201341, 2004."}, {"ref": "H. Poon and P. Domingos. Unsupervised ontology induction from text. In Proceedings of the 48th Annual Meeting of the Association for Computl Linguistics, pages 296\u2013305, 2010."}, {"ref": "R. J. Rummel. Dimensionality of nations project: Attributes of nations and behavior of nation dyads. In ICPSR data file, pages 1950\u20131965. 1999."}, {"ref": "D. Shen, J.-T. Sun, H. Li, Q. Yang, and Z. Chen. Document summarization using conditional random fields. In Proc. of the 20th Intl Joint Conf. on Artif. Intel., pages 2862\u20132867, 2007."}, {"ref": "A. P. Singh and G. J. Gordon. Relational learning via collective matrix factorization. In Proc. of SIGKDD\u201908, pages 650\u2013658, 2008."}, {"ref": "I. Sutskever, R. Salakhutdinov, and J. Tenenbaum. Modelling relational data using bayesian clustered tensor factorization. In Adv. in Neur. Inf. Proc. Syst. 22, 2009."}, {"ref": "L. R. Tucker. Some mathematical notes on three-mode factor analysis. Psychometrika, 31:279\u2013311, 1966."}, {"ref": "Y. J. Wang and G. Y. Wong. Stochastic blockmodels for directed graphs. Journal of the American Statistical Association, 82(397), 1987."}, {"ref": "D. Yang and D. M. W. Powers. Verb similarity on the taxonomy of wordnet. Proceedings of GWC-06, pages 121\u2013128, 2006."}, {"ref": "J. Zhu. Max-margin nonparametric latent feature models for link prediction. In Proceedings of the 29th Intl Conference on Machine Learning, 2012."}]}, {"author": ["Bordes Antoine", "\u00a0Glorot Xavier", "\u00a0Weston Jason", "\u00a0Bengio Yoshua"], "title": "A semantic matching energy function for learning with multi-relational data", "journal": "Machine Learning", "year": 2014, "DOI": "10.1007/s10994-013-5363-6", "month": 2.0, "citations": 320, "abstract": "Large-scale relational learning becomes crucial for handling the huge amounts of structured data generated daily in many application domains ranging from computational biology or information retrieval, to natural language processing. In this paper, we present a new neural network architecture designed to embed multi-relational graphs into a flexible continuous vector space in which the original data is kept and enhanced. The network is trained to encode the semantics of these graphs in order to assign high probabilities to plausible components. We empirically show that it reaches competitive performance in link prediction on standard datasets from the literature as well as on data from a real-world knowledge base (WordNet). In addition, we present how our method can be applied to perform word-sense disambiguation in a context of open-text semantic parsing, where the goal is to learn to assign a structured meaning representation to almost any sentence of free text, demonstrating that it can scale up to tens of thousands of nodes and thousands of types of relation.", "keywords": ["Neural networks", "Multi-relational data", "Word-sense disambiguation"], "reference_count": 57, "ccf_class": "B", "is_important": 1.0, "references": [{"ref": "Agirre E, Ansa O, Hovy E, Martinez D (2000) Enriching very large ontologies using the WWW. In: Proceedings of the ECAI 2000 Ontology Learning Worskshop"}, {"ref": "Baker C, Fillmore C, Lowe J (1998) The berkeley FrameNet project. In: ACL \u201998, pp 86\u201390"}, {"ref": "Banerjee S, Pedersen T (2002) An adapted lesk algorithm for word sense disambiguation using wordnet. In: Proceedings of the Third International Conference on Computational Linguistics and Intelligent Text Processing, Springer-Verlag, CICLing \u201902, pp 136\u2013145"}, {"ref": "Bengio Y (2008) Neural net language models. Scholarpedia 3(1):3881"}, {"ref": "Bengio Y, Ducharme R, Vincent P, Jauvin C (2003) A neural probabilistic language model. JMLR 3:1137\u20131155"}, {"ref": "Bergstra J, Breuleux O, Bastien F, Lamblin P, Pascanu R, Desjardins G, Turian J, Warde-Farley D, Bengio Y (2010) Theano: a CPU and GPU A Semantic Matching Energy Function for Learning with Multi-relational Data 27 math expression compiler. In: Proceedings of the Python for Scientific Computing Conference (SciPy), URL http://www.iro.umontreal.ca/~lisa/pointeurs/theano_scipy2010.pdf, oral Presentation"}, {"ref": "Bilenko M, Mooney RJ (2003) Adaptive duplicate detection using learnable string similarity measures. In: Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, KDD \u201903, pp 39\u201348"}, {"ref": "Bordes A, Usunier N, Collobert R, Weston J (2010) Towards understanding situated natural language. In: Proc. of the 13th Intern. Conf. on Artif. Intel. and Stat., vol 9, pp 65\u201372"}, {"ref": "Bordes A, Weston J, Collobert R, Bengio Y (2011) Learning structured embeddings of knowledge bases. In: Proceedings of the 25th Conference on Artificial Intelligence (AAAI-11), San Francisco, USA"}, {"ref": "Bordes A, Glorot X, Weston J, Bengio Y (2012) Joint learning of words and meaning representations for open-text semantic parsing. In: Proc. of the 15th Intern. Conf. on Artif. Intel. and Stat., JMLR, vol 22, pp 127\u2013135"}, {"ref": "Boser B, Guyon I, Vapnik V (1992) A training algorithm for optimal margin classifiers. Proceedings of the fifth annual workshop on Computational learning theory pp 144\u2013152"}, {"ref": "Bottou L (2011) From machine learning to machine reasoning. Tech. rep., arXiv.1102.1808, URL http://arxiv.org/abs/1102.1808"}, {"ref": "Cambria E, Hussain A, Havasi C, Eckl C (2009) Affectivespace: Blending common sense and affective knowledge to perform emotive reasoning. In: WOMSA at CAEPIA, pp 32\u201341"}, {"ref": "Caruana R (1995) Learning many related tasks at the same time with backpropagation. In: Tesauro G, Touretzky D, Leen T (eds) Advances in Neural Information Processing Systems 7 (NIPS\u201994), MIT Press, Cambridge, MA, pp 657\u2013664"}, {"ref": "Chu W, Ghahramani Z (2009) Probabilistic models for incomplete multidimensional arrays. Journal of Machine Learning Research - Proceedings Track 5:89\u201396"}, {"ref": "Cimiano P (2006) Ontology Learning and Population from Text: Algorithms, Evaluation and Applications. Springer-Verlag Collobert R, Weston J (2008) A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning. In: Proc. of the 25th Inter. Conf. on Mach. Learn."}, {"ref": "Collobert R, Weston J, Bottou L, Karlen M, Kavukcuoglu K, Kuksa P (2011) Natural language processing (almost) from scratch. Journal of Machine Learning Research 12:2493\u20132537"}, {"ref": "Coppola B, Moschitti A (2010) A general purpose FrameNet-based shallow semantic parser. In: Proceedings of the International Conference on Language Resources and Evaluation (LREC\u201910)"}, {"ref": "Cuadros M, Rigau G (2008) Knownet: using topic signatures acquired from the web for building automatically highly dense knowledge bases. In: Proceedings of COLING\u201908"}, {"ref": "Decadt B, Hoste V, Daeleamns W, van den Bosh A (2004) Gamble, genetic algorithm optimization of memory-based WSD. In: Proceeding of ACL/SIGLEX Senseval-3 Denham W (1973) The detection of patterns in alyawarra nonverbal behavior. PhD thesis"}, {"ref": "Franz T, Schultz A, Sizov S, Staab S (2009) Triplerank: Ranking semantic web data by tensor decomposition. In: Proceedings of the 8th International Semantic Web Conference, ISWC \u201909, pp 213\u2013228"}, {"ref": "Ge R, Mooney RJ (2009) Learning a Compositional Semantic Parser using an Existing Syntactic Parser. In: Proc. of the 47th An. Meeting of the ACL Getoor L, Taskar B (2007) Introduction to Statistical Relational Learning (Adaptive Computation and Machine Learning). The MIT Press"}, {"ref": "Giuglea A, Moschitti A (2006) Shallow semantic parsing based on FrameNet, VerbNet and PropBank. In: Proceeding of the 17th European Conference on Artificial Intelligence (ECAI\u201906), pp 563\u2013567"}, {"ref": "Hamel P, Lemieux S, Bengio Y, Eck D (2011) Temporal pooling and multiscale learning for automatic annotation and ranking of music audio. In: In Proceedings of the 12th International Conference on Music Information Retrieval (ISMIR11)"}, {"ref": "Harabagiu S, Moldovan D (2002) Knowledge processing on extended WordNet. In: Fellbaum C (ed) WordNet: An Electronic Lexical Database and Some of its Applications, MIT Press, pp 379\u2013405"}, {"ref": "Harshman RA, Lundy ME (1994) Parafac: parallel factor analysis. Comput Stat Data Anal 18(1):39\u201372"}, {"ref": "Havasi C, Speer R, Pustejovsky J (2010) Coarse Word-Sense Disambiguation using common sense. In: AAAI Fall Symposium Series"}, {"ref": "Kemp C, Tenenbaum JB, Griffiths TL, Yamada T, Ueda N (2006) Learning systems of concepts with an infinite relational model. In: Proceedings of the 21st national conference on Artificial intelligence - Volume 1, AAAI Press, AAAI\u201906, pp 381\u2013388"}, {"ref": "Kingsbury P, Palmer M (2002) From Treebank to PropBank. In: Proc. of the 3rd International Conference on Language Resources and Evaluation Kok S, Domingos P (2007) Statistical predicate invention. In: Proceedings of the 24th international conference on Machine learning, ACM, New York, NY, USA, ICML \u201907, pp 433\u2013440"}, {"ref": "Kolda TG, Bader BW (2009) Tensor decompositions and applications. SIAM Rev 51(3):455\u2013500"}, {"ref": "Lecun Y, Chopra S, Hadsell R, marc\u2019aurelio R, Huang f (2006) A tutorial on Energy-Based learning. In: Bakir G, Hofman T, sch\u00a8olkopf B, Smola A, Taskar B (eds) Predicting Structured Data, MIT Press"}, {"ref": "Liang P, Jordan MI, Klein D (2011) Learning dependency-based compositional semantics. In: Association for Computational Linguistics (ACL)"}, {"ref": "Liu H, Singh P (2004) Focusing on conceptnet\u2019s natural language knowledge representation. In: Proc. of the 8th Intl Conf. on Knowledge-Based Intelligent Information and Engineering Syst."}, {"ref": "Martinez D, de Lacalle O, Agirre E (2008) On the use of automatically acquired examples for all-nouns word sense disambiguation. J Artif Int Res 33:79\u2013107"}, {"ref": "McCray AT (2003) An upper level ontology for the biomedical domain. Comparative and Functional Genomics 4:80\u201388"}, {"ref": "Mooney R (2004) Learning Semantic Parsers: An Important But UnderStudied Problem. In: Proc. of the 19th AAAI Conf. on Artif. Intel."}, {"ref": "Nickel M, Tresp V, Kriegel HP (2011) A three-way model for collective learning on multi-relational data. In: Getoor L, Scheffer T (eds) Proceedings of the 28th International Conference on Machine Learning (ICML-11), ACM, ICML \u201911, pp 809\u2013816"}, {"ref": "Nickel M, Tresp V, Kriegel HP (2012) Factorizing yago: scalable machine learning for linked data. In: Proceedings of the 21st international conference on World Wide Web, WWW \u201912, pp 271\u2013280"}, {"ref": "Paccanaro A (2000) Learning distributed representations of concepts from relational data. IEEE Transactions on Knowledge and Data Engineering 13:200\u20130"}, {"ref": "Paccanaro A, Hinton G (2001) Learning distributed representations of concepts using linear relational embedding. IEEE Trans on Knowl and Data Eng 13:232\u2013244"}, {"ref": "Poon H, Domingos P (2009) Unsupervised semantic parsing. In: Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Singapore, pp 1\u201310"}, {"ref": "Poon H, Domingos P (2010) Unsupervised ontology induction from text. In: Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden, pp 296\u2013305"}, {"ref": "Robbins H, Monro S (1951) A stochastic approximation method. Annals of Mathematical Statistics 22:400\u2013407"}, {"ref": "Rummel RJ (1999) Dimensionality of nations project: Attributes of nations and behavior of nation dyads. In: ICPSR data file, pp 1950\u20131965"}, {"ref": "Shi L, Mihalcea R (2004) Open text semantic parsing using FrameNet and WordNet. In: HLT-NAACL 2004: Demonstration Papers, Boston, Massachusetts, USA, pp 19\u201322"}, {"ref": "Singh AP, Gordon GJ (2008) Relational learning via collective matrix factorization. In: Proc. of SIGKDD\u201908, pp 650\u2013658"}, {"ref": "Singla P, Domingos P (2006) Entity resolution with markov logic. In: Proceedings of the Sixth International Conference on Data Mining, IEEE Computer Society, pp 572\u2013582"}, {"ref": "Snow R, Jurafsky D, Ng A (2006) Semantic taxonomy induction from heterogenous evidence. In: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pp 801\u2013808"}, {"ref": "Speer R, Havasi C, Lieberman H (2008) Analogyspace: reducing the dimensionality of common sense knowledge. In: Proceedings of the 23rd national conference on Artificial intelligence - Volume 1, AAAI Press, AAAI\u201908, pp 548\u2013553"}, {"ref": "Suchanek F, Kasneci G, Weikum G (2008) Yago: A large ontology from Wikipedia and WordNet. Web Semant 6:203\u2013217"}, {"ref": "Sutskever I, Salakhutdinov R, Tenenbaum J (2009) Modelling relational data using bayesian clustered tensor factorization. In: Adv. in Neur. Inf. Proc. Syst. 22"}, {"ref": "Tucker LR (1966) Some mathematical notes on three-mode factor analysis. Psychometrika 31:279\u2013311"}, {"ref": "van der Maaten L, Hinton G (2008) Visualizing high-dimensional data using t-sne. Journal of Machine Learning Research 9:2579\u20132605"}, {"ref": "Weston J, Bengio S, Usunier N (2010) Large scale image annotation: learning to rank with joint word-image embeddings. Machine Learning 81:21\u201335"}, {"ref": "Wu F, Weld D (2010) Open information extraction using Wikipedia. In: Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden, pp 118\u2013127"}, {"ref": "Yates A, Banko M, Broadhead M, Cafarella M, Etzioni O, Soderland S (2007) TextRunner: Open information extraction on the Web. In: Proceedings of NAACL-HLT \u201907, pp 25\u201326"}, {"ref": "Zettlemoyer L, Collins M (2009) Learning Context-Dependent Mappings from Sentences to Logical Form. In: Proceedings of the 47th Annual Meeting of the ACL"}]}, {"author": ["Richard Socher ", "Danqi Chen", "Christopher D. Manning", "Andrew Y. Ng"], "title": "Reasoning with neural tensor networks for knowledge base completion", "journal": "NeurIPS", "year": 2013, "DOI": "", "month": 0.0, "citations": 973, "abstract": "A common problem in knowledge representation and related fields is reasoning over a large joint knowledge graph, represented as triples of a relation between two entities. The goal of this paper is to develop a more powerful neural network model suitable for inference over these relationships. Previous models suffer from weak interaction between entities or simple linear projection of the vector space. We address these problems by introducing a neural tensor network (NTN) model which allow the entities and relations to interact multiplicatively. Additionally, we observe that such knowledge base models can be further improved by representing each entity as the average of vectors for the words in the entity name, giving an additional dimension of similarity by which entities can share statistical strength. We assess the model by considering the problem of predicting additional true relations between entities given a partial knowledge base. Our model outperforms previous models and can classify unseen relationships in WordNet and FreeBase with an accuracy of 86.2% and 90.0%, respectively.", "keywords": [""], "reference_count": 24, "ccf_class": "A", "is_important": 1.0, "references": [{"ref": "G.A. Miller. WordNet: A Lexical Database for English. Communications of the ACM, 1995."}, {"ref": "F. M. Suchanek, G. Kasneci, and G. Weikum. Yago: a core of semantic knowledge. In Proceedings of the 16th international conference on World Wide Web, 2007."}, {"ref": "J. Graupmann, R. Schenkel, and G. Weikum. The SphereSearch engine for unified ranked retrieval of heterogeneous XML and web documents. In Proceedings of the 31st international conference on Very large data bases, VLDB, 2005."}, {"ref": "V. Ng and C. Cardie. Improving machine learning approaches to coreference resolution. In ACL, 2002."}, {"ref": "R. Snow, D. Jurafsky, and A. Y. Ng. Learning syntactic patterns for automatic hypernym discovery. In NIPS, 2005."}, {"ref": "A. Fader, S. Soderland, and O. Etzioni. Identifying relations for open information extraction. In EMNLP, 2011."}, {"ref": "G. Angeli and C. D. Manning. Philosophers are mortal: Inferring the truth of unseen facts. In CoNLL, 2013."}, {"ref": "A. Bordes, J. Weston, R. Collobert, and Y. Bengio. Learning structured embeddings of knowledge bases. In AAAI, 2011."}, {"ref": "R. Jenatton, N. Le Roux, A. Bordes, and G. Obozinski. A latent factor model for highly multi-relational data. In NIPS, 2012."}, {"ref": "A. Bordes, X. Glorot, J. Weston, and Y. Bengio. Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing. AISTATS, 2012."}, {"ref": "I. Sutskever, R. Salakhutdinov, and J. B. Tenenbaum. Modelling relational data using Bayesian clustered tensor factorization. In NIPS, 2009."}, {"ref": "M. Ranzato and A. Krizhevsky G. E. Hinton. Factored 3-Way Restricted Boltzmann Machines For Modeling Natural Images. AISTATS, 2010."}, {"ref": "D. Yu, L. Deng, and F. Seide. Large vocabulary speech recognition using deep tensor neural networks. In INTERSPEECH, 2012."}, {"ref": "R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Ng, and C. Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In EMNLP, 2013."}, {"ref": "A. Yates, M. Banko, M. Broadhead, M. J. Cafarella, O. Etzioni, and S. Soderland. Textrunner: Open information extraction on the web. In HLT-NAACL (Demonstrations), 2007."}, {"ref": "M. Nickel, V. Tresp, and H. Kriegel. A three-way model for collective learning on multirelational data. In ICML, 2011."}, {"ref": "A. Bordes, N. Usunier, A. Garca-Durn, J. Weston, and O. Yakhnenko. Irreflexive and hierarchical relations as translations. CoRR, abs/1304.7158, 2013."}, {"ref": "J. Turian, L. Ratinov, and Y. Bengio. Word representations: a simple and general method for semi-supervised learning. In Proceedings of ACL, pages 384\u2013394, 2010."}, {"ref": "R. Socher, B. Huval, C. D. Manning, and A. Y. Ng. Semantic Compositionality Through Recursive Matrix-Vector Spaces. In EMNLP, 2012."}, {"ref": "R. Collobert and J. Weston. A unified architecture for natural language processing: deep neural networks with multitask learning. In ICML, 2008.9"}, {"ref": "R. Socher, E. H. Huang, J. Pennington, A. Y. Ng, and C. D. Manning. Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection. In NIPS. MIT Press, 2011."}, {"ref": "E. H. Huang, R. Socher, C. D. Manning, and A. Y. Ng. Improving Word Representations via Global Context and Multiple Word Prototypes. In ACL, 2012."}, {"ref": "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, SIGMOD, 2008."}, {"ref": "N. Tandon, G. de Melo, and G. Weikum. Deriving a web-scale commonsense fact database. In AAAI Conference on Artificial Intelligence (AAAI 2011), 2011."}]}, {"author": ["Jason Weston", "\u00a0Antoine Bordes", "\u00a0Oksana Yakhnenko", "\u00a0Nicolas Usunier"], "title": "Connecting language and knowledge bases with embedding models for relation extraction", "journal": "EMNLP", "year": 2013, "DOI": "", "month": 7.0, "citations": 145, "abstract": "This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on two scoring functions that operate by learning low-dimensional embeddings of words and of entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over existing methods that rely on text features alone.", "keywords": [""], "reference_count": 20, "ccf_class": "B", "is_important": "", "references": [{"ref": "Michele Banko, Michael J Cafarella,Stephen Soderland, Matthew Broadhead, and Oren Et-zioni. 2007. Open information extraction from theweb. In IJCAI, volume 7, pages 2670\u20132676."}, {"ref": "Antoine Bordes, Nicolas Usunier, andJason Weston. 2010. Label ranking under ambiguoussupervision for learning semantic correspondences. InProceedings of the 27th International Conference onMachine Learning (ICML-10), pages 103\u2013110."}, {"ref": "Antoine Bordes, Jason Weston, Ro-nan Collobert, and Yoshua Bengio. 2011. Learningstructured embeddings of knowledge bases. In Proc.of the 25th Conf. on Artif. Intel. (AAAI)."}, {"ref": "Antoine Bordes, Xavier Glorot, JasonWeston, and Yoshua Bengio. 2012. Joint learningof words and meaning representations for open-textsemantic parsing. In Proc. of the 15th Intern. Conf.on Artif. Intel. and Stat., volume 22, pages 127\u2013135.JMLR."}, {"ref": "Antoine Bordes, Nicolas Usunier,Alberto Garcia-Duran, Jason Weston, and OksanaYakhnenko. 2013. Irre\ufb02exive and hierarchical rela-tions as translations. arXiv preprint arXiv:1304.7158."}, {"ref": "Andrew Carlson, Justin Betteridge,Bryan Kisiel, Burr Settles, Estevam R Hruschka Jr,and Tom M Mitchell. 2010. Toward an architecturefor never-ending language learning. In AAAI."}, {"ref": "Mark Craven, Johan Kumlien, et al.1999. Constructing biological knowledge bases by ex-tracting information from text sources. In ISMB, vol-ume 1999, pages 77\u201386."}, {"ref": "Jenny Rose Finkel, Trond Grenager,and Christopher Manning. 2005. Incorporating non-local information into information extraction systemsby gibbs sampling. In Proceedings of the 43rd AnnualMeeting on Association for Computational Linguis-tics, pages 363\u2013370. Association for ComputationalLinguistics."}, {"ref": "Raphael Hoffmann, CongleZhang, Xiao Ling, Luke Zettlemoyer, and Daniel SWeld. 2011. Knowledge-based weak supervisionfor information extraction of overlapping relations.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies, volume 1, pages 541\u2013550."}, {"ref": "Rohit J Kate and Raymond JMooney. 2007. Learning language semantics fromambiguous supervision. In AAAI, volume 7, pages895\u2013900."}, {"ref": "Percy Liang, Michael I Jordan, andDan Klein. 2009. Learning semantic correspondenceswith less supervision. In Proceedings of the Joint Con-ference of the 47th Annual Meeting of the ACL andthe 4th InternationalJointConference on Natural Lan-guage Processing of the AFNLP: Volume 1-Volume 1,pages 91\u201399. Association for Computational Linguis-tics."}, {"ref": "Cynthia Matuszek, NicholasFitzGerald, Luke Zettlemoyer, Liefeng Bo, and DieterFox. 2012. A joint model of language and perceptionfor grounded attribute learning. In Proceedings of theInternational Conference on Machine Learning."}, {"ref": "Mike Mintz, Steven Bills, Rion Snow,and Dan Jurafsky. 2009. Distant supervision for re-lation extraction without labeled data. In Proceedingsof the Joint Conference of the 47th Annual Meeting ofthe ACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP: Volume2-Volume 2, pages 1003\u20131011. Association for Com-putational Linguistics."}, {"ref": "Maximilian Nickel, Volker Tresp, andHans-Peter Kriegel. 2011. A three-way model for col-lective learning on multi-relational data. In Proceed-ings of the 28th International Conference on MachineLearning (ICML-11), pages 809\u2013816."}, {"ref": "Sebastian Riedel, Limin Yao, and An-drew McCallum. 2010. Modeling relations and theirmentions without labeled text. In Machine Learningand Knowledge Discovery in Databases, pages 148\u2013163. Springer."}, {"ref": "Sebastian Riedel, Limin Yao, AndrewMcCallum, and Benjamin M Marlin. 2013. Rela-tion extraction with matrix factorization and universalschemas. In Proceedings of NAACL-HLT, pages 74\u201384."}, {"ref": "Mihai Surdeanu, Julie Tibshirani,Ramesh Nallapati, and Christopher D Manning. 2012.Multi-instance multi-label learning for relation extrac-tion. In Proceedings of the 2012 Joint Conferenceon Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning, pages 455\u2013465. Association for Computational Lin-guistics."}, {"ref": "Jason Weston, Samy Bengio, andNicolas Usunier. 2010. Large scale image annotation:learning to rank with joint word-image embeddings.Machine learning, 81(1):21\u201335."}, {"ref": "Fei Wu and Daniel S Weld. 2007.Autonomously semantifying wikipedia. In Proceed-ings of the sixteenth ACM conference on Conferenceon information and knowledge management, pages41\u201350. ACM."}, {"ref": "Fei Wu and Daniel S Weld. 2010.Open information extraction using wikipedia. In Pro-ceedings of the 48th AnnualMeeting of the Associationfor Computational Linguistics, pages 118\u2013127. Asso-ciation for Computational Linguistics."}]}, {"author": ["Sebastian Riedel", "Limin Yao", "Andrew McCallum", "Benjamin M. Marlin"], "title": "Relation extraction with matrix factorization and universal schemas", "journal": "NAACL", "year": 2013, "DOI": "", "month": 6.0, "citations": 411, "abstract": "Traditional relation extraction predicts relations within some fixed and finite target schema. Machine learning approaches to this task require either manual annotation or, in the case of distant supervision, existing structured sources of the same schema. The need for existing datasets can be avoided by using a universal schema: the union of all involved schemas (surface form predicates as in OpenIE, and relations in the schemas of preexisting databases). This schema has an almost unlimited set of relations (due to surface forms), and supports integration with existing structured data (through the relation types of existing databases). To populate a database of such schema we present matrix factorization models that learn latent feature vectors for entity tuples and relations. We show that such latent models achieve substantially higher accuracy than a traditional classification approach. More importantly, by operating simultaneously on relations observed in text and in pre-existing structured DBs such as Freebase, we are able to reason about unstructured and structured data in mutually-supporting ways. By doing so our approach outperforms stateof-the-art distant supervision.", "keywords": [""], "reference_count": 33, "ccf_class": "C", "is_important": "", "references": [{"ref": "Ronald J. Brachman. 1983. What is-a is and isn t: An analysis of taxonomic links in semantic networks. IEEE Computer, 16(10):30\u201336."}, {"ref": "Razvan C. Bunescu and Raymond J. Mooney. 2007. Learning to extract relations from the web using minimal supervision. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL \u201907)."}, {"ref": "Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka, and Tom M. Mitchell. 2010. Toward an architecture for never-ending language learning. In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI \u201910)."}, {"ref": "Michael Collins, Sanjoy Dasgupta, and Robert E. Schapire. 2001. A generalization of principal component analysis to the exponential family. In Proceedings of NIPS."}, {"ref": "M. Craven and J. Kumlien. 1999. Constructing biological knowledge-bases by extracting information from text sources. In Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology, pages 77\u201386, Germany."}, {"ref": "Aron Culotta and Jeffery Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of ACL, Barcelona, Spain."}, {"ref": "Oren Etzioni, Michele Banko, Stephen Soderland, and Daniel S. Weld. 2008. Open information extraction from the web. Commun. ACM, 51(12):68\u201374."}, {"ref": "T. Hasegawa, S. Sekine, and R. Grishman. 2004. Discovering Relations among Named Entities from Large Corpora. Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL \u201904), pages 415\u2013422."}, {"ref": "Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S. Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In Proceedings of ACL."}, {"ref": "Stanley Kok and Pedro Domingos. 2008. Extracting Semantic Networks from Text Via Relational Clustering. In ECML."}, {"ref": "Yehuda Koren. 2008. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD \u201908, pages 426\u2013434, New York, NY, USA. ACM."}, {"ref": "Dekang Lin and Patrick Pantel. 2001. DIRT - discovery of inference rules from text. In Knowledge Discovery and Data Mining, pages 323\u2013328."}, {"ref": "Christopher D. Manning, Prabhakar Raghavan, and Hinrich Sch\u00fctze. 2008. Introduction to Information Retrieval. Cambridge University Press, Cambridge, UK."}, {"ref": "Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL \u201909), pages 1003\u20131011. Association for Computational Linguistics."}, {"ref": "Brian Murphy, Partha Pratim Talukdar, and Tom Mitchell. 2012. Learning effective and interpretable semantic models using non-negative sparse embedding. In COLING, pages 1933\u20131950."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2012. Factorizing yago: scalable machine learning for linked data. In Proceedings of the 21st international conference on World Wide Web, WWW \u201912, pages 271\u2013280, New York, NY, USA. ACM."}, {"ref": "Patrick Pantel, Rahul Bhagat, Bonaventura Coppola, Timothy Chklovski, and Eduard Hovy. 2007. ISP: Learning Inferential Selectional Preferences. In Proceedings of NAACL HLT."}, {"ref": "Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. Bpr: Bayesian personalized ranking from implicit feedback. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI \u201909, pages 452\u2013461, Arlington, Virginia, United States. AUAI Press."}, {"ref": "Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD \u201910)."}, {"ref": "Evan Sandhaus, 2008. The New York Times Annotated Corpus. Linguistic Data Consortium, Philadelphia."}, {"ref": "Stefan Schoenmackers, Oren Etzioni, and Daniel S. Weld. 2008. Scaling textual inference to the web. In EMNLP \u201908: Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 79\u201388, Morristown, NJ, USA. Association for Computational Linguistics."}, {"ref": "Stefan Schoenmackers, Oren Etzioni, Daniel S. Weld, and Jesse Davis. 2010. Learning first-order horn clauses from web text. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP \u201910, pages 1088\u20131098, Stroudsburg, PA, USA. Association for Computational Linguistics."}, {"ref": "Yusuke Shinyama and Satoshi Sekine. 2006. Preemptive information extraction using unrestricted relation discovery. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL \u201906, pages 304\u2013311, Stroudsburg, PA, USA. Association for Computational Linguistics."}, {"ref": "Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D. Manning. 2012. Multi-instance multilabel learning for relation extraction. In Proceedings of the Conference on Empirical methods in natural language processing (EMNLP \u201912), pages 455\u2013465."}, {"ref": "Idan Szpektor and Ido Dagan. 2008. Learning entailment rules for unary templates. In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, COLING \u201908, pages 849\u2013856,"}, {"ref": "Stroudsburg, PA, USA. Association for Computational Linguistics."}, {"ref": "Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaventura Coppola. 2004. Scaling web-based acquisition of entailment relations. In Proceedings of EMNLP."}, {"ref": "Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa. 2011. Probabilistic matrix factorization leveraging contexts for unsupervised relation discovery. In Proceedings of PAKDD."}, {"ref": "Limin Yao, Aria Haghighi, Sebastian Riedel, and Andrew McCallum. 2011. Structured relation discovery using generative models. In Proceedings of the Conference on Empirical methods in natural language processing (EMNLP \u201911), July."}, {"ref": "Limin Yao, Sebastian Riedel, and Andrew McCallum. 2012a. Probabilistic databases of universal schema. In Proceedings of the AKBC-WEKEX Workshop at NAACL 2012, June."}, {"ref": "Limin Yao, Sebastian Riedel, and Andrew McCallum. 2012b. Unsupervised relation discovery with sense disambiguation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL \u201912), July."}, {"ref": "Alexander Yates and Oren Etzioni. 2009. Unsupervised methods for determining object and relation synonyms on the web. Journal of Artificial Intelligence Research, 34:255\u2013296."}, {"ref": "Fabio Massimo Zanzotto, Marco Pennacchiotti, and Maria Teresa Pazienza. 2006. Discovering asymmetric entailment relations between verbs using selectional preferences. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics (ACL \u201906)."}]}, {"author": ["Maximilian Nickel ", "Volker Tresp ", "Otto-hahn Ring ", "Hans-peter Kriegel"], "title": "Factorizing YAGO: Scalable machine learning for linked data", "journal": "WWW", "year": 2012, "DOI": "10.1145/2187836.2187874", "month": 4.0, "citations": 297, "abstract": "Vast amounts of structured information have been published in the Semantic Web\u2019s Linked Open Data (LOD) cloud and their size is still growing rapidly. Yet, access to this information via reasoning and querying is sometimes difficult, due to LOD\u2019s size, partial data inconsistencies and inherent noisiness. Machine Learning offers an alternative approach to exploiting LOD\u2019s data with the advantages that Machine Learning algorithms are typically robust to both noise and data inconsistencies and are able to efficiently utilize nondeterministic dependencies in the data. From a Machine Learning point of view, LOD is challenging due to its relational nature and its scale. Here, we present an efficient approach to relational learning on LOD data, based on the factorization of a sparse tensor that scales to data consisting", "keywords": ["Large-Scale Machine Learning", "Semantic Web", "Linked OpenData", "Tensor Factorization", "Relational Learnin"], "reference_count": 33, "ccf_class": "A", "is_important": "", "references": [{"ref": "M. Ankerst, M. Breunig, H. Kriegel, and J. Sander. OPTICS: ordering points to identify the clustering structure. In ACM SIGMOD Record, volume 28, page 49\u201360, 1999."}, {"ref": "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. Dbpedia: A nucleus for a web of open data. The Semantic Web, page 722\u2013735, 2008."}, {"ref": "S. Auer and J. Lehmann. Creating knowledge out of interlinked data. Semantic Web, 1(1):97\u2013104, Jan. 2010."}, {"ref": "B. W. Bader, R. A. Harshman, and T. G. Kolda. Temporal analysis of semantic graphs using ASALSAN. In Seventh IEEE International Conference on Data Mining (ICDM 2007), pages 33\u201342, Omaha, NE, USA, Oct. 2007."}, {"ref": "V. Bicer, T. Tran, and A. Gossen. Relational kernel machines for learning from Graph-Structured RDF data. The Semantic Web: Research and Applications, page 47\u201362, 2011."}, {"ref": "C. Bizer, T. Heath, and T. Berners-Lee. Linked data-the story so far. International Journal on Semantic Web and Information Systems, 5(3):1\u201322, 2009."}, {"ref": "S. Bloehdorn and Y. Sure. Kernel methods for mining instance data in ontologies. In Proceedings of the 6th international The semantic web and 2nd Asian conference on Asian semantic web conference, page 58\u201371, 2007."}, {"ref": "R. Bro. PARAFAC. tutorial and applications. Chemometrics and Intelligent Laboratory Systems, 38(2):149\u2013171, 1997."}, {"ref": "C. d\u2019Amato, N. Fanizzi, and F. Esposito. Non-parametric statistical learning methods for inductive classifiers in semantic knowledge bases. In Proceedings of the 2008 IEEE International Conference on Semantic Computing, page 291\u2013298, Washington, DC, USA, 2008. IEEE Computer Society."}, {"ref": "J. Davis and M. Goadrich. The relationship between Precision-Recall and ROC curves. In Proceedings of the 23rd international conference on Machine learning, page 233\u2013240, 2006."}, {"ref": "N. Fanizzi, C. D\u2019Amato, and F. Esposito. DL-FOIL concept learning in description logics. In Proceedings of the 18th international conference on Inductive Logic Programming, ILP \u201908, page 107\u2013121, Berlin, Heidelberg, 2008. Springer-Verlag."}, {"ref": "T. Franz, A. Schultz, S. Sizov, and S. Staab. Triplerank: Ranking semantic web data by tensor decomposition. The Semantic Web-ISWC 2009, page 213\u2013228, 2009."}, {"ref": "H. Halpin, P. Hayes, J. McCusker, D. Mcguinness, and H. Thompson. When owl: sameAs isn\u2019t the same: An analysis of identity in linked data. The Semantic Web\u2013ISWC 2010, page 305\u2013320, 2010."}, {"ref": "S. Hellmann, J. Lehmann, and S. Auer. Learning of OWL class descriptions on very large knowledge bases. Int. J. Semantic Web Inf. Syst, 5(2):25\u201348, 2009."}, {"ref": "P. Hitzler and F. van Harmelen. A reasonable semantic web. Semantic Web, 1(1):39\u201344, 2010."}, {"ref": "A. Hogan, A. Harth, A. Passant, S. Decker, and A. Polleres. Weaving the pedantic web. Linked Data on the Web (LDOW 2010), 2010."}, {"ref": "Y. Huang, V. Tresp, M. Bundschus, and A. Rettinger. Multivariate structured prediction for learning on semantic web. 2010."}, {"ref": "C. Kiefer, A. Bernstein, and A. Locher. Adding data mining support to SPARQL via statistical relational learning methods. In Proceedings of the 5th European semantic web conference, pages 478\u2014492, 2008."}, {"ref": "S. Kok and P. Domingos. Statistical predicate invention. In Proceedings of the 24th international conference on Machine learning, page 433\u2013440, 2007."}, {"ref": "T. G. Kolda and B. W. Bader. Tensor decompositions and applications. SIAM Review, 51(3):455, 2009."}, {"ref": "H. T. Lin, N. Koul, and V. Honavar. Learning relational bayesian classifiers from RDF data. In Proceedings of the International Semantic Web Conference (ISWC 2011), 2011. In press."}, {"ref": "M. Nickel, V. Tresp, and H. Kriegel. A Three-Way model for collective learning on Multi-Relational data. In Proceedings of the 28th International Conference on Machine Learning, ICML \u201911, pages 809\u2014816, Bellevue, WA, USA, 2011. ACM."}, {"ref": "S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. Factorizing personalized markov chains for next-basket recommendation. In Proceedings of the 19th international conference on World wide web, page 811\u2013820, 2010."}, {"ref": "M. Richardson and P. Domingos. Markov logic networks. Machine Learning, 62(1):107\u2013136, 2006."}, {"ref": "D. Roy, C. Kemp, V. Mansinghka, and J. Tenenbaum. Learning annotated hierarchies from relational data. Advances in neural information processing systems, 19:1185, 2007."}, {"ref": "P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Galligher, and T. Eliassi-Rad. Collective classification in network data. AI Magazine, 29(3):93, 2008."}, {"ref": "F. Suchanek, G. Kasneci, and G. Weikum. Yago: a core of semantic knowledge. In Proceedings of the 16th international conference on World Wide Web, page 697\u2013706, 2007."}, {"ref": "J. Sun, D. Tao, and C. Faloutsos. Beyond streams and graphs: dynamic tensor analysis. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, page 374\u2013383, 2006."}, {"ref": "I. Sutskever, R. Salakhutdinov, and J. B. Tenenbaum. Modelling relational data using bayesian clustered tensor factorization. Advances in Neural Information Processing Systems, 22, 2009."}, {"ref": "P. Tan, M. Steinbach, V. Kumar, et al. Introduction to data mining. Pearson Addison Wesley Boston, 2006."}, {"ref": "J. V\u00a8olker and M. Niepert. Statistical schema induction. The Semantic Web: Research and Applications, page 124\u2013138, 2011."}, {"ref": "K. Weinberger, A. Dasgupta, J. Langford, A. Smola, and J. Attenberg. Feature hashing for large scale multitask learning. In Proceedings of the 26th Annual International Conference on Machine Learning, page 1113\u20131120, 2009."}, {"ref": "M. Welling and Y. W. Teh. Bayesian learning via stochastic gradient langevin dynamics. In Proceedings of the 28th International Conference on Machine Learning, Bellevue, WA, USA, 2011."}]}, {"author": ["Ruobing Xie", "Zhiyuan Liu", "Maosong Sun"], "title": "Representation learning of knowledge graphs with hierarchical types", "journal": "IJCAI", "year": 2016, "DOI": "", "month": 7.0, "citations": 68, "abstract": "Representation learning of knowledge graphs aims to encode both entities and relations into a continuous low-dimensional vector space. Most existing methods only concentrate on learning representations with structured information located in triples, regardless of the rich information located in hierarchical types of entities, which could be collected in most knowledge graphs. In this paper, we propose a novel method named Type-embodied Knowledge Representation Learning (TKRL) to take advantages of hierarchical entity types. We suggest that entities should have multiple representations in different types. More specifically, we consider hierarchical types as projection matrices for entities, with two type encoders designed to model hierarchical structures. Meanwhile, type information is also utilized as relation-specific type constraints. We evaluate our models on two tasks including knowledge graph completion and triple classification, and further explore the performances on long-tail dataset. Experimental results show that our models significantly outperform all baselines on both tasks, especially with long-tail distribution. It indicates that our models are capable of capturing hierarchical type information which is significant when constructing representations of knowledge graphs. The source code of this paper can be obtained from https://github.com/thunlp/TKRL.", "keywords": [""], "reference_count": 22, "ccf_class": "A", "is_important": 1.0, "references": [{"ref": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of KDD, pages 1247\u20131250, 2008."}, {"ref": "Antoine Bordes, Jason Weston, Ronan Collobert, and Yoshua Bengio. Learning structured embeddings of knowledge bases. In Proceedings of AAAI, pages 301\u2013306, 2011."}, {"ref": "Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. Joint learning of words and meaning representations for open-text semantic parsing. In Proceedings of AISTATS, pages 127\u2013135, 2012."}, {"ref": "Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multirelational data. In Proceedings of NIPS, pages 2787\u20132795, 2013."}, {"ref": "Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. A semantic matching energy function for learning with multi-relational data. Machine Learning, 94(2):233\u2013259, 2014."}, {"ref": "Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In Proceedings of KDD, pages 601\u2013610, 2014."}, {"ref": "Kelvin Gu, John Miller, and Percy Liang. Traversing knowledge graphs in vector space. In Proceedings of EMNLP, pages 318\u2013327, 2015."}, {"ref": "Zhiting Hu, Poyao Huang, Yuntian Deng, Yingkai Gao, and Eric P Xing. Entity hierarchy embedding. In Proceedings of ACL, volume 1, pages 1292\u20131300, 2015."}, {"ref": "Rodolphe Jenatton, Nicolas L Roux, Antoine Bordes, and Guillaume R Obozinski. A latent factor model for highly multi-relational data. In Proceedings of NIPS, pages 3167\u20133175, 2012."}, {"ref": "Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu, and Jun Zhao. Knowledge graph embedding via dynamic mapping matrix. In Proceedings of ACL, pages 687\u2013696, 2015."}, {"ref": "Denis Krompa\u00df, Stephan Baier, and Volker Tresp. Type-constrained representation learning in knowledge graphs. In Proceedings of ISWC, pages 640\u2013655. 2015."}, {"ref": "Yankai Lin, Zhiyuan Liu, Huanbo Luan, Maosong Sun, Siwei Rao, and Song Liu. Modeling relation paths for representation learning of knowledge bases. In Proceedings of EMNLP, pages 705\u2013714, 2015."}, {"ref": "Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of AAAI, 2015."}, {"ref": "Arvind Neelakantan, Benjamin Roth, and Andrew McCallum. Compositional vector space models for knowledge base completion. Proceedings of EMNLP, 2015."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. A three-way model for collective learning on multi-relational data. In Proceedings of ICML, pages 809\u2013816, 2011."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. Factorizing yago: scalable machine learning for linked data. In Proceedings of WWW, pages 271\u2013280, 2012."}, {"ref": "Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. Reasoning with neural tensor networks for knowledge base completion. In Proceedings of NIPS, pages 926\u2013934, 2013."}, {"ref": "Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. Knowledge graph and text jointly embedding. In Proceedings of EMNLP, pages 1591\u20131601, 2014."}, {"ref": "Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. Knowledge graph embedding by translating on hyperplanes. In Proceedings of AAAI, pages 1112\u20131119, 2014."}, {"ref": "Ruobing Xie, Zhiyuan Liu, Jia Jia, Huanbo Luan, and Maosong Sun. Representation learning of knowledge graphs with entity descriptions. In Proceedings of AAAI, 2016."}, {"ref": "Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and relations for learning and inference in knowledge bases. Proceedings of ICLR, 2014."}, {"ref": "Huaping Zhong, Jianwen Zhang, Zhen Wang, Hai Wan, and Zheng Chen. Aligning knowledge and text embeddings by entity descriptions. In Proceedings of EMNLP, pages 267\u2013272, 2015."}]}, {"author": ["Yankai Lin", "\u00a0Zhiyuan Liu", "\u00a0Huanbo Luan", "\u00a0Maosong Sun", "\u00a0Siwei Rao", "\u00a0Song Liu"], "title": "Modeling relation paths for representation learning of knowledge bases", "journal": "EMNLP", "year": 2015, "DOI": "10.18653/v1/D15-1082", "month": 9.0, "citations": 237, "abstract": "Representation learning of knowledge bases (KBs) aims to embed both entities and relations into a low-dimensional space. Most existing methods only consider direct relations in representation learning. We argue that multiple-step relation paths also contain rich inference patterns between entities, and propose a path-based representation learning model. This model considers relation paths as translations between entities for representation learning, and addresses two key challenges: (1) Since not all relation paths are reliable, we design a path-constraint resource allocation algorithm to measure the reliability of relation paths. (2) We represent relation paths via semantic composition of relation embeddings. Experimental results on real-world datasets show that, as compared with baselines, our model achieves significant and consistent improvements on knowledge base completion and relation extraction from text.", "keywords": [""], "reference_count": 33, "ccf_class": "B", "is_important": 1.0, "references": [{"ref": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of KDD, pages 1247\u20131250."}, {"ref": "Antoine Bordes, Jason Weston, Ronan Collobert, Yoshua Bengio, et al. 2011. Learning structured embeddings of knowledge bases. In Proceedings of AAAI, pages 301\u2013306."}, {"ref": "Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. 2012. Joint learning of words and meaning representations for open-text semantic parsing. In Proceedings of AISTATS, pages 127\u2013135."}, {"ref": "Antoine Bordes, Nicolas Usunier, Alberto GarciaDuran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multirelational data. In Proceedings of NIPS, pages"}, {"ref": "2787\u20132795."}, {"ref": "Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. 2014. A semantic matching energy function for learning with multi-relational data. Machine Learning, 94(2):233\u2013259."}, {"ref": "Danqi Chen, Richard Socher, Christopher D Manning, and Andrew Y Ng. 2013. Learning new facts from knowledge bases with neural tensor networks and semantic word vectors. Proceedings of ICLR."}, {"ref": "Matt Gardner, Partha Pratim Talukdar, Bryan Kisiel, and Tom M Mitchell. 2013. Improving learning and inference in a large knowledge-base using latent syntactic cues. In Proceedings of EMNLP, pages 833\u2013838."}, {"ref": "Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In Proceedings of ACLHLT, pages 541\u2013550."}, {"ref": "Rodolphe Jenatton, Nicolas L Roux, Antoine Bordes, and Guillaume R Obozinski. 2012. A latent factor model for highly multi-relational data. In Proceedings of NIPS, pages 3167\u20133175."}, {"ref": "Charles Kemp, Joshua B Tenenbaum, Thomas L Griffiths, Takeshi Yamada, and Naonori Ueda. 2006. Learning systems of concepts with an infinite relational model. In Proceedings of AAAI, volume 3, page 5."}, {"ref": "Ni Lao and William W Cohen. 2010. Relational retrieval using a combination of path-constrained random walks. Machine learning, 81(1):53\u201367."}, {"ref": "Ni Lao, Tom Mitchell, and William W Cohen. 2011. Random walk inference and learning in a large scale knowledge base. In Proceedings of EMNLP, pages 529\u2013539."}, {"ref": "Ni Lao, Amarnag Subramanya, Fernando Pereira, and William W Cohen. 2012. Reading the web with learned syntactic-semantic inference rules. In Proceedings of EMNLP-CoNLL, pages 1017\u20131026."}, {"ref": "Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of AAAI, pages 2181\u20132187."}, {"ref": "Linyuan Lu and Tao Zhou. 2011. Link prediction in complex networks: A survey. Physica A: Statistical Mechanics and its Applications, 390(6):1150\u20131170."}, {"ref": "Tomas Mikolov, Martin Karafiat, Lukas Burget, Jan Cernocky, and Sanjeev Khudanpur. 2010. Recurrent neural network based language model. In Proceedings of Interspeech, pages 1045\u20131048."}, {"ref": "Kurt Miller, Michael I Jordan, and Thomas L Griffiths. 2009. Nonparametric latent feature models for link prediction. In Proceedings of NIPS, pages 1276\u20131284."}, {"ref": "Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of ACLIJCNLP, pages 1003\u20131011."}, {"ref": "Jeff Mitchell and Mirella Lapata. 2008. Vector-based models of semantic composition. In Proceedings of ACL, pages 236\u2013244."}, {"ref": "Arvind Neelakantan, Benjamin Roth, and Andrew McCallum. 2015. Compositional vector space models for knowledge base inference. In 2015 AAAI Spring Symposium Series."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2011. A three-way model for collective learning on multi-relational data. In Proceedings of ICML, pages 809\u2013816."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2012. Factorizing yago: scalable machine learning for linked data. In Proceedings of WWW, pages 271\u2013280."}, {"ref": "Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Proceedings of ECML-PKDD, pages 148\u2013163."}, {"ref": "Ajit P Singh and Geoffrey J Gordon. 2008. Relational learning via collective matrix factorization. In Proceedings of KDD, pages 650\u2013658."}, {"ref": "Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In Proceedings of NIPS, pages 926\u2013934."}, {"ref": "Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D Manning. 2012. Multi-instance multi-label learning for relation extraction. In Proceedings of EMNLP, pages 455\u2013465."}, {"ref": "Ilya Sutskever, Joshua B Tenenbaum, and Ruslan Salakhutdinov. 2009. Modelling relational data using bayesian clustered tensor factorization. In Proceedings of NIPS, pages 1821\u20131828."}, {"ref": "Hanghang Tong, Christos Faloutsos, and Jia-Yu Pan. 2006. Fast random walk with restart and its applications. In Proceedings of ICDM, pages 613\u2013622."}, {"ref": "Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by translating on hyperplanes. In Proceedings of AAAI, pages 1112\u20131119."}, {"ref": "Jason Weston, Antoine Bordes, Oksana Yakhnenko, and Nicolas Usunier. 2013. Connecting language and knowledge bases with embedding models for relation extraction. In Proceedings of EMNLP, pages 1366\u20131371."}, {"ref": "Tao Zhou, Jie Ren, Matu\u00b4s Medo, and Yi-Cheng Zhang. 2007. Bipartite network projection and personal recommendation. Physical Review E, 76(4):046115."}, {"ref": "Jun Zhu. 2012. Max-margin nonparametric latent feature models for link prediction. In Proceedings of ICML, pages 719\u2013726."}]}, {"author": ["Kelvin Guu", "John Miller", "Percy Liang"], "title": "Traversing knowledge graphs in vector space", "journal": "EMNLP", "year": 2015, "DOI": "10.18653/v1/D15-1038", "month": 9.0, "citations": 161, "abstract": "Path queries on a knowledge graph can be used to answer compositional questions such as \"What languages are spoken by people living in Lisbon?\". However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \"compositional\" training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.", "keywords": [""], "reference_count": 26, "ccf_class": "B", "is_important": "", "references": [{"ref": "F. Bastien, P. Lamblin, R. Pascanu, J. Bergstra, I. J. Goodfellow, A. Bergeron, N. Bouchard, and Y. Bengio. 2012. Theano: new features and speed improvements. Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop."}, {"ref": "J. Bergstra, O. Breuleux, F. Bastien, P. Lamblin, R. Pascanu, G. Desjardins, J. Turian, D. Warde-Farley, and Y. Bengio. 2010. Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference (SciPy)."}, {"ref": "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In 326 International Conference on Management of Data (SIGMOD), pages 1247\u20131250."}, {"ref": "A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko. 2013. Translating embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems (NIPS), pages 2787\u20132795."}, {"ref": "A. Bordes, S. Chopra, and J. Weston. 2014. Question answering with subgraph embeddings. In Empirical Methods in Natural Language Processing (EMNLP)."}, {"ref": "S. R. Bowman, C. Potts, and C. D. Manning. 2014. Can recursive neural tensor networks learn logical reasoning? In International Conference on Learning Representations (ICLR)."}, {"ref": "X. Dong, E. Gabrilovich, G. Heitz, W. Horn, N. Lao, K. Murphy, T. Strohmann, S. Sun, and W. Zhang. 2014. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In International Conference on Knowledge Discovery and Data Mining (KDD), pages 601\u2013610."}, {"ref": "J. Duchi, E. Hazan, and Y. Singer. 2010. Adaptive subgradient methods for online learning and stochastic optimization. In Conference on Learning Theory (COLT)."}, {"ref": "M. Gardner, P. Talukdar, J. Krishnamurthy, and T. Mitchell. 2014. Incorporating vector space similarity in random walk inference over knowledge bases. In Empirical Methods in Natural Language Processing (EMNLP)."}, {"ref": "E. Grefenstette. 2013. Towards a formal distributional semantics: Simulating logical calculi with tensors. arXiv preprint arXiv:1304.5823."}, {"ref": "N. Lao and W. W. Cohen. 2010. Relational retrieval using a combination of path-constrained random walks. Machine learning, 81(1):53\u201367."}, {"ref": "N. Lao, T. Mitchell, and W. W. Cohen. 2011. Random walk inference and learning in a large scale knowledge base. In Empirical Methods in Natural Language Processing (EMNLP), pages 529\u2013539."}, {"ref": "B. Min, R. Grishman, L. Wan, C. Wang, and D. Gondek. 2013. Distant supervision for relation extraction with an incomplete knowledge base. In North American Association for Computational Linguistics (NAACL), pages 777\u2013782."}, {"ref": "A. Neelakantan, B. Roth, and A. McCallum. 2015. Compositional vector space models for knowledge base completion. In Association for Computational Linguistics (ACL)."}, {"ref": "M. Nickel, V. Tresp, and H. Kriegel. 2011. A three-way model for collective learning on multirelational data. In International Conference on Machine Learning (ICML), pages 809\u2013816."}, {"ref": "M. Nickel, V. Tresp, and H. Kriegel. 2012. Factorizing YAGO. In World Wide Web (WWW)."}, {"ref": "M. Nickel, X. Jiang, and V. Tresp. 2014. Reducing the rank in relational factorization models by including observable patterns. In Advances in Neural Information Processing Systems (NIPS), pages 1179\u20131187."}, {"ref": "J. Pennington, R. Socher, and C. D. Manning. 2014. Glove: Global vectors for word representation. In Empirical Methods in Natural Language Processing (EMNLP)."}, {"ref": "B. Perozzi, R. Al-Rfou, and S. Skiena. 2014. Deepwalk: Online learning of social representations. In International Conference on Knowledge Discovery and Data Mining (KDD), pages 701\u2013710."}, {"ref": "S. Riedel, L. Yao, and A. McCallum. 2013. Relation extraction with matrix factorization and universal schemas. In North American Association for Computational Linguistics (NAACL)."}, {"ref": "R. Socher, B. Huval, C. D. Manning, and A. Y. Ng. 2012. Semantic compositionality through recursive matrix-vector spaces. In Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL), pages 1201\u20131211."}, {"ref": "R. Socher, D. Chen, C. D. Manning, and A. Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems (NIPS), pages 926\u2013934."}, {"ref": "R. Socher, A. Karpathy, Q. V. Le, C. D. Manning, and A. Y. Ng. 2014. Grounded compositional semantics for finding and describing images with sentences. Transactions of the Association for Computational Linguistics (TACL), 2:207\u2013218."}, {"ref": "J. Turian, L. Ratinov, and Y. Bengio. 2010. Word representations: a simple and general method for semisupervised learning. In Proceedings of the 48th annual meeting of the association for computational linguistics, pages 384\u2013394."}, {"ref": "J. D. Ullman. 1985. Implementation of logical query languages for databases. ACM Transactions on Database Systems (TODS), 10(3):289\u2013321."}, {"ref": "B. Yang, W. Yih, X. He, J. Gao, and L. Deng. 2015. Embedding entities and relations for learning and inference in knowledge bases. arXiv preprint arXiv:1412.6575."}]}, {"author": ["Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen"], "title": "Knowledge graph and text jointly embedding", "journal": "EMNLP", "year": 2014, "DOI": "10.3115/v1/D14-1167", "month": 1.0, "citations": 213, "abstract": "We examine the embedding approach to reason new relational facts from a largescale knowledge graph and a text corpus. We propose a novel method of jointly embedding entities and words into the same continuous vector space. The embedding process attempts to preserve the relations between entities in the knowledge graph and the concurrences of words in the text corpus. Entity names and Wikipedia anchors are utilized to align the embeddings of entities and words in the same space. Large scale experiments on Freebase and a Wikipedia/NY Times corpus show that jointly embedding brings promising improvement in the accuracy of predicting facts, compared to separately embedding knowledge graphs and text. Particularly, jointly embedding enables the prediction of facts containing entities out of the knowledge graph, which cannot be handled by previous embedding methods. At the same time, concerning the quality of the word embeddings, experiments on the analogical reasoning task show that jointly embedding is comparable to or slightly better than word2vec (Skip-Gram)", "keywords": [""], "reference_count": 18, "ccf_class": "B", "is_important": 1.0, "references": [{"ref": "Yoshua Bengio, Rejean Ducharme, Pascal Vincent, and Christian Jauvin. 2003. A neural probabilistic language model. Journal of Machine Learning Research, 3:1137\u20131155."}, {"ref": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, pages 1247\u20131250. ACM."}, {"ref": "Antoine Bordes, Jason Weston, Ronan Collobert, and Yoshua Bengio. 2011. Learning structured embeddings of knowledge bases. In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, pages 301\u2013306."}, {"ref": "Antoine Bordes, Nicolas Usunier, Alberto GarciaDuran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multirelational data. In Advances in Neural Information Processing Systems, pages 2787\u20132795."}, {"ref": "Kai-Wei Chang, Wen-tau Yih, and Christopher Meek. 2013. Multi-relational latent semantic analysis. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1602\u20131612, Seattle, Washington, USA, October. Association for Computational Linguistics."}, {"ref": "Ronan Collobert, Jason Weston, Leon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12:2493\u20132537."}, {"ref": "Miao Fan, Deli Zhao, Qiang Zhou, Zhiyuan Liu, Thomas Fang Zheng, and Edward Y. Chang. 2014. Distant supervision for relation extraction with matrix completion. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 839\u2013849, Baltimore, Maryland, June. Association for Computational Linguistics."}, {"ref": "Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesVolume 1, pages 541\u2013550. Association for Computational Linguistics."}, {"ref": "Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013a. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781."}, {"ref": "Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013b. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems 26, pages 3111\u20133119."}, {"ref": "George A Miller. 1995. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39\u201341."}, {"ref": "Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 1003\u20131011. Association for Computational Linguistics."}, {"ref": "Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Machine Learning and Knowledge Discovery in Databases, pages 148\u2013163. Springer."}, {"ref": "Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems, pages 926\u2013934."}, {"ref": "Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D Manning. 2012. Multi-instance multi-label learning for relation extraction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 455\u2013465. Association for Computational Linguistics."}, {"ref": "Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by translating on hyperplanes. In Proceedings of the TwentyEighth AAAI Conference on Artificial Intelligence, pages 1112\u20131119."}, {"ref": "Jason Weston, Antoine Bordes, Oksana Yakhnenko, and Nicolas Usunier. 2013. Connecting language and knowledge bases with embedding models for relation extraction. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1366\u20131371, Seattle, Washington, USA, October. Association for Computational Linguistics."}, {"ref": "Xingxing Zhang, Jianwen Zhang, Junyu Zeng, Jun Yan, Zheng Chen, and Zhifang Sui. 2013. Towards accurate distant supervision for relational facts extraction. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 810\u2013815, Sofia, Bulgaria, August. Association for Computational Linguistics."}]}, {"author": ["Ruobing Xie", "Zhiyuan Liu", "Jia Jia", "Huanbo Luan", "Maosong Sun"], "title": "Representation learning of knowledge graphs with entity descriptions", "journal": "AAAI", "year": 2016, "DOI": "", "month": 2.0, "citations": 171, "abstract": "Representation learning (RL) of knowledge graphs aims to project both entities and relations into a continuous low-dimensional space. Most methods concentrate on learning representations with knowledge triples indicating relations between entities. In fact, in most knowledge graphs there are usually concise descriptions for entities, which cannot be well utilized by existing methods. In this paper, we propose a novel RL method for knowledge graphs taking advantages of entity descriptions. More specifically, we explore two encoders, including continuous bag-of-words and deep convolutional neural models to encode semantics of entity descriptions. We further learn knowledge representations with both triples and descriptions. We evaluate our method on two tasks, including knowledge graph completion and entity classification. Experimental results on real-world datasets show that, our method outperforms other baselines on the two tasks, especially under the zero-shot setting, which indicates that our method is capable of building representations for novel entities according to their descriptions. The source code of this paper can be obtained from https://github.com/xrb92/DKRL.", "keywords": ["knowledge graph; representation learning; entity; convolutional neural network; description"], "reference_count": 18, "ccf_class": "A", "is_important": "", "references": [{"ref": "Kurt Bollacker , Colin Evans , Praveen Paritosh , Tim Sturge , Jamie Taylor, Freebase: a collaboratively created graph database for structuring human knowledge, Proceedings of the 2008 ACM SIGMOD international conference on Management of data, June 09-12, 2008, Vancouver, Canada"}, {"ref": "Bordes, A.; Usunier, N.; Garcia-Duran, A.; Weston, J.; and Yakhnenko, O. 2013. Translating embeddings for modeling multi-relational data. In Proceedings of NIPS, 2787-2795."}, {"ref": "Ronan Collobert , Jason Weston , L\u00e9on Bottou , Michael Karlen , Koray Kavukcuoglu , Pavel Kuksa, Natural Language Processing (Almost) from Scratch, The Journal of Machine Learning Research, 12, p.2493-2537, 2/1/201"}, {"ref": "Xin Dong , Evgeniy Gabrilovich , Geremy Heitz , Wilko Horn , Ni Lao , Kevin Murphy , Thomas Strohmann , Shaohua Sun , Wei Zhang, Knowledge vault: a web-scale approach to probabilistic knowledge fusion, Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, August 24-27, 2014, New York, New York, USA"}, {"ref": "dos Santos, C.; Xiang, B.; and Zhou, B. 2015. Classifying relations by ranking with convolutional neural networks. In Proceedings of ACL, 626-634."}, {"ref": "Lin, Y.; Liu, Z.; Luan, H.; Sun, M.; Rao, S.; and Liu, S. 2015a. Modeling relation paths for representation learning of knowledge bases. In Proceedings of EMNLP, 705-714."}, {"ref": "Yankai Lin , Zhiyuan Liu , Maosong Sun , Yang Liu , Xuan Zhu, Learning entity and relation embeddings for knowledge graph completion, Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, p.2181-2187, January 25-30, 2015, Austin, Texas"}, {"ref": "Mikolov, T.; Chen, K.; Corrado, G.; and Dean, J. 2013. Efficient estimation of word representations in vector space. In Proceedings of ICLR."}, {"ref": "Neelakantan, A., and Chang, M.-W. 2015. Inferring missing entity type instances for knowledge base completion: New dataset and methods. In Proceedings of NAACL."}, {"ref": "Neelakantan, A.; Roth, B.; and McCallum, A. 2015. Compositional vector space models for knowledge base completion. Proceedings of EMNLP."}, {"ref": "Socher, R.; Chen, D.; Manning, C. D.; and Ng, A. 2013. Reasoning with neural tensor networks for knowledge base completion. In Proceedings of NIPS, 926-934."}, {"ref": "1Sean Szumlanski , Fernando Gomez, Automatically acquiring a semantic network of related concepts, Proceedings of the 19th ACM international conference on Information and knowledge management, October 26-30, 2010, Toronto, ON, Canada"}, {"ref": "Wang, Z.; Zhang, J.; Feng, J.; and Chen, Z. 2014a. Knowledge graph and text jointly embedding. In Proceedings of EMNLP, 1591-1601."}, {"ref": "Zhen Wang , Jianwen Zhang , Jianlin Feng , Zheng Chen, Knowledge graph embedding by translating on hyperplanes, Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, p.1112-1119, July 27-31, 2014, Qu\u00e9bec City, Qu\u00e9bec, Canada"}, {"ref": "Yang, B.; Yih, W.-t.; He, X.; Gao, J.; and Deng, L. 2014. Embedding entities and relations for learning and inference in knowledge bases. Proceedings of ICLR."}, {"ref": "Zeng, D.; Liu, K.; Lai, S.; Zhou, G.; and Zhao, J. 2014. Relation classification via convolutional deep neural network. In Proceedings of COLING, 2335-2344."}, {"ref": "Zhang, D.; Yuan, B.; Wang, D.; and Liu, R. 2015. Joint semantic relevance learning with text data and graph knowledge. ACL-IJCNLP 2015 32-40."}, {"ref": "Zhong, H.; Zhang, J.; Wang, Z.; Wan, H.; and Chen, Z. 2015. Aligning knowledge and text embeddings by entity descriptions. In Proceedings of EMNLP, 267-272."}]}, {"author": ["Zhigang Wang", "Juanzi Li", "Zhiyuan Liu", "Jie Tang"], "title": "Text-enhanced representation learning for knowledge graph", "journal": "IJCAI", "year": 2016, "DOI": "", "month": 7.0, "citations": 66, "abstract": "Learning the representations of a knowledge graph has attracted significant research interest in the field of intelligent Web. By regarding each relation as one translation from head entity to tail entity, translation-based methods including TransE, TransH and TransR are simple, effective and achieving the state-of-the-art performance. However, they still suffer the following issues: (i) low performance when modeling 1-to-N, N-to-1 and N-to-N relations. (ii) limited performance due to the structure sparseness of the knowledge graph. In this paper, we propose a novel knowledge graph representation learning method by taking advantage of the rich context information in a text corpus. The rich textual context information is incorporated to expand the semantic structure of the knowledge graph and each relation is enabled to own different representations for different head and tail entities to better handle 1-to-N, N-to-1 and N-to-N relations. Experiments on multiple benchmark datasets show that our proposed method successfully addresses the above issues and significantly outperforms the state-of-the-art methods.", "keywords": [""], "reference_count": 17, "ccf_class": "A", "is_important": "", "references": [{"ref": "Kurt Bollacker , Colin Evans , Praveen Paritosh , Tim Sturge , Jamie Taylor, Freebase: a collaboratively created graph database for structuring human knowledge, Proceedings of the 2008 ACM SIGMOD international conference on Management of data, June 09-12, 2008, Vancouver, Canada"}, {"ref": "Antoine Bordes , Nicolas Usunier , Alberto Garcia-Dur\u00e1n , Jason Weston , Oksana Yakhnenko, Translating embeddings for modeling multi-relational data, Proceedings of the 26th International Conference on Neural Information Processing Systems, p.2787-2795, December 05-10, 2013, Lake Tahoe, Nevada"}, {"ref": "Paolo Ferragina , Ugo Scaiella, TAGME: on-the-fly annotation of short text fragments (by wikipedia entities), Proceedings of the 19th ACM international conference on Information and knowledge management, October 26-30, 2010, Toronto, ON, Canada"}, {"ref": "Yankai Lin, Zhiyuan Liu, Huan-Bo Luan, Maosong Sun, Siwei Rao, and Song Liu. Modeling relation paths for representation learning of knowledge bases. In EMNLP, pages 705-714, 2015."}, {"ref": "Yankai Lin , Zhiyuan Liu , Maosong Sun , Yang Liu , Xuan Zhu, Learning entity and relation embeddings for knowledge graph completion, Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, p.2181-2187, January 25-30, 2015, Austin, Texas"}, {"ref": "Rada Mihalcea , Andras Csomai, Wikify!: linking documents to encyclopedic knowledge, Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, November 06-10, 2007, Lisbon, Portugal"}, {"ref": "Tomas Mikolov , Ilya Sutskever , Kai Chen , Greg Corrado , Jeffrey Dean, Distributed representations of words and phrases and their compositionality, Proceedings of the 26th International Conference on Neural Information Processing Systems, p.3111-3119, December 05-10, 2013, Lake Tahoe, Nevada"}, {"ref": "George A. Miller, WordNet: a lexical database for English, Communications of the ACM, v.38 n.11, p.39-41, Nov. 199"}, {"ref": "Mike Mintz , Steven Bills , Rion Snow , Dan Jurafsky, Distant supervision for relation extraction without labeled data, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2, August 02-07, 2009, Suntec, Singapore"}, {"ref": "Richard Socher , Danqi Chen , Christopher D. Manning , Andrew Y. Ng, Reasoning with neural tensor networks for knowledge base completion, Proceedings of the 26th International Conference on Neural Information Processing Systems, p.926-934, December 05-10, 2013, Lake Tahoe, Nevada"}, {"ref": "Zhigang Wang, Zhixing Li, Juanzi Li, Jie Tang, and Jeff Z. Pan. Transfer learning based cross-lingual knowledge extraction for wikipedia. In ACL, pages 641-650, 2013."}, {"ref": "Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. Knowledge graph and text jointly embedding. In EMNLP, pages 1591-1601, 2014."}, {"ref": "Zhen Wang , Jianwen Zhang , Jianlin Feng , Zheng Chen, Knowledge graph embedding by translating on hyperplanes, Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, p.1112-1119, July 27-31, 2014, Qu\u00e9bec City, Qu\u00e9bec, Canada"}, {"ref": "Ruobing Xie , Zhiyuan Liu , Jia Jia , Huanbo Luan , Maosong Sun, Representation learning of knowledge graphs with entity descriptions, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona"}, {"ref": "Mohamed Amir Yosef, Johannes Hoffart, Ilaria Bordino, Marc Spaniol, and Gerhard Weikum. Aida: An online tool for accurate disambiguation of named entities in text and tables. In PVLDB, volume 4, pages 1450-1453, 2011."}, {"ref": "Dongxu Zhang, Bin Yuan, Dong Wang, and Rong Liu. Joint semantic relevance learning with text data and graph knowledge. In ACL-IJCNLP, pages 32-40, 2015."}, {"ref": "Huaping Zhong, Jianwen Zhang, Zhen Wang, Hai Wan, and Zheng Chen. Aligning knowledge and text embeddings by entity descriptions. In EMNLP, pages 267-272, 2015."}]}, {"author": ["Shu Guo", "Quan Wang", "Lihong Wang ", "Bin Wang", "Li Guo"], "title": "Jointly embedding knowledge graphs and logical rules", "journal": "EMNLP", "year": 2016, "DOI": "10.18653/v1/D16-1019", "month": 11.0, "citations": 57, "abstract": "Embedding knowledge graphs into continuous vector spaces has recently attracted increasing interest. Most existing methods perform the embedding task using only fact triples. Logical rules, although containing rich background information, have not been well studied in this task. This paper proposes a novel method of jointly embedding knowledge graphs and logical rules. The key idea is to represent and model triples and rules in a unified framework. Specifically, triples are represented as atomic formulae and modeled by the translation assumption, while rules represented as complex formulae and modeled by t-norm fuzzy logics. Embedding then amounts to minimizing a global loss over both atomic and complex formulae. In this manner, we learn embeddings compatible not only with triples but also with rules, which will certainly be more predictive for knowledge acquisition and inference. We evaluate our method with link prediction and triple classification tasks. Experimental results show that joint embedding brings significant and consistent improvements over stateof-the-art methods. Particularly, it enhances the prediction of new facts which cannot even be directly inferred by pure logical inference, demonstrating the capability of our method to learn more predictive embeddings.", "keywords": [""], "reference_count": 39, "ccf_class": "B", "is_important": "", "references": [{"ref": "Islam Beltagy and Raymond J. Mooney. 2014. Efficient markov logic inference for natural language semantics. In Proceedings of the 28th AAAI Conference on Artificial Intelligence - Workshop on Statistical Relational Artificial Intelligence, pages 9\u201314."}, {"ref": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, pages 1247\u20131250."}, {"ref": "Antoine Bordes, Jason Weston, Ronan Collobert, and Yoshua Bengio. 2011. Learning structured embeddings of knowledge bases. In Proceedings of the 25th AAAI Conference on Artificial Intelligence, pages 301\u2013306."}, {"ref": "Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multi-relational data. In Proceedings of the 27th Annual Conference on Neural Information Processing Systems, pages 2787\u20132795."}, {"ref": "Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. 2014. A semantic matching energy function for learning with multi-relational data. Machine Learning, 94(2):233\u2013259."}, {"ref": "Matthias Brocheler, Lilyana Mihalkova, and Lise Getoor. 2010. Probabilistic similarity logic. In Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence, pages 73\u201382."}, {"ref": "Kai-wei Chang, Wen-tau Yih, Bishan Yang, and Christopher Meek. 2014. Typed tensor decomposition of knowledge bases for relation extraction. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 1568\u20131579."}, {"ref": "Thomas Demeester, Tim Rocktaschel, and Sebastian Riedel. 2016. Regularizing relation representations by first-order implications. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Workshop on Automated Knowledge Base Construction, pages 75\u201380."}, {"ref": "Shu Guo, Quan Wang, Lihong Wang, Bin Wang, and Li Guo. 2015. Semantically smooth knowledge graph embedding. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 84\u201394."}, {"ref": "Petr Hajek. 1998. The metamathematics of fuzzy logic. Kluwer. Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S. Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 541\u2013550."}, {"ref": "Rodolphe Jenatton, Nicolas L. Roux, Antoine Bordes, and Guillaume R. Obozinski. 2012. A latent factor model for highly multi-relational data. In Proceedings of the 26th Annual Conference on Neural Information Processing Systems, pages 3167\u20133175. Shangpu Jiang, Daniel Lowd, and Dejing Dou. 2012."}, {"ref": "Learning to refine an automatically extracted knowledge base using markov logic. In Proceedings of 12th IEEE International Conference on Data Mining, pages 912\u2013917."}, {"ref": "Charles Kemp, Joshua B. Tenenbaum, Thomas L. Griffiths, Takeshi Yamada, and Naonori Ueda. 2006. Learning systems of concepts with an infinite relational model. In Proceedings of the 21st AAAI Conference on Artificial Intelligence, pages 381\u2013388."}, {"ref": "Denis Krompa\u00df, Stephan Baier, and Volker Tresp. 2015. Type-constrained representation learning in knowledge graphs. In Proceedings of the 14th International Semantic Web Conference, pages 640\u2013655."}, {"ref": "Yankai Lin, Zhiyuan Liu, Huanbo Luan, Maosong Sun, Siwei Rao, and Song Liu. 2015a. Modeling relation paths for representation learning of knowledge bases. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 705\u2013714."}, {"ref": "Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015b. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of the 29th AAAI Conference on Artificial Intelligence, pages 2181\u20132187."}, {"ref": "Yuanfei Luo, Quan Wang, Bin Wang, and Li Guo. 2015. Context-dependent knowledge graph embedding. In Proceedings of the 2015 Conference on"}, {"ref": "Empirical Methods in Natural Language Processing, pages 1656\u20131661."}, {"ref": "Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013. Linguistic regularities in continuous space word representations. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 746\u2013751."}, {"ref": "George A. Miller. 1995. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39\u201341."}, {"ref": "Arvind Neelakantan, Benjamin Roth, and Andrew McCallum. 2015. Compositional vector space models for knowledge base completion. In Proceedings ofthe 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 156\u2013166."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans P. Kriegel. 2011. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th International Conference on Machine Learning, pages 809\u2013816."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans P. Kriegel. 2012. Factorizing yago: Scalable machine learning for linked data. In Proceedings of the 21st International Conference on World Wide Web, pages 271\u2013280. Maximilian Nickel, Lorenzo Rosasco, and Tomaso Poggio. 2016. Holographic embeddings of knowledge graphs. In Proceedings of the 30th AAAI Conference on Artificial Intelligence, pages 1955\u20131961."}, {"ref": "Jay Pujara, Hui Miao, Lise Getoor, and William Cohen. 2013. Knowledge graph identification. In Proceedings of the 12th International Semantic Web Conference, pages 542\u2013557."}, {"ref": "Matthew Richardson and Pedro Domingos. 2006. Markov logic networks. Machine Learning, 62(1-2):107\u2013136."}, {"ref": "Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M. Marlin. 2013. Relation extraction with matrix factorization and universal schemas. In Proceedings of the 2013 Conference on North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 74\u201384."}, {"ref": "Tim Rocktaschel, Matko Bosnjak, Sameer Singh, and Sebastian Riedel. 2014. Low-dimensional embeddings of logic. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics - Workshop on Semantic Parsing, pages 45\u201349."}, {"ref": "Tim Rocktaschel, Sameer Singh, and Sebastian Riedel. 2015. Injecting logical background knowledge into embeddings for relation extraction. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1119\u20131129."}, {"ref": "Richard Socher, Danqi Chen, Christopher D. Manning, and Andrew Y. Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In Proceedings of the 27th Annual Conference on Neural Information Processing Systems, pages 926\u2013934."}, {"ref": "Giorgos Stoilos, Giorgos B. Stamou, Jeff Z. Pan, Vassilis Tzouvaras, and Ian Horrocks. 2007. Reasoning with very expressive fuzzy description logics. Journal of Artificial Intelligence Research, 30:273\u2013320."}, {"ref": "Ilya Sutskever, Joshua B. Tenenbaum, and Ruslan R. Salakhutdinov. 2009. Modelling relational data using bayesian clustered tensor factorization. In Proceedings of the 23rd Annual Conference on Neural Information Processing Systems, pages 1821\u20131828."}, {"ref": "Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by translating on hyperplanes. In Proceedings of the 28th AAAI Conference on Artificial Intelligence, pages 1112\u20131119."}, {"ref": "Quan Wang, Bin Wang, and Li Guo. 2015. Knowledge base completion using embeddings and rules. In Proceedings of the 24th International Joint Conference on Artificial Intelligence, pages 1859\u20131865."}, {"ref": "Evgenia Wasserman-Pritsker, William W. Cohen, and Einat Minkov. 2015. Learning to identify the best contexts for knowledge-based wsd. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1662\u20131667."}, {"ref": "Zhuoyu Wei, Jun Zhao, Kang Liu, Zhenyu Qi, Zhengya Sun, and Guanhua Tian. 2015. Large-scale knowledge base completion: inferring via grounding network sampling over selected instances. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, pages 1331\u20131340."}, {"ref": "Jason Weston, Antoine Bordes, Oksana Yakhnenko, and Nicolas Usunier. 2013. Connecting language and knowledge bases with embedding models for relation extraction. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1366\u20131371."}, {"ref": "Zhao Xu, Volker Tresp, Kai Yu, and Hanspeter Kriegel. 2006. Infinite hidden relational models. In Proceedings of Proceedings of the 22nd Conference on Uncertainty in Artificial Intelligence, pages 544\u2013551."}, {"ref": "Huaping Zhong, Jianwen Zhang, Zhen Wang, Hai Wan, and Zheng Chen. 2015. Aligning knowledge and text embeddings by entity descriptions. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 267\u2013272."}]}, {"author": ["Tim Rocktaschel", "Sameer Singh", "Sebastian Riedel"], "title": "Injecting Logical Background Knowledge into Embeddings for Relation Extraction", "journal": "NAACL", "year": 2015, "DOI": "10.3115/v1/N15-1118", "month": 6.0, "citations": 126, "abstract": "Matrix factorization approaches to relation extraction provide several attractive features: they support distant supervision, handle open schemas, and leverage unlabeled data. Unfortunately , these methods share a shortcoming with all other distantly supervised approaches: they cannot learn to extract target relations without existing data in the knowledge base, and likewise, these models are inaccurate for relations with sparse data. Rule-based extractors, on the other hand, can be easily extended to novel relations and improved for existing but inaccurate relations, through first-order formu-lae that capture auxiliary domain knowledge. However, usually a large set of such formulae is necessary to achieve generalization. In this paper, we introduce a paradigm for learning low-dimensional embeddings of entity-pairs and relations that combine the advantages of matrix factorization with first-order logic domain knowledge. We introduce simple approaches for estimating such embeddings, as well as a novel training algorithm to jointly optimize over factual and first-order logic information. Our results show that this method is able to learn accurate extractors with little or no distant supervision alignments, while at the same time generalizing to textual patterns that do not appear in the formulae.", "keywords": [""], "reference_count": 49, "ccf_class": "C", "is_important": "", "references": [{"ref": "Yaser S Abu-Mostafa. 1990. Learning from hints in neural networks. Journal of complexity, 6(2):192\u2013198."}, {"ref": "Alan Akbik, Thilo Michael, and Christoph Boden. 2014. Exploratory relation extraction in large text corpora. In International Conference on Computational Linguistics (COLING), pages 2087\u20132096."}, {"ref": "Franz Baader, Bernhard Ganter, Baris Sertkaya, and Ulrike Sattler. 2007. Completing description logic knowledge bases using formal concept analysis. In IJCAI, pages 230\u2013235."}, {"ref": "Islam Beltagy, Cuong Chau, Gemma Boleda, Dan Garrette, Katrin Erk, and Raymond Mooney. 2013. Montague meets markov: Deep semantics with probabilistic logical form. In 2nd Joint Conference on Lexical and Computational Semantics: Proceeding of the Main Conference and the Shared Task, Atlanta, pages 11\u201321."}, {"ref": "Islam Beltagy, Katrin Erk, and Raymond J. Mooney. 2014. Probabilistic soft logic for semantic textual similarity. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL-14), Baltimore, MD."}, {"ref": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, pages 1247\u20131250. ACM."}, {"ref": "Antoine Bordes, Jason Weston, Ronan Collobert, and Yoshua Bengio. 2011. Learning structured embeddings of knowledge bases. In AAAI."}, {"ref": "Johan Bos and Katja Markert. 2005. Recognising textual entailment with logical inference. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 628\u2013635. Association for Computational Linguistics."}, {"ref": "Johan Bos. 2008. Wide-coverage semantic analysis with boxer. In Johan Bos and Rodolfo Delmonte, editors, Semantics in Text Processing. STEP 2008 Conference Proceedings, Research in Computational Semantics, pages 277\u2013286. College Publications."}, {"ref": "Samuel R Bowman. 2014. Can recursive neural tensor networks learn logical reasoning? In ICLR\u201914."}, {"ref": "Razvan C. Bunescu and Raymond J. Mooney. 2007. Learning to Extract Relations from the Web using Minimal Supervision. In Annual Meeting of the Association for Computational Linguistics (ACL), Prague, Czech Republic, June."}, {"ref": "Andrew Carlson, Justin Betteridge, Richard C. Wang, Estevam R. Hruschka, Jr., and Tom M. Mitchell. 2010. Coupled semi-supervised learning for information extraction. In International conference on Web search and data mining (WSDM)."}, {"ref": "Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007. Guiding semi-supervision with constraint-driven learning. In Annual Meeting of the Association for Computational Linguistics (ACL), pages 280\u2013287."}, {"ref": "Kai-Wei Chang, Wen-tau Yih, Bishan Yang, and Christopher Meek. 2014. Typed tensor decomposition of knowledge bases for relation extraction."}, {"ref": "Laura Chiticariu, Yunyao Li, and Frederick R. Reiss. 2013. Rule-based information extraction is dead! long live rule-based information extraction systems! In Empirical Methods in Natural Language Processing (EMNLP), pages 827\u2013832."}, {"ref": "Stephen Clark and Stephen Pulman. 2007. Combining symbolic and distributional models of meaning. In AAAI Spring Symposium: Quantum Interaction, pages 52\u201355."}, {"ref": "Bob Coecke, Mehrnoosh Sadrzadeh, and Stephen Clark. 2010. Mathematical foundations for a compositional distributional model of meaning. CoRR, abs/1003.4394."}, {"ref": "Michael Collins, Sanjoy Dasgupta, and Robert E Schapire. 2001. A generalization of principal components analysis to the exponential family. In Advances in neural information processing systems, pages 617\u2013624."}, {"ref": "Oier Lopez de Lacalle and Mirella Lapata. 2013. Unsupervised relation extraction with general domain knowledge. In EMNLP, pages 415\u2013425."}, {"ref": "Gregory Druck, Gideon Mann, and Andrew McCallum. 2009. Semi-supervised learning of dependency parsers using generalized expectation criteria. In Joint Conference of the Annual Meeting of the ACL and the International Joint Conference on Natural Language Processing of the AFNLP."}, {"ref": "John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. The Journal of Machine Learning Research, 12:2121\u20132159."}, {"ref": "Miao Fan, Deli Zhao, Qiang Zhou, Zhiyuan Liu, Thomas Fang Zheng, and Edward Y Chang. 2014. Distant supervision for relation extraction with matrix completion. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, volume 1, pages 839\u2013849."}, {"ref": "Kuzman Ganchev, Joao Graca, Jennifer Gillenwater, and Ben Taskar. 2010. Posterior regularization for structured latent variable models. Journal of Machine Learning Research (JMLR), July."}, {"ref": "Dan Garrette, Katrin Erk, and Raymond Mooney. 2011. Integrating logical representations with probabilistic information using markov logic. In Proceedings of the Ninth International Conference on Computational Semantics, pages 105\u2013114. Association for Computational Linguistics."}, {"ref": "Edward Grefenstette. 2013. Towards a formal distributional semantics: Simulating logical calculi with tensors. In Proceedings of the Second Joint Conference on Lexical and Computational Semantics, pages 1\u201310."}, {"ref": "Karl Moritz Hermann and Phil Blunsom. 2013. The role of syntax in vector space models of compositional semantics. In Proc. of ACL, pages 894\u2013904."}, {"ref": "Jochen Hipp, Ulrich Guntzer, and Gholamreza Nakhaeizadeh. 2000. Algorithms for association rule mininga general survey and comparison. ACM sigkdd explorations newsletter, 2(1):58\u201364."}, {"ref": "Pascal Hitzler, Steffen Holldobler, and Anthony Karel Seda. 2004. Logic programs and connectionist networks. Journal of Applied Logic, 2(3):245\u2013272."}, {"ref": "Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S. Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In Annual Meeting of the Association for Computational Linguistics (ACL)."}, {"ref": "Steffen Holldobler, Yvonne Kalinke, and Hans-Peter Storr. 1999. Approximating the semantics of logic programs by recurrent neural networks. Appl. Intell., 11(1):45\u201358."}, {"ref": "Mike Lewis and Mark Steedman. 2013. Combined distributional and logical semantics. In Transactions of the Association for Computational Linguistics, volume 1, pages 179\u2013192."}, {"ref": "Gideon S. Mann and Andrew McCallum. 2008. Generalized expectation criteria for semi-supervised learning of conditional random fields. In Annual Meeting of the Association for Computational Linguistics (ACL), pages 870\u2013878."}, {"ref": "Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Association for Computational Linguistics (ACL)."}, {"ref": "Jeff Mitchell and Mirella Lapata. 2008. Vector-based models of semantic composition. In Proc. of ACL, pages 236\u2013244."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2012. Factorizing yago: scalable machine learning for linked data. In Proc. of WWW, pages 271\u2013280."}, {"ref": "Frederick Reiss, Sriram Raghavan, Rajasekar Krishnamurthy, Huaiyu Zhu, and Shivakumar Vaithyanathan. 2008. An algebraic approach to rule-based information extraction. In International Conference on Data Engineering (ICDE), pages 933\u2013942, April."}, {"ref": "Matthew Richardson and Pedro Domingos. 2006. Markov logic networks. Machine Learning, 62(1-2):107\u2013136."}, {"ref": "Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M Marlin. 2013. Relation extraction with matrix factorization and universal schemas. In Proceedings of NAACL-HLT, pages 74\u201384."}, {"ref": "Tim Rocktaschel, Matko Bosnjak, Sameer Singh, and Sebastian Riedel. 2014. Low-Dimensional Embeddings of Logic. In ACL Workshop on Semantic Parsing (SP\u201914)."}, {"ref": "Evan Sandhaus. 2008. The New York Times annotated corpus. Linguistic Data Consortium. Stefan Schoenmackers, Oren Etzioni, and Daniel S. Weld. 2008. Scaling textual inference to the web. In Empirical Methods in Natural Language Processing (EMNLP)."}, {"ref": "Stefan Schoenmackers, Jesse Davis, Oren Etzioni, and Daniel Weld. 2010. Learning first-order horn clauses from web text. In Empirical Methods in Natural Language Processing (EMNLP)."}, {"ref": "Sameer Singh, Dustin Hillard, and Chris Leggetter. 2010. Minimally-supervised extraction of entities from text advertisements. In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT)."}, {"ref": "Richard Socher, Danqi Chen, Christopher D. Manning, and Andrew Y. Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In NIPS, pages 926\u2013934."}, {"ref": "Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D. Manning. 2012. Multi-instance multilabel learning for relation extraction. In Empirical Methods in Natural Language Processing (EMNLP)."}, {"ref": "Geoffrey G Towell and Jude W Shavlik. 1994. Knowledge-based artificial neural networks. Artificial intelligence, 70(1):119\u2013165."}, {"ref": "Johanna Volker and Mathias Niepert. 2011. Statistical schema induction. In The Semantic Web: Research and Applications, pages 124\u2013138. Springer."}, {"ref": "Wentao Wu, Hongsong Li, Haixun Wang, and Kenny Q Zhu. 2012. Probase: A probabilistic taxonomy for text understanding. In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, pages 481\u2013492. ACM."}, {"ref": "Limin Yao, Aria Haghighi, Sebastian Riedel, and Andrew McCallum. 2011. Structured relation discovery using generative models. In Proceedings of the Conference on Empirical methods in natural language processing (EMNLP \u201911), July."}, {"ref": "Luke S Zettlemoyer and Michael Collins. 2005. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Uncertainty in Artifical Intelligence (UAI)."}]}, {"author": ["Shizhu He", "Kang Liu", "Guoliang Ji and Jun Zhao"], "title": "Learning to represent knowledge graphs with Gaussian embedding", "journal": "CIKM", "year": 2015, "DOI": "10.1145/2806416.2806502", "month": 8.0, "citations": 105, "abstract": "The representation of a knowledge graph (KG) in a latent space recently has attracted more and more attention. To this end, some proposed models (e.g., TransE) embed entities and relations of a KG into a \"point\" vector space by optimizing a global loss function which ensures the scores of positive triplets are higher than negative ones. We notice that these models always regard all entities and relations in a same manner and ignore their (un)certainties. In fact, different entities and relations may contain different certainties, which makes identical certainty insufficient for modeling. Therefore, this paper switches to\u00a0density-based\u00a0embedding and propose\u00a0KG2E\u00a0for explicitly modeling the certainty of entities and relations, which learn the representations of KGs in the space of multi-dimensional Gaussian distributions. Each entity/relation is represented by a Gaussian distribution, where the mean denotes its position and the covariance (currently with diagonal covariance) can properly represent its certainty. In addition, compared with the symmetric measures used in\u00a0point-based\u00a0methods, we employ the KL-divergence for scoring triplets, which is a natural asymmetry function for effectively modeling multiple types of relations. We have conducted extensive experiments on link prediction and triplet classification with multiple benchmark datasets (WordNet and Freebase). Our experimental results demonstrate that our method can effectively model the (un)certainties of entities and relations in a KG, and it significantly outperforms state-of-the-art methods (including TransH and TransR).", "keywords": ["Distributed Representation", "Gaussian Embedding", "Knowledge Graph"], "reference_count": 32, "ccf_class": "B", "is_important": 1.0, "references": [{"ref": "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, pages 1247\u20131250. ACM, 2008."}, {"ref": "A. Bordes, S. Chopra, and J. Weston. Question answering with subgraph embeddings. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 615\u2013620, 2014."}, {"ref": "A. Bordes, X. Glorot, J. Weston, and Y. Bengio. A semantic matching energy function for learning with multi-relational data. volume 94, pages 233\u2013259. Springer, 2012."}, {"ref": "A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko. Translating embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems, pages 2787\u20132795, 2013."}, {"ref": "A. Bordes, J. Weston, R. Collobert, Y. Bengio, et al. Learning structured embeddings of knowledge bases. In AAAI, 2011."}, {"ref": "R. Brachman and H. Levesque. Knowledge representation and reasoning. Elsevier, 2004."}, {"ref": "A. Carlson, J. Betteridge, B. Kisiel, B. Settles, E. R. H. Jr., and T. M. Mitchell. Toward an architecture for never-ending language learning. In Proceedings of the Twenty-Fourth Conference on Artificial Intelligence (AAAI 2010), 2010."}, {"ref": "X. Dong, P. Frossard, P. Vandergheynst, and N. Nefedov. Clustering with multi-layer graphs: A spectral perspective. Signal Processing, IEEE Transactions on, 60(11):5820\u20135831, 2012."}, {"ref": "J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. The Journal of Machine Learning Research, 12:2121\u20132159, 2011."}, {"ref": "F. Hayes-Roth, D. Waterman, and D. Lenat. Building expert systems. 1984."}, {"ref": "S. He, K. Liu, Y. Zhang, L. Xu, and J. Zhao. Question answering over linked data using first-order logic. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1092\u20131103, 2014."}, {"ref": "T. Jebara, R. Kondor, and A. Howard. Probability product kernels. The Journal of Machine Learning Research, 5:819\u2013844, 2004."}, {"ref": "R. Jenatton, N. L. Roux, A. Bordes, and G. R. Obozinski. A latent factor model for highly multi-relational data. In Advances in Neural Information Processing Systems, pages 3167\u20133175, 2012."}, {"ref": "Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. Computer, (8):30\u201337, 2009."}, {"ref": "N. Lao, T. Mitchell, and W. W. Cohen. Random walk inference and learning in a large scale knowledge base. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 529\u2013539. Association for Computational Linguistics, 2011."}, {"ref": "Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, 2015."}, {"ref": "T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages 3111\u20133119, 2013."}, {"ref": "G. A. Miller. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39\u201341, 1995."}, {"ref": "M. Nickel, V. Tresp, and H.-P. Kriegel. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th international conference on machine learning (ICML-11), pages 809\u2013816, 2011."}, {"ref": "A. Paccanaro and G. E. Hinton. Learning distributed representations of concepts using linear relational embedding. volume 13, pages 232\u2013244. IEEE, 2001."}, {"ref": "K. B. Petersen, M. S. Pedersen, et al. The matrix cookbook, volume 450. 2008."}, {"ref": "T. Rockt\u00e4schel, S. Singh, and S. Riedel. Injecting logical background knowledge into embeddings for relation extraction. In Proceedings of the 2015 Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, 2015."}, {"ref": "H. Schuetze and C. Scheible. Two svds produce more focal deep learning representations. arXiv preprint arXiv:1301.3627, 2013."}, {"ref": "W. Shen, J. Wang, P. Luo, and M. Wang. Linking named entities in tweets with knowledge base via user interest modeling. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 68\u201376. ACM, 2013."}, {"ref": "R. Socher, D. Chen, C. D. Manning, and A. Ng. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems, pages 926\u2013934, 2013."}, {"ref": "I. Sutskever, J. B. Tenenbaum, and R. R. Salakhutdinov. Modelling relational data using bayesian clustered tensor factorization. In Advances in neural information processing systems, pages 1821\u20131828, 2009."}, {"ref": "S. Szumlanski and F. Gomez. Automatically acquiring a semantic network of related concepts. In Proceedings of the 19th ACM international conference on Information and knowledge management, pages 19\u201328. ACM, 2010."}, {"ref": "L. Vilnis and A. McCallum. Word representations via gaussian embedding. In Proceedings of the International Conference on Learning Representations (ICLR 2015), 2015."}, {"ref": "W. Y. Wang, K. Mazaitis, N. Lao, and W. W. Cohen. Efficient inference and learning in a large knowledge base. Machine Learning, pages 1\u201326, 2015."}, {"ref": "Z. Wang, J. Zhang, J. Feng, and Z. Chen. Knowledge graph embedding by translating on hyperplanes. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, pages 1112\u20131119, 2014."}, {"ref": "M. Yahya, K. Berberich, S. Elbassuoni, and G. Weikum. Robust question answering over the web of linked data. In Proceedings of the 22nd ACM international conference on Conference on information & knowledge management, pages 1107\u20131116. ACM, 2013."}, {"ref": "L. Yao, S. Riedel, and A. McCallum. Probabilistic databases of universal schema. In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction, pages 116\u2013121. Association for Computational Linguistics, 2012."}]}, {"author": ["Han Xiao", "Minlie Huang ", "Xiaoyan Zhu"], "title": "TransG: A Generative Model for Knowledge Graph Embedding", "journal": "ACL", "year": 2016, "DOI": "10.18653/v1/P16-1219", "month": 8.0, "citations": 107, "abstract": "Recently, knowledge graph embedding, which projects symbolic entities and relations into continuous vector space, has become a new, hot topic in artificial intelligence. This paper addresses a new issue of \\textbf{multiple relation semantics} that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples, and proposes a novel Gaussian mixture model for embedding, \\textbf{TransG}. The new model can discover latent semantics for a relation and leverage a mixture of relation component vectors for embedding a fact triple. To the best of our knowledge, this is the first generative model for knowledge graph embedding, which is able to deal with multiple relation semantics. Extensive experiments show that the proposed model achieves substantial improvements against the state-of-the-art baselines.", "keywords": [""], "reference_count": 17, "ccf_class": "A", "is_important": "", "references": [{"ref": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, pages 1247\u20131250.ACM."}, {"ref": "Antoine Bordes, Jason Weston, Ronan Collobert, Yoshua Bengio, et al. 2011. Learning structured embeddings of knowledge bases. In Proceedings of the Twenty-fifth AAAI Conference on Artificial Intelligence."}, {"ref": "Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. 2012. Joint learning of words and meaning representations for open-text semantic parsing. In International Conference on Artificial Intelligence and Statistics, pages 127\u2013135."}, {"ref": "Antoine Bordes, Nicolas Usunier, Alberto GarciaDuran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multirelational data. In Advances in Neural Information Processing Systems, pages 2787\u20132795."}, {"ref": "Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. 2014. A semantic matching energy function for learning with multi-relational data. Machine Learning, 94(2):233\u2013259."}, {"ref": "Miao Fan, Qiang Zhou, Emily Chang, and Thomas Fang Zheng. 2014. Transition-based knowledge graph embedding with relational mapping properties. In Proceedings of the 28th Pacific Asia Conference on Language, Information, and Computation, pages 328\u2013337."}, {"ref": "Alberto Garc\u00b4\u0131a-Duran, Antoine Bordes, Nicolas Usunier, and Yves Grandvalet. 2015. Combining two and three-way embeddings models for link prediction in knowledge bases. CoRR, abs/1506.00999."}, {"ref": "Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training deep feedforward neural networks. In International conference on artificial intelligence and statistics, pages 249\u2013256."}, {"ref": "Thomas L Griffiths and Zoubin Ghahramani. 2011. The indian buffet process: An introduction and review. The Journal of Machine Learning Research, 12:1185\u20131224."}, {"ref": "Shu Guo, Quan Wang, Bin Wang, Lihong Wang, and Li Guo. 2015. Semantically smooth knowledge graph embedding. In Proceedings of ACL."}, {"ref": "Shizhu He, Kang Liu, Guoliang Ji, and Jun Zhao. 2015. Learning to represent knowledge graphs with gaussian embedding. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, pages 623\u2013632.ACM."}, {"ref": "Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesVolume 1, pages 541\u2013550. Association for Computational Linguistics."}, {"ref": "Rodolphe Jenatton, Nicolas L Roux, Antoine Bordes, and Guillaume R Obozinski. 2012. A latent factor model for highly multi-relational data. In Advances in Neural Information Processing Systems, pages 3167\u20133175."}, {"ref": "Yankai Lin, Zhiyuan Liu, and Maosong Sun. 2015a. Modeling relation paths for representation learning of knowledge bases. Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics."}, {"ref": "Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015b. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence."}, {"ref": "George A Miller. 1995. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39\u201341."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2011. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th international conference on machine learning (ICML-11), pages 809\u2013816."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2012. Factorizing yago: scalable machine learning for linked data. In Proceedings of the 21st international conference on World Wide Web, pages 271\u2013280. ACM."}, {"ref": "Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems, pages 926\u2013934."}, {"ref": "Ilya Sutskever, Joshua B Tenenbaum, and Ruslan Salakhutdinov. 2009. Modelling relational data using bayesian clustered tensor factorization. In Advances in neural information processing systems, pages 1821\u20131828."}, {"ref": "Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by translating on hyperplanes. In Proceedings of the TwentyEighth AAAI Conference on Artificial Intelligence, pages 1112\u20131119."}, {"ref": "Quan Wang, Bin Wang, and Li Guo. 2015. Knowledge base completion using embeddings and rules. In Proceedings of the 24th International Joint Conference on Artificial Intelligence."}, {"ref": "Han Xiao, Minlie Huang, and Xiaoyan Zhu. 2016. From one point to a manifold: Knowledge graph embedding for precise link prediction. In IJCAI."}]}, {"author": ["Yantao Jia", "Yuanzhuo Wang", "Hailun Lin", "Xiaolong Jin", "Xueqi Cheng"], "title": "Locally Adaptive Translation for Knowledge Graph Embedding", "journal": "AAAI", "year": 2016, "DOI": "", "month": 2.0, "citations": 51, "abstract": "Knowledge graph embedding aims to represent entities and relations in a large-scale knowledge graph as elements in a continuous vector space. Existing methods, e.g., TransE and TransH, learn embedding representation by defining a global margin-based loss function over the data. However, the optimal loss function is determined during experiments whose parameters are examined among a closed set of candidates. Moreover, embeddings over two knowledge graphs with different entities and relations share the same set of candidate loss functions, ignoring the locality of both graphs. This leads to the limited performance of embedding related applications. In this paper, we propose a locally adaptive translation method for knowledge graph embedding, called TransA, to find the optimal loss function by adaptively determining its margin over different knowledge graphs. Experiments on two benchmark data sets demonstrate the superiority of the proposed method, as compared to the-state-of-the-art ones.", "keywords": [":locally adaptive translation", "knowledge graph embedding", "optimal margin"], "reference_count": 17, "ccf_class": "A", "is_important": "", "references": [{"ref": "Bollacker, K.; Evans, C.; Paritosh, P.; Sturge, T.; and Taylor, J. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, 1247\u20131250.ACM."}, {"ref": "Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning structured embeddings of knowledge bases. In Conference on Artificial Intelligence, number EPFL-CONF192344."}, {"ref": "Bordes, A.; Glorot, X.; Weston, J.; and Bengio, Y. 2012. Joint learning of words and meaning representations for open-text semantic parsing. In International Conference on Artificial Intelligence and Statistics, 127\u2013135."}, {"ref": "Bordes, A.; Usunier, N.; Garcia-Duran, A.; Weston, J.; and Yakhnenko, O. 2013. Translating embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems, 2787\u20132795."}, {"ref": "Bordes, A.; Glorot, X.; Weston, J.; and Bengio, Y. 2014. A semantic matching energy function for learning with multirelational data. Machine Learning 94(2):233\u2013259."}, {"ref": "Boser, B. E.; Guyon, I. M.; and Vapnik, V. N. 1992. A training algorithm for optimal margin classifiers. In Proceedings of the fifth annual workshop on Computational learning theory, 144\u2013152. ACM."}, {"ref": "Bousquet, O., and Elisseeff, A. 2002. Stability and generalization. The Journal of Machine Learning Research 2:499\u2013526."}, {"ref": "Do, H.; Kalousis, A.; Wang, J.; and Woznica, A. 2012. A metric learning perspective of svm: on the relation of lmnn and svm. In International Conference on Artificial Intelligence and Statistics, 308\u2013317."}, {"ref": "Fan, M.; Zhou, Q.; Zheng, T. F.; and Grishman, R. 2015. Large margin nearest neighbor embedding for knowledge representation. arXiv preprint arXiv:1504.01684."}, {"ref": "Jenatton, R.; Roux, N. L.; Bordes, A.; and Obozinski, G. R. 2012. A latent factor model for highly multi-relational data. In Advances in Neural Information Processing Systems, 3167\u20133175."}, {"ref": "Jia, Y.; Wang, Y.; Cheng, X.; Jin, X.; and Guo, J. 2014. Openkn: An open knowledge computational engine for network big data. In Advances in Social Networks Analysis and Mining (ASONAM), 2014 IEEE/ACM International Conference on, 657\u2013664.IEEE."}, {"ref": "Lin, Y.; Liu, Z.; Sun, M.; Liu, Y.; and Zhu, X. 2015. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of AAAI."}, {"ref": "Liu, D.; Wang, Y.; Jia, Y.; Li, J.; and Yu, Z. 2014. Lsdh: a hashing approach for large-scale link prediction in microblogs. In Twenty-Eighth AAAI Conference on Artificial Intelligence. Miller, G. A. 1995. Wordnet: a lexical database for english. Communications of the ACM 38(11):39\u201341."}, {"ref": "Nickel, M.; Tresp, V.; and Kriegel, H.-P. 2012. Factorizing yago: scalable machine learning for linked data. In Proceedings of the 21st international conference on World Wide Web, 271\u2013280.ACM."}, {"ref": "Socher, R.; Chen, D.; Manning, C. D.; and Ng, A. 2013. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems, 926\u2013934."}, {"ref": "Sutskever, I.; Tenenbaum, J. B.; and Salakhutdinov, R. R. 2009. Modelling relational data using bayesian clustered tensor factorization. In Advances in neural information processing systems, 1821\u20131828."}, {"ref": "Vapnik, V. 2013. The nature of statistical learning theory. Springer Science & Business Media."}, {"ref": "Wang, Z.; Zhang, J.; Feng, J.; and Chen, Z. 2014. Knowledge graph embedding by translating on hyperplanes. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, 1112\u20131119."}, {"ref": "Citeseer. Weinberger, K. Q., and Saul, L. K. 2008. Fast solvers and efficient implementations for distance metric learning. In Proceedings of the 25th international conference on Machine learning, 1160\u20131167. ACM."}, {"ref": "Weinberger, K. Q., and Saul, L. K. 2009. Distance metric learning for large margin nearest neighbor classification. The Journal of Machine Learning Research 10:207\u2013244."}, {"ref": "Wu, W.; Li, H.; Wang, H.; and Zhu, K. Q. 2012. Probase: A probabilistic taxonomy for text understanding. In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, 481\u2013492. ACM."}, {"ref": "Zhao, Z.; Jia, Y.; and Wang, Y. 2014. Content-structural relation inference in knowledge base. In Twenty-Eighth AAAI Conference on Artificial Intelligence."}]}, {"author": ["Zhang Wen ", "Chen Huajun"], "title": "Knowledge graph embedding with diversity of structures", "journal": "WWW", "year": 2017, "DOI": "10.1145/3041021.3053380", "month": 4.0, "citations": 8, "abstract": "In recent years, different web knowledge graphs, both free and commercial, have been created. Knowledge graphs use relations between entities to describe facts in the world. We engage in embedding a large scale knowledge graph into a continuous vector space. TransE, TransH, TransR and TransD are promising methods proposed in recent years and achieved state-of-the-art predictive performance. In this paper, we discuss that graph structures should be considered in embedding and propose to embed substructures called \u201cone-relation-circle\u201d (ORC) to further improve the performance of the above methods as they are unable to encode ORC substructures. Some complex models are capable of handling ORC structures but sacrifice efficiency in the process. To make a good trade-off between the model capacity and efficiency, we propose a method to decompose ORC substructures by using two vectors to represent the entity as a head or tail entity with the same relation. In this way, we can encode the ORC structure properly when apply it to TransH, TransR and TransD with almost the same model complexity of themselves. We conduct experiments on link prediction with benchmark dataset WordNet. Our experiments show that applying our method improves the results compared with the corresponding original results of TransH, TransR and TransD.", "keywords": [""], "reference_count": 29, "ccf_class": "A", "is_important": "", "references": [{"ref": "J. W. A. Bordes, X. Glorot and Y. Bengio. A semantic matching energy function for learning with multi-relational data. Machine Learning, 2013."}, {"ref": "R. C. A. Bordes, J.Weston and Y. Bengio. Learning structured embeddings of knowledge bases. AAAI, 2011."}, {"ref": "N. U. Alberto Garc\u02c6At\u2019\u00a8A\u00b4sa-Dur\u02c6At\u2019an, Antoine Bordes and Y. Grandvalet. Combining two and three-way embedding models for link prediction in knowledge bases. Journal of Arti\ufb01cial Intelligence Research, 2016."}, {"ref": "B. K. B. S. E. R. H. J. Andrew Carlson, Justin Betteridge and T. M. Mitchell1. Toward an architecture for never-ending language learning. AAAI, 2010."}, {"ref": "R. C. Antoine Bordes, JasonWeston and Y. Bengio. Learning structured embeddings of knowledge bases. AAAI, 2011."}, {"ref": "U. N. G.-D. A. W. J. Bordes, Antoine and O. Yakhnenko. Translating embeddings for modeling multi-relational data. NIPS, 2013b."}, {"ref": "S. B. Denis Krompa\u02dc A\u00a7 and V. Tresp. Type-constrained representation learning in knowledge graphs. ISWC, 2015."}, {"ref": "G. K. F. M. Suchanek and G. Weikum. Yago: a core of semantic knowledge. WWW, 2007."}, {"ref": "L. X. K. L. Guoliang Ji, Shizhu He and J. Zhao. Knowledge graph embedding via dynamic mapping matrix. ACL, 2015."}, {"ref": "M. H. Han Xiao and X. Zhu. Ssp: Semantic space projection for knowledge graph embedding with text descriptions. AAAI, 2017."}, {"ref": "P. P. T. S. K. Bollacker, C. Evans and J. Taylor. Freebase: A collaboratively created graph database for structuring human knowledge. SIGMOD, 2008."}, {"ref": "L. R. M. Nickel and P. Tomaso. Holographic embeddings of knowledge graphs. AAAI, 2016."}, {"ref": "V. T. M. Nickel and H.-P. Kriegel. A three-way model for collective learning on multi- relational data. ICML, 2011."}, {"ref": "B. R. F. C. G. D. M. K. Miller, G.A. Introduction to wordnet: An on-line lexical database. International journal of lexicography, 1990."}, {"ref": "G. A. Miller. Wordnet: A lexical database for english. Communications of the ACM Vol. 38, 1995."}, {"ref": "F. P. Ni Lao, Amarnag Subramanya and W. Cohen. Reading the web with learned syntactic-semantic inference rules. EMNLP, 2012."}, {"ref": "A. B. G. O. R. Jenatton, N. Le Roux. A latent factor model for highly multi-relational data. AISTATS, 2010."}, {"ref": "H. Robbins and Monro. A stochastic approximation method. Annals of Mathematical Statistics, 1951."}, {"ref": "Z. L. Ruobing Xie and M. Sun. Representation learning of knowledge graphs with hierarchical types. IJCAI, 2016."}, {"ref": "B. Shi and T. Weninger. Proje:embedding projection for knowledge graph completion. AAAI, 2017."}, {"ref": "G. J. Shizhu He, Kang Liu and J. Zhao. Learning to represent knowledge graphs with gaussian embedding. CIKM, 2015."}, {"ref": "C. D. M. C. D. Socher, Richard and A. Y. Ng. Reasoning with neural tensor networks for knowledge base completion. NIPS, 2013."}, {"ref": "M. Xiao, H.; Huang and X. Zhu. Transg : A generative model for knowledge graph embedding. ACL, 2016."}, {"ref": "Z. J. J. L. H. Xie, R.; Liu and M. Sun. Representation learning of knowledge graphs with entity descriptions. AAAI, 2016."}, {"ref": "H. L. X. J. Y. Jia, Y. Wang and X. Cheng. Locally adaptive translation for knowledge graph embedding. AAAI, 2016."}, {"ref": "M. S. Y. L. Y. Lin, Z. Liu and X. Zhu. Learning entity and relation embeddings for knowledge graph completion. AAAI, 2015."}, {"ref": "Z. L. Y. Lin and M. Sun. Modeling relation paths for representation learning of knowledge bases. EMNLP, 2015."}, {"ref": "M. S. Yankai Lin, Zhiyuan Liu. Knowledge representation learning with entities, attributes and relations. IJCAI, 2016."}, {"ref": "J. F. Z. Wang, J. Zhang and Z. Chen. Knowledge graph embedding by translating on hyperplanes. AAAI, 2014."}]}, {"author": ["Takuma Ebisu", "Ryutaro Ichise"], "title": "TorusE: Knowledge graph embedding on a lie group", "journal": "AAAI", "year": 2018, "DOI": "", "month": 2.0, "citations": 25, "abstract": "Knowledge graphs are useful for many artificial intelligence (AI) tasks. However, knowledge graphs often have missing facts. To populate the graphs, knowledge graph embedding models have been developed. Knowledge graph embedding models map entities and relations in a knowledge graph to a vector space and predict unknown triples by scoring candidate triples. TransE is the first translation-based method and it is well known because of its simplicity and efficiency for knowledge graph completion. It employs the principle that the differences between entity embeddings represent their relations. The principle seems very simple, but it can effectively capture the rules of a knowledge graph. However, TransE has a problem with its regularization. TransE forces entity embeddings to be on a sphere in the embedding vector space. This regularization warps the embeddings and makes it difficult for them to fulfill the abovementioned principle. The regularization also affects adversely the accuracies of the link predictions. On the other hand, regularization is important because entity embeddings diverge by negative sampling without it. This paper proposes a novel embedding model, TorusE, to solve the regularization problem. The principle of TransE can be defined on any Lie group. A torus, which is one of the compact Lie groups, can be chosen for the embedding space to avoid regularization. To the best of our knowledge, TorusE is the first model that embeds objects on other than a real or complex vector space, and this paper is the first to formally discuss the problem of regularization of TransE. Our approach outperforms other state-of-the-art approaches such as TransE, DistMult and ComplEx on a standard link prediction task. We show that TorusE is scalable to large-size knowledge graphs and is faster than the original TransE.", "keywords": ["knowledge graph; knowledge inference"], "reference_count": 22, "ccf_class": "A", "is_important": "", "references": [{"ref": "Angeli, G.; Premkumar, M. J. J.; and Manning, C. D. 2015. Leveraging linguistic structure for open domain information extraction. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics, 344\u2013354."}, {"ref": "Auer, S.; Bizer, C.; Kobilarov, G.; Lehmann, J.; Cyganiak, R.; and Ives, Z. G. 2007. DBpedia: A nucleus for a web of open data. In The Semantic Web, 6th International Semantic Web Conference, 2nd Asian Semantic Web Conference, 722\u2013 735."}, {"ref": "Bollacker, K.; Evans, C.; Paritosh, P.; Sturge, T.; and Taylor, J. 2008. Freebase: A collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, 1247\u20131250."}, {"ref": "Bordes, A.; Usunier, N.; Garc\u00b4\u0131a-Duran, A.; Weston, J.; and Yakhnenko, O. 2013. Translating embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems, 2787\u20132795."}, {"ref": "Dong, X.; Gabrilovich, E.; Heitz, G.; Horn, W.; Lao, N.; Murphy, K.; Strohmann, T.; Sun, S.; and Zhang, W. 2014. Knowledge vault: a web-scale approach to probabilistic knowledge fusion. In Proceedings of The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 601\u2013610."}, {"ref": "Ebisu, T., and Ichise, R. 2017. Triple prediction from texts by using distributed representations of words. IEICE Transactions on Information and Systems Vol.E100-D(12):3001\u2013 3009."}, {"ref": "Fader, A.; Soderland, S.; and Etzioni, O. 2011. Identifying relations for open information extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 1535\u20131545."}, {"ref": "Lin, Y.; Liu, Z.; Luan, H.; Sun, M.; Rao, S.; and Liu, S. 2015a. Modeling relation paths for representation learning of knowledge bases. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, 705\u2013714."}, {"ref": "Lin, Y.; Liu, Z.; Sun, M.; Liu, Y.; and Zhu, X. 2015b. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, 2181\u20132187."}, {"ref": "Mausam; Schmitz, M.; Bart, R.; Soderland, S.; and Etzioni, O. 2012. Open language learning for information extraction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, 523\u2013534."}, {"ref": "Mikolov, T.; Chen, K.; Corrado, G.; and Dean, J. 2013a. Efficient estimation of word representations in vector space. CoRR abs/1301.3781."}, {"ref": "Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; and Dean, J. 2013b. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, 3111\u20133119."}, {"ref": "Miller, G. A. 1995. Wordnet: A lexical database for English. Commun. ACM 38(11):39\u201341."}, {"ref": "Nickel, M.; Rosasco, L.; and Poggio, T. A. 2016. Holographic embeddings of knowledge graphs. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, 1955\u20131961."}, {"ref": "Nickel, M.; Tresp, V.; and Kriegel, H. 2011. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th International Conference on Machine Learning, 809\u2013816."}, {"ref": "Socher, R.; Chen, D.; Manning, C. D.; and Ng, A. Y. 2013. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems, 926\u2013934."}, {"ref": "Suchanek, F. M.; Kasneci, G.; and Weikum, G. 2007. Yago: a core of semantic knowledge. In Proceedings of the 16th International Conference on World Wide Web, 697\u2013706."}, {"ref": "Trouillon, T.; Welbl, J.; Riedel, S.; Gaussier, E.; and Bouchard, G. 2016. Complex embeddings for simple link prediction. In Proceedings of the 33rd International Conference on Machine Learning, 2071\u20132080."}, {"ref": "Trouillon, T.; Dance, C. R.; Welbl, J.; Riedel, S.; Gaussier, E.; and Bouchard, G. 2017. Knowledge graph completion via complex tensor factorization. CoRR abs/1702.06879."}, {"ref": "Wang, Z.; Zhang, J.; Feng, J.; and Chen, Z. 2014. Knowledge graph embedding by translating on hyperplanes. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, 1112\u20131119."}, {"ref": "Xiao, H.; Huang, M.; and Zhu, X. 2016. TransG : A generative model for knowledge graph embedding. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics."}, {"ref": "Yang, B.; Yih, W.; He, X.; Gao, J.; and Deng, L. 2014. Embedding entities and relations for learning and inference in knowledge bases. CoRR abs/1412.6575."}]}, {"author": ["Boyang Ding", "Quan Wang", "Bin Wang", "Li Guo"], "title": "Improving knowledge graph embedding using simple constraints", "journal": "ACL", "year": 2018, "DOI": "", "month": 7.0, "citations": 17, "abstract": " Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of current research. Early works performed this task via simple models developed over KG triples. Recent attempts focused on either designing more complicated triple scoring models, or incorporating extra information beyond triples. This paper, by contrast, investigates the potential of using very simple constraints to improve KG embedding. We examine non-negativity constraints on entity representations and approximate entailment constraints on relation representations. The former help to learn compact and interpretable representations for entities. The latter further encode regularities of logical entailment between relations into their distributed representations. These constraints impose prior beliefs upon the structure of the embedding space, without negative impacts on efficiency or scalability. Evaluation on WordNet, Freebase, and DBpedia shows that our approach is simple yet surprisingly effective, significantly and consistently outperforming competitive baselines. The constraints imposed indeed improve model interpretability, leading to a substantially increased structuring of the embedding space. Code and data are available at https://github.com/iieir-km/ComplEx-NNE_AER.", "keywords": [""], "reference_count": 49, "ccf_class": "A", "is_important": "", "references": [{"ref": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: A collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data. pages 1247\u20131250."}, {"ref": "Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. 2014. A semantic matching energy function for learning with multi-relational data. Machine Learning 94(2):233\u2013259."}, {"ref": "Antoine Bordes, Nicolas Usunier, Alberto Garc\u00b4\u0131aDuran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multirelational data. In Advances in Neural Information Processing Systems. pages 2787\u20132795."}, {"ref": "Antoine Bordes, Jason Weston, Ronan Collobert, and Yoshua Bengio. 2011. Learning structured embeddings of knowledge bases. In Proceedings of the 25th AAAI Conference on Artificial Intelligence. pages 301\u2013306."}, {"ref": "Kai-Wei Chang, Wen-tau Yih, Bishan Yang, and Christopher Meek. 2014. Typed tensor decomposition of knowledge bases for relation extraction. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. pages 1568\u20131579."}, {"ref": "Thomas Demeester, Tim Rocktaschel, and Sebastian Riedel. 2016. Lifted rule injection for relation embeddings. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. pages 1389\u20131399."}, {"ref": "Tim Dettmers, Minervini Pasquale, Stenetorp Pontus, and Sebastian Riedel. 2018. Convolutional 2D knowledge graph embeddings. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence. pages 1811\u20131818."}, {"ref": "Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. 2014. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pages 601\u2013610."}, {"ref": "John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research 12(Jul):2121\u20132159."}, {"ref": "Alona Fyshe, Leila Wehbe, Partha P. Talukdar, Brian Murphy, and Tom M. Mitchell. 2015. A compositional and interpretable semantic space. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pages 32\u2013 41."}, {"ref": "Luis Antonio Galarraga, Christina Teflioudi, Katja Hose, and Fabian M. Suchanek. 2015. Fast rule mining in ontological knowledge bases with AMIE+. The VLDB Journal 24(6):707\u2013730."}, {"ref": "Shu Guo, Quan Wang, Bin Wang, Lihong Wang, and Li Guo. 2015. Semantically smooth knowledge graph embedding. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing. pages 84\u201394."}, {"ref": "Shu Guo, Quan Wang, Lihong Wang, Bin Wang, and Li Guo. 2016. Jointly embedding knowledge graphs and logical rules. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. pages 192\u2013202."}, {"ref": "Shu Guo, Quan Wang, Lihong Wang, Bin Wang, and Li Guo. 2018. Knowledge graph embedding with iterative guidance from soft rules. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence. pages 4816\u20134823."}, {"ref": "Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S. Weld. 2011. Knowledge-based weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics. pages 541\u2013550."}, {"ref": "Rodolphe Jenatton, Nicolas L. Roux, Antoine Bordes, and Guillaume R. Obozinski. 2012. A latent factor model for highly multi-relational data. In Advances in Neural Information Processing Systems. pages 3167\u20133175."}, {"ref": "Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu, and Jun Zhao. 2015. Knowledge graph embedding via dynamic mapping matrix. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing. pages 687\u2013696."}, {"ref": "Rudolf Kadlec, Ondrej Bajgar, and Jan Kleindienst. 2017. Knowledge base completion: Baselines strike back. In Proceedings of the 2nd Workshop on Representation Learning for NLP. pages 69\u201374."}, {"ref": "German Kruszewski, Denis Paperno, and Marco Baroni. 2015. Deriving Boolean structures from distributional vectors. Transactions of the Association for Computational Linguistics 3:375\u2013388."}, {"ref": "Daniel D. Lee and H. Sebastian Seung. 1999. Learning the parts of objects by non-negative matrix factorization. Nature 401:788\u2013791."}, {"ref": "Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N. Mendes, Sebastian Hellmann, Mohamed Morsey, Patrick van Kleef, Soren Auer, et al. 2015. DBpedia: A large- scale, multilingual knowledge base extracted from Wikipedia. Semantic Web Journal 6(2):167\u2013195."}, {"ref": "Yankai Lin, Zhiyuan Liu, Huanbo Luan, Maosong Sun, Siwei Rao, and Song Liu. 2015a. Modeling relation paths for representation learning of knowledge bases. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. pages 705\u2013714."}, {"ref": "Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015b. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of the 29th AAAI Conference on Artificial Intelligence. pages 2181\u20132187."}, {"ref": "Hanxiao Liu, Yuexin Wu, and Yiming Yang. 2017. Analogical inference for multi-relational embeddings. In Proceedings of the 34th International Conference on Machine Learning. pages 2168\u20132178."}, {"ref": "Hongyin Luo, Zhiyuan Liu, Huanbo Luan, and Maosong Sun. 2015a. Online learning of interpretable word embeddings. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. pages 1687\u20131692."}, {"ref": "Yuanfei Luo, Quan Wang, Bin Wang, and Li Guo. 2015b. Context-dependent knowledge graph embedding. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. pages 1656\u20131661."}, {"ref": "Pasquale Minervini, Luca Costabello, Emir Munoz, V \u02dc\u0131t Nova\u00b4cek, and Pierre-Yves Vandenbussche. 2017a. \u02c7 Regularizing knowledge graph embeddings via equivalence and inversion axioms. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. pages 668\u2013683."}, {"ref": "Pasquale Minervini, Thomas Demeester, Tim Rocktaschel, and Sebastian Riedel. 2017b. Adver- sarial sets for regularising neural link predictors. In Proceedings of the 33rd Conference on Uncertainty in Artificial Intelligence."}, {"ref": "Brian Murphy, Partha Talukdar, and Tom Mitchell. 2012. Learning effective and interpretable semantic models using non-negative sparse embedding. In Proceedings of COLING 2012. pages 1933\u20131950."}, {"ref": "Arvind Neelakantan, Benjamin Roth, and Andrew McCallum. 2015. Compositional vector space models for knowledge base completion. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing. pages 156\u2013166."}, {"ref": "Maximilian Nickel, Kevin Murphy, Volker Tresp, and Evgeniy Gabrilovich. 2016a. A review of relational machine learning for knowledge graphs. Proceedings of the IEEE 104(1):11\u201333."}, {"ref": "Maximilian Nickel, Lorenzo Rosasco, and Tomaso Poggio. 2016b. Holographic embeddings of knowledge graphs. In Proceedings of the 30th AAAI Conference on Artificial Intelligence. pages 1955\u20131961."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2011. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th International Conference on Machine Learning. pages 809\u2013816."}, {"ref": "Tim Rocktaschel, Sameer Singh, and Sebastian Riedel. 2015. Injecting logical background knowledge into embeddings for relation extraction. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pages 1119\u20131129."}, {"ref": "Michael Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. 2017. Modeling relational data with graph convolutional networks. arXiv:1703.06103 ."}, {"ref": "Baoxu Shi and Tim Weninger. 2017. ProjE: Embedding projection for knowledge graph completion. In Proceedings of the 31st AAAI Conference on Artificial Intelligence. pages 1236\u20131242."}, {"ref": "Richard Socher, Danqi Chen, Christopher D. Manning, and Andrew Y. Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems. pages 926\u2013934."}, {"ref": "Theo Trouillon, Johannes Welbl, Sebastian Riedel, Eric Gaussier, and Guillaume Bouchard. 2016. Complex embeddings for simple link prediction. In Proceedings of the 33rd International Conference on Machine Learning. pages 2071\u20132080."}, {"ref": "Quan Wang, Zhendong Mao, Bin Wang, and Li Guo. 2017. Knowledge graph embedding: A survey of approaches and applications. IEEE Transactions on Knowledge and Data Engineering 29(12):2724\u2013 2743."}, {"ref": "Quan Wang, Bin Wang, and Li Guo. 2015. Knowledge base completion using embeddings and rules. In Proceedings of the 24th International Joint Conference on Artificial Intelligence. pages 1859\u20131865."}, {"ref": "Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by translating on hyperplanes. In Proceedings of the 28th AAAI Conference on Artificial Intelligence. pages 1112\u20131119."}, {"ref": "Evgenia Wasserman-Pritsker, William W. Cohen, and Einat Minkov. 2015. Learning to identify the best contexts for knowledge-based WSD. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. pages 1662\u20131667."}, {"ref": "Han Xiao, Minlie Huang, and Xiaoyan Zhu. 2016. TransG: A generative model for knowledge graph embedding. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. pages 2316\u20132325."}, {"ref": "Han Xiao, Minlie Huang, and Xiaoyan Zhu. 2017. SSP: Semantic space projection for knowledge graph embedding with text descriptions. In Proceedings of the 31st AAAI Conference on Artificial Intelligence. pages 3104\u20133110."}, {"ref": "Ruobing Xie, Zhiyuan Liu, Jia Jia, Huanbo Luan, and Maosong Sun. 2016a. Representation learning of knowledge graphs with entity descriptions. In Proceedings of the 30th AAAI Conference on Artificial Intelligence. pages 2659\u20132665."}, {"ref": "Ruobing Xie, Zhiyuan Liu, and Maosong Sun. 2016b. Representation learning of knowledge graphs with hierarchical types. In Proceedings of the 25th International Joint Conference on Artificial Intelligence. pages 2965\u20132971."}, {"ref": "Bishan Yang and Tom Mitchell. 2017. Leveraging knowledge bases in LSTMs for improving machine reading. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. pages 1436\u20131446."}, {"ref": "Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. 2015. Embedding entities and relations for learning and inference in knowledge bases. In Proceedings of the International Conference on Learning Representations."}, {"ref": "Huaping Zhong, Jianwen Zhang, Zhen Wang, Hai Wan, and Zheng Chen. 2015. Aligning knowledge and text embeddings by entity descriptions. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. pages 267\u2013272."}]}, {"author": ["Shu Guo", "Quan Wang", "Lihong Wang", "Bin Wang", "Li Guo"], "title": "Knowledge graph embedding with iterative guidance from soft rules", "journal": "AAAI", "year": 2018, "DOI": "", "month": 2.0, "citations": 30, "abstract": " Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of current research. Combining such an embedding model with logic rules has recently attracted increasing attention. Most previous attempts made a one-time injection of logic rules, ignoring the interactive nature between embedding learning and logical inference. And they focused only on hard rules, which always hold with no exception and usually require extensive manual effort to create or validate. In this paper, we propose Rule-Guided Embedding (RUGE), a novel paradigm of KG embedding with iterative guidance from soft rules. RUGE enables an embedding model to learn simultaneously from 1) labeled triples that have been directly observed in a given KG, 2) unlabeled triples whose labels are going to be predicted iteratively, and 3) soft rules with various confidence levels extracted automatically from the KG. In the learning process, RUGE iteratively queries rules to obtain soft labels for unlabeled triples, and integrates such newly labeled triples to update the embedding model. Through this iterative procedure, knowledge embodied in logic rules may be better transferred into the learned embeddings. We evaluate RUGE in link prediction on Freebase and YAGO. Experimental results show that: 1) with rule knowledge injected iteratively, RUGE achieves significant and consistent improvements over state-of-the-art baselines; and 2) despite their uncertainties, automatically extracted soft rules are highly beneficial to KG embedding, even those with moderate confidence levels. The code and data used for this paper can be obtained from https://github.com/iieir-km/RUGE.", "keywords": [""], "reference_count": 41, "ccf_class": "A", "is_important": "", "references": [{"ref": "Bollacker, K.; Evans, C.; Paritosh, P.; Sturge, T.; and Taylor, J. 2008. Freebase: A collaboratively created graph database for structuring human knowledge. In SIGMOD, 1247\u20131250."}, {"ref": "Bordes, A.; Usunier, N.; Garc\u00b4\u0131a-Duran, A.; Weston, J.; and Yakhnenko, O. 2013. Translating embeddings for modeling multirelational data. In NIPS, 2787\u20132795."}, {"ref": "Bordes, A.; Glorot, X.; Weston, J.; and Bengio, Y. 2014. A semantic matching energy function for learning with multi-relational data. MACH LEARN 94(2):233\u2013259."}, {"ref": "Carlson, A.; Betteridge, J.; Kisiel, B.; Settles, B.; Hruschka Jr, E. R.; and Mitchell, T. M. 2010. Toward an architecture for neverending language learning. In AAAI, 1306\u20131313."}, {"ref": "Demeester, T.; Rocktaschel, T.; and Riedel, S. 2016. Lifted rule injection for relation embeddings. In EMNLP, 1389\u20131399."}, {"ref": "Dong, X.; Gabrilovich, E.; Heitz, G.; Horn, W.; Lao, N.; Murphy, K.; Strohmann, T.; Sun, S.; and Zhang, W. 2014. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In SIGKDD, 601\u2013610."}, {"ref": "Duchi, J.; Hazan, E.; and Singer, Y. 2011. Adaptive subgradient methods for online learning and stochastic optimization. J MACH LEARN RES 12(Jul):2121\u20132159."}, {"ref": "Faruqui, M.; Dodge, J.; Jauhar, S. K.; Dyer, C.; Hovy, E.; and Smith, N. A. 2014. Retrofitting word vectors to semantic lexicons. arXiv:1411.4166."}, {"ref": "Galarraga, L. A.; Teflioudi, C.; Hose, K.; and Suchanek, F. M. 2013. AMIE: Association rule mining under incomplete evidence in ontological knowledge bases. In WWW, 413\u2013422."}, {"ref": "Galarraga, L. A.; Teflioudi, C.; Hose, K.; and Suchanek, F. M. 2015. Fast rule mining in ontological knowledge bases with AMIE+. VLDB J 24(6):707\u2013730."}, {"ref": "Gardner, M.; Talukdar, P.; and Mitchell, T. 2015. Combining vector space embeddings with symbolic logical inference over opendomain text. In AAAI Spring Symposium Series, 61\u201365."}, {"ref": "Guo, S.; Wang, Q.; Wang, L.; Wang, B.; and Guo, L. 2015. Semantically smooth knowledge graph embedding. In ACL, 84\u201394."}, {"ref": "Guo, S.; Wang, Q.; Wang, L.; Wang, B.; and Guo, L. 2016. Jointly embedding knowledge graphs and logical rules. In EMNLP, 192\u2013 202."}, {"ref": "Guu, K.; Miller, J.; and Liang, P. 2015. Traversing knowledge graphs in vector space. In EMNLP, 318\u2013327."}, {"ref": "Hajek, P. 1998. The metamathematics of fuzzy logic. Kluwer."}, {"ref": "Hu, Z.; Ma, X.; Liu, Z.; Hovy, E.; and Xing, E. 2016. Harnessing deep neural networks with logic rules. In ACL, 2410\u20132420."}, {"ref": "Lin, Y.; Liu, Z.; Luan, H.; Sun, M.; Rao, S.; and Liu, S. 2015a. Modeling relation paths for representation learning of knowledge bases. In EMNLP, 705\u2013714."}, {"ref": "Lin, Y.; Liu, Z.; Sun, M.; Liu, Y.; and Zhu, X. 2015b. Learning entity and relation embeddings for knowledge graph completion. In AAAI, 2181\u20132187."}, {"ref": "Liu, Q.; Jiang, H.; Evdokimov, A.; Ling, Z.-H.; Zhu, X.; Wei, S.; and Hu, Y. 2016. Probabilistic reasoning via deep learning: Neural association models."}, {"ref": "Miller, G. A. 1995. WordNet: A lexical database for English. COMMUN ACM 38(11):39\u201341."}, {"ref": "Neelakantan, A.; Roth, B.; and McCallum, A. 2015. Compositional vector space models for knowledge base completion. In ACL, 156\u2013 166."}, {"ref": "Nickel, M.; Rosasco, L.; and Poggio, T. 2016. Holographic embeddings of knowledge graphs. In AAAI, 1955\u20131961."}, {"ref": "Nickel, M.; Tresp, V.; and Kriegel, H.-P. 2011. A three-way model for collective learning on multi-relational data. In ICML, 809\u2013816."}, {"ref": "Rocktaschel, T.; Bo snjak, M.; Singh, S.; and Riedel, S. 2014. Low- \u02c7 dimensional embeddings of logic. In ACL Workshop on Semantic Parsing, 45\u201349."}, {"ref": "Rocktaschel, T.; Singh, S.; and Riedel, S. 2015. Injecting logical background knowledge into embeddings for relation extraction. In NAACL, 1119\u20131129."}, {"ref": "Socher, R.; Chen, D.; Manning, C. D.; and Ng, A. Y. 2013. Reasoning with neural tensor networks for knowledge base completion. In NIPS, 926\u2013934."}, {"ref": "Suchanek, F. M.; Kasneci, G.; and Weikum, G. 2007. YAGO: A core of semantic knowledge. In WWW, 697\u2013706."}, {"ref": "Trouillon, T.; Welbl, J.; Riedel, S.; Gaussier, E.; and Bouchard, G. 2016. Complex embeddings for simple link prediction. In ICML, 2071\u20132080."}, {"ref": "Vendrov, I.; Kiros, R.; Fidler, S.; and Urtasun, R. 2015. Orderembeddings of images and language. arXiv:1511.06361."}, {"ref": "Wang, W. Y., and Cohen, W. W. 2016. Learning first-order logic embeddings via matrix factorization. In IJCAI, 2132\u20132138."}, {"ref": "Wang, Z.; Zhang, J.; Feng, J.; and Chen, Z. 2014. Knowledge graph embedding by translating on hyperplanes. In AAAI, 1112\u20131119."}, {"ref": "Wang, Q.; Mao, Z.; Wang, B.; and Guo, L. 2017. Knowledge graph embedding: A survey of approaches and applications. IEEE TRANS KNOWL DATA ENG 29(12):2724\u20132743."}, {"ref": "Wang, Q.; Wang, B.; and Guo, L. 2015. Knowledge base completion using embeddings and rules. In IJCAI, 1859\u20131865."}, {"ref": "Wei, Z.; Zhao, J.; Liu, K.; Qi, Z.; Sun, Z.; and Tian, G. 2015. Large-scale knowledge base completion: Inferring via grounding network sampling over selected instances. In CIKM, 1331\u20131340."}, {"ref": "Weston, J.; Bordes, A.; Yakhnenko, O.; and Usunier, N. 2013. Connecting language and knowledge bases with embedding models for relation extraction. In EMNLP, 1366\u20131371."}, {"ref": "Xiao, H.; Huang, M.; and Zhu, X. 2017. SSP: Semantic space projection for knowledge graph embedding with text descriptions. In AAAI, 3104\u20133110."}, {"ref": "Xie, R.; Liu, Z.; Jia, J.; Luan, H.; and Sun, M. 2016. Representation learning of knowledge graphs with entity descriptions. In AAAI, 2659\u20132665."}, {"ref": "Xie, R.; Liu, Z.; and Sun, M. 2016. Representation learning of knowledge graphs with hierarchical types. In IJCAI, 2965\u20132971."}, {"ref": "Xiong, C.; Power, R.; and Callan, J. 2017. Explicit semantic ranking for academic search via knowledge graph embedding. In WWW, 1271\u20131279."}, {"ref": "Yang, B.; Yih, W.-t.; He, X.; Gao, J.; and Deng, L. 2015. Embedding entities and relations for learning and inference in knowledge bases. In ICLR."}, {"ref": "Zhang, F.; Yuan, N. J.; Lian, D.; Xie, X.; and Ma, W.-Y. 2016. Collaborative knowledge base embedding for recommender systems. In SIGKDD, 353\u2013362."}]}, {"author": ["Yongqi Zhang", "Quanming Yao", "Yingxia Shao", "Lei Chen"], "title": "NSCaching: Simple and efficient negative sampling for knowledge graph embedding", "journal": "ICDE", "year": 2019, "DOI": "10.1109/ICDE.2019.00061", "month": 4.0, "citations": 4, "abstract": "Knowledge graph (KG) embedding is a fundamental problem in data mining research with many real-world applications. It aims to encode the entities and relations in the graph into low dimensional vector space, which can be used for subsequent algorithms. Negative sampling, which samples negative triplets from non-observed ones in the training data, is an important step in KG embedding. Recently, generative adversarial network (GAN), has been introduced in negative sampling. By sampling negative triplets with large scores, these methods avoid the problem of vanishing gradient and thus obtain better performance. However, using GAN makes the original model more complex and harder to train, where reinforcement learning must be used. In this paper, motivated by the observation that negative triplets with large scores are important but rare, we propose to directly keep track of them with cache. However, how to sample from and update the cache are two important questions. We carefully design the solutions, which are not only efficient but also achieve good balance between exploration and exploitation. In this way, our method acts as a 'distilled' version of previous GAN-based methods, which does not waste training time on additional parameters to fit the full distribution of negative triplets. The extensive experiments show that our method can gain significant improvement on various KG embedding models, and outperform the state-of-the-arts negative sampling methods based on GAN.", "keywords": [""], "reference_count": 44, "ccf_class": "A", "is_important": "", "references": [{"ref": "M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein GAN. Technical report, 2017."}, {"ref": "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. DBpedia: A nucleus for a web of open data. In The Semantic Web, pages 722\u2013735. Springer, 2007."}, {"ref": "Y. Bengio, J. Louradour, R. Collobert, and J. Weston. Curriculum learning. In ICML, pages 41\u201348. ACM, 2009."}, {"ref": "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, pages 1247\u20131250. ACM, 2008."}, {"ref": "A. Bordes, S. Chopra, and J. Weston. Question answering with subgraph embeddings. In EMNLP, pages 615\u2013620, 2014."}, {"ref": "A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko. Translating embeddings for modeling multi-relational data. In NIPS, pages 2787\u20132795, 2013."}, {"ref": "A. Bordes, J. Weston, and N. Usunier. Open question answering with weakly supervised embedding models. In ECML-PKDD, pages 165\u2013 180. Springer, 2014."}, {"ref": "L. Cai and W.Y. Wang. Kbgan: Adversarial learning for knowledge graph embeddings. In ACL, volume 1, pages 1470\u20131480, 2018."}, {"ref": "L. Drumond, S. Rendle, and L. Schmidt-Thieme. Predicting rdf triples in incomplete knowledge bases with tensor factorization. In SAC, pages 326\u2013331, 2012."}, {"ref": "M. Fan, Q. Zhou, E. Chang, and T. F. Zheng. Transition-based knowledge graph embedding with relational mapping properties. In PACLIC, 2014."}, {"ref": "H. Gao and H. Huang. Self-paced network embedding. In SIGKDD, pages 1406\u20131415, 2018."}, {"ref": "L. Getoor and B. Taskar. Introduction to statistical relational learning, volume 1. The MIT Press, 2007."}, {"ref": "X. Glorot and Y. Bengio. Understanding the dif\ufb01culty of training deep feedforward neural networks. In AISTATS, pages 249\u2013256, 2010."}, {"ref": "Y. Goldberg and O. Levy. word2vec explained: deriving mikolov et al.\u2019s negative-sampling word-embedding method. Technical report, 2014."}, {"ref": "I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In NIPS, pages 2672\u20132680, 2014."}, {"ref": "A. Grover and J. Leskovec. node2vec: Scalable feature learning for networks. In SIGKDD, pages 855\u2013864. ACM, 2016."}, {"ref": "I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville. Improved training of wasserstein gans. In NIPS, pages 5767\u20135777, 2017."}, {"ref": "M. Gutmann and A. Hyv\u00a8arinen. Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In AISTATS, pages 297\u2013304, 2010."}, {"ref": "G. Ji, S. He, L. Xu, K. Liu, and J. Zhao. Knowledge graph embedding via dynamic mapping matrix. In ACL, volume 1, pages 687\u2013696, 2015."}, {"ref": "G. Ji, K. Liu, S. He, and J. Zhao. Knowledge graph completion with adaptive sparse transfer matrix. In AAAI, pages 985\u2013991, 2016."}, {"ref": "Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. Technical report, 2014."}, {"ref": "S. Kok and P. Domingos. Statistical predicate invention. In ICML, pages 433\u2013440, 2007."}, {"ref": "M. P. Kumar, B. Packer, and D. Koller. Self-paced learning for latent variable models. In NIPS, pages 1189\u20131197, 2010."}, {"ref": "N. Lao, T. Mitchell, and W. W. Cohen. Random walk inference and learning in a large scale knowledge base. In EMNLP, pages 529\u2013539. Association for Computational Linguistics, 2011."}, {"ref": "Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu. Learning entity and relation embeddings for knowledge graph completion. In AAAI, volume 15, pages 2181\u20132187, 2015."}, {"ref": "H. Liu, Y. Wu, and Y. Yang. Analogical inference for multi-relational embeddings. In ICML, pages 2168\u20132178, 2017."}, {"ref": "T. Mikolov, W. Yih, and G. Zweig. Linguistic regularities in continuous space word representations. In ACL, pages 746\u2013751, 2013."}, {"ref": "G. A. Miller. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39\u201341, 1995."}, {"ref": "M. Nickel, K. Murphy, V. Tresp, and E. Gabrilovich. A review of relational machine learning for knowledge graphs. Proceedings of the IEEE, 104(1):11\u201333, 2016."}, {"ref": "M. Nickel, L. Rosasco, and T. A. Poggio. Holographic embeddings of knowledge graphs. In AAAI, volume 2, pages 3\u20132, 2016."}, {"ref": "M. Nickel, V. Tresp, and H. Kriegel. A three-way model for collective learning on multi-relational data. In ICML, volume 11, pages 809\u2013816, 2011."}, {"ref": "A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga, and A. Lerer. Automatic differentiation in pytorch. Technical report, 2017."}, {"ref": "A.Singhal. Introducingtheknowledge graph:things,notstrings. Of\ufb01cial Google blog, 5, 2012."}, {"ref": "Q. Song, H. Ge, J. Caverlee, and X. Hu. Self-attention generative adversarial networks. Technical report, 2018."}, {"ref": "F. M. Suchanek, G. Kasneci, and G. Weikum. Yago: a core of semantic knowledge. In WWW, pages 697\u2013706, 2007."}, {"ref": "T. Trouillon, J. Welbl, S. Riedel, and G. Gaussier,E. Complex embeddings for simple link prediction. In ICML, pages 2071\u20132080, 2016."}, {"ref": "P. Wang, S. Li, and R. Pan. Incorporating GAN for negative sampling in knowledge representation learning. AAAI, 2018."}, {"ref": "Q. Wang, Z. Mao, B. Wang, and L. Guo. Knowledge graph embedding: A survey of approaches and applications. TKDE, 29(12):2724\u20132743, 2017."}, {"ref": "Z. Wang, J. Zhang, J. Feng, and Z. Chen. Knowledge graph embedding by translating on hyperplanes. In AAAI, volume 14, pages 1112\u20131119, 2014."}, {"ref": "D. A. White. The knowledge-based software assistant: A program summary. In ICKBSE, pages 2\u20136, 1991."}, {"ref": "R. J. Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning, 8(3-4):229\u2013 256, 1992."}, {"ref": "H. Xiao, M. Huang, and X. Zhu. From one point to a manifold: knowledge graph embedding for precise link prediction. In IJCAI, pages 1315\u20131321, 2016."}, {"ref": "B. Yang, W. Yih, X. He, J. Gao, and L. Deng. Embedding entities and relations for learning and inference in knowledge bases. Technical report, 2017."}, {"ref": "J. Zhu, T. Park, P. Isola, and A. A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In ICCV, pages 2242\u20132251. IEEE, 2017."}]}, {"author": ["V\u0131ctor Gutierrez-Basulto", "Steven Schockaert"], "title": "From Knowledge Graph Embedding to Ontology Embedding? An Analysis of the Compatibility between Vector Space Representations and Rules", "journal": "AAAI", "year": 2018, "DOI": "", "month": 9.0, "citations": 7, "abstract": "Recent years have witnessed the successful application of low-dimensional vector space representations of knowledge graphs to predict missing facts or find erroneous ones. However, it is not yet well-understood to what extent ontological knowledge, e.g. given as a set of (existential) rules, can be embedded in a principled way. To address this shortcoming, in this paper we introduce a general framework based on a view of relations as regions, which allows us to study the compatibility between ontological knowledge and different types of vector space embeddings. Our technical contribution is two-fold. First, we show that some of the most popular existing embedding methods are not capable of modelling even very simple types of rules, which in particular also means that they are not able to learn the type of dependencies captured by such rules. Second, we study a model in which relations are modelled as convex regions. We show particular that ontologies which are expressed using so-called quasi-chained existential rules can be exactly represented using convex regions, such that any set of facts which is induced using that vector space embedding is logically consistent and deductively closed with respect to the input ontology.", "keywords": [""], "reference_count": 40, "ccf_class": "A", "is_important": "", "references": [{"ref": "Baader, F.; Horrocks, I.; Lutz, C.; and Sattler, U. 2017. An Introduction to Description Logic. Cambridge University Press."}, {"ref": "Bollacker, K.; Evans, C.; Paritosh, P.; Sturge, T.; and Taylor, J. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the ACM SIGMOD International Conference on Management of Data, 1247-1250."}, {"ref": "Bordes, A.; Usunier, N.; Garcia-Duran, A.; Weston, J.; and Yakhnenko, O. 2013. Translating embeddings for modeling multi-relational data. In Proc. NIPS, 2787-2795."}, {"ref": "Cal`\u0131, A.; Gottlob, G.; and Kifer, M. 2013. Taming the infinite chase: Query answering under expressive relational constraints. J. Artif. Intell. Res. 48:115-174."}, {"ref": "Camacho-Collados, J.; Pilehvar, M. T.; and Navigli, R. 2016. Nasari: Integrating explicit knowledge and corpus statistics for a multilingual representation of concepts and entities. Artificial Intelligence 240:36-64."}, {"ref": "Carlson, A.; Betteridge, J.; Kisiel, B.; Settles, B.; Hruschka Jr., E. R.; and Mitchell, T. M. 2010. Toward an architecture for never-ending language learning. In Proc. AAAI, 1306\u20131313."}, {"ref": "Demeester, T.; Rocktaschel, T.; and Riedel, S. 2016. Lifted rule injection for relation embeddings. In Proc. EMNLP, 1389-1399."}, {"ref": "Dong, X.; Gabrilovich, E.; Heitz, G.; Horn, W.; Lao, N.; Murphy, K.; Strohmann, T.; Sun, S.; and Zhang, W. 2014. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In SIGKDD, 601-610."}, {"ref": "Fagin, R.; Kolaitis, P. G.; Miller, R. J.; and Popa, L. 2005. Data exchange: semantics and query answering. Theor. Comput. Sci. 336(1):89-124."}, {"ref": "Gardenfors, P. 2000. Conceptual Spaces: The Geometry of Thought. MIT Press. Gardner, M., and Mitchell, T. M. 2015. Efficient and expressive knowledge base completion using subgraph feature extraction. In Proc. of EMNLP-15, 1488-1498."}, {"ref": "Hohenecker, P., and Lukasiewicz, T. 2017. Deep learning for ontology reasoning. arXiv preprint arxiv:1705.10342. Kazemi, S. M., and Poole, D. 2018. SimplE embedding for link prediction in knowledge graphs. arXiv preprint arXiv:1802.04868."}, {"ref": "Krotzsch, M.; Marx, M.; Ozaki, A.; and Thost, V. 2017. Attributed description logics: Ontologies for knowledge graphs. In Proc. of ISWC-17."}, {"ref": "Lin, Y.; Liu, Z.; Sun, M.; Liu, Y.; and Zhu, X. 2015. Learning entity and relation embeddings for knowledge graph completion. In AAAI, 2181-2187."}, {"ref": "Miller, G. A. 1995. Wordnet: a lexical database for english. Communications of the ACM 38:39-41."}, {"ref": "Minervini, P.; Demeester, T.; Rocktaschel, T.; and Riedel, S. \u00a8 2017. Adversarial sets for regularising neural link predictors. In Proc. of UAI-17."}, {"ref": "Nenov, Y.; Piro, R.; Motik, B.; Horrocks, I.; Wu, Z.; and Banerjee, J. 2015. RDFox: A highly-scalable RDF store. In Proc. of ISWC-15, 3-20."}, {"ref": "Nguyen, D. Q.; Sirts, K.; Qu, L.; and Johnson, M. 2016. STransE: a novel embedding model of entities and relationships in knowledge bases. In Proc. of NAACL-HLT, 460\u2013466."}, {"ref": "Nickel, M.; Tresp, V.; and Kriegel, H.-P. 2011. A threeway model for collective learning on multi-relational data. In Proc. ICML, 809-816."}, {"ref": "Niepert, M. 2016. Discriminative gaifman models. In Proc. of NIPS-16, 3405-3413."}, {"ref": "Riedel, S.; Yao, L.; McCallum, A.; and Marlin, B. M. 2013. Relation extraction with matrix factorization and universal schemas. In Proc. HLT-NAACL, 74-84."}, {"ref": "Rocktaschel, T., and Riedel, S. 2017. End-to-end differentiable proving. In Proc. NIPS, 3791-3803."}, {"ref": "Rosseel, Y. 2002. Mixture models of categorization. Journal of Mathematical Psychology 46(2):178\u2013210."}, {"ref": "Sarker, M. K.; Xie, N.; Doran, D.; Raymer, M.; and Hitzler, P. 2017. Explaining trained neural networks with semantic web technologies: First steps. In Proc. of NeSy-17."}, {"ref": "Shmueli, O. 1987. Decidability and expressiveness of logic queries. In Proc. of PODS-87, 237-249."}, {"ref": "Socher, R.; Chen, D.; Manning, C. D.; and Ng, A. 2013. Reasoning with neural tensor networks for knowledge base completion. In Proc. NIPS, 926-934."}, {"ref": "Sourek, G.; Svatos, M.; Zelezny, F.; Schockaert, S.; and \u00b4 Kuzelka, O. 2017. Stacked structure learning for lifted relational neural networks. In Proc. ILP, 140-151."}, {"ref": "Speer, R.; Chin, J.; and Havasi, C. 2017. Conceptnet 5.5: An open multilingual graph of general knowledge. In Proc. AAAI, 4444-4451."}, {"ref": "Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choudhury, P.; and Gamon, M. 2015. Representing text for joint embedding of text and knowledge bases. In Proc. of EMNLP-15, 1499\u2013 1509."}, {"ref": "Trouillon, T.; Welbl, J.; Riedel, S.; Gaussier, E.; and \u00b4 Bouchard, G. 2016. Complex embeddings for simple link prediction. In Proc. ICML, 2071-2080."}, {"ref": "Turney, P. D. 2005. Measuring semantic similarity by latent relational analysis. In Proc. IJCAI, 1136-1141."}, {"ref": "Ullman, J. D., and Gelder, A. V. 1988. Parallel complexity of logical query programs. Algorithmica 3:5-42."}, {"ref": "Vrandeci\u02c7 c, D., and Kr \u00b4 otzsch, M. 2014. Wikidata: a free collaborative knowledge base. Communications of the ACM 57:78-85."}, {"ref": "Wang, W. Y., and Cohen, W. W. 2016. Learning firstorder logic embeddings via matrix factorization. In Proc. of IJCAI-16, 2132-2138."}, {"ref": "Wang, Z.; Zhang, J.; Feng, J.; and Chen, Z. 2014. Knowledge graph embedding by translating on hyperplanes. In AAAI, 1112-1119."}, {"ref": "Wang, Q.; Mao, Z.; Wang, B.; and Guo, L. 2017. Knowledge graph embedding: A survey of approaches and applications. IEEE Trans. Knowl. Data Eng. 29(12):2724-2743."}, {"ref": "Wang, Q.; Wang, B.; and Guo, L. 2015. Knowledge base completion using embeddings and rules. In Proc. IJCAI, 1859-1866."}, {"ref": "Xiao, H.; Huang, M.; Meng, L.; and Zhu, X. 2017. Ssp: Semantic space projection for knowledge graph embedding with text descriptions. In Proc. AAAI, volume 17, 3104\u20133110."}, {"ref": "Xie, R.; Liu, Z.; Jia, J.; Luan, H.; and Sun, M. 2016. Representation learning of knowledge graphs with entity descriptions. In Proc. of AAAI, 2659-2665."}, {"ref": "Yang, B.; Yih, W.; He, X.; Gao, J.; and Deng, L. 2015. Embedding entities and relations for learning and inference in knowledge bases. In Proc. of ICLR-15."}, {"ref": "Zhong, H.; Zhang, J.; Wang, Z.; Wan, H.; and Chen, Z. 2015. Aligning knowledge and text embeddings by entity descriptions. In EMNLP, 267-272."}]}, {"author": ["Muhao Chen", "Yingtao Tian", "Xuelu Chen", "Zijun Xue", "Carlo Zaniolo"], "title": "On2Vec: Embedding-based Relation Prediction for Ontology Population", "journal": "SDM", "year": 2018, "DOI": "10.1137/1.9781611975321.36", "month": 5.0, "citations": 9, "abstract": "Populating ontology graphs represents a long-standing problem for the Semantic Web community. Recent advances in translation-based graph embedding methods for populating instance-level knowledge graphs lead to promising new approaching for the ontology population problem. However, unlike instance-level graphs, the majority of relation facts in ontology graphs come with comprehensive semantic relations, which often include the properties of transitivity and symmetry, as well as hierarchical relations. These comprehensive relations are often too complex for existing graph embedding methods, and direct application of such methods is not feasible. Hence, we propose\u00a0On2Vec, a novel translation-based graph embedding method for ontology population.\u00a0On2Vec\u00a0integrates two model components that effectively characterize comprehensive relation facts in ontology graphs. The first is the Component-specific Model that encodes concepts and relations into low-dimensional embedding spaces without a loss of relational properties; the second is the Hierarchy Model that performs focused learning of hierarchical relation facts. Experiments on several well-known ontology graphs demonstrate the promising capabilities of\u00a0On2Vec\u00a0in predicting and verifying new relation facts. These promising results also make possible significant improvements in related methods.", "keywords": [""], "reference_count": 43, "ccf_class": "B", "is_important": "", "references": [{"ref": "A. Bordes, X. Glorot, et al., Joint learning of words and meaning representations for open-text semantic parsing, in AISTATS, 2012."}, {"ref": "A. Bordes, X. Glorot, et al., A semantic matching energy function for learning with multi-relational data, Machine Learning, 94 (2014)."}, {"ref": "A. Bordes, N. Usunier, et al., Translating embeddings for modeling multi-relational data, in NIPS, 2013."}, {"ref": "A. Bordes, J. Weston, et al., Learning structured embeddings of knowledge bases, in AAAI, 2011."}, {"ref": "E. Camossi, M. Bertolotto, et al., A multigranular object-oriented framework supporting spatiotemporal granularity conversions, IJGIS, 20 (2006), pp. 511\u2013534."}, {"ref": "M. Chen, S. Gao, et al., Converting spatiotemporal data among heterogeneous granularity systems, in FUZZ-IEEE, 2016."}, {"ref": "M. Chen, S. Gao, et al., Converting spatiotemporal data among multiple granularity systems, in SAC, 2016."}, {"ref": "M. Chen, Y. Tian, et al., Multilingual knowledge graph embeddings for cross-lingual knowledge alignment, IJCAI, (2017)."}, {"ref": "M. Chen and C. Zaniolo, Learning multi-faceted knowledge graph embeddings for natural language processing, IJCAI, (2017)."}, {"ref": "M. Chen, T. Zhou, et al., Multi-graph a\ufb03nity embeddings for multilingual knowledge graphs, in AKBC, 2017."}, {"ref": "J. Cheng, S. Sun, et al., Neta\ufb00x gene ontology mining tool: a visual approach for microarray data analysis, Bioinformatics, 20 (2004)."}, {"ref": "R. Collobert and J. Weston, A uni\ufb01ed architecture for natural language processing: Deep neural networks with multitask learning, in ICML, 2008."}, {"ref": "A. Culotta and J. Sorensen, Dependency tree kernels for relation extraction, in ACL, 2004."}, {"ref": "K. Fundel, R. K   uffner, et al., RelEx\u2013Relation extraction using dependency parse trees, Bioinformatics, 23 (2007)."}, {"ref": "C. Giuliano and A. Gliozzo, Instance-based ontology population exploiting named-entity substitution, in COLING, 2008."}, {"ref": "R. Jenatton, N. L. Roux, et al., A latent factor model for highly multi-relational data, in NIPS, 2012."}, {"ref": "G. Ji, S. He, et al., Knowledge graph embedding via dynamic mapping matrix, in ACL, 2015."}, {"ref": "Y. Jia, Y. Wang, et al., Locally adaptive translation for knowledge graph embedding, in AAAI, 2016."}, {"ref": "R. Y. Lau, D. Song, et al., Toward a fuzzy domain ontology extraction method for adaptive e-learning, TKDE, 21 (2009)."}, {"ref": "J. Lehmann, R. Isele, et al., Dbpedia\u2013a large-scale, multilingual knowledge base extracted from Wikipedia, Semantic Web, 6 (2015)."}, {"ref": "Y. Lin, Z. Liu, et al., Learning entity and relation embeddings for knowledge graph completion., in AAAI, 2015."}, {"ref": "Y. Lin, S. Shen, et al., Neural relation extraction with selective attention over instances, in ACL, 2016."}, {"ref": "A. Maedche and S. Staab, Learning ontologies for the semantic web, in ISWC, 2001."}, {"ref": "F. Mahdisoltani, J. Biega, et al., Yago3: A knowledge base from multilingual Wikipedias, in CIDR, 2015."}, {"ref": "H. Mousavi, M. Atzori, et al., Text-mining, structured queries, and knowledge management on web document corpora, SIGMOD Record, 43 (2014)."}, {"ref": "H. Mousavi, S. Gao, , et al., Mining semantics structures from syntactic structures in web document corpora, International Journal of Semantic Computing, 8 (2014)."}, {"ref": "D. Needell, R. Ward, et al., Stochastic gradient descent, weighted sampling, and the randomized kaczmarz algorithm, in NIPS, 2014."}, {"ref": "D. Q. Nguyen, K. Sirts, et al., Stranse: a novel embedding model of entities and relationships in knowledge bases, in NAACL HLT, 2016."}, {"ref": "M. Nickel, L. Rosasco, et al., Holographic embeddings of knowledge graphs, in AAAI, 2016."}, {"ref": "M. Nickel, V. Tresp, et al., A three-way model for collective learning on multi-relational data, in ICML, 2011."}, {"ref": "T. T. Quan, S. C. Hui, et al., Automatic generation of ontology for scholarly semantic web, in ISWC, 2004."}, {"ref": "P. Ristoski and H. Paulheim, Rdf2vec: Rdf graph embeddings for data mining, in ISWC, 2016."}, {"ref": "A. M. Saxe, J. L. McClelland, et al., Exact solutions to the nonlinear dynamics of learning in deep linear neural networks, ICLR, (2014)."}, {"ref": "R. Socher, D. Chen, et al., Reasoning with neural tensor networks for knowledge base completion, in NIPS, 2013."}, {"ref": "R. Speer, J. Chin, et al., Conceptnet 5.5: An open multilingual graph of general knowledge., in AAAI, 2017."}, {"ref": "T. Wang, Y. Li, K. Bontcheva, et al., Automatic extraction of hierarchical relations from text, in ESWC, 2006."}, {"ref": "Z. Wang, J. Zhang, et al., Knowledge graph and text jointly embedding., in EMNLP, 2014."}, {"ref": "Z. Wang, J. Zhang, et al., Knowledge graph embedding by translating on hyperplanes, in AAAI, 2014."}, {"ref": "D. H. Widyantoro and J. Yen, A fuzzy ontologybased abstract search engine and its user studies, in FUZZ-IEEE, 2001."}, {"ref": "C. Yang, Z. Liu, et al., Network representation learning with rich text information, in IJCAI, 2015."}, {"ref": "C. Zaniolo, S. Gao, et al., User-friendly temporal queries on historical knowledge bases, Information and Computation, (2017)."}, {"ref": "D. Zeng, K. Liu, et al., Distant supervision for relation extraction via piecewise convolutional neural networks., in EMNLP, 2015."}, {"ref": "H. Zhong, J. Zhang, et al., Aligning knowledge and text embeddings by entity descriptions, in EMNLP, 2015."}]}, {"author": ["Junheng Hao", "Muhao Chen", "Wenchao Yu", "Yizhou Sun", "Wei Wang"], "title": "Universal Representation Learning of Knowledge Bases by Jointly Embedding Instances and Ontological Concepts", "journal": "KDD", "year": 2019, "DOI": "10.1145/3292500.3330838", "month": 8.0, "citations": 2, "abstract": "Many large-scale knowledge bases simultaneously represent two views of knowledge graphs (KGs): an ontology view for abstract and commonsense concepts, and an instance view for specific entities that are instantiated from ontological concepts. Existing KG embedding models, however, merely focus on representing one of the two views alone. In this paper, we propose a novel two-view KG embedding model, JOIE, with the goal to produce better knowledge embedding and enable new applications that rely on multi-view knowledge. JOIE employs both cross-view and intra-view modeling that learn on multiple facets of the knowledge base. The cross-view association model is learned to bridge the embeddings of ontological concepts and their corresponding instance-view entities. The intra-view models are trained to capture the structured knowledge of instance and ontology views in separate embedding spaces, with a hierarchy-aware encoding technique enabled for ontologies with hierarchies. We explore multiple representation techniques for the two model components and investigate with nine variants of JOIE. Our model is trained on large-scale knowledge bases that consist of massive instances and their corresponding ontological concepts connected via a (small) set of cross-view links. Experimental results on public datasets show that the best variant of JOIE significantly outperforms previous models on instance-view triple prediction task as well as ontology population on ontologyview KG. In addition, our model successfully extends the use of KG embeddings to entity typing with promising performance.", "keywords": ["Knowledge Graph; Relational Embeddings; Ontology Learning"], "reference_count": 44, "ccf_class": "A", "is_important": "", "references": [{"ref": "Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. 2014. A semantic matching energy function for learning with multi-relational data. Machine Learning 94, 2 (2014), 233\u2013259."}, {"ref": "Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multi-relational data. In NIPS."}, {"ref": "Antoine Bordes, Jason Weston, and Nicolas Usunier. 2014. Open question answering with weakly supervised embedding models. In ECML-PKDD."}, {"ref": "Muhao Chen, Yingtao Tian, Kai-Wei Chang, Steven Skiena, and Carlo Zaniolo. 2018. Co-training Embeddings of Knowledge Graphs and Entity Descriptions for Cross-lingual Entity Alignment. IJCAI (2018)."}, {"ref": "Muhao Chen, Yingtao Tian, Xuelu Chen, Zijun Xue, and Carlo Zaniolo. 2018. On2Vec: Embedding-based Relation Prediction for Ontology Population. In SDM."}, {"ref": "Muhao Chen, Yingtao Tian, Mohan Yang, and Carlo Zaniolo. 2017. Multilingual knowledge graph embeddings for cross-lingual knowledge alignment. (2017)."}, {"ref": "Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree kernels for relation extraction. In ACL."}, {"ref": "Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. 2018. Convolutional 2d knowledge graph embeddings. AAAI."}, {"ref": "Jianfeng Du, Kunxun Qi, Hai Wan, Bo Peng, Shengbin Lu, and Yuming Shen. 2017. Enhancing Knowledge Graph Embedding from a Logical Perspective. In JIST. Springer, 232\u2013247."}, {"ref": "Yuan Fang, Kingsley Kuan, Jie Lin, Cheston Tan, and Vijay Chandrasekhar. 2017. Object detection meets knowledge graphs. (2017)."}, {"ref": "Claudio Giuliano and Alfio Gliozzo. 2008. Instance-based ontology population exploiting named-entity substitution. In COLING."}, {"ref": "Shu Guo, Quan Wang, Lihong Wang, Bin Wang, and Li Guo. 2016. Jointly embedding knowledge graphs and logical rules. In EMNLP."}, {"ref": "V\u0131ctor Guti\u00e9rrez-Basulto and Steven Schockaert. 2018. From Knowledge Graph Embedding to Ontology Embedding? An Analysis of the Compatibility between Vector Space Representations and Rules. In KR."}, {"ref": "He He, Anusha Balakrishnan, Mihail Eric, and Percy Liang. 2017. Learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings. In ACL."}, {"ref": "Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu, and Jun Zhao. 2015. Knowledge graph embedding via dynamic mapping matrix. In IJCNLP."}, {"ref": "Yantao Jia, Yuanzhuo Wang, Hailun Lin, Xiaolong Jin, and Xueqi Cheng. 2016. Locally Adaptive Translation for Knowledge Graph Embedding.. In AAAI."}, {"ref": "Denis Krompa\u00df, Stephan Baier, Volker Tresp, et al. 2015. Type-constrained representation learning in knowledge graphs. In ISWC."}, {"ref": "Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N Mendes, Sebastian Hellmann, Mohamed Morsey, Patrick Van Kleef, S\u00f6ren Auer, et al. 2015. DBpedia\u2013a large-scale, multilingual knowledge base extracted from Wikipedia. Semantic Web (2015)."}, {"ref": "Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015. Learning entity and relation embeddings for knowledge graph completion. In AAAI."}, {"ref": "Xin Lv, Lei Hou, Juanzi Li, and Zhiyuan Liu. 2018. Differentiating Concepts and Instances for Knowledge Graph Embedding. In EMNLP."}, {"ref": "Jianxin Ma, Peng Cui, Xiao Wang, and Wenwu Zhu. 2018. Hierarchical taxonomy aware network embedding. In KDD. ACM."}, {"ref": "Shiheng Ma, Jianhui Ding, Weijia Jia, et al. 2017. Transt: Type-based multiple embedding representations for knowledge graph completion. In ECML-PKDD."}, {"ref": "Farzaneh Mahdisoltani, Joanna Biega, and Fabian M Suchanek. 2015. Yago3: A knowledge base from multilingual Wikipedias. In CIDR."}, {"ref": "Hamid Mousavi, Maurizio Atzori, Shi Gao, and Carlo Zaniolo. 2014. Text-mining, structured queries, and knowledge management on web document corpora. SIGMOD (2014)."}, {"ref": "Maximilian Nickel, Lorenzo Rosasco, Tomaso A Poggio, et al. 2016. Holographic Embeddings of Knowledge Graphs.. In AAAI."}, {"ref": "Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2011. A Three-Way Model for Collective Learning on Multi-Relational Data.. In ICML."}, {"ref": "Naoki Otani, Hirokazu Kiyomaru, Daisuke Kawahara, and Sadao Kurohashi. 2018. Cross-lingual Knowledge Projection Using Machine Translation and Target-side Knowledge Base Completion. In COLING."}, {"ref": "Jeff Pasternack and Dan Roth. 2013. Latent credibility analysis. In WWW. ACM."}, {"ref": "Jay Pujara, Eriq Augustine, and Lise Getoor. 2017. Sparsity and Noise: Where Knowledge Graph Embeddings Fall Short. In EMNLP."}, {"ref": "Sashank J Reddi, Satyen Kale, and Sanjiv Kumar. 2018. On the convergence of adam and beyond. In ICLR."}, {"ref": "Tim Rockt\u00e4schel, Sameer Singh, and Sebastian Riedel. 2015. Injecting logical background knowledge into embeddings for relation extraction. In NAACL-HLT."}, {"ref": "Andrew M Saxe, James L McClelland, and Surya Ganguli. 2013. Exact solutions to the nonlinear dynamics of learning in deep linear neural networks. ICLR (2013)."}, {"ref": "Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In NIPS."}, {"ref": "Robert Speer, Joshua Chin, and Catherine Havasi. 2017. ConceptNet 5.5: An Open Multilingual Graph of General Knowledge. In AAAI."}, {"ref": "Zequn Sun, Wei Hu, and Chengkai Li. 2017. Cross-lingual entity alignment via joint attribute-preserving embedding. In ISWC."}, {"ref": "Zequn Sun, Wei Hu, Qingheng Zhang, and Yuzhong Qu. 2018. Bootstrapping Entity Alignment with Knowledge Graph Embedding.. In IJCAI."}, {"ref": "Th\u00e9o Trouillon, Johannes Welbl, Sebastian Riedel, \u00c9ric Gaussier, and Guillaume Bouchard. 2016. Complex embeddings for simple link prediction. In ICML."}, {"ref": "Quan Wang, Zhendong Mao, Bin Wang, and Li Guo. 2017. Knowledge graph embedding: A survey of approaches and applications. IEEE TKDE (2017)."}, {"ref": "Ting Wang, Yaoyong Li, Kalina Bontcheva, Hamish Cunningham, and Ji Wang. 2006. Automatic extraction of hierarchical relations from text. In ESWC."}, {"ref": "Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge Graph Embedding by Translating on Hyperplanes.. In AAAI."}, {"ref": "Ruobing Xie, Zhiyuan Liu, and Maosong Sun. 2016. Representation Learning of Knowledge Graphs with Hierarchical Types.. In IJCAI."}, {"ref": "Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. 2015. Embedding entities and relations for learning and inference in knowledge bases. ICLR."}, {"ref": "Jinyoung Yeo, Geungyu Wang, Hyunsouk Cho, Seungtaek Choi, and Seung-won Hwang. 2018. Machine-Translated Knowledge Transfer for Commonsense Causal Reasoning.. In AAAI."}, {"ref": "Hao Zhu, Ruobing Xie, Zhiyuan Liu, and Maosong Sun. 2017. Iterative entity alignment via joint knowledge embeddings. In AAAI."}]}, {"author": ["Nickel Maximilian", "Lorenzo Rosasco", "Tomaso Poggio"], "title": "Holographic embeddings of knowledge graphs", "journal": "AAAI", "year": 2016, "DOI": "", "month": 3.0, "citations": 319, "abstract": "Learning embeddings of entities and relations is an efficient\nand versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HOLE) to learn compositional\nvector space representations of entire knowledge graphs. The\nproposed method is related to holographic models of associative memory in that it employs circular correlation to create\ncompositional representations. By using correlation as the\ncompositional operator, HOLE can capture rich interactions\nbut simultaneously remains efficient to compute, easy to train,\nand scalable to very large datasets. Experimentally, we show\nthat holographic embeddings are able to outperform state-ofthe-art methods for link prediction on knowledge graphs and\nrelational learning benchmark datasets.", "keywords": ["Knowledge Graph", "Compositional Embeddings", "Holographic Embeddings"], "reference_count": 30, "ccf_class": "A", "is_important": 1.0, "references": ""}, {"author": ["Garc\u00eda-Dur\u00e1n Alberto", "Antoine Bordes", "Nicolas Usunier"], "title": "Effective blending of two and three-way interactions for modeling multi-relational data", "journal": "ECML-PKDD", "year": 2014, "DOI": "", "month": 9.0, "citations": 30, "abstract": "Much work has been recently proposed to model relational data, especially in the multi-relational case, where different kinds of relationships are used to connect the various data entities. Previous attempts either consist of powerful systems with high capacity to model complex connectivity patterns, which unfortunately usually end up overfitting on rare relationships, or in approaches that trade capacity for simplicity in order to fairly model all relationships, frequent or not. In this paper, we propose a happy medium obtained by complementing a high-capacity model with a simpler one, both pre-trained separately and jointly fine-tuned. We show that our approach outperforms existing models on different types of relationships, and achieves state-of-the-art results on two benchmarks of the literature.", "keywords": ["Representation learning", "Multi-relational data"], "reference_count": 24, "ccf_class": "B", "is_important": "", "references": ""}, {"author": ["Yang Bishan", "Wen-tau Yih", "Xiaodong He", "Jianfeng Gao", "Li Deng"], "title": "Embedding entities and relations for learning and inference in knowledge bases", "journal": "ICLR", "year": 2014, "DOI": "", "month": 12.0, "citations": 415, "abstract": "We consider learning representations of entities and relations in KBs using the neural-embedding approach. We show that most existing models, including NTN (Socher et al., 2013) and TransE (Bordes et al., 2013b), can be generalized under a unified learning framework, where entities are low-dimensional vectors learned from a neural network and relations are bilinear and/or linear mapping functions. Under this framework, we compare a variety of embedding models on the link prediction task. We show that a simple bilinear formulation achieves new state-of-the-art results for the task (achieving a top-10 accuracy of 73.2% vs. 54.7% by TransE on Freebase). Furthermore, we introduce a novel approach that utilizes the learned relation embeddings to mine logical rules such as \"BornInCity(a,b) and CityInCountry(b,c) => Nationality(a,c)\". We find that embeddings learned from the bilinear objective are particularly good at capturing relational semantics and that the composition of relations is characterized by matrix multiplication. More interestingly, we demonstrate that our embedding-based rule extraction approach successfully outperforms a state-of-the-art confidence-based rule mining approach in mining Horn rules that involve compositional reasoning.", "keywords": [""], "reference_count": 35, "ccf_class": "", "is_important": 1.0, "references": ""}, {"author": ["Trouillon Th\u00e9o", "Johannes Welbl", "Sebastian Riedel", "\u00c9ric Gaussier", "Guillaume Bouchard"], "title": "Complex embeddings for simple link prediction", "journal": "ICML", "year": 2016, "DOI": "", "month": 6.0, "citations": 299, "abstract": "In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, here we make use of complex valued embeddings. The composition of complex embeddings can handle a large variety of binary relations, among them symmetric and antisymmetric relations. Compared to state-of-the-art models such as Neural Tensor Network and Holographic Embeddings, our approach based on complex embeddings is arguably simpler, as it only uses the Hermitian dot product, the complex counterpart of the standard dot product between real vectors. Our approach is scalable to large datasets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.1", "keywords": [""], "reference_count": 26, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Liu Hanxiao", "Yuexin Wu", "Yiming Yang"], "title": "Analogical inference for multi-relational embeddings", "journal": "ICML", "year": 2017, "DOI": "", "month": 8.0, "citations": 70, "abstract": "Large-scale multi-relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs. An effective and scalable solution for this problem is crucial for the true success of knowledgebased inference in a broad range of applications. This paper proposes a novel framework for optimizing the latent representations with respect to the analogical properties of the embedded entities and relations. By formulating the learning objective in a differentiable fashion, our model enjoys both theoretical power and computational scalability, and significantly outperformed a large number of representative baseline methods on benchmark datasets. Furthermore, the model offers an elegant unification of several well-known methods in multi-relational embedding, which can be proven to be special instantiations of our framework.", "keywords": [""], "reference_count": 49, "ccf_class": "A", "is_important": 1.0, "references": ""}, {"author": ["Dong Xin", "Evgeniy Gabrilovich", "Geremy Heitz", "Wilko Horn", "Ni Lao", "Kevin Murphy", "Thomas Strohmann", "Shaohua Sun", "Wei Zhang"], "title": "Knowledge vault: A web-scale approach to probabilistic knowledge fusion", "journal": "SIGKDD", "year": 2014, "DOI": "", "month": 8.0, "citations": 972, "abstract": "Recent years have witnessed a proliferation of large-scale knowledge bases, including Wikipedia, Freebase, YAGO, Microsoft's Satori, and Google's Knowledge Graph. To increase the scale even further, we need to explore automatic methods for constructing knowledge bases. Previous approaches have primarily focused on text-based extraction, which can be very noisy. Here we introduce Knowledge Vault, a Web-scale probabilistic knowledge base that combines extractions from Web content (obtained via analysis of text, tabular data, page structure, and human annotations) with prior knowledge derived from existing knowledge repositories. We employ supervised machine learning methods for fusing these distinct information sources. The Knowledge Vault is substantially bigger than any previously published structured knowledge repository, and features a probabilistic inference system that computes calibrated probabilities of fact correctness. We report the results of multiple studies that explore the relative utility of the different information sources and extraction methods.", "keywords": [""], "reference_count": 48, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Liu Quan", "Hui Jiang", "Andrew Evdokimov", "Zhen-Hua Ling", "Xiaodan Zhu", "Si Wei", "Yu Hu"], "title": "Probabilistic reasoning via deep learning: Neural association models", "journal": "arXiv preprint", "year": 2016, "DOI": 1603.07704, "month": 3.0, "citations": 26, "abstract": "In this paper, we propose a new deep learning approach, called neural association model (NAM), for probabilistic reasoning in artificial intelligence. We propose to use neural networks to model association between any two events in a domain. Neural networks take one event as input and compute a conditional probability of the other event to model how likely these two events are to be associated. The actual meaning of the conditional probabilities varies between applications and depends on how the models are trained. In this work, as two case studies, we have investigated two NAM structures, namely deep neural networks (DNN) and relation-modulated neural nets (RMNN), on several probabilistic reasoning tasks in AI, including recognizing textual entailment, triple classification in multi-relational knowledge bases and commonsense reasoning. Experimental results on several popular datasets derived from WordNet, FreeBase and ConceptNet have all demonstrated that both DNNs and RMNNs perform equally well and they can significantly outperform the conventional methods available for these reasoning tasks. Moreover, compared with DNNs, RMNNs are superior in knowledge transfer, where a pre-trained model can be quickly extended to an unseen relation after observing only a few training samples. To further prove the effectiveness of the proposed models, in this work, we have applied NAMs to solving challenging Winograd Schema (WS) problems. Experiments conducted on a set of WS problems prove that the proposed models have the potential for commonsense reasoning.", "keywords": ["Probabilistic reasoning", "Winograd Schema Challenge", "Deep learning", "Neural Networks", "Distributed Representation"], "reference_count": 41, "ccf_class": "", "is_important": "", "references": ""}, {"author": ["Jiang Tingsong", "Tianyu Liu", "Tao Ge", "Lei Sha", "Sujian Li", "Baobao Chang", "Zhifang Sui"], "title": "Encoding temporal information for time-aware link prediction", "journal": "EMNLP", "year": 2016, "DOI": "10.18653/v1/D16-1260", "month": 11.0, "citations": 12, "abstract": "Most existing knowledge base (KB) embedding methods solely learn from time-unknown fact triples but neglect the temporal information in the knowledge base. In this paper, we propose a novel time-aware KB embedding approach taking advantage of the happening time of facts. Specifically, we use temporal order constraints to model transformation between time-sensitive relations and enforce the embeddings to be temporally consistent and more accurate. We empirically evaluate our approach in two tasks of link prediction and triple classification. Experimental results show that our method outperforms other baselines on the two tasks consistently", "keywords": [""], "reference_count": 22, "ccf_class": "B", "is_important": "", "references": ""}, {"author": ["Esteban Crist\u00f3bal", "Volker Tresp", "Yinchong Yang", "Stephan Baier", "Denis Krompa\u00df"], "title": "Predicting the co-evolution of event and knowledge graphs", "journal": "International Conference on Information Fusion", "year": 2016, "DOI": "", "month": 7.0, "citations": 17, "abstract": "Knowledge graphs have evolved as flexible and powerful means for representing general world knowledge. Typical examples are DBpedia, Yago, or the Google Knowledge Graph, which all started off by representing information derived from Wikipedia and were then greatly expanded. In this paper we use the concept of a knowledge graph to present information about specific classes of entities, such as patients or users. The knowledge graph represents all that is known about the entities and their relationships and the goal is to integrate and exploit that information for prediction and decision support. In previous papers it was shown that embedding learning, a.k.a. representation learning, is capable of modelling large-scale semantic knowledge graphs, by exploiting information that describes the context of an entity in the knowledge graph. In Machine Learning we often map the knowledge graph to a tensor representation. Then we learn the latent representations of the entities that compose the tensor and use them to predict unobserved facts. However knowledge graphs represent the current status of the world and therefore they lack of a temporal dimension, which means we can only use them to predict facts about the present moment. In this paper we introduce an additional set of tensors that contain temporal information. Each of this event tensors contains all the events that occurred on a particular time step. Our goal will be to predict the events that will happen in future time steps, using for that task both dynamic information from the previous event tensors and static information that is stored in the knowledge graph. Therefore, this architecture allows us to fuse static and dynamic information to predict future events. We present experiments showing how this model performs well in multiple scenarios: medical data, a recommendation engine and sensor data.", "keywords": ["Tensile stress", "Brain modeling", "Predictive models", "Neural networks", "Google", "Data models", "Lifting equipment"], "reference_count": 36, "ccf_class": "", "is_important": "", "references": ""}, {"author": ["Trivedi Rakshit", "Hanjun Dai", "Yichen Wang", "Le Song"], "title": "Know-evolve: Deep temporal reasoning for dynamic knowledge graphs", "journal": "ICML", "year": 2017, "DOI": "", "month": 8.0, "citations": 50, "abstract": "The availability of large scale event data with time stamps has given rise to\u00a0dynamically evolving\u00a0knowledge graphs that contain temporal information for each edge. Reasoning over time in such dynamic knowledge graphs is not yet well understood. To this end, we present\u00a0Know-Evolve, a novel deep evolutionary knowledge network that learns non-linearly evolving entity representations over time. The occurrence of a fact (edge) is modeled as a multivariate point process whose intensity function is modulated by the score for that fact computed based on the learned entity embed-dings. We demonstrate significantly improved performance over various relational learning approaches on two large scale real-world datasets. Further, our method effectively predicts occurrence or recurrence time of a fact which is novel compared to prior reasoning approaches in multi-relational setting.", "keywords": [""], "reference_count": 39, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Feng Jun", "Minlie Huang", "Yang Yang"], "title": "GAKE: Graph aware knowledge embedding", "journal": "COLING", "year": 2016, "DOI": "", "month": 12.0, "citations": 36, "abstract": "Knowledge embedding, which projects triples in a given knowledge base to d-dimensional vectors, has attracted considerable research efforts recently. Most existing approaches treat the given knowledge base as a set of triplets, each of whose representation is then learned separately. However, as a fact, triples are connected and depend on each other. In this paper, we propose a graph aware knowledge embedding method (GAKE), which formulates knowledge base as a directed graph, and learns representations for any vertices or edges by leveraging the graph\u2019s structural information. We introduce three types of graph context for embedding: neighbor context, path context, and edge context, each reflects properties of knowledge from different perspectives. We also design an attention mechanism to learn representative power of different vertices or edges. To validate our method, we conduct several experiments on two tasks. Experimental results suggest that our method outperforms several state-of-art knowledge embedding models.", "keywords": [""], "reference_count": 30, "ccf_class": "B", "is_important": "", "references": ""}, {"author": ["Jiang Xueyan", "Volker Tresp", "Yi Huang", "Maximilian Nickel"], "title": "Link prediction in multi-relational graphs using additive models", "journal": "SeRSy", "year": 2012, "DOI": "", "month": 11.0, "citations": 24, "abstract": "We present a general and novel framework for predicting links in multirelational graphs using a set of matrices describing the various instantiated relations in the knowledge base. We construct matrices that add information further remote in the knowledge graph by join operations and we describe how unstructured information can be integrated in the model. We show that efficient learning can be achieved using an alternating least squares approach exploiting sparse matrix algebra and low-rank approximations. We discuss the relevance of modeling nonlinear interactions and add corresponding model components. We also discuss a kernel solution which is of interest when it is easy to define sensible kernels. We discuss the relevance of feature selection for the interaction terms and apply a random search strategy to tune the hyperparameters in the model. We validate our approach using data sets from the Linked Open Data (LOD) cloud and from other sources.", "keywords": [""], "reference_count": 32, "ccf_class": "", "is_important": "", "references": ""}, {"author": ["Zhang Fuzheng", "Yuan Nicholas Jing", "Lian Defu", "Xie Xing", "Ma Wei-Ying"], "title": "Collaborative Knowledge Base Embedding for Recommender Systems", "journal": "SIGKDD", "year": 2016, "DOI": "10.1145/2939672.2939673", "month": "", "citations": 277, "abstract": "Among different recommendation techniques, collaborative filtering usually suffer from limited performance due to the sparsity of user-item interactions. To address the issues, auxiliary information is usually used to boost the performance. Due to the rapid collection of information on the web, the knowledge base provides heterogeneous information including both structured and unstructured data with different semantics, which can be consumed by various applications. In this paper, we investigate how to leverage the heterogeneous information in a knowledge base to improve the quality of recommender systems. First, by exploiting the knowledge base, we design three components to extract items' semantic representations from structural content, textual content and visual content, respectively. To be specific, we adopt a heterogeneous network embedding method, termed as TransR, to extract items' structural representations by considering the heterogeneity of both nodes and relationships. We apply stacked denoising auto-encoders and stacked convolutional auto-encoders, which are two types of deep learning based embedding techniques, to extract items' textual representations and visual representations, respectively. Finally, we propose our final integrated framework, which is termed as Collaborative Knowledge Base Embedding (CKE), to jointly learn the latent representations in collaborative filtering as well as items' semantic representations from the knowledge base. To evaluate the performance of each embedding component as well as the whole system, we conduct extensive experiments with two real-world datasets from different scenarios. The results reveal that our approaches outperform several widely adopted state-of-the-art recommendation methods.", "keywords": [""], "reference_count": 31, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Qingheng Zhang", "Zequn Sun", "Wei Hu", "Muhao Chen", "Lingbing Guo", "Yuzhong Qu"], "title": "Multi-view Knowledge Graph Embedding for Entity Alignment", "journal": "IJCAI", "year": 2019, "DOI": "10.24963/ijcai.2019/754", "month": "", "citations": 4, "abstract": "We study the problem of embedding-based entity alignment between knowledge graphs (KGs). Previous works mainly focus on the relational structure of entities. Some further incorporate another type of features, such as attributes, for refinement. However, a vast of entity features are still unexplored or not equally treated together, which impairs the accuracy and robustness of embedding-based entity alignment. In this paper, we propose a novel framework that unifies multiple views of entities to learn embeddings for entity alignment. Specifically, we embed entities based on the views of entity names, relations and attributes, with several combination strategies. Furthermore, we design some cross-KG inference methods to enhance the alignment between two KGs. Our experiments on real-world datasets show that the proposed framework significantly outperforms the state-of-the-art embedding-based entity alignment methods. The selected views, cross-KG inference and combination strategies all contribute to the performance improvement.", "keywords": [""], "reference_count": 28, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Deepak Nathani", "Jatin Chauhan", "Charu Sharma", "Manohar Kaul"], "title": "Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs", "journal": "ACL", "year": 2019, "DOI": "10.18653/v1/P19-1466", "month": "", "citations": 0, "abstract": "The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multihop relations in our model. Our empirical study offers insights into the efficacy of our attention based model and we show marked performance gains in comparison to state of the art methods on all datasets.", "keywords": [""], "reference_count": 28, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Canran Xu", "Ruijiang Li"], "title": "Relation Embedding with Dihedral Group in Knowledge Graph", "journal": "ACL", "year": 2019, "DOI": "10.18653/v1/P19-1026", "month": "", "citations": 0, "abstract": "Link prediction is critical for the application of incomplete knowledge graph (KG) in the downstream tasks. As a family of effective approaches for link predictions, embedding methods try to learn low-rank representations for both entities and relations such that the bilinear form defined therein is a well-behaved scoring function. Despite of their successful performances, existing bilinear forms overlook the modeling of relation compositions, resulting in lacks of interpretability for reasoning on KG. To fulfill this gap, we propose a new model called DihEdral, named after dihedral symmetry group. This new model learns knowledge graph embeddings that can capture relation compositions by nature. Furthermore, our approach models the relation embeddings parametrized by discrete values, thereby decrease the solution space drastically. Our experiments show that DihEdral is able to capture all desired properties such as (skew-) symmetry, inversion and (non-) Abelian composition, and outperforms existing bilinear form based approach and is comparable to or better than deep learning models such as ConvE.", "keywords": [""], "reference_count": 34, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Namyong Park", "Andrey Kan", "Xin Luna Dong", "Tong Zhao", "Christos Faloutsos"], "title": "Estimating Node Importance in Knowledge Graphs Using Graph Neural Networks", "journal": "KDD", "year": 2019, "DOI": "10.1145/3292500.3330855", "month": "", "citations": 0, "abstract": "How can we estimate the importance of nodes in a knowledge graph (KG)? A KG is a multi-relational graph that has proven valuable for many tasks including question answering and semantic search. In this paper, we present GENI, a method for tackling the problem of estimating node importance in KGs, which enables several downstream applications such as item recommendation and resource allocation. While a number of approaches have been developed to address this problem for general graphs, they do not fully utilize information available in KGs, or lack flexibility needed to model complex relationship between entities and their importance. To address these limitations, we explore supervised machine learning algorithms. In particular, building upon recent advancement of graph neural networks (GNNs), we develop GENI, a GNN-based method designed to deal with distinctive challenges involved with predicting node importance in KGs. Our method performs an aggregation of importance scores instead of aggregating node embeddings via predicate-aware attention mechanism and flexible centrality adjustment. In our evaluation of GENI and existing methods on predicting node importance in real-world KGs with different characteristics, GENI achieves 5-17% higher NDCG@100 than the state of the art.", "keywords": [""], "reference_count": 26, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Kun Xu", "Liwei Wang", "Mo Yu", "Yansong Feng", "Yan Song", "Zhiguo Wang", "Dong Yu"], "title": "Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network", "journal": "ACL", "year": 2019, "DOI": "10.18653/v1/P19-1304", "month": "", "citations": 1, "abstract": "Previous cross-lingual knowledge graph (KG) alignment studies rely on entity embeddings derived only from monolingual KG structural information, which may fail at matching entities that have different facts in two KGs. In this paper, we introduce the topic entity graph, a local sub-graph of an entity, to represent entities with their contextual information in KG. From this view, the KB-alignment task can be formulated as a graph matching problem; and we further propose a graph-attention based solution, which first matches all entities in two topic entity graphs, and then jointly model the local matching information to derive a graph-level matching vector. Experiments show that our model outperforms previous state-of-the-art methods by a large margin.", "keywords": [""], "reference_count": 19, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Lingbing Guo", "Zequn Sun", "Wei Hu"], "title": "Learning to Exploit Long-term Relational Dependencies in Knowledge Graphs", "journal": "ICML", "year": 2019, "DOI": "", "month": "", "citations": 1, "abstract": "We study the problem of knowledge graph (KG) embedding. A widely-established assumption to this problem is that similar entities are likely to have similar relational roles. However, existing related methods derive KG embeddings mainly based on triple-level learning, which lack the capability of capturing long-term relational dependencies of entities. Moreover, triple-level learning is insufficient for the propagation of semantic information among entities, especially for the case of cross-KG embedding. In this paper, we propose recurrent skipping networks (RSNs), which employ a skipping mechanism to bridge the gaps between entities. RSNs integrate recurrent neural networks (RNNs) with residual learning to efficiently capture the long-term relational dependencies within and between KGs. We design an end-to-end framework to support RSNs on different tasks. Our experimental results showed that RSNs outperformed state-of-the-art embedding-based methods for entity alignment and achieved competitive performance for KG completion.", "keywords": [""], "reference_count": 41, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Michael Kampffmeyer", "Yinbo Chen", "Xiaodan Liang", "Hao Wang", "Yujia Zhang", "Eric P. Xing"], "title": "Rethinking Knowledge Graph Propagation for Zero-Shot Learning", "journal": "CVPR ", "year": 2019, "DOI": "", "month": "", "citations": 13, "abstract": "Graph convolutional neural networks have recently shown great potential for the task of zero-shot learning. These models are highly sample efficient as related concepts in the graph structure share statistical strength allowing generalization to new classes when faced with a lack of data. However, multi-layer architectures, which are required to propagate knowledge to distant nodes in the graph, dilute the knowledge by performing extensive Laplacian smoothing at each layer and thereby consequently decrease performance. In order to still enjoy the benefit brought by the graph structure while preventing dilution of knowledge from distant nodes, we propose a Dense Graph Propagation (DGP) module with carefully designed direct links among distant nodes. DGP allows us to exploit the hierarchical graph structure of the knowledge graph through additional connections. These connections are added based on a node's relationship to its ancestors and descendants. A weighting scheme is further used to weigh their contribution depending on the distance to the node to improve information propagation in the graph. Combined with finetuning of the representations in a two-stage training approach our method outperforms state-of-the-art zero-shot learning approaches.", "keywords": [""], "reference_count": 33, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Xiang Wang", "Xiangnan He", "Yixin Cao", "Meng Liu", "Tat-Seng Chua"], "title": "KGAT: Knowledge Graph Attention Network for Recommendation", "journal": "KDD", "year": 2019, "DOI": " 10.1145/3292500.3330989", "month": "", "citations": 10, "abstract": "To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism.", "keywords": [""], "reference_count": 41, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Hongwei Wang", "Fuzheng Zhang", "Mengdi Zhang", "Jure Leskovec", "Miao Zhao", "Wenjie Li", "Zhongyuan Wang"], "title": "Knowledge Graph Convolutional Networks for Recommender Systems with Label Smoothness Regularization", "journal": "KDD", "year": 2019, "DOI": "", "month": "", "citations": 6, "abstract": "Knowledge graphs capture interlinked information between entities and they represent an attractive source of structured information that can be harnessed for recommender systems. However, existing recommender engines use knowledge graphs by manually designing features, do not allow for end-to-end training, or provide poor scalability. Here we propose Knowledge Graph Convolutional Networks (KGCN), an end-to-end trainable framework that harnesses item relationships captured by the knowledge graph to provide better recommendations. Conceptually, KGCN computes user-specific item embeddings by first applying a trainable function that identifies important knowledge graph relations for a given user and then transforming the knowledge graph into a user-specific weighted graph. Then, KGCN applies a graph convolutional neural network that computes an embedding of an item node by propagating and aggregating knowledge graph neighborhood information. Moreover, to provide better inductive bias KGCN uses label smoothness (LS), which provides regularization over edge weights and we prove that it is equivalent to label propagation scheme on a graph. Finally, We unify KGCN and LS regularization, and present a scalable minibatch implementation for KGCN-LS model. Experiments show that KGCN-LS outperforms strong baselines in four datasets. KGCN-LS also achieves great performance in sparse scenarios and is highly scalable with respect to the knowledge graph size.", "keywords": [""], "reference_count": 37, "ccf_class": "A", "is_important": "", "references": ""}, {"author": ["Rik Koncel-Kedziorski", "Dhanush Bekal", "Yi Luan", "Mirella Lapata", "Hannaneh Hajishirzi"], "title": "Text Generation from Knowledge Graphs with Graph Transformers", "journal": "NAACL", "year": 2019, "DOI": "", "month": "", "citations": 8, "abstract": "Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.", "keywords": [""], "reference_count": 35, "ccf_class": "C", "is_important": "", "references": ""}]