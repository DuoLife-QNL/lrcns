[{"author": ["Scott A.Golder"], "title": "Measuring Social Networks with Digital Photograph Collections", "journal": "ACM Conference on Hypertext and Hypermedia", "year": 2008, "DOI": "10.1145/1379092.1379104", "month": 6, "citations(google scholar)": 37, "abstract": "The ease and lack of cost associated with taking digital photographs have allowed people to amass large personal photograph collections. These collections contain valuable information about their owners' social relationships. This paper is a preliminary investigation into how digital photo collections can provide useful data for the study of social networks. Results from an analysis of 23 subjects\u2019 photo collections demonstrate the feasibility of this approach. The relationship between perceived closeness and network position, as well as future questions, are also discussed.", "keywords": ["Social Networks", "Photographs."], "reference_count": 16, "ccfClass": "", "important": true, "references": [{"ref": "[1] Adamic, Lada A. and Bernardo A. Huberman. (2002). Zipf's Law and the Internet. Glottometrics. 3. 143--150."}, {"ref": "[2] Ames, Morgan. (2006). The Social Life of Snapshots. Thesis. UC Berkeley School of Information Mgt. and Systems."}, {"ref": "[3] Marko Balabanovi\u0107 , Lonny L. Chu , Gregory J. Wolff, Storytelling with digital photographs, Proceedings of the SIGCHI conference on Human Factors in Computing Systems, p.564-571, April 01-06, 2000, The Hague, The Netherlands  [doi>10.1145/332040.332505]"}, {"ref": "[4] Feld, Scott L. (1981). The Focused Organization of Social Ties. American Journal of Sociology. 86(5). 1015--1035."}, {"ref": "[5] Ferligoj, Anuska and Valentina Hlebec. (1999). Evaluation of Social Network Measurement Instruments. Social Networks. 21. 111--130."}, {"ref": "[6] Fu, Yang-chih. (2005). Measuring Personal Networks with Daily Contacts: A Single--Item Survey Question and the Contact Diary. Social Networks. 27. 169--186."}, {"ref": "[7] Scott A. Golder , Bernardo A. Huberman, Usage patterns of collaborative tagging systems, Journal of Information Science, v.32 n.2, p.198-208, April 2006  [doi>10.1177/0165551506062337]"}, {"ref": "[8] Granovetter, Mark S. (1974). Getting a Job: A Study of Contacts and Careers. Cambridge, MA: Harvard U. P."}, {"ref": "[9] Higgins, Christopher A., Ronald J. McClean and David W. Conrath. (1985). The Accuracy and Biases of Diary Communication Data. Social Networks. 7. 173--187."}, {"ref": "[10] Tim Kindberg , Mirjana Spasojevic , Rowanne Fleck , Abigail Sellen, The Ubiquitous Camera: An In-Depth Study of Camera Phone Use, IEEE Pervasive Computing, v.4 n.2, p.42-50, April 2005  [doi>10.1109/MPRV.2005.42]"}, {"ref": "[11] Milgram, Stanley. (1967). The Small World Problem. Psychology Today. Vol. 1, issue 61."}, {"ref": "[12] Kerry Rodden , Kenneth R. Wood, How do people manage their digital photographs?, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 05-10, 2003, Ft. Lauderdale, Florida, USA  [doi>10.1145/642611.642682]"}, {"ref": "[13] Joshua R. Tyler , Dennis M. Wilkinson , Bernardo A. Huberman, Email as spectroscopy: automated discovery of community structure within organizations, Communities and technologies, Kluwer, B.V., Deventer, The Netherlands, 2003"}, {"ref": "[14] Fernanda B. Vi\u00e9gas , Scott Golder , Judith Donath, Visualizing email content: portraying relationships from conversational histories, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 22-27, 2006, Montr\u00e9al, Qu\u00e9bec, Canada  [doi>10.1145/1124772.1124919]"}, {"ref": "[15] Wasserman, Stanley and Katherine Faust. (1994). Social Network Analysis: Methods and Applications. Cambridge."}, {"ref": "[16] Wu, Fang and Bernardo A. Huberman. (2004). \"Finding Communities in Linear Time: A Physics Approach.\" Eur. Phys. J. 38(2). Springer."}]}, {"author": ["Peng Wu", "Weimin Ding", "Zhidong Mao", "Dan Tretter"], "title": "CLOSE & CLOSER: DISCOVER SOCIAL RELATIONSHIP FROM PHOTO COLLECTIONS", "journal": "ICME", "year": 2009, "DOI": "10.1109/ICME.2009.5202837", "month": 6, "citations(google scholar)": 16, "abstract": "\"Close & Closer\" is a social imaging application that performs analysis on photo collections to reveal closeness of people's relationship and presents the discovered relationship in an interactive manner to prompt photo sharing and people connection. It addresses two challenges with innovative solutions: first, a closeness measurement is proposed based on face detection and clustering result; Secondly, a computing framework is designed and implemented to execute computation extensive jobs, such as face detection and clustering, in a both distributed and parallel manner to assure the application's usability. The application is deployed on Facebook social networking platform. The effectiveness of the closeness measurement and computing framework are validated through the real user experience.", "keywords": ["Social relationship", "photo collections", "face detection", "face clustering"], "reference_count": 7, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Facebook platform http://developers.facebook.com/"}, {"ref": "[2] Scott Golder \"Measuring social networks with digital photograph collections \" Proceedings of the nineteenth ACM conference on Hypertext and hypermedia June 2008."}, {"ref": "[3] Liexian Gu Tong Zhang Xiaoqing Ding \"Clustering consumer photos based on face recognition \" Proc. of IEEE International Conference on Multimedia and Expo pp.1998-2001 Beijing July 2007"}, {"ref": "[4] Y. Ma X. Ding \"Real-time rotation invariant face detection based on cost-sensitive AdaBoost\" Proc. of International Conf. on Image Processing vol.3 pp.921-924 Barcelona Spain 2003."}, {"ref": "[5] Quartz http://www.opensymphony.com/quartz/"}, {"ref": "[6] Ryan Rowe German Creamer Shlomo Hershkop Salvatore J Stolfo \"Automated social hierarchy detection through email network analysis \" Proceedings of the 9th WebKDD and 1st SNAKDD 2007 workshop on Web mining and social network analysis August 2007"}, {"ref": "[7] Stone Z.; Zickler T.; Darrell T.; \"Autotagging Facebook: Social network context improves photo annotation \" Computer Vision and Pattern Recognition Workshops June 2008."}]}, {"author": ["Peng Wu", "Dan Tretter"], "title": "Close & Closer: Social Cluster and Closeness from Photo Collections", "journal": "MM", "year": 2009, "DOI": "10.1145/1631272.1631394", "month": 10, "citations(google scholar)": 34, "abstract": "We investigate the discovery of social clusters from consumer photo collections. People's participation in various social activities is the base on which social clusters are formed. The photos that record those social activities can reflect the social structure of people to a certain degree, depending on the extent of coverage of the photos on the social activities. In this paper, we propose a scheme to construct a weighted undirected graph from photo collections by examining the co-appearance of individuals in photos, wherein the weights of edges are measures of the social closeness of the involved individuals (vertices in the graph). We further apply a graph clustering algorithm that maximizes the modularity of the graph partition to detect the embedded social clusters. The experiment results demonstrate that this scheme can reveal the social cluster with high precision rate. In addition, we also introduce a few photo management capabilities enabled by the social graph and discovered social clusters.", "keywords": ["Social relationship", "photo collection", "graph clustering."], "reference_count": 6, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Scott Golder, Measuring social networks with digital photograph collections, Proceedings of the nineteenth ACM conference on Hypertext and hypermedia, June 19-21, 2008, Pittsburgh, PA, USA  [doi>10.1145/1379092.1379104]"}, {"ref": "[2] Gu, Liexian; Zhang, Tong; Ding, Xiaoqing. Clustering consumer photos based on face recognition. Proc. of IEEE International Conference on Multimedia and Expo, pp.1998 -- 2001, Beijing, July 2007"}, {"ref": "[3] Newman, M. E. J. 2006. Finding community structure in networks using the eigenvectors of matrices. Phys. Rev. E 74, 036104."}, {"ref": "[4] Ryan Rowe , German Creamer , Shlomo Hershkop , Salvatore J Stolfo, Automated social hierarchy detection through email network analysis, Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 workshop on Web mining and social network analysis, p.109-117, August 12-12, 2007, San Jose, California  [doi>10.1145/1348549.1348562]"}, {"ref": "[5] Stone, Z.; Zickler, T.; Darrell, T.. Autotagging Facebook: Social network context improves photo annotation,\" Computer Vision and Pattern Recognition Workshops, June 2008."}, {"ref": "[6] Peng Wu , Weimin Ding , Zhidong Mao , Dan Tretter, Close & closer: discover social relationship from photo collections, Proceedings of the 2009 IEEE international conference on Multimedia and Expo, p.1652-1655, June 28-July 03, 2009, New York, NY, USA"}]}, {"author": ["Siyu Xia", "Ming Shao", "Jiebo Luo", "Yun Fu"], "title": "Understanding Kin Relationships in a Photo", "journal": "IEEE MM", "year": 2012, "DOI": "10.1109/TMM.2012.2187436", "month": 8, "citations(google scholar)": 172, "abstract": "There is an urgent need to organize and manage images of people automatically due to the recent explosion of such data on the Web in general and in social media in particular. Beyond face detection and face recognition, which have been extensively studied over the past decade, perhaps the most interesting aspect related to human-centered images is the relationship of people in the image. In this work, we focus on a novel solution to the latter problem, in particular the kin relationships. To this end, we constructed two databases: the first one named UB KinFace Ver2.0, which consists of images of children, their young parents and old parents, and the second one named FamilyFace. Next, we develop a transfer subspace learning based algorithm in order to reduce the significant differences in the appearance distributions between children and old parents facial images. Moreover, by exploring the semantic relevance of the associated metadata, we propose an algorithm to predict the most likely kin relationships embedded in an image. In addition, human subjects are used in a baseline study on both databases. Experimental results have shown that the proposed algorithms can effectively annotate the kin relationships among people in an image and semantic context can further improve the accuracy.", "keywords": ["Context", "face recognition", "kinship verification", "semantics."], "reference_count": 49, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Z. Stone T. Zickler T. Darrell \"Toward large-scale face recognition using social network context\" Proc. IEEE vol. 98 no. 8 pp. 1408-1415 Aug. 2010."}, {"ref": "[2] P. Viola M. Jones \"Robust real-time face detection\" Int. J. Comput. Vis. vol. 57 no. 2 pp. 137-154 2004."}, {"ref": "[3] G. Huang V. Jain E. Learned-Miller \"Unsupervised joint alignment of complex images\" IEEE Int. Conf. Comput. Vis. 2007."}, {"ref": "[4] M. Turk A. Pentland \"Eigenfaces for recognition\" J. Cognitive Neurosci. vol. 3 no. 1 pp. 71-86 1991."}, {"ref": "[5] M. Bartlett J. Movellan T. Sejnowski \"Face recognition by independent component analysis\" IEEE Trans. Neural Netw. vol. 13 no. 6 pp. 1450-1464 Nov. 2002."}, {"ref": "[6] P. Belhumeur J. Hespanha D. Kriegman \"Eigenfaces vs. Fisherfaces: Recognition using class specific linear projection\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 19 no. 7 pp. 711-720 Jul. 2002."}, {"ref": "[7] X. He P. Niyogi \"Locality preserving projections\" in Advances in Neural Information Processing Systems MA Cambridge:MIT Press 2004."}, {"ref": "[8] X. He D. Cai S. Yan H. Zhang \"Neighborhood preserving embedding\" Proc. IEEE Int. Conf. Comput. Vis. pp. 1208-1213 2005."}, {"ref": "[9] S. Yan D. Xu B. Zhang H. Zhang Q. Yang S. Lin \"Graph embedding and extensions: A general framework for dimensionality reduction\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 29 no. 1 pp. 40-51 Jan. 2007."}, {"ref": "[10] T. Zhang D. Tao J. Yang \"Discriminative locality alignment\" Proc. Eur. Conf. Comput. Vis. pp. 725-738 2008."}, {"ref": "[11] Y. Adini Y. Moses S. Ullman \"Face recognition: The problem of compensating for changes in illumination direction\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 19 no. 7 pp. 721-732 Jul. 2002."}, {"ref": "[12] T. Ahonen \"Face description with local binary patterns: Application to face recognition\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 28 no. 12 pp. 2037-2041 Dec. 2006."}, {"ref": "[13] Z. Cao Q. Yin X. Tang J. Sun \"Face recognition with learning-based descriptor\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 2707-2714 2010."}, {"ref": "[14] M. Guillaumin J. Verbeek C. Schmid \"Is that you? Metric learning approaches for face identification\" Proc. IEEE Int. Conf. Comput. Vis. pp. 498-505 2009."}, {"ref": "[15] N. Kumar A. Berg P. Belhumeur S. Nayar \"Attribute and simile classifiers for face verification\" Proc. IEEE Int. Conf. Comput. Vis. pp. 365-372 2009."}, {"ref": "[16] K. Jia S. Gong \"Generalized face super-resolution\" IEEE Trans. Image Process. vol. 17 no. 6 pp. 873-886 Jun. 2008."}, {"ref": "[17] C. Liu H. Shum W. Freeman \"Face hallucination: Theory and practice\" Int. J. Comput. Vis. vol. 75 no. 1 pp. 115-134 2007."}, {"ref": "[18] G. B. Huang M. Ramesh T. Berg E. Learned-Miller Labeled faces in the wild: A database for studying face recognition in unconstrained environments 2007."}, {"ref": "[19] M. Naaman R. Yeh H. Garcia-Molina A. Paepcke \"Leveraging context to resolve identity in photo albums\" Proc. ACM/IEEE-CS Joint Conf. Digital Libraries pp. 178-187 2005."}, {"ref": "[20] A. Gallagher T. Chen \"Understanding images of groups of people\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 256-263 2009."}, {"ref": "[21] G. Wang A. Gallagher J. Luo D. Forsyth \"Seeing people in social context: Recognizing people and social relationships\" Proc. Eur. Conf. Comput. Vis. pp. 169-182 2010."}, {"ref": "[22] J. Yagnik A. Islam \"Learning people annotation from the web via consistency learning\" Proc. Int. Workshop Multimedia Inf. Retrieval pp. 285-290 2007."}, {"ref": "[23] T. L. Berg E. C. Berg J. Edwards M. Maire R. White Y. whye Teh E. Learned-miller D. A. Forsyth \"Names and faces in the news\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 848-854 2004."}, {"ref": "[24] A. Gallagher T. Chen \"Clothing cosegmentation for recognizing people\" IEEE Conf. Comput. Vis. Pattern Recognit. 2008-Jun."}, {"ref": "[25] R. Fang K. Tang N. Snavely T. Chen \"Towards computational models of kinship verification\" Proc. IEEE Int. Conf. Image Process. pp. 1577-1580 2010."}, {"ref": "[26] S. Ng C. Lai M. Tsai R. Fang T. Chen \"Automatic kinship recognition using social contextual information\" Bits on Our Minds 2011."}, {"ref": "[27] S. Xia M. Shao Y. Fu \"Kinship verification through transfer learning\" Proc. Int. Joint Conf. Artificial Intell. pp. 2539-2544 2011."}, {"ref": "[28] M. Shao S. Xia Y. Fu \"Genealogical face recognition based on UB kinface database\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (Workshop Biometrics) pp. 65-70 2011."}, {"ref": "[29] A. Alvergne C. Faurie M. Raymond \"Differential facial resemblance of young children to their parents: Who do children look like more?\" Evol. Human Behavior vol. 28 no. 2 pp. 135-144 2007."}, {"ref": "[30] M. D. Martello L. Maloney \"Where are kin recognition signals in the human face?\" J. Vis. vol. 6 no. 12 pp. 1356-1366 2006."}, {"ref": "[31] L. DeBruine F. Smith B. Jones S. C. Roberts M. Petrie T. Spector \"Kin recognition signals in adult faces\" Vis. Res. vol. 49 no. 1 pp. 38-43 2009."}, {"ref": "[32] S. J. Pan Q. Yang \"A survey on transfer learning\" IEEE Trans. Knowledge Data Eng. vol. 22 no. 10 pp. 1345-1359 Oct. 2010."}, {"ref": "[33] W. Dai Q. Yang G. Xue Y. Yu \"Boosting for transfer learning\" Proc. Int. Conf. Machine Learning pp. 193-200 2007."}, {"ref": "[34] R. Raina A. Battle H. Lee B. Packer A. Ng \"Self-taught learning: Transfer learning from unlabeled data\" Proc. Int. Conf. Mach. Learning pp. 759-766 2007."}, {"ref": "[35] J. Jiang C. Zhai \"Instance weighting for domain adaptation in NLP\" Proc. Annu. MeetingAssoc. Comput. Ling. vol. 45 pp. 264-264 2007."}, {"ref": "[36] A. Evgeniou M. Pontil \"Multi-task feature learning\" in Advances in Neural Information Processing Systems MA Cambridge:MIT Press vol. 19 2007."}, {"ref": "[37] N. Lawrence J. Platt \"Learning to learn with the informative vector machine\" Proc. Int. Conf. Machine Learning pp. 512-519 2004."}, {"ref": "[38] L. Mihalkova T. Huynh R. Mooney \"Mapping and revising Markov logic networks for transfer learning\" Proc. AAAI vol. 22 no. 1 pp. 608-614 2007."}, {"ref": "[39] A. Arnold R. Nallapati W. Cohen \"A comparative study of methods for transductive transfer learning\" Proc. Int. Conf. Data Mining (Workshops) pp. 77-82 2007."}, {"ref": "[40] W. Dai G.-R. Xue Q. Yang Y. Yu \"Transferring naive Bayes classifiers for text classification\" Proc. AAAI pp. 540-545 2007."}, {"ref": "[41] W. Dai G. Xue Q. Yang Y. Yu \"Co-clustering based classification for out-of-domain documents\" Proc. ACM SIGKDD Conf. Knowl. Discovery Data Mining pp. 210-219 2007."}, {"ref": "[42] S. Si D. Tao B. Geng \"Bregman divergence-based regularization for transfer subspace learning\" IEEE Trans. Knowl. Data Eng. vol. 22 no. 7 pp. 929-942 Jul. 2010."}, {"ref": "[43] Y. Su Y. Fu Q. Tian X. Gao \"Cross-database age estimation based on transfer learning\" Proc. IEEE Int. Conf. Acoustics Speech Signal Process. pp. 1270-1273 2010."}, {"ref": "[44] A. Gallagher T. Chen \"Using group prior to identify people in consumer images\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 1-8 2007."}, {"ref": "[45] P. Singla H. Kautz J. Luo A. Gallagher \"Discovery of social relationships in consumer photo collections using Markov logic\" IEEE Conf. Comput. Vis. Pattern Recognit. 2008."}, {"ref": "[46] J. Wong S. Cho \"A face emotion tree structure representation with probabilistic recursive neural network modeling\" Neural Comput. Appl. vol. 19 no. 1 pp. 33-54 2010."}, {"ref": "[47] N. Ramanathan R. Chellappa \"Modeling age progression in young faces\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 387-394 2006."}, {"ref": "[48] T. Chen W. Yin X. Zhou D. Comaniciu T. Huang \"Total variation models for variable lighting face recognition\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 28 no. 9 pp. 1519-1524 Sep. 2006."}, {"ref": "[49] A. Jain S. Li Handbook of Face Recognition New York:Springer 2005."}]}, {"author": ["Yan-Ying Chen", "Winston H. Hsu", "Hong-Yuan Mark Liao"], "title": "Discovering Informative Social Subgraphs and Predicting Pairwise Relationships from Group Photos", "journal": "MM", "year": 2012, "DOI": "10.1145/2393347.2393439", "month": 8, "citations(google scholar)": 39, "abstract": "An increasing number of users are contributing the sheer amount of group photos (e.g., for family, classmates, colleagues, etc.) on social media for the purpose of photo sharing and social communication. There arise strong needs for automatically understanding the group types (e.g., family vs. classmates) for recommendation services (e.g., recommending a family-friendly restaurant) and even predicting the pairwise relationships (e.g., mother-child) between the people in the photo for mining implicit social connections. Interestingly, we observe that the group photos are composed of atomic subgroups corresponding to certain social relationships. For this work, we propose a novel framework to (1) connect faces of different attributes and positions as a face graph and (2) discover informative subgraphs to represent social subgroups in group photos. A group photo can be further represented by a bag-of-face-subgraphs (BoFG) -- the occurring frequency of social subgroups, which is informative to categorize specific group types or events. We demonstrate the effectiveness of BoFG in recognizing family photos and achieve 30.5% relative improvement over the state-of-the-art low-level features. Moreover, we propose to predict the pairwise relationships (e.g., husband-wife) in a face graph by the co-occurrence information (e.g., co-occurring with a child) in the mined subgraphs. The experiments demonstrate that the informative social subgroups significantly outperform prior work (36% relatively) which considers merely facial attributes for determining pairwise relationships.", "keywords": ["Face graph", "face subgraph mining", "social relationship"], "reference_count": 31, "ccfClass": "A", "important": true, "references": [{"ref": "[1] available at http://www.flickr.com/photos/spencerfinnley/5377578656/, http://www.flickr.com/photos/spolyak/1031569673/."}, {"ref": "[2] M. Argyle and J. Dean. Eye-contact, distance and affliation. In Sociometry, 1965."}, {"ref": "[3] Anna Bosch , Andrew Zisserman , Xavier Munoz, Representing shape with a spatial pyramid kernel, Proceedings of the 6th ACM international conference on Image and video retrieval, p.401-408, July 09-11, 2007, Amsterdam, The Netherlands  [doi>10.1145/1282280.1282340]"}, {"ref": "[4] An-Jung Cheng , Yan-Ying Chen , Yen-Ta Huang , Winston H. Hsu , Hong-Yuan Mark Liao, Personalized travel recommendation by mining people attributes from community-contributed photos, Proceedings of the 19th ACM international conference on Multimedia, November 28-December 01, 2011, Scottsdale, Arizona, USA  [doi>10.1145/2072298.2072311]"}, {"ref": "[5] Navneet Dalal , Bill Triggs, Histograms of Oriented Gradients for Human Detection, Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Volume 1, p.886-893, June 20-26, 2005  [doi>10.1109/CVPR.2005.177]"}, {"ref": "[6] Mukund Deshpande , Michihiro Kuramochi , Nikil Wale , George Karypis, Frequent Substructure-Based Approaches for Classifying Chemical Compounds, IEEE Transactions on Knowledge and Data Engineering, v.17 n.8, p.1036-1050, August 2005  [doi>10.1109/TKDE.2005.127]"}, {"ref": "[7] K. A. Frank. Identifying cohesive subgroups. In Social Networks, 1995."}, {"ref": "[8] K. A. Frank and J. Y. Yasumoto. Linking action to social structure within a system: Social capital within and between subgroups. In American Journal of Sociology, 1998."}, {"ref": "[9] A. C. Gallagher and T. Chen. Understanding images of groups of people. In CVPR, 2009."}, {"ref": "[10] E. T. Hall. The hidden dimension. In Culture, 1966."}, {"ref": "[11] P. Isola , Jianxiong Xiao , A. Torralba , A. Oliva, What makes an image memorable?, Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition, p.145-152, June 20-25, 2011  [doi>10.1109/CVPR.2011.5995721]"}, {"ref": "[12] Thorsten Joachims, Text Categorization with Suport Vector Machines: Learning with Many Relevant Features, Proceedings of the 10th European Conference on Machine Learning, p.137-142, April 21-23, 1998"}, {"ref": "[13] T. Kudo et al. An application of boosting to graph classification. In NIPS, 2004."}, {"ref": "[14] N. Kumar et al. Attribute and simile classifiers for face verification. In ICCV, 2009."}, {"ref": "[15] Yu-Heng Lei , Yan-Ying Chen , Bor-Chun Chen , Lime Iida , Winston H. Hsu, Where is who: large-scale photo retrieval by facial attributes and canvas layout, Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, August 12-16, 2012, Portland, Oregon, USA  [doi>10.1145/2348283.2348377]"}, {"ref": "[16] Beibei Li , Anindya Ghose , Panagiotis G. Ipeirotis, Towards a theory model for product search, Proceedings of the 20th international conference on World wide web, March 28-April 01, 2011, Hyderabad, India  [doi>10.1145/1963405.1963453]"}, {"ref": "[17] C. Li et al. Aesthetic quality assessment of consumer photos with faces. In ICIP, 2010."}, {"ref": "[18] B. Liu et al. Integrating classification and association rule mining. In KDD, 1998."}, {"ref": "[19] T. M. Mitchell. In Machine Learning, 1998."}, {"ref": "[20] S. Nowozin and K. Tsuda. Weighted substructure mining for image analysis. In CVPR, 2007."}, {"ref": "[21] P. Singla et al. Discovery of social relationships in consumer photo collections using markov logic. In CVPRW, 2008."}, {"ref": "[22] Josef Sivic , Andrew Zisserman, Video Google: A Text Retrieval Approach to Object Matching in Videos, Proceedings of the Ninth IEEE International Conference on Computer Vision, p.1470, October 13-16, 2003"}, {"ref": "[23] R. Sommer. Further studies of small group ecology. In Sociometry, 1965."}, {"ref": "[24] P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. In CVPR, 2001."}, {"ref": "[25] Gang Wang , Andrew Gallagher , Jiebo Luo , David Forsyth, Seeing people in social context: recognizing people and social relationships, Proceedings of the 11th European conference on Computer vision: Part V, September 05-11, 2010, Heraklion, Crete, Greece"}, {"ref": "[26] Peng Wu , Weimin Ding , Zhidong Mao , Dan Tretter, Close & closer: discover social relationship from photo collections, Proceedings of the 2009 IEEE international conference on Multimedia and Expo, p.1652-1655, June 28-July 03, 2009, New York, NY, USA"}, {"ref": "[27] Xifeng Yan , Jiawei Han, gSpan: Graph-Based Substructure Pattern Mining, Proceedings of the 2002 IEEE International Conference on Data Mining, p.721, December 09-12, 2002"}, {"ref": "[28] Jun Yang , Yu-Gang Jiang , Alexander G. Hauptmann , Chong-Wah Ngo, Evaluating bag-of-visual-words representations in scene classification, Proceedings of the international workshop on Workshop on multimedia information retrieval, September 24-29, 2007, Augsburg, Bavaria, Germany  [doi>10.1145/1290082.1290111]"}, {"ref": "[29] J. Yang et al. Linear spatial pyramid matching using sparse coding for image classification. In CVPR, 2009."}, {"ref": "[30] Yiming Yang , Jan O. Pedersen, A Comparative Study on Feature Selection in Text Categorization, Proceedings of the Fourteenth International Conference on Machine Learning, p.412-420, July 08-12, 1997"}, {"ref": "[31] Tong Zhang , Hui Chao , Chris Willis , Dan Tretter, Consumer image retrieval by estimating relation tree from family photo collections, Proceedings of the ACM International Conference on Image and Video Retrieval, July 05-07, 2010, Xi'an, China  [doi>10.1145/1816041.1816065]"}]}, {"author": ["Afshin Dehghan", "Enrique G. Ortiz", "Ruben Villegas", "Mubarak Shah"], "title": "Who Do I Look Like? Determining Parent-Offspring Resemblance via Gated Autoencoders", "journal": "CVPR", "year": 2014, "DOI": "10.1109/CVPR.2014.227", "month": 9, "citations(google scholar)": 77, "abstract": "Recent years have seen a major push for face recognition technology due to the large expansion of image sharing on social networks. In this paper, we consider the difficult task of determining parent-offspring resemblance using deep learning to answer the question \"Who do I look like?\" Although humans can perform this job at a rate higher than chance, it is not clear how they do it [2]. However, recent studies in anthropology [24] have determined which features tend to be the most discriminative. In this study, we aim to not only create an accurate system for resemblance detection, but bridge the gap between studies in anthropology with computer vision techniques. Further, we aim to answer two key questions: 1) Do offspring resemble their parents? and 2) Do offspring resemble one parent more than the other? We propose an algorithm that fuses the features and metrics discovered via gated autoencoders with a discriminative neural network layer that learns the optimal, or what we call genetic, features to delineate parent-offspring relationships. We further analyze the correlation between our automatically detected features and those found in anthropological studies. Meanwhile, our method outperforms the state-of-the-art in kinship verification by 3-10% depending on the relationship using specific (father-son, mother-daughter, etc.) and generic models.", "keywords": ["None"], "reference_count": 28, "ccfClass": "A", "important": true, "references": [{"ref": "[1] D. Alain and S. Olivier. Gated autoencoders with tied input weights. ICML, 2013. 2, 3"}, {"ref": "[2] A. Alvergne, C. Faurie, and M. Raymond. Differential facial resemblance of young children to their parents: who do children look like more? Evolution and Human Behavior, 2007. 1, 4, 5, 6"}, {"ref": "[3] C. L. Apicella and F. W. Marlowe. Perceived mate fidelity and paternal resemblance predict men\u2019s investment in children. Evolution and Human Behavior, 2004. 2"}, {"ref": "[4] Y. Bengio, A. C. Courville, and P. Vincent. Unsupervised feature learning and deep learning:a review and new perspectives. CoRR, 2012. 2"}, {"ref": "[5] S. Br\u00b4edart and R. M. French. Do babies resemble their fathers more than their mothers? A failure to replicate Christenfeld and Hill (1995). Evolution and Human Behavior, 1999. 1, 4, 5"}, {"ref": "[6] P. Bressan and M. Grassi. Parental resemblance in 1-yearolds and the Gaussian curve. Evolution and Human Behavior, 2004. 1, 4, 5"}, {"ref": "[7] P. Burke. Intrapair facial differences in twins. Acta Geneticae Medicae et Gemellologiae, 1989. 1"}, {"ref": "[8] V. C, K. K, S. R, R. LC, and T. GC. Genetic and environmental influences on facial profile. Australian Dental Journal, 1995. 1"}, {"ref": "[9] N. Christenfeld and E. Hill. Whose baby are you? Nature, 1995. 1"}, {"ref": "[10] J. V. Davis, B. Kulis, P. Jain, S. Sra, and I. S. Dhillon. Information-theoretic metric learning. ICML, 2007. 7, 8"}, {"ref": "[11] R. Fang, A. C. Gallagher, T. Chen, and A. Loui. Kinship Classification by Modeling Facial Feature Heredity. IEEE ICIP, 2013. 2, 4"}, {"ref": "[12] R. Fang, K. D. Tang, N. Snavely, and T. Chen. Towards computational models of kinship verification. In IEEE ICIP, 2010. 2"}, {"ref": "[13] A. Gallagher and T. Chen. Understanding images of groups of people. IEEE CVPR, 2009. 2"}, {"ref": "[14] G. E. Hinton, S. Osindero, and Y. whye Teh. A fast learning algorithm for deep belief nets. Neural Computation, 2006. 2"}, {"ref": "[15] Q. V. Le, R. Monga, M. Devin, G. Corrado, K. Chen, M. Ranzato, J. Dean, and A. Y. Ng. Building high-level features using large scale unsupervised learning. ICML, 2012. 2"}, {"ref": "[16] H. Lee, R. Grosse, R. Ranganath, and A. Y. Ng. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. ICML, 2009. 2"}, {"ref": "[17] H. Lee, R. Raina, A. Teichman, and A. Y. Ng.. Exponential family sparse coding with application to self-taught learning. IJCAI, 2009. 2"}, {"ref": "[18] D. L.M. Facial resemblance enhances trust. Proceedings of the Royal Society of London B, 2002. 2"}, {"ref": "[19] J. Lu, X. Zhou, Y.-P. Tan, Y. Shang, and J. Zhou. Neighborhood Repulsed Metric Learning for Kinship Verification. IEEE TPAMI, 2013. 2, 6, 7, 8"}, {"ref": "[20] N. G. Martin, L. J. Eaves, M. J. Kearsey, and P. Davies. The power of the classical twin study. Heredity, 1978. 1"}, {"ref": "[21] R. Memisevic. On multi-view feature learning. ICML, 2012. 2, 3"}, {"ref": "[22] R. Memisevic. Learning to relate images. IEEE TPAMI, 2013. 2, 3"}, {"ref": "[23] M. Naaman, R. Yeh, H. Garcia-Molina, and A. Paepcke. Leveraging context to resolve identity in photo albums. ACM/IEEE-CS JCDL, 2005. 2"}, {"ref": "[24] F. B. Naini and J. P. Moss. Three-dimensional assessment of the relative contribution of genetics and environment to various facial parameters with the twin method. American Journal of Orthodontics and Dentofacial Orthopedics, 2004. 1, 2, 6, 7"}, {"ref": "[25] S. M. Platek. An evolutionary model of the effects of human paternal resemblance on paternal investment. Evolution and Cognition, 2003. 2"}, {"ref": "[26] P. Vincent, H. Larochelle, Y. Bengio, and P. A. Manzagol. Extracting and composing robust features with denoising autoencoders. ICML, 2008. 2"}, {"ref": "[27] G. Wang, A. Gallagher, J. Luo, and D. Forsyth. Seeing people in social context: Recognizing people and social relationships. ECCV, 2010. 2"}, {"ref": "[28] S. Xia, M. Shao, J. Luo, and Y. Fu. Understanding Kin Relationships in a Photo. IEEE TMM, 2012. 2"}]}, {"author": ["Yuanhao Guo\uff0c Hamdi Dibeklio\u02d8glu\uff0c Laurens van der Maaten"], "title": "Graph-based Kinship Recognition", "journal": "ICPR", "year": 2014, "DOI": "10.1109/ICPR.2014.735", "month": 8, "citations(google scholar)": 49, "abstract": "Image-based kinship recognition is an important problem in the reconstruction and analysis of social networks. Prior studies on image-based kinship recognition have focused solely on pair wise kinship verification, i.e. on the question of whether or not two people are kin. Such approaches fail to exploit the fact that many real-world photographs contain several family members, for instance, the probability of two people being brothers increases when both people are recognized to have the same father. In this work, we propose a graph-based approach that incorporates facial similarities between all family members in a photograph in order to improve the performance of kinship recognition. In addition, we introduce a database of group photographs with kinship annotations.", "keywords": ["None"], "reference_count": 15, "ccfClass": "C", "important": true, "references": [{"ref": "[1] L. T. Maloney and M. F. Dal Martello \"Kin recognition and the perceived facial similarity of children \" Journal of Vision vol. 6 no. 10 2006."}, {"ref": "[2] R. Fang K. D. Tang N. Snavely and T. Chen \"Towards computational models of kinship verification \" in IEEE International Conference on Image Processing 2010 pp. 1577-1580."}, {"ref": "[3] M. F. Dal Martello and L. T. Maloney \"Where are kin recognition signals in the human face?\" Journal of Vision vol. 6 no. 12 2006."}, {"ref": "[4] S. Xia M. Shao and Y. Fu \"Kinship verification through transfer learning \" in International Joint Conference on Artificial Intelligence vol. 3 2011 pp. 2539-2544."}, {"ref": "[5] J. Lu X. Zhou Y.-P. Tan Y. Shang and J. Zhou \"Neighborhood repulsed metric learning for kinship verification \" IEEE Trans. on PAMI vol. 36 no. 2 pp. 331-345 2014."}, {"ref": "[6] H. Dibeklio?glu A. A. Salah and T. Gevers \"Like father like son: Facial expression dynamics for kinship verification \" in International Conference on Computer Vision 2013 pp. 1497-1504."}, {"ref": "[7] P. F. Felzenszwalb and D. P. Huttenlocher \"Pictorial structures for object recognition \" International Journal of Computer Vision vol. 61 no. 1 pp. 55-79 2005."}, {"ref": "[8] S. Xia M. Shao J. Luo and Y. Fu \"Understanding kin relationships in a photo \" IEEE Trans. on Multimedia vol. 14 no. 4 pp. 1046-1056 2012."}, {"ref": "[9] Y.-Y. Chen W. H. Hsu and H.-Y. M. Liao \"Discovering informative social subgraphs and predicting pairwise relationships from group photos \" in ACM International Conference on Multimedia 2012 pp. 669-678."}, {"ref": "[10] X. Xiong and F. De la Torre \"Supervised descent method and its applications to face alignment \" in IEEE Conference on Computer Vision and Pattern Recognition 2013 pp. 532-539."}, {"ref": "[11] T. Ojala M. Pietikainen and T. Maenpaa \"Multiresolution gray-scale and rotation invariant texture classification with local binary patterns \" IEEE Trans. on PAMI vol. 24 no. 7 pp. 971-987 2002."}, {"ref": "[12] G. Guo G. Mu Y. Fu and T. S. Huang \"Human age estimation using bio-inspired features \" in IEEE Conference on Computer Vision and Pattern Recognition 2009 pp. 112-119."}, {"ref": "[13] H. Dibeklio?glu A. A. Salah and T. Gevers \"Are you really smiling at me? Spontaneous versus posed enjoyment smiles \" in European Conference on Computer Vision 2012 pp. 525-538."}, {"ref": "[14] G. Guo C. R. Dyer Y. Fu and T. S. Huang \"Is gender recognition affected by age?\" in International Conference on Computer Vision Workshops 2009 pp. 2032-2039."}, {"ref": "[15] G. Guo and X. Wang \"A study on human age estimation under facial expression changes \" in IEEE Conference on Computer Vision and Pattern Recognition 2012 pp. 2547-2553."}]}, {"author": ["Xiaoqian Qin", "Xiaoyang Tan", "and Songcan Chen"], "title": "Tri-Subject Kinship Verification: Understanding the Core of A Family", "journal": "IEEE MM", "year": 2015, "DOI": "10.1109/TMM.2015.2461462", "month": 7, "citations(google scholar)": 65, "abstract": "One major challenge in computer vision is to go beyond the modeling of individual objects and to investigate the bi- (one-versus-one) or tri- (one-versus-two) relationship among multiple visual entities, answering such questions as whether a child in a photo belongs to the given parents. The child-parents relationship plays a core role in a family, and understanding such kin relationship would have a fundamental impact on the behavior of an artificial intelligent agent working in the human world. In this work, we tackle the problem of one-versus-two (tri-subject) kinship verification and our contributions are threefold: 1) a novel relative symmetric bilinear model (RSBM) is introduced to model the similarity between the child and the parents, by incorporating the prior knowledge that a child may resemble one particular parent more than the other; 2) a spatially voted method for feature selection, which jointly selects the most discriminative features for the child-parents pair, while taking local spatial information into account; and 3) a large-scale tri-subject kinship database characterized by over 1,000 child-parents families. Extensive experiments on KinFaceW, Family101, and our newly released kinship database show that the proposed method outperforms several previous state of the art methods, while could also be used to significantly boost the performance of one-versus-one kinship verification when the information about both parents are available.", "keywords": ["Feature selection", "kinship verification", "tri-subject relationship."], "reference_count": 43, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Y.-G. Jiang J. Wang X. Xue S.-F. Chang \"Query-adaptive image search with hash codes\" IEEE Trans. Multimedia vol. 15 no. 2 pp. 442-453 Feb. 2013."}, {"ref": "[2] X. Benavent A. Garcia-Serrano R. Granados J. Benavent E. de Ves \"Multimedia information retrieval based on late semantic fusion approaches: Experiments on a Wikipedia image collection\" IEEE Trans. Multimedia vol. 15 no. 8 pp. 2009-2021 Dec. 2013."}, {"ref": "[3] E. Spyromitros-Xioufis S. Papadopoulos I. Kompatsiaris G. Tsoumakas I. Vlahavas \"A comprehensive study over VLAD and product quantization in large-scale image retrieval\" IEEE Trans. Multimedia vol. 16 no. 6 pp. 1713-1728 Oct. 2014."}, {"ref": "[4] Z. Ma Y. Yang N. Sebe K. Zheng A. G. Hauptmann \"Multimedia event detection using a classifier-specific intermediate representation\" IEEE Trans. Multimedia vol. 15 no. 7 pp. 1628-1637 Nov. 2013."}, {"ref": "[5] O. Zoidi A. Tefas N. Nikolaidis I. Pitas \"Person identity label propagation in stereo videos\" IEEE Trans. Multimedia vol. 16 no. 5 pp. 1358-1368 Aug. 2014."}, {"ref": "[6] G. Wang A. Gallagher J. Luo D. Forsyth \"Seeing people in social context: Recognizing people and social relationships\" Proc. Eur. Conf. Comput. Vis. pp. 169-182 2010."}, {"ref": "[7] M. Shao S. Xia Y. Fu \"Identity and kinship relations in group pictures\" in Human-Centered Social Media Analytics USA NY New York:Springer pp. 175-190 2014."}, {"ref": "[8] X. Zhou J. Lu J. Hu Y. Shang \"Gabor-based gradient orientation pyramid for kinship verification under uncontrolled environments\" Proc. 20th ACM Int. Conf. Multimedia pp. 725-728 2012."}, {"ref": "[9] Z. Xu Y. Zhang L. Cao \"Social image analysis from a non-IID perspective\" IEEE Trans. Multimedia vol. 16 no. 7 pp. 1986-1998 Nov. 2014."}, {"ref": "[10] G. Guo X. Wang \"Kinship measurement on salient facial features\" IEEE Trans. Instrum. Meas. vol. 61 no. 8 pp. 2322-2325 Aug. 2012."}, {"ref": "[11] Y. Sun X. Wang X. Tang \"Deep learning face representation by joint identification-verification\" CoRR vol. abs/1406.4773 2014."}, {"ref": "[12] R. Fang K. D. Tang N. Snavely T. Chen \"Towards computational models of kinship verification\" 2010 IEEE Int. Conf. Image Process. pp. 1577-1580 2010-Sep."}, {"ref": "[13] S. Xia M. Shao Y. Fu \"Kinship verification through transfer learning\" Proc. 22nd Int. Joint Conf. Artificial Intell. vol. 3 pp. 2539-2544 2011."}, {"ref": "[14] S. Xia M. Shao Y. Fu \"Toward kinship verification using visual attributes\" Proc. IEEE Int. Conf. Pattern Recog. pp. 549-552 2012-Nov."}, {"ref": "[15] J. Lu X. Zhou Y.-P. Tan Y. Shang J. Zhou \"Neighborhood repulsed metric learning for kinship verification\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 36 no. 2 pp. 331-345 Feb. 2014."}, {"ref": "[16] H. Dibeklioglu A. A. Salah T. Gevers \"Like father like son: Facial expression dynamics for kinship verification\" Proc. IEEE Int. Conf. Comput. Vis. pp. 1497-1504 2013-Dec."}, {"ref": "[17] H. Yan J. Lu W. Deng X. Zhou \"Discriminative multi-metric learning for kinship verification\" IEEE Trans. Inf. Forensics Security vol. 9 no. 7 pp. 1169-1178 Jul. 2014."}, {"ref": "[18] M. Ghahramani W.-Y. Yau E. K. Teoh \"Family verification based on similarity of individual family members facial segments\" Mach. Vis. Appl. vol. 25 no. 4 pp. 919-930 2014."}, {"ref": "[19] R. Fang A. C. Gallagher T. Chen A. Loui \"Kinship classification by modeling facial feature heredity\" Proc. IEEE Int. Conf. Image Process. pp. 2983-2987 2013-Sep."}, {"ref": "[20] A. Alvergne C. Faurie M. Raymond \"Differential facial resemblance of young children to their parents: Who do children look like more?\" Evolution Human Behavior vol. 28 no. 2 pp. 135-144 2007."}, {"ref": "[21] Q. Xiaoqian T. Xiaoyang C. Songcan \"Tri-subjects kinship verification: Understanding the core of a family\" Proc. Int. Conf. Mach. Vis. Appl.."}, {"ref": "[22] M. F. Dal Martello L. T. Maloney \"Where are kin recognition signals in the human face?\" J. Vis. vol. 6 no. 12 pp. 2 2006."}, {"ref": "[23] L. M. DeBruine \"Kin recognition signals in adult faces\" Vis. Res. vol. 49 no. 1 pp. 38-43 2009."}, {"ref": "[24] X. Zhou J. Hu J. Lu Y. Shang Y. Guan \"Kinship verification from facial images under uncontrolled conditions\" Proc. 19th ACM Int. Conf. Multimedia pp. 953-956 2011."}, {"ref": "[25] A. Dehghan E. G. Ortiz R. Villegas M. Shah \"Who do I look like? determining parent-offspring resemblance via gated autoencoders\" Proc. IEEE Conf. Comput. Vis. Pattern Recog. pp. 1757-1764 2014-Jun."}, {"ref": "[26] N. Kohli R. Singh M. Vatsa \"Self-similarity representation of Weber faces for kinship classification\" Proc. IEEE 5th Int. Conf. Biometrics: Theory Appl. Syst. pp. 245-250 2012-Sep."}, {"ref": "[27] H. Yan J. Lu X. Zhou \"Prototype-based discriminative feature learning for kinship verification\" IEEE Trans. Cybern.."}, {"ref": "[28] J. Hu J. Lu J. Yuan Y.-P. Tan \"Large margin multimetric learning for face and kinship verification in the wild\" Proc. ACCV pp. 252-267 2014."}, {"ref": "[29] M. Shao D. Kit Y. Fu \"Generalized transfer subspace learning through low-rank constraint\" Int. J. Comput. Vis. vol. 109 no. 1\u20132 pp. 74-93 2014."}, {"ref": "[30] S. Xia M. Shao J. Luo Y. Fu \"Understanding kin relationships in a photo\" IEEE Trans. Multimedia vol. 14 no. 4 pp. 1046-1056 Aug. 2012."}, {"ref": "[31] N. Syed B. K. P. P. Q. Shareq \"Understanding familial relationship in an image\" Int. J. Sci. Res. Educ. vol. 2 no. 06 pp. 1037-1045 2014."}, {"ref": "[32] S. Ji J. Ye \"An accelerated gradient method for trace norm minimization\" Proc. 26th Annual Int. Conf. Mach. Learn. pp. 457-464 2009."}, {"ref": "[33] L. Meier S. Van De Geer P. B\u00fchlmann \"The group lasso for logistic regression\" J. Royal Statist. Soc.: Ser. B (Statist. Methodology) vol. 70 no. 1 pp. 53-71 2008."}, {"ref": "[34] M. Shao S. Xia Y. Fu \"Genealogical face recognition based on UB KinFace database\" Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recog. Workshops pp. 60-65 2011-Jun."}, {"ref": "[35] X. Tan F. Song Z.-H. Zhou S. Chen \"Enhanced pictorial structures for precise eye localization under uncontrolled conditions\" Proc. IEEE Conf. Comput. Vis. Pattern Recog. pp. 1621-1628 2009-Jun."}, {"ref": "[36] J. V. Davis B. Kulis P. Jain S. Sra I. S. Dhillon \"Information-theoretic metric learning\" Proc. 24th Int. Conf. Mach. Learn. pp. 209-216 2007."}, {"ref": "[37] K. Weinberger J. Blitzer L. Saul \"Distance metric learning for large margin nearest neighbor classification\" Adv. Neural Inf. Process. Syst. vol. 18 pp. 18-1473 2006."}, {"ref": "[38] J. Hu J. Lu Y.-P. Tan \"Discriminative deep metric learning for face verification in the wild\" Proc. IEEE Conf. Comput. Vis. Pattern Recog. pp. 1875-1882 2014-Jun."}, {"ref": "[39] S. M. Platek \"Reactions to children\u2019s faces: Males are more affected by resemblance than females are and so are their brains\" Evolution Human Behavior vol. 25 no. 6 pp. 394-405 2004."}, {"ref": "[40] B. W. Domingue J. Fletcher D. Conley J. D. Boardman \"Genetic and educational assortative mating among us adults\" Proc. Nat. Academy Sci. vol. 111 no. 22 pp. 7996-8000 2014."}, {"ref": "[41] J. Lu \"The FG 2015 kinship verification in the wild evaluation\" Proc. IEEE Int. Conf. Automat. Face Gesture Recog. pp. 1-7 2015-May."}, {"ref": "[42] D. Wang X. Tan \"Centering SVDD for unsupervised feature representation in object classification\" in Neural Information Processing USA NY New York:Springer pp. 376-383 2013."}, {"ref": "[43] L. Wolf \"Descriptor based methods in the wild\" Proc. Workshop Faces \"Real-Life\" Images: Detection Alignment Recog. pp. 4-12 2008."}]}, {"author": ["Qieyun Dai", "Peter Carr", "Leonid Sigal", "Derek Hoiem"], "title": "Family Member Identification from Photo Collections", "journal": "WACV", "year": 2015, "DOI": "10.1109/WACV.2015.136", "month": 1, "citations(google scholar)": 10, "abstract": "Family photo collections often contain richer semantics than arbitrary images of people because families contain a handful of specific individuals who can be associated with certain social roles (e.g. father, mother, or child). As a result, family photo collections have unique challenges and opportunities for face recognition compared to random groups of photos containing people. We address the problem of unsupervised family member discovery: given a collection of family photos, we infer the size of the family, as well as the visual appearance and social role of each family member. As a result, we are able to recognize the same individual across many different photos. We propose an unsupervised EM-style joint inference algorithm with a probabilistic CRF that models identity and role assignments for all detected faces, along with associated pairwise relationships between them. Our experiments illustrate how joint inference of both identity and role (across all photos simultaneously) outperforms independent estimates of each. Joint inference also improves the ability to recognize the same individual across many different photos.", "keywords": ["None"], "reference_count": 23, "ccfClass": "", "important": true, "references": [{"ref": "[1] T. Berg A. Berg J. Edwards M. Maire R. White Y. Teh E. Learned-Miller D. Forsyth \"Names and faces in the news\" CVPR 2004."}, {"ref": "[2] C.-C. Chang C.-J. Lin \"LIBSVM: A library for support vector machines\" ACM Transactions on Intelligent Systems and Technology 2011."}, {"ref": "[3] L. Ding A. Yilmaz \"Inferring social relations from visual concepts\" ICCV 2011."}, {"ref": "[4] B. J. Frey D. Dueck \"Clustering by passing messages between data points\" Science 2007."}, {"ref": "[5] A. Gallagher T. Chen \"Clothing cosegmentation for recognizing people\" CVPR 2008."}, {"ref": "[6] G. B. Huang V. Jain E. Learned-Miller \"Unsupervised joint alignment of complex images\" ICCV 2007."}, {"ref": "[7] G. B. Huang M. Ramesh E. L.-M. T. Berg \"Labeled faces in the wild: A database for studying face recognition in unconstrained environments\" Technical report University of Massachusetts Amherst 2007."}, {"ref": "[8] G. Kim E. P. Xing \"Jointly aligning and segmenting multiple web photo streams for the inference of collective photo storylines\" CVPR 2013."}, {"ref": "[9] V. Kolmogorov \"Convergent tree-reweighted message passing for energy minimization\" PAMI October 2006."}, {"ref": "[10] C. K\u00fcblbeck T. Ruf A. Ernst \"A modular framework to detect and analyze faces for audience measurement systems\" GI Jahrestagung 2009."}, {"ref": "[11] Y. Lee K. Grauman \"Face discovery with social context\" BMVC 2012."}, {"ref": "[12] H. Li G. Hua Z. Lin J. Brandt J. Yang \"Probabilistic elastic matching for pose variant face verification\" CVPR 2013."}, {"ref": "[13] D. Lin A. Kapoor G. Hua S. Baker \"Joint people event and localization recognition in personal photo collections using cross-domain context\" ECCV 2010."}, {"ref": "[14] T. Malisiewicz A. Gupta A. A. Efros \"Ensemble of exemplar-svms for object detection and beyond\" ICCV 2011."}, {"ref": "[15] C. D. Manning P. Raghavan H. Schtze Introduction to Information Retrieval chapter Flat clustering Cambridge University Press 2008."}, {"ref": "[16] A. Murilloy I. S. Kwakz L. Bourdevx D. Kriegmanz S. Belongie \"Urban tribes: Analyzing group photos from a social perspective\" CVPR 2012."}, {"ref": "[17] P. Obrador R. Oliveria N. Oliver \"Supporting personal photo storytelling for social albums\" ACM Multimedia 2010."}, {"ref": "[18] V. Ramanathan B. Yao L. Fei-Fei \"Social role discovery in human events\" CVPR 2013."}, {"ref": "[19] G. Wang A. Gallagher D. F. J. Luo \"Seeing people in social context: Recognizing people and social relationships\" ECCV 2010."}, {"ref": "[20] L. Wolf T. Hassner Y. Taigman \"Descriptor based methods in the wild\" Post ECCV workshop on Faces in Real-Life Images: Detection Alignment and Recognition 2008."}, {"ref": "[21] S. Xia M. Shao J. Luo Y. Fu \"Understanding kin relationships in a photo\" IEEE Transactions on Multimedia 2012."}, {"ref": "[22] J. Yang J. Luo J. Yu T. Huang \"Photo stream alignment and summarization for collaborative photo collection and sharing\" IEEE Transactions on Multimedia 2012."}, {"ref": "[23] C.-H. Yeh Y.-C. Ho B. A. Barsky M. Ouhyoung \"Personalized photograph ranking and selection system\" ACM Multimedia 2010."}]}, {"author": ["Joseph P. Robinson", "Ming Shao", "Yue Wu", "Hongfu Liu", "Timothy Gillis", "Yun Fu"], "title": "Visual Kinship Recognition of Families in the Wild", "journal": "IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE", "year": 2018, "DOI": "10.1109/TPAMI.2018.2826549", "month": 11, "citations(google scholar)": 15, "abstract": "We present the largest database for visual kinship recognition, Families In the Wild (FIW), with over 13,000 family photos of 1,000 family trees with 4-to-38 members. It took only a small team to build FIW with efficient labeling tools and work-flow. To extend FIW, we further improved upon this process with a novel semi-automatic labeling scheme that used annotated faces and unlabeled text metadata to discover labels, which were then used, along with existing FIW data, for the proposed clustering algorithm that generated label proposals for all newly added data-both processes are shared and compared in depth, showing great savings in time and human input required. Essentially, the clustering algorithm proposed is semi-supervised and uses labeled data to produce more accurate clusters. We statistically compare FIW to related datasets, which unarguably shows enormous gains in overall size and amount of information encapsulated in the labels. We benchmark two tasks, kinship verification and family classification, at scales incomparably larger than ever before. Pre-trained CNN models fine-tuned on FIW outscores other conventional methods and achieved state-of-the art on the renowned KinWild datasets. We also measure human performance on kinship recognition and compare to a fine-tuned CNN.", "keywords": ["Large-scale image dataset", "kinship verification", "family classification", "semi-supervised clustering", "deep learning"], "reference_count": 72, "ccfClass": "A", "important": true, "references": [{"ref": "[1] R. Fang K. D. Tang N. Snavely T. Chen \"Towards computational models of kinship verification\" Proc. 17th IEEE Int. Conf. Image Process. pp. 1577-1580 2010."}, {"ref": "[2] X. Chen L. An S. Yang W. Wu \"Kinship verification in multi-linear coherent spaces\" Multimedia Tools Appl. vol. 76 pp. 4105-4122 2015."}, {"ref": "[3] Y. Chen H. Hu S. Cao B. Ma \"Sparse coding based kinship recognition\" Proc. 4th Int. Conf. Multimedia Technol. 2015."}, {"ref": "[4] A. Dehghan E. Ortiz R. Villegas M. Shah \"Who do I look like? determining parent-offspring resemblance via gated autoencoders\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 1757-1764 2014."}, {"ref": "[5] X. Duan Z.-H. Tan \"A feature subtraction method for image based kinship verification under uncontrolled environments\" Proc. Int. Conf. Image Process. pp. 1573-1577 2015."}, {"ref": "[6] X. Duan Z. H. Tan \"Neighbors based discriminative feature difference learning for kinship verification\" Proc. Int. Symp. Visual Comput. pp. 258-267 2015."}, {"ref": "[7] R. Fang A. Gallagher T. Chen A. Loui \"Kinship classification by modeling facial feature heredity\" Proc. Int. Conf. Image Process. pp. 2983-2987 2013."}, {"ref": "[8] Y. Guo H. Dibeklioglu L. van der Maaten \"Graph-based kinship recognition\" Proc. 22nd Int. Conf. Pattern Recognit. pp. 4287-4292 2014."}, {"ref": "[9] J. Hu J. Lu J. Yuan Y.-P. Tan \"Large margin multi-metric learning for face and kinship verification in the wild\" Proc. Asian Conf. Comput. Vis. pp. 252-267 2014."}, {"ref": "[10] L. Kou X. Zhou M. Xu Y. Shang \"Learning a genetic measure for kinship verification using facial images\" Math. Problems Eng. vol. 2015 2015."}, {"ref": "[11] Q. Liu A. Puthenputhussery C. Liu \"Inheritable Fisher vector feature for kinship verification\" Proc. IEEE 7th Int. Conf. Biometrics Theory Appl. Syst. pp. 1-6 2015."}, {"ref": "[12] X. Qin X. Tan S. Chen \"Tri-subject kinship verification: Understanding the core of a family\" IEEE Trans. Multimedia vol. 17 no. 10 pp. 1855-1867 2015."}, {"ref": "[13] T. F. Vieira A. Bottino I. U. Islam \"Automatic verification of parent-child pairs from face images\" Proc. Progress Pattern Recognit. Image Anal. Comput. Vis. Appl. pp. 326-333 2013."}, {"ref": "[14] T. F. Vieira A. Bottino A. Laurentini M. De Simone \"Detecting siblings in image pairs\" The Visual Comput. vol. 30 no. 12 pp. 1333-1345 2014."}, {"ref": "[15] X. Wang C. Kambhamettu \"Leveraging appearance and geometry for kinship verification\" Proc. IEEE Int. Conf. Image Process. pp. 5017-5021 2014."}, {"ref": "[16] S. Xia M. Shao Y. Fu \"Kinship verification through transfer learning\" Proc. 22nd Int. Joint Conf. Artif. Intell. pp. 2539-2544 2011."}, {"ref": "[17] M. Xu Y. Shang \"Kinship verification using facial images by robust similarity learning\" Math. Problems Eng. vol. 2016 2016."}, {"ref": "[18] H. Yan J. Lu W. Deng X. Zhou \"Discriminative multimetric learning for kinship verification\" IEEE Trans. Inf. Forensics Security vol. 9 no. 7 pp. 1169-1178 Jul. 2014."}, {"ref": "[19] H. Yan J. Lu X. Zhou \"Prototype-based discriminative feature learning for kinship verification\" IEEE Trans. Cybern. vol. 45 no. 11 pp. 2535-2545 Nov. 2015."}, {"ref": "[20] L. Zhang K. Ma H. Nejati L. Foo T. Sim D. Guo \"A talking profile to distinguish identical twins\" Image Vis. Comput. vol. 32 no. 10 pp. 771-778 2014."}, {"ref": "[21] X. Zhou J. Hu J. Lu Y. Shang Y. Guan \"Kinship verification from facial images under uncontrolled conditions\" Proc. 19th ACM Int. Conf. Multimedia pp. 953-956 2011."}, {"ref": "[22] X. Zhou Y. Shang H. Yan G. Guo \"Ensemble similarity learning for kinship verification from facial images in the wild\" Inf. Fusion vol. 32 pp. 40-48 2016."}, {"ref": "[23] Y. Wu Z. Ding H. Liu J. Robinson Y. Fu \"Kinship classification through latent adaptive subspace\" Proc. 13th IEEE Int. Conf. Autom. Face Gesture Recognit. pp. 143-149 2018."}, {"ref": "[24] M. Shao S. Xia Y. Fu \"Identity and kinship relations in group pictures\" in Human-Centered Social Media Analytics Berlin Germany:Springer pp. 175-190 2014."}, {"ref": "[25] J. Zhang S. Xia M. Shao Y. Fu \"Family photo recognition via multiple instance learning\" Proc. ACM Int. Conf. Multimedia Retrieval pp. 424-428 2017."}, {"ref": "[26] S. Xia M. Shao Y. Fu \"Toward kinship verification using visual attributes\" Proc. 21st Int. Conf. Pattern Recognit. pp. 549-552 2012."}, {"ref": "[27] J. P. Robinson M. Shao Y. Wu Y. Fu \"Families in the wild (FIW): Large-scale kinship image database and benchmarks\" Proc. ACM Multimedia Conf. pp. 242-246 2016 [online] Available: http://doi.acm.org/10.1145/2964284.2967219."}, {"ref": "[28] S. Xia M. Shao J. Luo Y. Fu \"Understanding kin relationships in a photo\" IEEE Trans. Multimedia vol. 14 no. 4 pp. 1046-1056 Aug. 2012."}, {"ref": "[29] S. X. M. Shao Y. Fu \"Genealogical face recognition based on UB kinface database\" Proc. IEEE CVPR Workshop Biometrics pp. 60-65 2011."}, {"ref": "[30] J. Lu X. Zhou Y.-P. Tan Y. Shang J. Zhou \"Neighborhood repulsed metric learning for kinship verification\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 36 no. 2 pp. 331-345 Feb. 2014."}, {"ref": "[31] J. Lu J. Hu V. E. Liong X. Zhou A. Bottino I. Ul Islam T. Figueiredo Vieira X. Qin X. Tan S. Chen et al. \"The FG 2015 kinship verification in the wild evaluation\" Proc. 11th IEEE Int. Conf. Workshops Autom. Face Gesture Recognit. pp. 1-7 2015."}, {"ref": "[32] J. Lu J. Hu X. Zhou J. Zhou M. Castrill\u00f3n-Santana J. Lorenzo-Navarro L. Kou Y. Shang A. Bottino T. Figuieiredo Vieira \"Kinship verification in the wild: The first kinship verification competition\" Proc. IEEE Int. Joint Conf. Biometrics pp. 1-6 2014."}, {"ref": "[33] A. Krizhevsky I. Sutskever G. E. Hinton \"Imagenet classification with deep convolutional neural networks\" Proc. Int. Conf. Neural Inf. Process. Syst. pp. 1097-1105 2012."}, {"ref": "[34] O. Russakovsky J. Deng H. Su J. Krause S. Satheesh S. Ma Z. Huang A. Karpathy A. Khosla M. Bernstein et al. \"Imagenet large scale visual recognition challenge\" Int. J. Comput. Vis. vol. 115 no. 3 pp. 211-252 2015."}, {"ref": "[35] L. Wolf \"DeepFace: Closing the gap to human-level performance in face verification\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 1701-1708 2014."}, {"ref": "[36] O. M. Parkhi A. Vedaldi A. Zisserman \"Deep face recognition\" Proc. Brit. Mach. Vis. Conf. vol. 1 no. 3 pp. 6 2015."}, {"ref": "[37] F. Schroff D. Kalenichenko J. Philbin \"FaceNet: A unified embedding for face recognition and clustering\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 815-823 2015."}, {"ref": "[38] K. Zhang Y. Huang C. Song H. Wu L. Wang \"Kinship verification with deep convolutional neural networks\" Proc. Brit. Mach. Vis. Conf. pp. 148.1-148.12 Sep. 2015."}, {"ref": "[39] A. Dehghan E. G. Ortiz R. Villegas M. Shah \"Who do I look like? determining parent-offspring resemblance via gated autoencoders\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 1757-1764 2014."}, {"ref": "[40] C. Xiong L. Liu X. Zhao S. Yan T.-K. Kim \"Convolutional fusion network for face verification in the wild\" IEEE Trans. Circuits and Syst. Video Technol. vol. 26 no. 3 pp. 517-528 2016."}, {"ref": "[41] S. Wang J. P. Robinson Y. Fu \"Kinship verification on families in the wild with marginalized denoising metric learning\" Proc. 12th IEEE Int. Conf. Workshops Autom. Face Gesture Recognit. pp. 216-221 2017."}, {"ref": "[42] X. Wu E. Boutellaa X. Feng A. Hadid \"Kinship verification from faces: Methods databases and challenges\" Proc. IEEE Int. Conf. Signal Process. Commun. Comput. pp. 1-6 2016."}, {"ref": "[43] H. Liu Y. Fu \"Clustering with partition level side information\" Proc. Int. Conf. Data Mining pp. 877-882 2015."}, {"ref": "[44] C. W. Leong R. Mihalcea S. Hassan \"Text mining for automatic image tagging\" Proc. 23rd Int. Conf. Comput. Linguistics: Posters pp. 647-655 2010."}, {"ref": "[45] E. Law B. Settles T. Mitchell \"Learning to tag using noisy labels\" Proc. Eur. Conf. Mach. Learn. pp. 1-29 2010."}, {"ref": "[46] D. Wang S. C. Hoi Y. He J. Zhu \"Mining weakly labeled web facial images for search-based face annotation\" IEEE Trans. Knowl. Data Eng. vol. 26 no. 1 pp. 166-179 Jan. 2014."}, {"ref": "[47] D. Yi Z. Lei S. Liao S. Z. Li \"Learning face representation from scratch\" 2014."}, {"ref": "[48] G. B. Huang M. Ramesh T. Berg E. Learned-Miller \"Labeled faces in the wild: A database for studying face recognition in unconstrained environments\" Oct. 2007."}, {"ref": "[49] D. E. King \"Dlib-ml: A machine learning toolkit\" J. Mach. Learn. Res. vol. 10 pp. 1755-1758 2009."}, {"ref": "[50] V. Kazemi J. Sullivan \"One millisecond face alignment with an ensemble of regression trees\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 1867-1874 2014."}, {"ref": "[51] A. Bottino M. De Simone A. Laurentini T. F. Vieira \"A new problem in face image analysis: Finding kinship clues for siblings pairs\" ICPRAM vol. 2 pp. 405-410 2012."}, {"ref": "[52] J. R. Finkel T. Grenager C. Manning \"Incorporating non-local information into information extraction systems by gibbs sampling\" Proc. 43rd Annu. Meeting Assoc. Comput. Linguistics pp. 363-370 2005."}, {"ref": "[53] H. Liu Z. Tao Y. Fu \"Partition level constrained clustering\" IEEE Trans. Pattern Anal. Mach. Intell. 2017."}, {"ref": "[54] B. Mirkin \"Reinterpreting the category utility function\" Mach. Learn. vol. 45 pp. 219-228 2001."}, {"ref": "[55] J. Wu H. Liu H. Xiong J. Cao J. Chen \"K-means-based consensus clustering: A unified view\" IEEE Trans. Knowl. Data Eng. vol. 27 no. 1 pp. 155-169 Jan. 2015."}, {"ref": "[56] T. Ahonen A. Hadid M. Pietikainen \"Face description with local binary patterns: Application to face recognition\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 28 no. 12 pp. 2037-2041 Dec. 2006."}, {"ref": "[57] N. Dalal B. Triggs \"Histograms of oriented gradients for human detection\" Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. pp. 886-893 Jun. 2005."}, {"ref": "[58] Y. Wen K. Zhang Z. Li Y. Qiao \"A discriminative feature learning approach for deep face recognition\" Proc. Eur. Conf. Comput. Vis. pp. 499-515 2016."}, {"ref": "[59] J. V. Davis B. Kulis P. Jain S. Sra I. S. Dhillon \"Information-theoretic metric learning\" Proc. 24th Int. Conf. Mach. Learn. pp. 209-216 2007."}, {"ref": "[60] X. Niyogi \"Locality preserving projections\" Proc. Int. Conf. Neural Inf. Process. Syst. 2004."}, {"ref": "[61] K. Q. Weinberger L. K. Saul \"Distance metric learning for large margin nearest neighbor classification\" J. Mach. Learn. Res. vol. 10 no. Feb pp. 207-244 2009."}, {"ref": "[62] Y. Peng S. Wang B.-L. Lu \"Marginalized denoising autoencoder via graph regularization for domain adaptation\" Proc. Int. Conf. Neural Inf. Process. pp. 156-163 2013."}, {"ref": "[63] Z. Ding S. Suh J.-J. Han C. Choi Y. Fu \"Discriminative low-rank metric learning for face recognition\" Proc. 11th IEEE Int. Conf. Workshops Autom. Face Gesture Recognit. pp. 1-6 2015."}, {"ref": "[64] J. P. Robinson M. Shao H. Zhao Y. Wu T. Gillis Y. Fu \"Recognizing families in the wild (RFIW)\" Proc. Workshop Recognizing Families Wild pp. 5-12 2017."}, {"ref": "[65] W. Liu Y. Wen Z. Yu M. Li B. Raj L. Song \"Sphereface: Deep hypersphere embedding for face recognition\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 6738-6746 2017."}, {"ref": "[66] D. G. Lowe \"Distinctive image features from scale-invariant keypoints\" Int. J. Comput. Vis. vol. 60 pp. 91-110 2004."}, {"ref": "[67] L. Wolf T. Hassner I. Maoz \"Face recognition in unconstrained videos with matched background similarity\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp. 529-534 2011."}, {"ref": "[68] G. B. Huang M. Ramesh T. Berg E. Learned-Miller \"Labeled faces in the wild: A database for studying face recognition in unconstrained environments\" 2007."}, {"ref": "[69] J. P. Robinson Y. Fu \"Pre-trained D-CNN models for detecting complex events in unconstrained videos\" Proc. SPIE Commercial+ Sci. Sens. Imaging pp. 98&nbsp;710O-98&nbsp;710O 2016."}, {"ref": "[70] D. Pelleg D. Baras \"K-means with large and noisy constraint sets\" Proc. Eur. Conf. Mach. Learn. pp. 674-682 2007."}, {"ref": "[71] M. F. Dal Martello L. T. Maloney \"Where are kin recognition signals in the human face?\" J. Vis. vol. 6 no. 12 pp. 1356-1366 2006."}, {"ref": "[72] L. Best-Rowden S. Bisht J. C. Klontz A. K. Jain \"Unconstrained face recognition: Establishing baseline human performance via crowdsourcing\" Proc. IEEE Int. Joint Conf. Biometrics pp. 1-8 2014."}]}, {"author": ["Xiuzhuang Zhou", "Kai Jin", "Min Xu", "Guodong Guo"], "title": "Learning deep compact similarity metric for kinship verification from face images", "journal": "Information Fusion", "year": 2019, "DOI": "10.1016/j.inffus.2018.07.011", "month": 8, "citations(google scholar)": 7, "abstract": "Recent advances in kinship verification have shown that learning an appropriate kinship similarity metric on human faces plays a critical role in this problem. However, most of existing distance metric learning (DML) based solutions rely on linearity assumption of the kinship metric model, and the domain knowledge of large cross-generation discrepancy (e.g., large age span and gender difference between parent and child images) has not been considered in metric learning, leading to degraded performance for genetic similarity measure on human faces. To address these limitations, we propose in this work a new kinship metric learning (KML) method with a coupled deep neural network (DNN) model. KML explicitly models the cross-generation discrepancy inherent on parent-child pairs, and learns a coupled deep similarity metric such that the image pairs with kinship relation are pulled close, while those without kinship relation (but with high appearance similarity) are pushed as far away as possible. Moreover, by imposing the intra-connection diversity and inter-connection consistency over the coupled DNN, we introduce the property of hierarchical compactness into the coupled network to facilitate deep metric learning with limited amount of kinship training data. Empirically, we evaluate our algorithm on several kinship benchmarks against the state-of-the-art DML alternatives, and the results demonstrate the superiority of our method.", "keywords": ["Face recognition", "Kinship verification", "Metric learning", "Deep neural network", "Hierarchical compactness"], "reference_count": 66, "ccfClass": "", "important": true, "references": [{"ref": "[1] A. Alvergne, R. Oda, C. Faurie, A. Matsumoto-Oda, V. Durand, M. Raymond Cross-cultural perceptions of facial resemblance between kin J. Vis., 9 (6) (2009)"}, {"ref": "[2] G. Kaminski, S. Dridi, C. Graff, E. Gentaz Human ability to detect kinship in strangers\u2019 faces: effects of the degree of relatedness Proc. R. Soc. Lond. B, 276 (1670) (2009), pp. 3193-3200"}, {"ref": "[3] M.F. Dal Martello, L.T. Maloney Lateralization of kin recognition signals in the human face J. Vis., 10 (8) (2010)"}, {"ref": "[4] R. Fang, K.D. Tang, N. Snavely, T. Chen Towards computational models of kinship verification 2010 IEEE International Conference on Image Processing, IEEE (2010), pp. 1577-1580"}, {"ref": "[5] S. Xia, M. Shao, Y. Fu Kinship verification through transfer learning IJCAI Proceedings-International Joint Conference on Artificial Intelligence, vol. 22 (2011), p. 2539"}, {"ref": "[6] X. Zhou, J. Hu, J. Lu, Y. Shang, Y. Guan Kinship verification from facial images under uncontrolled conditions Proceedings of the 19th ACM International Conference on Multimedia, ACM (2011), pp. 953-956"}, {"ref": "[7] J. Lu, X. Zhou, Y.-P. Tan, Y. Shang, J. Zhou Neighborhood repulsed metric learning for kinship verification Pattern Anal. Mach. Intell. IEEE Trans., 36 (2) (2014), pp. 331-345"}, {"ref": "[8] R.G. Cinbis, J. Verbeek, C. Schmid Unsupervised metric learning for face identification in TV video 2011 International Conference on Computer Vision, IEEE (2011), pp. 1559-1566"}, {"ref": "[9] M. Guillaumin, J. Verbeek, C. Schmid Is that you? Metric learning approaches for face identification 2009 IEEE 12th International Conference on Computer Vision, IEEE (2009), pp. 498-505"}, {"ref": "[10] M. K\u00f6stinger, M. Hirzer, P. Wohlhart, P.M. Roth, H. Bischof Large scale metric learning from equivalence constraints Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, IEEE (2012), pp. 2288-2295"}, {"ref": "[11] Y. Taigman, M. Yang, M. Ranzato, L. Wolf Deepface: closing the gap to human-level performance in face verification Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2014), pp. 1701-1708"}, {"ref": "[12] A. Mignon, F. Jurie Pcca: a new approach for distance learning from sparse pairwise constraints Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, IEEE (2012), pp. 2666-2672"}, {"ref": "[13] H.V. Nguyen, L. Bai Cosine similarity metric learning for face verification Asian Conference on Computer Vision, Springer (2010), pp. 709-720"}, {"ref": "[14] Z. Cui, W. Li, D. Xu, S. Shan, X. Chen Fusing robust face region descriptors via multiple metric learning for face recognition in the wild Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2013), pp. 3554-3561"}, {"ref": "[15] O.M. Parkhi, A. Vedaldi, A. Zisserman Deep face recognition British Machine Vision Conference (2015)"}, {"ref": "[16] W. Deng, J. Hu, J. Lu, J. Guo Transform-invariant PCA: a unified approach to fully automatic face alignment, representation, and recognition IEEE Trans. Pattern Anal. Mach. Intell., 36 (6) (2014), pp. 1275-1284"}, {"ref": "[17] X. Cai, C. Wang, B. Xiao, X. Chen, J. Zhou Deep nonlinear metric learning with independent subspace analysis for face verification Proceedings of the 20th ACM international conference on Multimedia, ACM (2012), pp. 749-752"}, {"ref": "[18] J. Lu, Y.-P. Tan, G. Wang Discriminative multimanifold analysis for face recognition from a single training sample per person IEEE Trans. Pattern Anal. Mach. Intell., 35 (1) (2013), pp. 39-51"}, {"ref": "[19] J. Lu, V.E. Liong, X. Zhou, J. Zhou Learning compact binary face descriptor for face recognition IEEE Trans. Pattern Anal. Mach. Intell., 37 (10) (2015), pp. 2041-2056"}, {"ref": "[20] J. Hu, J. Lu, Y.-P. Tan Discriminative deep metric learning for face verification in the wild Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2014), pp. 1875-1882"}, {"ref": "[21] J. Hu, J. Lu, Y.-P. Tan Deep transfer metric learning Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2015), pp. 325-333"}, {"ref": "[22] X. Zhou, K. Jin, Q. Chen, M. Xu, Y. Shang Multiple face tracking and recognition with identity-specific localized metric learning Pattern Recognit., 75 (2018), pp. 41-50 ArticleDownload PDF"}, {"ref": "[23] E.P. Xing, A.Y. Ng, M.I. Jordan, S. Russell Distance metric learning with application to clustering with side-information Advances in Neural Information Processing Systems, vol. 15, MIT; 1998 (2003), pp. 505-512"}, {"ref": "[24] J. Goldberger, G.E. Hinton, S.T. Roweis, R. Salakhutdinov Neighbourhood components analysis Advances in Neural Information Processing Systems (2004), pp. 513-520"}, {"ref": "[25] K.Q. Weinberger, J. Blitzer, L.K. Saul Distance metric learning for large margin nearest neighbor classification Advances in Neural Information Processing Systems (2005), pp. 1473-1480"}, {"ref": "[26] J.V. Davis, B. Kulis, P. Jain, S. Sra, I.S. Dhillon Information-theoretic metric learning Proceedings of the 24th International Conference On Machine Learning, ACM (2007), pp. 209-216"}, {"ref": "[27] J. Hu, J. Lu, Y.P. Tan, J. Yuan, J. Zhou Local large-margin multi-metric learning for face and kinship verification IEEE Trans. Circuits Syst. Video Technol. (2017)"}, {"ref": "[28] H. Yan, J. Lu, W. Deng, X. Zhou Discriminative multimetric learning for kinship verification IEEE Trans. Inf. Forensics Secur., 9 (7) (2014), pp. 1169-1178"}, {"ref": "[29] Y. LeCun, B. Boser, J.S. Denker, D. Henderson, R.E. Howard, W. Hubbard, L.D. Jackel Backpropagation applied to handwritten zip code recognition Neural Comput., 1 (4) (1989), pp. 541-551"}, {"ref": "[30] G. Guo, X. Wang Kinship measurement on salient facial features IEEE Trans. Instrum. Meas., 61 (8) (2012), pp. 2322-2325"}, {"ref": "[31] X. Zhou, J. Lu, J. Hu, Y. Shang Gabor-based gradient orientation pyramid for kinship verification under uncontrolled environments Proceedings of the 20th ACM International Conference on Multimedia, ACM (2012), pp. 725-728"}, {"ref": "[32] A. Dehghan, E.G. Ortiz, R. Villegas, M. Shah Who do i look like? determining parent-offspring resemblance via gated autoencoders Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2014), pp. 1757-1764"}, {"ref": "[33] H. Yan, J. Lu, X. Zhou Prototype-based discriminative feature learning for kinship verification IEEE Trans. Cybern., 45 (11) (2015), pp. 2535-2545"}, {"ref": "[34] N. Kohli, M. Vatsa, R. Singh, A. Noore, A. Majumdar Hierarchical representation learning for kinship verification IEEE Trans. Image Process., 26 (1) (2017), pp. 289-302"}, {"ref": "[35] S. Xia, M. Shao, J. Luo, Y. Fu Understanding kin relationships in a photo IEEE Trans. Multimedia, 14 (4) (2012), pp. 1046-1056"}, {"ref": "[36] S. Mahpod, Y. Keller Kinship verification using multiview hybrid distance learning Comput. Vision Image Understanding, 167 (2018), pp. 28-36 ArticleDownload PDF"}, {"ref": "[37] J. Lu, J. Hu, Y.-P. Tan Discriminative deep metric learning for face and kinship verification IEEE Trans. Image Process., 26 (9) (2017), pp. 4269-4282"}, {"ref": "[38] S. Wang, J.P. Robinson, Y. Fu Kinship verification on families in the wild with marginalized denoising metric learning Automatic Face & Gesture Recognition (FG 2017), 2017 12th IEEE International Conference on, IEEE (2017), pp. 216-221"}, {"ref": "[39] G.B. Huang, M. Ramesh, T. Berg, E. Learned-Miller Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments Technical Report, Technical Report 07\u201349, University of Massachusetts, Amherst (2007)"}, {"ref": "[40] K. Zhang, Y. Huang, C. Song, H. Wu, L. Wang Kinship verification with deep convolutional neural networks Proceedings of the British Machine Vision Conference (BMVC) (2015), pp. 148.1-148.12"}, {"ref": "[41] H. Dibeklioglu, A. Ali Salah, T. Gevers Like father, like son: facial expression dynamics for kinship verification Proceedings of the IEEE International Conference on Computer Vision (2013), pp. 1497-1504"}, {"ref": "[42] N. Kohli, R. Singh, M. Vatsa Self-similarity representation of weber faces for kinship classification Biometrics: Theory, Applications and Systems (BTAS), 2012 IEEE Fifth International Conference on, IEEE (2012), pp. 245-250"}, {"ref": "[43] X. Qin, X. Tan, S. Chen Tri-subject kinship verification: understanding the core of a family IEEE Trans. Multimedia, 17 (10) (2015), pp. 1855-1867"}, {"ref": "[44] X. Zhou, Y. Shang, H. Yan, G. Guo Ensemble similarity learning for kinship verification from facial images in the wild Inf. Fusion, 32 (2016), pp. 40-48 ArticleDownload PDF"}, {"ref": "[45] J. Lu, J. Hu, V.E. Liong, X. Zhou, A. Bottino, I.U. Islam, T.F. Vieira, X. Qin, X. Tan, S. Chen, S. Mahpod, Y. Keller, L. Zheng, K. Idrissi, C. Garcia, S. Duffner, A. Baskurt, M.Castrilln-Santana, J. Lorenzo-Navarro The fg 2015 kinship verification in the wild evaluation Automatic Face and Gesture Recognition (FG), 2015 11th IEEE International Conference and Workshops on, 1 (2015)"}, {"ref": "[46] A. Krizhevsky, I. Sutskever, G.E. Hinton Imagenet classification with deep convolutional neural networks Advances in Neural Information Processing Systems (2012), pp. 1097-1105"}, {"ref": "[47] K. He, X. Zhang, S. Ren, J. Sun Deep residual learning for image recognition Proceedings of the IEEE conference on computer vision and pattern recognition (2016), pp. 770-778"}, {"ref": "[48] Y. Sun, Y. Chen, X. Wang, X. Tang Deep learning face representation by joint identification-verification Advances in Neural Information Processing Systems (2014), pp. 1988-1996"}, {"ref": "[49] S. Ji, W. Xu, M. Yang, K. Yu 3D convolutional neural networks for human action recognition IEEE Trans. Pattern Anal. Mach. Intell., 35 (1) (2013), pp. 221-231"}, {"ref": "[50] G.E. Hinton, S. Osindero, Y.-W. Teh A fast learning algorihm for deep belief nets Neural Comput., 18 (7) (2006), pp. 1527-1554"}, {"ref": "[51] Q.V. Le, W.Y. Zou, S.Y. Yeung, A.Y. Ng Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, IEEE (2011), pp. 3361-3368"}, {"ref": "[52] J. Wang, F. Zhou, S. Wen, X. Liu, Y. Lin Deep metric learning with angular loss Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2017), pp. 2593-2601"}, {"ref": "[53] C. Zhu, L. Cao, Q. Liu, J. Yin, V. Kumar Heterogeneous metric learning of categorical data with hierarchical couplings IEEE Trans. Knowl. Data Eng. (2018)"}, {"ref": "[54] P. Xie Learning compact and effective distance metrics with diversity regularization Joint European Conference on Machine Learning and Knowledge Discovery in Databases, Springer (2015), pp. 610-624"}, {"ref": "[55] A. Mignon, F. Jurie CMML: a new metric learning approach for cross modal matching Asian Conference on Computer Vision, South Korea (2012), p. 14pages"}, {"ref": "[56] B. Geng, D. Tao, C. Xu Daml: domain adaptation metric learning IEEE Trans. Image Process., 20 (10) (2011), pp. 2980-2989"}, {"ref": "[57] Y.C. Chen, W.S. Zheng, J.H. Lai, P. Yuen An asymmetric distance model for cross-view feature mapping in person re-identification IEEE Trans. Circuits Syst. Video Technol., PP (99) (2016)"}, {"ref": "[58] V.E. Liong, J. Lu, Y.P. Tan, J. Zhou Deep coupled metric learning for cross-modal matching IEEE Trans. Multimedia, PP (99) (2016) 1\u20131. doi:10.1109/TMM.2016.2646180."}, {"ref": "[59] H. Liu, J. Cheng, F. Wang Kinship verification based on status-aware projection learning Image Processing (ICIP), 2017 IEEE International Conference on, IEEE (2017), pp. 1072-1076"}, {"ref": "[60] J. Wang, Y. Song, T. Leung, C. Rosenberg, J. Wang, J. Philbin, B. Chen, Y. Wu Learning fine-grained image similarity with deep ranking Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2014), pp. 1386-1393"}, {"ref": "[61] S. Si, D. Tao, B. Geng Bregman divergence-based regularization for transfer subspace learning IEEE Trans. Knowl. Data Eng., 22 (7) (2010), pp. 929-942"}, {"ref": "[62] J.T. Kwok, R.P. Adams Priors for diversity in generative latent variable models F. Pereira, C.J.C. Burges, L. Bottou, K.Q. Weinberger (Eds.), Advances in Neural Information Processing Systems 25 (2012), pp. 2996-3004"}, {"ref": "[63] T. Ahonen, A. Hadid, M. Pietikainen Face description with local binary patterns: application to face recognition IEEE Trans. Pattern Anal. Mach. Intell., 28 (12) (2006), pp. 2037-2041"}, {"ref": "[64] N. Dalal, B. Triggs Histograms of oriented gradients for human detection 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\u201905), vol. 1, IEEE (2005), pp. 886-893"}, {"ref": "[65] D.G. Lowe Distinctive image features from scale-invariant keypoints Int. J. Comput. Vis., 60 (2) (2004), pp. 91-110"}, {"ref": "[66] J.P. Robinson, M. Shao, H. Zhao, Y. Wu, T. Gillis, Y. Fu Rfiw: large-scale kinship recognition challenge Proceedings of the 2017 ACM on Multimedia Conference, ACM (2017), pp. 1971-1973"}]}, {"author": ["Haibin Yan", "Shiwei Wang"], "title": "Learning part-aware attention networks for kinship verification", "journal": "Pattern Recognition Letters", "year": 2019, "DOI": "10.1016/j.patrec.2019.08.023", "month": 12, "citations(google scholar)": 0, "abstract": "In this paper, we present a method for facial kinship verification, which uses an attention network to focus on extracting information of local facial parts. Unlike most existing approaches which use low-level features for verification, we introduce an attention mechanism in the deep network to extract high-level features for face representation. We also propose a self-supervised approach to directing the attention network. Specifically, we randomly include a mask to five facial feature parts of each face to help the network focus on extracting more discriminative information at these locations. Experimental results on the KinFaceW-I and KinFaceW-II datasets are presented to show the effectiveness of our proposed approach.", "keywords": ["Kinship verification", "Deep neural networks", "Biometrics"], "reference_count": 29, "ccfClass": "C", "important": true, "references": [{"ref": "[1] X. Cai, C. Wang, B. Xiao, X. Chen, J. Zhou Deep nonlinear metric learning with independent subspace analysis for face verification Proceedings of the Twentieth ACM International Conference on Multimedia, ACM (2012), pp. 749-752"}, {"ref": "[2] X. Cao, D. Wipf, F. Wen, G. Duan, J. Sun A practical transfer learning algorithm for face verification Proceedings of the IEEE International Conference on Computer Vision (2013), pp. 3208-3215"}, {"ref": "[3] N.V. Chawla, K.W. Bowyer Actively exploring creation of face space (s) for improved face recognition Proceedings of the National Conference on Artificial Intelligence, 22, AAAI Press; MIT Press; 1999, Menlo Park, CA; Cambridge, MA; London (2007), p. 809"}, {"ref": "[4] A. Dehghan, E.G. Ortiz, R. Villegas, M. Shah Who do I look like? Determining parent-offspring resemblance via gated autoencoders Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2014), pp. 1757-1764"}, {"ref": "[5] R. Fang, K.D. Tang, N. Snavely, T. Chen Towards computational models of kinship verification Proceedings of the Seventeenth IEEE International Conference on Image Processing (ICIP), IEEE (2010), pp. 1577-1580"}, {"ref": "[6] G. Guo, X. Wang Kinship measurement on salient facial features IEEE Trans. Instrum. Meas., 61 (8) (2012), pp. 2322-2325"}, {"ref": "[7] S. Hochreiter, J. Schmidhuber Long short-term memory Neural Comput., 9 (8) (1997), pp. 1735-1780"}, {"ref": "[8] A. Holub, Y.-h. Liu, P. Perona On constructing facial similarity maps Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE (2007), pp. 1-8"}, {"ref": "[9] J. Hu, J. Lu, J. Yuan, Y.-P. Tan Large margin multi-metric learning for face and kinship verification in the wild Proceedings of the Asian Conference on Computer Vision, Springer (2014), pp. 252-267"}, {"ref": "[10] G.B. Huang, H. Lee, E. Learned-Miller Learning hierarchical representations for face verification with convolutional deep belief networks Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE (2012), pp. 2518-2525"}, {"ref": "[11] N. Kohli, R. Singh, M. Vatsa Self-similarity representation of weber faces for kinship classification Proceedings of the IEEE Fifth International Conference on Biometrics: Theory, Applications and Systems (BTAS), IEEE (2012), pp. 245-250"}, {"ref": "[12] H. Larochelle, G.E. Hinton Learning to combine foveal glimpses with a third-order Boltzmann machine Proceedings of the Advances in Neural Information Processing Systems (2010), pp. 1243-1251"}, {"ref": "[13] J. Lu, J. Hu, Y.-P. Tan Discriminative deep metric learning for face and kinship verification IEEE Trans. Image Process., 26 (9) (2017), pp. 4269-4282"}, {"ref": "[14] J. Lu, J. Hu, J. Zhou Deep metric learning for visual understanding: an overview of recent advances IEEE Signal Process. Mag., 34 (6) (2017), pp. 76-84"}, {"ref": "[15] J. Lu, V.E. Liong, J. Zhou Cost-sensitive local binary feature learning for facial age estimation IEEE Trans. Image Process., 24 (12) (2015), pp. 5356-5368"}, {"ref": "[16] J. Lu, V.E. Liong, J. Zhou Learning compact binary face descriptor for face recognition IEEE Trans. Pattern Anal. Mach. Intell., 37 (10) (2015), pp. 2041-2056"}, {"ref": "[17] J. Lu, V.E. Liong, J. Zhou Deep hashing for scalable image search IEEE Trans. Image Process., 26 (5) (2017), pp. 2352-2367"}, {"ref": "[18] J. Lu, V.E. Liong, J. Zhou Simultaneous local binary feature learning and encoding for homogeneous and heterogeneous face recognition IEEE Trans. Pattern Anal. Mach. Intell., 40 (8) (2018), pp. 1979-1993"}, {"ref": "[19] J. Lu, X. Zhou, Y.-P. Tan, Y. Shang, J. Zhou Neighborhood repulsed metric learning for kinship verification IEEE Trans. Pattern Anal. Mach. Intell., 36 (2) (2014), pp. 331-345"}, {"ref": "[20] G. Somanath, C. Kambhamettu Can faces verify blood-relations? Proceedings of the IEEE Fifth International Conference on Biometrics: Theory, Applications and Systems (BTAS), IEEE (2012), pp. 105-112"}, {"ref": "[21] Y. Sun, X. Wang, X. Tang Deep learning face representation from predicting 10,000 classes Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2014), pp. 1891-1898"}, {"ref": "[22] F. Wang, M. Jiang, C. Qian, S. Yang, C. Li, H. Zhang, X. Wang, X. Tang Residual attention network for image classification Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2017), pp. 3156-3164"}, {"ref": "[23] S. Xia, M. Shao, J. Luo, Y. Fu Understanding kin relationships in a photo IEEE Trans Multimed., 14 (4) (2012), pp. 1046-1056"}, {"ref": "[24] H. Yan, J. Hu Video-based kinship verification using distance metric learning Pattern Recognit., 75 (3) (2018), pp. 15-24 ArticleDownload PDF"}, {"ref": "[25] H. Yan, J. Lu, W. Deng, X. Zhou Discriminative multimetric learning for kinship verification IEEE Trans. Inf. Forensics Secur., 9 (7) (2014), pp. 1169-1178"}, {"ref": "[26] H. Yan, J. Lu, X. Zhou Prototype-based discriminative feature learning for kinship verification IEEE Trans. Cybern., 45 (11) (2014), pp. 2535-2545"}, {"ref": "[27] K. Zhang, Y. Huang, C. Song, H. Wu, L. Wang S.M. Intelligence, Kinship veri-fication with deep convolutional neural networks British Machine Vision Conference (2015), pp. 1-12"}, {"ref": "[28] X. Zhou, J. Hu, J. Lu, Y. Shang, Y. Guan Kinship verification from facial images under uncontrolled conditions Proceedings of the Ninteenth ACM International Conference on Multimedia, ACM (2011), pp. 953-956"}, {"ref": "[29] X. Zhou, J. Lu, J. Hu, Y. Shang Gabor-based gradient orientation pyramid for kinship verification under uncontrolled environments Proceedings of the Twentieth ACM International Conference on Multimedia, ACM (2012), pp. 725-728."}]}, {"author": ["Zhanpeng Zhang", "Ping Luo", "Chen Change Loy", "Xiaoou Tang"], "title": "Learning Social Relation Traits from Face Images", "journal": "ICCV", "year": 2015, "DOI": "10.1109/ICCV.2015.414", "month": 2, "citations(google scholar)": 54, "abstract": "Social relation defines the association, e.g., warm, friendliness, and dominance, between two or more people. Motivated by psychological studies, we investigate if such fine grained and high-level relation traits can be characterised and quantified from face images in the wild. To address this challenging problem we propose a deep model that learns a rich face representation to capture gender, expression, head pose, and age-related attributes, and then performs pairwise-face reasoning for relation prediction. To learn from heterogeneous attribute sources, we formulate a new network architecture with a bridging layer to leverage the inherent correspondences among these datasets. It can also cope with missing target attribute labels. Extensive experiments show that our approach is effective for fine-grained social relation learning in images and videos.", "keywords": ["None"], "reference_count": 43, "ccfClass": "A", "important": true, "references": [{"ref": "[1] A. Ahmed, K. Yu, W. Xu, Y. Gong, and E. Xing. Training hierarchical feed-forward visual recognition models using transfer learning from pseudo-tasks. In ECCV, pages 69\u201382. Springer, 2008."}, {"ref": "[2] J. Bromley, I. Guyon, Y. Lecun, E. S\u00a8ackinger, and R. Shah. Signature verification using a siamese time delay neural network. In NIPS, 1994."}, {"ref": "[3] Y.-Y. Chen, W. H. Hsu, and H.-Y. M. Liao. Discovering informative social subgraphs and predicting pairwise relationships from group photos. In ACM MM, pages 669\u2013678, 2012."}, {"ref": "[4] M. Cristani, R. Raghavendra, A. Del Bue, and V. Murino. Human behavior analysis in video surveillance: A social signal processing perspective. Neurocomputing, 100:86\u201397, 2013."}, {"ref": "[5] L. Ding and A. Yilmaz. Learning relations among movie characters: A social network perspective. In ECCV, 2010."}, {"ref": "[6] L. Ding and A. Yilmaz. Inferring social relations from visual concepts. In ICCV, pages 699\u2013706, 2011."}, {"ref": "[7] N. Fairclough. Analysing discourse: Textual analysis for social research. Psychology Press, 2003."}, {"ref": "[8] A. Fathi, J. K. Hodgins, and J. M. Rehg. Social interactions: A firstperson perspective. In CVPR, 2012."}, {"ref": "[9] J. M. Girard. Perceptions of interpersonal behavior are influenced by gender, facial expression intensity, and head pose. In Proceedings of the 16th International Conference on Multimodal Interaction, pages 394\u2013398, 2014."}, {"ref": "[10] I. Goodfellow, D. Erhan, P.-L. Carrier, A. Courville, Mirza, et al. Challenges in representation learning: A report on three machine learning contests, 2013."}, {"ref": "[11] J. Gottman, R. Levenson, and E. Woodin. Facial expressions during marital conflict. Journal of Family Communication, 1(1):37\u201357, 2001."}, {"ref": "[12] A. K. Gupta and D. K. Nagar. Matrix variate distributions. CRC Press, 1999."}, {"ref": "[13] U. Hess, S. Blairy, and R. E. Kleck. The influence of facial emotion displays, gender, and ethnicity on judgments of dominance and affiliation. Journal of Nonverbal Behavior, 24(4):265\u2013283, 2000."}, {"ref": "[14] M. Hoai and A. Zisserman. Talking heads: detecting humans and recognizing their interactions. In CVPR, 2014."}, {"ref": "[15] H. Hung, D. Jayagopi, C. Yeo, G. Friedland, S. Ba, J.-M. Odobez, K. Ramchandran, N. Mirghafori, and D. Gatica-Perez. Using audio and video features to classify the most dominant person in a group meeting. In ACM MM, 2007."}, {"ref": "[16] J. Joo, W. Li, F. Steen, and S.-C. Zhu. Visual persuasion: Inferring communicative intents of images. In CVPR, pages 216\u2013223, 2014."}, {"ref": "[17] D. J. Kiesler. The 1982 interpersonal circle: A taxonomy for complementarity in human transactions. Psychological Review, 90(3):185, 1983."}, {"ref": "[18] B. Knutson. Facial expressions of emotion influence interpersonal trait inferences. Journal of Nonverbal Behavior, 20(3):165\u2013182, 1996."}, {"ref": "[19] Y. Kong, Y. Jia, and Y. Fu. Learning human interaction by interactive phrases. In ECCV, pages 300\u2013313. 2012."}, {"ref": "[20] M. Kostinger, P.Wohlhart, P. Roth, and H. Bischof. Annotated facial landmarks in the wild: A large-scale, real-world database for facial landmark localization. In ICCV Workshops, pages 2144\u20132151, 2011."}, {"ref": "[21] A. Krizhevsky, I. Sutskever, and G. E. Hinton. ImageNet classification with deep convolutional neural networks. In NIPS, 2012."}, {"ref": "[22] T. Lan, L. Sigal, and G. Mori. Social roles in hierarchical models for human activity recognition. In CVPR, 2012."}, {"ref": "[23] P. Liu, S. Han, Z. Meng, and Y. Tong. Facial expression recognition via a boosted deep belief network. In CVPR, pages 1805\u20131812, 2014."}, {"ref": "[24] Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face attributes in the wild. In ICCV, 2015."}, {"ref": "[25] P. Luo, X. Wang, and X. Tang. Hierarchical face parsing via deep learning. In CVPR, 2012."}, {"ref": "[26] P. Luo, X. Wang, and X. Tang. A deep sum-product architecture for robust facial attributes analysis. In ICCV, 2013."}, {"ref": "[27] J. Moody, S. Hanson, A. Krogh, and J. A. Hertz. A simple weight decay can improve generalization. Advances in neural information processing systems, 4:950\u2013957, 1995."}, {"ref": "[28] M. A. Nicolaou, V. Pavlovic, and M. Pantic. Dynamic probabilistic CCA for analysis of affective behaviour. In ECCV, pages 98\u2013111, 2012."}, {"ref": "[29] M. Pantic, R. Cowie, F. D\u2019Errico, D. Heylen, M. Mehu, C. Pelachaud, I. Poggi, M. Schroeder, and A. Vinciarelli. Social signal processing: the research agenda. In Visual analysis of humans, pages 511\u2013538. Springer, 2011."}, {"ref": "[30] A. Pentland. Social signal processing. IEEE Signal Processing Magazine, 24(4):108, 2007."}, {"ref": "[31] B. Raducanu and D. Gatica-Perez. Inferring competitive role patterns in reality TV show through nonverbal analysis. Multimedia Tools and Applications, 56(1):207\u2013226, 2012."}, {"ref": "[32] V. Ramanathan, B. Yao, and L. Fei-Fei. Social role discovery in human events. In CVPR, pages 2475\u20132482, 2013."}, {"ref": "[33] Y. Sun, X. Wang, and X. Tang. Hybrid deep learning for face verification. In ICCV, pages 1489\u20131496, 2013."}, {"ref": "[34] Y. Taigman, M. Yang, M. Ranzato, and L. Wolf. DeepFace: Closing the gap to human-level performance in face verification. In CVPR, 2014."}, {"ref": "[35] Y. Tang. Deep learning using linear support vector machines. In ICML Workshop on Challenges in Representation Learning, 2013."}, {"ref": "[36] A. Vinciarelli, M. Pantic, and H. Bourlard. Social signal processing: Survey of an emerging domain. Image and Vision Computing, 27(12):1743\u20131759, 2009."}, {"ref": "[37] A. Vinciarelli, M. Pantic, D. Heylen, C. Pelachaud, I. Poggi, F. D\u2019Errico, and M. Schr\u00a8oder. Bridging the gap between social animal and unsocial machine: A survey of social signal processing. IEEE Transactions on Affective Computing, 3(1):69\u201387, 2012."}, {"ref": "[38] G. Wang, A. Gallagher, J. Luo, and D. Forsyth. Seeing people in social context: Recognizing people and social relationships. In ECCV, pages 169\u2013182. 2010."}, {"ref": "[39] C.-Y. Weng, W.-T. Chu, and J.-L. Wu. Rolenet: Movie analysis from the perspective of social networks. IEEE Transactions on Multimedia, 11(2):256\u2013271, 2009."}, {"ref": "[40] J. Weston, F. Ratle, and R. Collobert. Deep learning via semisupervised embedding. In ICML, 2008."}, {"ref": "[41] X. Xiong and F. De La Torre. Supervised descent method and its applications to face alignment. In CVPR, 2013."}, {"ref": "[42] Z. Zhang, P. Luo, C. C. Loy, and X. Tang. Learning deep representation for face alignment with auxiliary attributes. In TPAMI, 2015."}, {"ref": "[43] Z. Zhu, P. Luo, X. Wang, and X. Tang. Deep learning identitypreserving face space. In ICCV, 2013."}]}, {"author": ["Qianru Sun", "Bernt Schiele", "Mario Fritz"], "title": "A Domain Based Approach to Social Relation Recognition", "journal": "CVPR", "year": 2017, "DOI": "10.1109/CVPR.2017.54", "month": 11, "citations(google scholar)": 31, "abstract": "Social relations are the foundation of human daily life. Developing techniques to analyze such relations from visual data bears great potential to build machines that better understand us and are capable of interacting with us at a social level. Previous investigations have remained partial due to the overwhelming diversity and complexity of the topic and consequently have only focused on a handful of social relations. In this paper, we argue that the domain-based theory from social psychology is a great starting point to systematically approach this problem. The theory provides coverage of all aspects of social relations and equally is concrete and predictive about the visual attributes and behaviors defining the relations included in each domain. We provide the first dataset built on this holistic conceptualization of social life that is composed of a hierarchical label space of social domains and social relations. We also contribute the first models to recognize such domains and relations and find superior performance for attribute based features. Beyond the encouraging performance of the attribute based approach, we also find interpretable features that are in accordance with the predictions from social psychology literature. Beyond our findings, we believe that our contributions more tightly interleave visual recognition and social psychology theory that has the potential to complement the theoretical work in the area with empirical and data-driven models of social life.", "keywords": ["None"], "reference_count": 48, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Bugental, D.B.: Acquisition of the Algorithms of Social Life: A Domain-Based Approach. Psychological Bulletin, Vol. 126, No. 2, pp. 187-219, 2000. 1, 2, 3, 4, 5, 6"}, {"ref": "[2] Reis, H.T., Collins, W.A. and Berscheid, E.: The relationship context of human behavior and development. Psychological Bulletin, 126(6), pp. 844-872, 2000. 3"}, {"ref": "[3] Fiske, A. P.: The four elementary forms of sociality: framework for a unified theory of social relations. Psychological Review, 99(4): 689, 1992. 3"}, {"ref": "[4] Fairclough, N.: Analysing discourse: Textual analysis for social research. Psychology Press. 2003. 1, 2"}, {"ref": "[5] Haslam, N., Fiske, A. P.: Implicit relationship prototypes: Investigating five theories of the cognitive organization of social relationships. Journal of Experimental Social Psychology, 28(5), pp. 441-474, 1992."}, {"ref": "[6] Clark, M. S., Mills, J.: Interpersonal attraction in exchange and communal relationships. Journal of personality and social psychology, 37(1): 12, 1979. 3"}, {"ref": "[7] Foa, E.B., Foa, U.G.: Resource theory. Social exchange. Springer US, pp. 77-94, 1980. 3"}, {"ref": "[8] Parsons, T., Shils, E. A. and Smelser, N. J. (Eds.): Toward a general theory of action: Theoretical foundations for the social sciences. Transaction publishers, 1965. 3"}, {"ref": "[9] MacCrimmon, K. R., Messick, D.M.: A framework for social motives. Behavioral Science, 21(2), pp. 86-100, 1976. 3"}, {"ref": "[10] Chu, X., Ouyang, W., Yang, W. and Wang, X.: Multi-task recurrent neural network for immediacy prediction. IEEE International Conference on Computer Vision. pp. 3352-3360, 2015. 2, 5, 6"}, {"ref": "[11] Yang, Y., Baker, S., Kannan, A. and Ramanan, D., 2012, June. Recognizing proxemics in personal photos. IEEE Conference on Computer Vision and Pattern Recognition, pp. 3522-3529, 2012. 2"}, {"ref": "[12] Barr, J.R., Cament, L.A., Bowyer, K.W. and Flynn, P.J.: Active clustering with ensembles for social structure extraction. IEEE Winter Conference on Applications of Computer Vision. pp. 969-976, 2014. 2"}, {"ref": "[13] Li, L.J., Shamma, D.A., Kong, X., Jafarpour, S., Van Zwol, R. and Wang, X.: CelebrityNet: A Social Network Constructed from Large-Scale Online Celebrity Images. ACM Transactions on Multimedia Computing, Communications, and Applications, 12(1), No. 3, 2015. 2"}, {"ref": "[14] Ramanathan, V., Yao, B. and Fei-Fei, L.: Social role discovery in human events. IEEE Conference on Computer Vision and Pattern Recognition. pp. 2475-2482, 2013. 2"}, {"ref": "[15] Lan, T., Sigal, L. and Mori, G.: Social roles in hierarchical models for human activity recognition. IEEE Conference on Computer Vision and Pattern Recognition, pp. 1354-1361. 2012. 2"}, {"ref": "[16] Shu, T., Xie, D., Rothrock, B., Todorovic, S. and Zhu, S.C.: Joint inference of groups, events and human roles in aerial videos. IEEE Conference on Computer Vision and Pattern Recognition. pp. 4576-4584, 2015. 2"}, {"ref": "[17] Zhang, J., Hu, W., Yao, B., Wang, Y. and Zhu, S.C.: Inferring social roles in long timespan video sequence. IEEE International Conference on Computer Vision Workshops. pp. 1456-1463, 2011. 2"}, {"ref": "[18] Murillo, A.C., Kwak, I.S., Bourdev, L., Kriegman, D. and Belongie, S.: Urban tribes: Analyzing group photos from a social perspective. IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops. pp. 28-35, 2012. 2"}, {"ref": "[19] Kwak, I.S., Murillo, A.C., Belhumeur, P.N., Kriegman, D.J. and Belongie, S.J.: From Bikers to Surfers: Visual Recognition of Urban Tribes. British Machine Vision Conference, 2013. 2"}, {"ref": "[20] Shu, H., Gallagher, A., Chen, H. and Chen, T.: Face-graph matching for classifying groups of people. IEEE International Conference on Image Processing. pp. 2425-2429, 2013. 2"}, {"ref": "[21] Hong, R., Hu, Z., Liu, L., Wang, M., Yan, S. and Tian, Q.: Understanding blooming human groups in social networks. IEEE Transactions on Multimedia, 17(11), pp.1980- 1988, 2015. 2"}, {"ref": "[22] Song, Z., Wang, M., Hua, X.S. and Yan, S.: Predicting occupation via human clothing and contexts. IEEE International Conference on Computer Vision. pp. 1084-1091, 2011. 2"}, {"ref": "[23] Shao, M., Li, L. and Fu, Y.: What do you do? occupation recognition in a photo via social context. IEEE International Conference on Computer Vision. pp. 3631-3638, 2013. 2"}, {"ref": "[24] Wang, G., Gallagher, A., Luo, J. and Forsyth, D.: Seeing people in social context: Recognizing people and social relationships. European Conference on Computer Vision. pp. 169- 182, 2010. 2"}, {"ref": "[25] Singla, P., Kautz, H., Luo, J. and Gallagher, A.: Discovery of social relationships in consumer photo collections using markov logic. IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops. pp. 1-7, 2008. 2"}, {"ref": "[26] Dai, Q., Carr, P., Sigal, L. and Hoiem, D.: Family Member Identification from Photo Collections. IEEE Winter Conference on Applications of Computer Vision. pp. 982-989, 2015. 2"}, {"ref": "[27] Shao, M., Xia, S. and Fu, Y.: Identity and kinship relations in group pictures. In Human-Centered Social Media Analytics. Springer International Publishing. pp. 175-190, 2014. 2"}, {"ref": "[28] Xia, S., Shao, M., Luo, J. and Fu, Y.: Understanding kin relationships in a photo. IEEE Transactions on Multimedia, 14(4), pp.1046-1056, 2012. 2"}, {"ref": "[29] Guo, Y., Dibeklioglu, H. and van der Maaten, L.: Graph- Based Kinship Recognition. IEEE International Conference on Pattern Recognition. pp. 4287-4292, 2014. 2"}, {"ref": "[30] Chen, Y.Y., Hsu, W.H. and Liao, H.Y.M.: Discovering informative social subgraphs and predicting pairwise relationships from group photos. The 20th ACM international conference on Multimedia. pp. 669-678, 2012. 2"}, {"ref": "[31] Dehghan, A., Ortiz, E.G., Villegas, R. and Shah, M.: Who do i look like? determining parent-offspring resemblance via gated autoencoders. IEEE Conference on Computer Vision and Pattern Recognition. pp. 1757-1764, 2014. 2"}, {"ref": "[32] Zhang, Z., Chen, Y. and Saligrama, V.: Group membership prediction. IEEE International Conference on Computer Vision. pp. 3916-3924, 2015. 2"}, {"ref": "[33] Zhang, H., Zawlin, K., Chang, S., and Chua. T. Visual Translation Embedding Network for Visual Relation Detection. IEEE Conference on Computer Vision and Pattern Recognition, 2017. 2"}, {"ref": "[34] Lu, C., Ranjay K., Michael B., and Li F.F.: Visual relationship detection with language priors. European Conference on Computer Vision. pp. 852-869, 2016."}, {"ref": "[35] Baker, C.F., Fillmore, C.J. and Lowe, J.B.: The berkeley framenet project. The 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics. Vol. 1, pp. 86-90, 1998. 2"}, {"ref": "[36] Zhang, N., Paluri, M., Taigman, Y., Fergus, R. and Bourdev, L.: Beyond frontal faces: Improving person recognition using multiple cues. IEEE Conference on Computer Vision and Pattern Recognition. pp. 4804-4813, 2015. 4"}, {"ref": "[37] Zhang, X., Sugano, Y., Fritz, M., Bulling, A.: Appearancebased gaze estimation in the wild. IEEE Conference on Computer Vision and Pattern Recognition. pp. 4511-4520, 2015. 2, 3, 4, 6"}, {"ref": "[38] Chopra, S., Hadsell, R., LeCun, Y.: Learning a similarity metric discriminatively, with application to face verification. IEEE Conference on Computer Vision and Pattern Recognition. Vol. 1, pp. 539-546, 2005. 5"}, {"ref": "[39] Zhang, Z., Luo, P., Loy, C. C., Tang, X.: Learning social relation traits from face images. IEEE International Conference on Computer Vision. pp. 3631-3639, 2015. 5"}, {"ref": "[40] Cheng, D., Gong, Y., Zhou, S., Wang, J. and Zheng, N.: Person re-identification by multi-channel parts-based CNN with improved triplet loss function. IEEE Conference on Computer Vision and Pattern Recognition. pp. 1335-1344, 2016. 2, 5"}, {"ref": "[41] Taigman, Y., Yang, M., Ranzato, M. A., Wolf, L.: Deepface: Closing the gap to human-level performance in face verification. IEEE Conference on Computer Vision and Pattern Recognition. pp. 1701-1708, 2014. 5 5"}, {"ref": "[42] Jia, Y., et al.: Caffe: Convolutional architecture for fast feature embedding. ACM international conference on Multimedia. pp. 675-678, 2014. 5, 6"}, {"ref": "[43] LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradientbased learning applied to document recognition. In Proceedings of the IEEE 86(11), pp. 2278-2324, 1998. 5"}, {"ref": "[44] Oh S., Benenson R., Fritz M., Schiele B.: Person Recognition in Personal Photo Collections. IEEE International Conference on Computer Vision. pp. 3862-3870, 2015. 5, 6"}, {"ref": "[45] Bourdev L., Maji S., Malik J.: Describing People: Poselet- Based Approach to Attribute Classification. IEEE International Conference on Computer Vision. pp. 1543-1550, 2011. 6, 8"}, {"ref": "[46] Liu, Z., Luo, P., Wang, X. and Tang, X.: Deep learning face attributes in the wild. IEEE International Conference on Computer Vision. pp. 3730-3738, 2015. 6"}, {"ref": "[47] Yatskar M., Zettlemoyer L., A. Farhadi: Situation recognition: Visual semantic role labeling for image understanding. IEEE Conference on Computer Vision and Pattern Recognition, 2015. 5, 6, 8"}, {"ref": "[48] S. Setty, et al.: Indian Movie Face Database: A Benchmark for Face Recognition Under Wide Variations. National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics, 2013. 6."}]}, {"author": ["Junnan Li", "Yongkang Wong", "Qi Zhao", "Mohan S. Kankanhalli"], "title": "Dual-Glance Model for Deciphering Social Relationships", "journal": "ICCV", "year": 2017, "DOI": "10.1109/ICCV.2017.289", "month": 8, "citations(google scholar)": 13, "abstract": "Since the beginning of early civilizations, social relationships derived from each individual fundamentally form the basis of social structure in our daily life. In the computer vision literature, much progress has been made in scene understanding, such as object detection and scene parsing. Recent research focuses on the relationship between objects based on its functionality and geometrical relations. In this work, we aim to study the problem of social relationship recognition, in still images. We have proposed a dual-glance model for social relationship recognition, where the first glance fixates at the individual pair of interest and the second glance deploys attention mechanism to explore contextual cues. We have also collected a new large scale People in Social Context (PISC) dataset, which comprises of 22,670 images and 76,568 annotated samples from 9 types of social relationship. We provide benchmark results on the PISC dataset, and qualitatively demonstrate the efficacy of the proposed model.", "keywords": ["None"], "reference_count": 43, "ccfClass": "A", "important": true, "references": [{"ref": "[1] A. Alahi, K. Goel, V. Ramanathan, A. Robicquet, L. Fei-Fei, and S. Savarese. Social LSTM: Human trajectory prediction in crowded spaces. In CVPR, pages 961\u2013971, 2016. 1, 2"}, {"ref": "[2] S. Alletto, G. Serra, S. Calderara, F. Solera, and R. Cucchiara. From ego to nos-vision: Detecting social relationships in first-person views. In CVPR Workshops, pages 594\u2013 599, 2014. 2"}, {"ref": "[3] Y. Chen, W. H. Hsu, and H. M. Liao. Discovering informative social subgraphs and predicting pairwise relationships from group photos. In ACMMM, pages 669\u2013678, 2012. 2"}, {"ref": "[4] W. Choi and S. Savarese. A unified framework for multitarget tracking and collective activity recognition. In ECCV, pages 215\u2013230, 2012. 1, 2"}, {"ref": "[5] H. R. Conte and R. Plutchik. A circumplex model for interpersonal personality traits. Journal of Personality and Social Psychology, 40(4):701, 1981. 2"}, {"ref": "[6] Z. Deng, A. Vahdat, H. Hu, and G. Mori. Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition. In CVPR, pages 4772\u20134781, 2016. 2"}, {"ref": "[7] H. Dibeklioglu, A. A. Salah, and T. Gevers. Like father, like son: Facial expression dynamics for kinship verification. In ICCV, pages 1497\u20131504, 2013. 2"}, {"ref": "[8] L. Ding and A. Yilmaz. Learning social relations from videos: Features, models, and analytics. In Human-Centered Social Media Analytics, pages 21\u201341. 2014. 2, 3"}, {"ref": "[9] C. Direkoglu and N. E. O\u2019Connor. Team activity recognition in sports. In ECCV, pages 69\u201383, 2012. 1, 2"}, {"ref": "[10] H. Fang, S. Gupta, F. N. Iandola, R. K. Srivastava, L. Deng, P. Doll\u00b4ar, J. Gao, X. He, M. Mitchell, J. C. Platt, C. L. Zitnick, and G. Zweig. From captions to visual concepts and back. In CVPR, pages 1473\u20131482, 2015. 3"}, {"ref": "[11] R. Fang, K. D. Tang, N. Snavely, and T. Chen. Towards computational models of kinship verification. In ICIP, pages 1577\u20131580, 2010. 2"}, {"ref": "[12] A. P. Fiske. The four elementary forms of sociality: framework for a unified theory of social relations. Psychological review, 99(4):689, 1992. 2"}, {"ref": "[13] A. C. Gallagher and T. Chen. Understanding images of groups of people. In CVPR, pages 256\u2013263, 2009. 2"}, {"ref": "[14] G. Gkioxari, R. B. Girshick, and J. Malik. Contextual action recognition with R*CNN. In ICCV, pages 1080\u20131088, 2015. 3, 7"}, {"ref": "[15] Y. Guo, H. Dibeklioglu, and L. van der Maaten. Graph-based kinship recognition. In ICPR, pages 4287\u20134292, 2014. 2"}, {"ref": "[16] E. T. Hall. The silent language, volume 3. Doubleday New York, 1959. 6"}, {"ref": "[17] N. Haslam. Categories of social relationship. Cognition, 53(1):59\u201390, 1994. 2"}, {"ref": "[18] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, pages 770\u2013778, 2016. 5"}, {"ref": "[19] C. Huang, C. C. Loy, and X. Tang. Unsupervised learning of discriminative attributes and visual representations. In CVPR, pages 5175\u20135184, 2016. 1"}, {"ref": "[20] H. Hung, D. B. Jayagopi, C. Yeo, G. Friedland, S. O. Ba, J. Odobez, K. Ramchandran, N. Mirghafori, and D. Gatica- Perez. Using audio and video features to classify the most dominant person in a group meeting. In ACMMM, pages 835\u2013838, 2007. 2"}, {"ref": "[21] R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen, Y. Kalantidis, L. Li, D. A. Shamma, M. S. Bernstein, and L. Fei-Fei. Visual genome: Connecting language and vision using crowdsourced dense image annotations. IJCV, 2016. 3"}, {"ref": "[22] T. Lan, L. Sigal, and G. Mori. Social roles in hierarchical models for human activity recognition. In CVPR, pages 1354\u20131361, 2012. 1, 2"}, {"ref": "[23] T. Lan, Y. Wang, W. Yang, S. N. Robinovitch, and G. Mori. Discriminative latent models for recognizing contextual group activities. TPAMI, 34(8):1549\u20131562, 2012. 1, 2"}, {"ref": "[24] T. Lin, M. Maire, S. J. Belongie, J. Hays, P. Perona, D. Ramanan, P. Doll\u00b4ar, and C. L. Zitnick. Microsoft COCO: common objects in context. In ECCV, pages 740\u2013755, 2014. 3"}, {"ref": "[25] C. Lu, R. Krishna, M. S. Bernstein, and L. Fei-Fei. Visual relationship detection with language priors. In ECCV, pages 852\u2013869, 2016. 1, 2, 5, 6"}, {"ref": "[26] Z. Qin and C. R. Shelton. Improving multi-target tracking via social grouping. In CVPR, pages 1972\u20131978, 2012. 1"}, {"ref": "[27] V. Ramanathan, B. Yao, and L. Fei-Fei. Social role discovery in human events. In CVPR, pages 2475\u20132482, 2013. 2, 3"}, {"ref": "[28] S. Ren, K. He, R. B. Girshick, and J. Sun. Faster R-CNN: towards real-time object detection with region proposal networks. In NIPS, pages 91\u201399, 2015. 2, 3, 4, 5"}, {"ref": "[29] R. Rienks, D. Zhang, D. Gatica-Perez, and W. Post. Detection and application of influence rankings in small group meetings. In ICMI, pages 257\u2013264, 2006. 2"}, {"ref": "[30] A. Robicquet, A. Sadeghian, A. Alahi, and S. Savarese. Learning social etiquette: Human trajectory understanding in crowded scenes. In ECCV, pages 549\u2013565, 2016. 1, 2"}, {"ref": "[31] H. Salamin, S. Favre, and A. Vinciarelli. Automatic role recognition in multiparty recordings: Using social affiliation networks for feature extraction. IEEE Trans. Multimedia, 11(7):1373\u20131380, 2009. 2"}, {"ref": "[32] E. R. Smith and M. A. Zarate. Exemplar and prototype use in social categorization. Social Cognition, 8(3):243, 1990. 1"}, {"ref": "[33] B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L. Li. YFCC100M: the new data in multimedia research. Commun. ACM, 59(2):64\u201373, 2016. 3"}, {"ref": "[34] A. Vinciarelli, M. Pantic, D. Heylen, C. Pelachaud, I. Poggi, F. D\u2019Errico, and M. Schr\u00a8oder. Bridging the gap between social animal and unsocial machine: A survey of social signal processing. IEEE Trans. Affective Computing, 3(1):69\u201387, 2012. 2"}, {"ref": "[35] G. Wang, A. C. Gallagher, J. Luo, and D. A. Forsyth. Seeing people in social context: Recognizing people and social relationships. In ECCV, pages 169\u2013182, 2010. 1, 2"}, {"ref": "[36] J. Wu, Y. Yu, C. Huang, and K. Yu. Deep multiple instance learning for image classification and auto-annotation. In CVPR, pages 3460\u20133469, 2015. 3, 7"}, {"ref": "[37] S. Xia, M. Shao, J. Luo, and Y. Fu. Understanding kin relationships in a photo. IEEE Trans. Multimedia, 14(4):1046\u2013 1056, 2012. 2"}, {"ref": "[38] T. Xiao, Y. Xu, K. Yang, J. Zhang, Y. Peng, and Z. Zhang. The application of two-level attention models in deep convolutional neural network for fine-grained image classification. In CVPR, pages 842\u2013850, 2015. 3"}, {"ref": "[39] K. Xu, J. Ba, R. Kiros, K. Cho, A. C. Courville, R. Salakhutdinov, R. S. Zemel, and Y. Bengio. Show, attend and tell: Neural image caption generation with visual attention. In ICML, pages 2048\u20132057, 2015. 3"}, {"ref": "[40] Z. Yang, X. He, J. Gao, L. Deng, and A. Smola. Stacked attention networks for image question answering. In CVPR, pages 21\u201329, 2016. 3"}, {"ref": "[41] Q. You, H. Jin, Z. Wang, C. Fang, and J. Luo. Image captioning with semantic attention. In CVPR, pages 4651\u20134659, 2016. 3"}, {"ref": "[42] Z. Zhang, P. Luo, C. C. Loy, and X. Tang. Learning social relation traits from face images. In ICCV, pages 3631\u20133639, 2015. 2"}, {"ref": "[43] B. Zhou, A. Khosla, A. Lapedriza, A. Torralba, and A. Oliva. Places: A 10 million image database for scene recognition. TPAMI, 2017. 6"}]}, {"author": ["Zhanpeng Zhang", "Ping Luo", "Chen Change Loy", "Xiaoou Tang"], "title": "From Facial Expression Recognition to Interpersonal Relation Prediction", "journal": "IJCV", "year": 2018, "DOI": "10.1007/s11263-017-1055-1", "month": 5, "citations(google scholar)": 27, "abstract": "Interpersonal relation defines the association, e.g., warm, friendliness, and dominance, between two or more people. We investigate if such fine-grained and high-level relation traits can be characterized and quantified from face images in the wild. We address this challenging problem by first studying a deep network architecture for robust recognition of facial expressions. Unlike existing models that typically learn from facial expression labels alone, we devise an effective multitask network that is capable of learning from rich auxiliary attributes such as gender, age, and head pose, beyond just facial expression data. While conventional supervised training requires datasets with complete labels (e.g., all samples must be labeled with gender, age, and expression), we show that this requirement can be relaxed via a novel attribute propagation method. The approach further allows us to leverage the inherent correspondences between heterogeneous attribute sources despite the disparate distributions of different datasets. With the network we demonstrate state-of-the-art results on existing facial expression recognition benchmarks. To predict inter-personal relation, we use the expression recognition network as branches for a Siamese model. Extensive experiments show that our model is capable of mining mutual context of faces for accurate fine-grained interpersonal prediction.", "keywords": ["Facial expression recognition", "Interpersonal relation", "Deep convolutional network"], "reference_count": 99, "ccfClass": "A", "important": true, "references": [{"ref": "[1]  Bi, W., & Kwok, J. T. (2014). Multilabel classification with label correlations and missing labels. In AAAI conference on artificial intelligence (pp. 1680\u20131686)."}, {"ref": "[2]  Bromley, J., Guyon, I., Lecun, Y., S\u00e4ckinger, E., & Shah, R. (1994). Signature verification using a Siamese time delay neural network. In Advances in neural information processing systems."}, {"ref": "[3]  Celeux, G., Forbes, F., & Peyrard, N. (2003). EM procedures using mean field-like approximations for markov model-based image segmentation. Pattern Recognition, 36(1), 131\u2013144."}, {"ref": "[4]  Chakraborty, I., Cheng, H., & Javed, O. (2013). 3D visual proxemics: Recognizing human interactions in 3D from a single image. In IEEE conference on computer vision and pattern recognition (pp. 3406\u20133413)."}, {"ref": "[5]  Chen, Y. Y., Hsu, W. H., & Liao, H. Y. M. (2012). Discovering informative social subgraphs and predicting pairwise relationships from group photos. In ACM multimedia (pp. 669\u2013678)."}, {"ref": "[6]  Chu, X., Ouyang, W., Yang, W., & Wang, X. (2015). Multi-task recurrent neural network for immediacy prediction. In Proceedings of the IEEE international conference on computer vision (pp. 3352\u20133360)."}, {"ref": "[7]  Cristani, M., Raghavendra, R., Del Bue, A., & Murino, V. (2013). Human behavior analysis in video surveillance: A social signal processing perspective. Neurocomputing, 100, 86\u201397."}, {"ref": "[8]  Dahmane, M., & Meunier, J. (2011). Emotion recognition using dynamic grid-based hog features. In IEEE international conference on automatic face & gesture recognition (pp. 884\u2013888)."}, {"ref": "[9]  Deng, Z., Vahdat, A., Hu, H., & Mori, G. (2016). Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[10] Dhall, A., Asthana, A., Goecke, R., & Gedeon, T. (2011). Emotion recognition using PHOG and LPQ features. In IEEE international conference on automatic face & gesture recognition and workshops (pp. 878\u2013883)."}, {"ref": "[11] Dhall, A., Ramana Murthy, O., Goecke, R., Joshi, J., & Gedeon, T. (2015). Video and image based emotion recognition challenges in the wild: Emotiw 2015. In ACM international conference on multimodal interaction (pp. 423\u2013426)."}, {"ref": "[12] Ding, L., & Yilmaz, A. (2010). Learning relations among movie characters: A social network perspective. In European conference on computer vision."}, {"ref": "[13] Ding, L., & Yilmaz, A. (2011). Inferring social relations from visual concepts. In IEEE international conference on computer vision (pp. 699\u2013706)."}, {"ref": "[14] Emily, M., & Hand, R. C. (2017). Attributes for improved attributes: A multi-task network utilizing implicit and explicit relationships for facial attribute classification. In AAAI conference on artificial intelligence."}, {"ref": "[15] Fabian Benitez-Quiroz, C., Srinivasan, R., & Martinez, A. M. (2016). Emotionet: An accurate, real-time algorithm for the automatic annotation of a million facial expressions in the wild. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[16] Fathi, A., Hodgins, J. K., & Rehg, J. M. (2012). Social interactions: A first-person perspective. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[17] Gallagher, A. C., & Chen, T. (2009). Understanding images of groups of people. In IEEE conference on computer vision and pattern recognition (pp. 256\u2013263). IEEE."}, {"ref": "[18] Girard, J. M. (2014). Perceptions of interpersonal behavior are influenced by gender, facial expression intensity, and head pose. In ACM international conference on multimodal interaction (pp. 394\u2013398)."}, {"ref": "[19] Goodfellow, I., Erhan, D., Carrier, P. L., Courville, A., Mirza, et al. (2013). Challenges in representation learning: A report on three machine learning contests. http://arxiv.org/abs/1307.0414."}, {"ref": "[20] Gottman, J., Levenson, R., & Woodin, E. (2001). Facial expressions during marital conflict. Journal of Family Communication, 1(1), 37\u201357."}, {"ref": "[21] Gupta, A. K., & Nagar, D. K. (1999). Matrix variate distributions. Boca Raton: CRC Press."}, {"ref": "[22] Hess, U., Blairy, S., & Kleck, R. E. (2000). The influence of facial emotion displays, gender, and ethnicity on judgments of dominance and affiliation. Journal of Nonverbal Behavior, 24(4), 265\u2013283."}, {"ref": "[23] Hoai, M., & Zisserman, A. (2014). Talking heads: Detecting humans and recognizing their interactions. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[24] Hu, Y., Zeng, Z., Yin, L., Wei, X., Zhou, X., & Huang, T. S. (2008). Multi-view facial expression recognition. In IEEE international conference on automatic face & gesture recognition.  https://xs.scihub.ltd/https://doi.org/10.1109/AFGR.2008.4813445."}, {"ref": "[25] Huang, C., Li, Y., Loy, C. C., & Tang, X. (2016). Learning deep representation for imbalanced classification. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[26] Hung, H., Jayagopi, D., Yeo, C., Friedland, G., Ba, S., Odobez, J. M., et al. (2007). Using audio and video features to classify the most dominant person in a group meeting. In ACM multimedia."}, {"ref": "[27] Ibrahim, M., Muralidharan, S., Deng, Z., Vahdat, A., & Mori, G. (2016). A hierarchical deep temporal model for group activity recognition. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[28] Ioffe, S., & Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. In Proceedings of the 32nd international conference on machine learning (pp. 448\u2013456)."}, {"ref": "[29] Joo, J., Li, W., Steen, F., & Zhu, S. C. (2014). Visual persuasion: Inferring communicative intents of images. In IEEE conference on computer vision and pattern recognition (pp. 216\u2013223)."}, {"ref": "[30] Jung, H., Lee, S., Yim, J., Park, S., & Kim, J. (2015). Joint fine-tuning in deep neural networks for facial expression recognition. In IEEE international conference on computer vision."}, {"ref": "[31] Khorrami, P., Paine, T., & Huang, T. (2015). Do deep neural networks learn facial action units when doing expression recognition? In IEEE international conference on computer vision workshop."}, {"ref": "[32] Kiesler, D. J. (1983). The 1982 interpersonal circle: A taxonomy for complementarity in human transactions. Psychological Review, 90(3), 185."}, {"ref": "[33] Knutson, B. (1996). Facial expressions of emotion influence interpersonal trait inferences. Journal of Nonverbal Behavior, 20(3), 165\u2013182."}, {"ref": "[34] Kong, Y., Jia, Y., & Fu, Y. (2012). Learning human interaction by interactive phrases. In European conference on computer vision (pp. 300\u2013313)."}, {"ref": "[35] Kostinger, M., Wohlhart, P., Roth, P., & Bischof, H. (2011). Annotated facial landmarks in the wild: A large-scale, real-world database for facial landmark localization. In IEEE international conference on computer vision workshop (pp. 2144\u20132151)."}, {"ref": "[36] Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks. In F. Pereira, C. J. C. Burges, L. Bottou & K. Q. Weinberger (Eds.), Advances in neural information processing systems. Curran Associates, Inc."}, {"ref": "[37] Kumar, N., Belhumeur, P., & Nayar, S. (2008). Facetracer: A search engine for large collections of images with faces. In European conference on computer vision (pp. 340\u2013353). Berlin: Springer."}, {"ref": "[38] Lan, T., Sigal, L., & Mori, G. (2012). Social roles in hierarchical models for human activity recognition. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[39] Lee, D. H. (2013). Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In International conference on machine learning workshop (vol. 3, p. 2)."}, {"ref": "[40] Levi, G., & Hassner, T. (2015). Emotion recognition in the wild via convolutional neural networks and mapped binary patterns. In ACM international conference on multimodal interaction (pp. 503\u2013510)."}, {"ref": "[41] Li, H., Lin, Z., Shen, X., Brandt, J., & Hua, G. (2015). A convolutional neural network cascade for face detection. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[42] Liu, M., Li, S., Shan, S., & Chen, X. (2015). AU-inspired deep networks for facial expression feature learning. Neurocomputing, 159, 126\u2013136."}, {"ref": "[43] Liu, M., Li, S., Shan, S., Wang, R., & Chen, X. (2014a). Deeply learning deformable facial action parts model for dynamic expression analysis. In Asian conference on computer vision."}, {"ref": "[44] Liu, M., Shan, S., Wang, R., & Chen, X. (2014b). Learning expressionlets on spatio-temporal manifold for dynamic facial expression recognition. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[45] Liu, P., Han, S., Meng, Z., & Tong, Y. (2014c). Facial expression recognition via a boosted deep belief network. In IEEE conference on computer vision and pattern recognition (pp. 1805\u20131812)."}, {"ref": "[46] Liu, S., Yang, J., Huang, C., & Yang, M. H. (2015a). Multi-objective convolutional learning for face labeling. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[47] Liu, Z., Luo, P., Wang, X., & Tang, X. (2015b). Deep learning face attributes in the wild. In IEEE international conference on computer vision."}, {"ref": "[48] Lucey, P., Cohn, J. F., Kanade, T., Saragih, J., Ambadar, Z., & Matthews, I. (2010). The extended Cohn\u2013Kanade dataset (CK+): A complete dataset for action unit and emotion-specified expression. In IEEE conference on computer vision and pattern recognition workshops (pp. 94\u2013101)."}, {"ref": "[49] Luo, P., Wang, X., & Tang, X. (2012). Hierarchical face parsing via deep learning. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[50] Lyons, M. J., Budynek, J., & Akamatsu, S. (1999). Automatic classification of single facial images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 21(12), 1357\u20131362."}, {"ref": "[51] Microsoft Cognitive Services. (2016). https://www.microsoft.com/cognitive-services/en-us/emotion-api."}, {"ref": "[52] Mollahosseini, A., Chan, D., & Mahoor, M. H. (2016). Going deeper in facial expression recognition using deep neural networks. In IEEE winter conference on applications of computer vision."}, {"ref": "[53] Moody, J., Hanson, S., Krogh, A., & Hertz, J. A. (1995). A simple weight decay can improve generalization. Advances in Neural Information Processing Systems, 4, 950\u2013957."}, {"ref": "[54] Ng, H. W., Nguyen, V. D., Vonikakis, V., & Winkler, S. (2015). Deep learning for emotion recognition on small datasets using transfer learning. In ACM international conference on multimodal interaction (pp. 443\u2013449)."}, {"ref": "[55] Opitz, M., Waltner, G., Poier, G., Possegger, H., & Bischof, H. (2016). Grid loss: Detecting occluded faces. In European conference on computer vision."}, {"ref": "[56] Pantic, M., Cowie, R., D\u2019Errico, F., Heylen, D., Mehu, M., Pelachaud, C., et al. (2011). Social signal processing: The research agenda. In T. B. Moeslund, A. Hilton, V. Kr\u00fcger & L. Sigal (Eds.), Visual analysis of humans (pp. 511\u2013538). Berlin: Springer."}, {"ref": "[57] Pantic, M., Valstar, M., Rademaker, R., & Maat, L. (2005). Web-based database for facial expression analysis. In IEEE international conference on multimedia and expo."}, {"ref": "[58] Parkhi, O. M., Vedaldi, A., & Zisserman, A. (2015). Deep face recognition. In British machine vision conference."}, {"ref": "[59] Pearson, K. (1895). Note on regression and inheritance in the case of two parents. Proceedings of the Royal Society of London, 58, 240\u2013242."}, {"ref": "[60] Pentland, A. (2007). Social signal processing. IEEE Signal Processing Magazine, 24(4), 108."}, {"ref": "[61] Raducanu, B., & Gatica-Perez, D. (2012). Inferring competitive role patterns in reality TV show through nonverbal analysis. Multimedia Tools and Applications, 56(1), 207\u2013226."}, {"ref": "[62] Ramanathan, V., Yao, B., & Fei-Fei, L. (2013). Social role discovery in human events. In IEEE conference on computer vision and pattern recognition (pp. 2475\u20132482)."}, {"ref": "[63] Ricci, E., Varadarajan, J., Subramanian, R., Rota Bulo, S., Ahuja, N., & Lanz, O. (2015). Uncovering interactions and interactors: Joint estimation of head, body orientation and f-formations from surveillance videos. In IEEE international conference on computer vision."}, {"ref": "[64] Ruiz, A., Van de Weijer, J., & Binefa, X. (2015). From emotions to action units with hidden and semi-hidden-task learning. In IEEE international conference on computer vision (pp. 3703\u20133711)."}, {"ref": "[65] Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., et al. (2015). ImageNet large scale visual recognition challenge. International Journal of Computer Vision, 115(3), 211\u2013252."}, {"ref": "[66] Schroff, F., Kalenichenko, D., & Philbin, J. (2015). Facenet: A unified embedding for face recognition and clustering. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[67] Shan, C., Gong, S., & McOwan, P. W. (2009). Facial expression recognition based on local binary patterns: A comprehensive study. Image and Vision Computing, 27(6), 803\u2013816."}, {"ref": "[68] Sun, Y., Wang, X., & Tang, X. (2016). Sparsifying neural network connections for face recognition. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[69] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., et al. (2015). Going deeper with convolutions. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[70] Tian, Y., Kanade, T., & Cohn, J. F. (2011). Facial expression recognition. In S. Z. Li & A. K. Jain (Eds.), Handbook of face recognition. Berlin: Springer."}, {"ref": "[71] Tian, Y. I., Kanade, T., & Cohn, J. F. (2001). Recognizing action units for facial expression analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence, 23(2), 97\u2013115."}, {"ref": "[72] Tianqi, C., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., et al. (2016). Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems. In NIPS workshop on machine learning systems."}, {"ref": "[73] Trigeorgis, G., Snape, P., Nicolaou, M. A., Antonakos, E., & Zafeiriou, S. (2016). Mnemonic descent method: A recurrent process applied for end-to-end face alignment. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[74] Valstar, M. F., Mehu, M., Jiang, B., Pantic, M., & Scherer, K. (2012). Meta-analysis of the first facial expression recognition challenge. IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 42(4), 966\u2013979."}, {"ref": "[75] Vinciarelli, A., Pantic, M., & Bourlard, H. (2009). Social signal processing: Survey of an emerging domain. Image and Vision Computing, 27(12), 1743\u20131759."}, {"ref": "[76] Vinciarelli, A., Pantic, M., Heylen, D., Pelachaud, C., Poggi, I., D\u2019Errico, F., et al. (2012). Bridging the gap between social animal and unsocial machine: A survey of social signal processing. IEEE Transactions on Affective Computing, 3(1), 69\u201387."}, {"ref": "[77] Wang, G., Gallagher, A., Luo, J., & Forsyth, D. (2010). Seeing people in social context: Recognizing people and social relationships. In European conference on computer vision (pp. 169\u2013182)."}, {"ref": "[78] Wang, J., Cheng, Y., & Feris, R. S. (2016). Walk and learn: Facial attribute representation learning from egocentric video and contextual data. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[79] Weng, C. Y., Chu, W. T., & Wu, J. L. (2009). RoleNet: Movie analysis from the perspective of social networks. IEEE Transactions on Multimedia, 11(2), 256\u2013271."}, {"ref": "[80] Wu, Y., & Ji, Q. (2016). Constrained joint cascade regression framework for simultaneous facial action unit recognition and facial landmark detection. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[81] Yang, B., Yan, J., Lei, Z., & Li, S. Z. (2014). Aggregate channel features for multi-view face detection. In International joint conference on biometrics."}, {"ref": "[82] Yang, B., Yan, J., Lei, Z., & Li, S. Z. (2015). Convolutional channel features. In IEEE international conference on computer vision."}, {"ref": "[83] Yang, H., Zhou, J. T., & Cai, J. (2016). Improving multi-label learning with missing labels by structured semantic correlations. In European conference on computer vision (pp. 835\u2013851)."}, {"ref": "[84] Yang, S., Luo, P., Loy, C. C., & Tang, X. (2015). From facial parts responses to face detection: A deep learning approach. In IEEE international conference on computer vision."}, {"ref": "[85] Yang, S., Luo, P., Loy, C. C., & Tang, X. (2016). Wider face: A face detection benchmark. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[86] Yao, A., Shao, J., Ma, N., & Chen, Y. (2015). Capturing au-aware facial features and their latent relations for emotion recognition in the wild. In ACM international conference on multimodal interaction (pp. 451\u2013458)."}, {"ref": "[87] Yu, H. F., Jain, P., Kar, P., & Dhillon, I. (2014). Large-scale multi-label learning with missing labels. In International conference on machine learning (pp. 593\u2013601)."}, {"ref": "[88] Yu, Z., & Zhang, C. (2015). Image based static facial expression recognition with multiple deep network learning. In ACM international conference on multimodal interaction (pp. 435\u2013442)."}, {"ref": "[89] Zafeiriou, S., Papaioannou, A., Kotsia, I., Nicolaou, M. A., & Zhao, G. (2016). Facial affect in-the-wild: A survey and a new database. In IEEE conference on computer vision and pattern recognition workshop."}, {"ref": "[90] Zelnik-Manor, L., & Perona, P. (2004). Self-tuning spectral clustering. In NIPS (pp. 1601\u20131608)."}, {"ref": "[91] Zhang, N., Paluri, M., Ranzato, M., Darrell, T., & Bourdev, L. (2014). Panda: Pose aligned networks for deep attribute modeling. In IEEE conference on computer vision and pattern recognition."}, {"ref": "[92] Zhang, Z., Luo, P., Loy, C. C., & Tang, X. (2015a). Learning deep representation for face alignment with auxiliary attributes. In IEEE transactions on pattern analysis and machine intelligence."}, {"ref": "[93] Zhang, Z., Luo, P., Loy, C. C., & Tang, X. (2015b). Learning social relation traits from face images. In IEEE international conference on computer vision."}, {"ref": "[94] Zhang, Z., Luo, P., Loy, C. C., & Tang, X. (2016). Joint face representation adaptation and clustering in videos. In European conference on computer vision."}, {"ref": "[95] Zhao, G., Huang, X., Taini, M., Li, S. Z., & Pietik\u00e4inen, M. (2011). Facial expression recognition from near-infrared videos. Image and Vision Computing, 29(9), 607\u2013619."}, {"ref": "[96] Zhao, G., & Pietikainen, M. (2007). Dynamic texture recognition using local binary patterns with an application to facial expressions. IEEE Transactions on Pattern Analysis and Machine Intelligence, 29(6), 915\u2013928."}, {"ref": "[97] Zhao, X., Liang, X., Liu, L., Li, T., Vasconcelos, N., & Yan, S. (2016). Peak-piloted deep network for facial expression recognition. In European conference on computer vision."}, {"ref": "[98] Zhong, L., Liu, Q., Yang, P., Liu, B., Huang, J., & Metaxas, D. N. (2012). Learning active facial patches for expression analysis. In IEEE conference on computer vision and pattern recognition (pp. 2562\u20132569)."}, {"ref": "[99] Zhu, X., Lei, Z., Liu, X., Shi, H., & Li, S. Z. (2016). Face alignment across large poses: A 3d solution. In IEEE conference on computer vision and pattern recognition."}]}, {"author": ["ZhouxiaWang", "Tianshui Chen", "Jimmy Ren", "Weihao Yu", "Hui Cheng", "Liang Lin"], "title": "Deep Reasoning with Knowledge Graph for Social Relationship Understanding", "journal": "IJCAI", "year": 2018, "DOI": "10.24963/ijcai.2018/142", "month": 7, "citations(google scholar)": 16, "abstract": "Social relationships (e.g., friends, couple etc.) form the basis of the social network in our daily life. Automatically interpreting such relationships bears a great potential for the intelligent systems to understand human behavior in depth and to better interact with people at a social level. Human beings interpret the social relationships within a group not only based on the people alone, and the interplay between such social relationships and the contextual information around the people also plays a significant role. However, these additional cues are largely overlooked by the previous studies. We found that the interplay between these two factors can be effectively modeled by a novel structured knowledge graph with proper message propagation and attention. And this structured knowledge can be efficiently integrated into the deep neural network architecture to promote social relationship understanding by an end-to-end trainable Graph Reasoning Model (GRM), in which a propagation mechanism is learned to propagate node message through the graph to explore the interaction between persons of interest and the contextual objects. Meanwhile, a graph attentional mechanism is introduced to explicitly reason about the discriminative objects to promote recognition. Extensive experiments on the public benchmarks demonstrate the superiority of our method over the existing leading competitors.", "keywords": ["None"], "reference_count": 37, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Alexandre Alahi, Kratarth Goel, Vignesh Ramanathan, Alexandre Robicquet, Li Fei-Fei, and Silvio Savarese. Social lstm: Human trajectory prediction in crowded spaces. In CVPR, pages 961\u2013971, 2016."}, {"ref": "[2] Daphne Blunt Bugental. Acquisition of the algorithms of social life: A domain-based approach. Psychological bulletin, 126(2):187, 2000."}, {"ref": "[3] Yan-Ying Chen, Winston H Hsu, and Hong- Yuan Mark Liao. Discovering informative social subgraphs and predicting pairwise relationships from group photos. In ACM MM, pages 669\u2013678, 2012."}, {"ref": "[4] Tianshui Chen, ZhouxiaWang, Guanbin Li, and Liang Lin. Recurrent attentional reinforcement learning for multi-label image recognition. In AAAI, pages 6730\u20136737, 2018."}, {"ref": "[5] Kyunghyun Cho, Bart Van Merri\u00a8enboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014."}, {"ref": "[6] Wongun Choi and Silvio Savarese. A unified framework for multi-target tracking and collective activity recognition. ECCV, pages 215\u2013230, 2012."}, {"ref": "[7] Zhiwei Deng, Arash Vahdat, Hexiang Hu, and Greg Mori. Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition. In CVPR, pages 4772\u20134781, 2016."}, {"ref": "[8] Hamdi Dibeklioglu, Albert Ali Salah, and Theo Gevers. Like father, like son: Facial expression dynamics for kinship verification. In ICCV, pages 1497\u20131504, 2013."}, {"ref": "[9] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Al\u00b4an Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular fingerprints. In NIPS, pages 2224\u2013 2232, 2015."}, {"ref": "[10] Norman Fairclough. Analysing discourse: Textual analysis for social research. Psychology Press, 2003."}, {"ref": "[11] Alan P Fiske. The four elementary forms of sociality: framework for a unified theory of social relations. Psychological review, 99(4):689, 1992."}, {"ref": "[12] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, pages 770\u2013778, 2016."}, {"ref": "[13] Chen Huang, Chen Change Loy, and Xiaoou Tang. Unsupervised learning of discriminative attributes and visual representations. In CVPR, pages 5175\u20135184, 2016."}, {"ref": "[14] Jin-Hwa Kim, Kyoung-Woon On, Woosang Lim, Jeonghee Kim, Jung-Woo Ha, and Byoung-Tak Zhang. Hadamard product for low-rank bilinear pooling. arXiv preprint arXiv:1610.04325, 2016."}, {"ref": "[15] Thomas N Kipf and Max Welling. Semisupervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016."}, {"ref": "[16] Tian Lan, Leonid Sigal, and Greg Mori. Social roles in hierarchical models for human activity recognition. In CVPR, pages 1354\u20131361, 2012."}, {"ref": "[17] Li-Jia Li, David A Shamma, Xiangnan Kong, Sina Jafarpour, Roelof Van Zwol, and Xuanhui Wang. Celebritynet: A social network constructed from large-scale online celebrity images. TOMM, 12(1):3, 2015."}, {"ref": "[18] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural networks. arXiv preprint arXiv:1511.05493, 2015."}, {"ref": "[19] Junnan Li, Yongkang Wong, Qi Zhao, and Mohan S Kankanhalli. Dual-glance model for deciphering social relationships. In ICCV, pages 2650\u20132659, 2017."}, {"ref": "[20] Xiaodan Liang, Xiaohui Shen, Jiashi Feng, Liang Lin, and Shuicheng Yan. Semantic object parsing with graph lstm. In ECCV, pages 125\u2013143, 2016."}, {"ref": "[21] Xiaodan Liang, Liang Lin, Xiaohui Shen, Jiashi Feng, Shuicheng Yan, and Eric P Xing. Interpretable structure-evolving lstm. In CVPR, pages 2175\u20132184, 2017."}, {"ref": "[22] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00b4ar, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In ECCV, pages 740\u2013755, 2014."}, {"ref": "[23] Liang Lin, Lili Huang, Tianshui Chen, Yukang Gan, and Hui Cheng. Knowledge-guided recurrent neural network learning for task-oriented action prediction. In ICME, pages 625\u2013630, 2017."}, {"ref": "[24] Cewu Lu, Ranjay Krishna, Michael Bernstein, and Li Fei-Fei. Visual relationship detection with language priors. In ECCV, pages 852\u2013869, 2016."}, {"ref": "[25] Tomasz Malisiewicz and Alyosha Efros. Beyond categories: The visual memex model for reasoning about object relationships. In NIPS, pages 1222\u20131230, 2009."}, {"ref": "[26] Kenneth Marino, Ruslan Salakhutdinov, and Abhinav Gupta. The more you know: Using knowledge graphs for image classification. arXiv preprint arXiv:1612.04844, 2016."}, {"ref": "[27] Xiaojuan Qi, Renjie Liao, Jiaya Jia, Sanja Fidler, and Raquel Urtasun. 3d graph neural networks for rgbd semantic segmentation. In CVPR, pages 5199\u20135208, 2017."}, {"ref": "[28] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In NIPS, pages 91\u201399, 2015."}, {"ref": "[29] Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and MaxWelling. Modeling relational data with graph convolutional networks. arXiv preprint arXiv:1703.06103, 2017."}, {"ref": "[30] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014."}, {"ref": "[31] Qianru Sun, Bernt Schiele, and Mario Fritz. A domain based approach to social relation recognition. In ICCV, pages 435\u2013444, 2017."}, {"ref": "[32] Damien Teney, Lingqiao Liu, and Anton van den Hengel. Graph-structured representations for visual question answering. In CVPR, pages 3233\u20133241, 2017."}, {"ref": "[33] GangWang, Andrew Gallagher, Jiebo Luo, and David Forsyth. Seeing people in social context: Recognizing people and social relationships. ECCV, pages 169\u2013182, 2010."}, {"ref": "[34] Zhouxia Wang, Tianshui Chen, Guanbin Li, Ruijia Xu, and Liang Lin. Multi-label image recognition by recurrently discovering attentional regions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 464\u2013472, 2017."}, {"ref": "[35] Siyu Xia, Ming Shao, Jiebo Luo, and Yun Fu. Understanding kin relationships in a photo. TMM, 14(4):1046\u20131056, 2012."}, {"ref": "[36] Ning Zhang, Manohar Paluri, Yaniv Taigman, Rob Fergus, and Lubomir Bourdev. Beyond frontal faces: Improving person recognition using multiple cues. In CVPR, pages 4804\u20134813, 2015."}, {"ref": "[37] Yuke Zhu, Alireza Fathi, and Li Fei-Fei. Reasoning about object affordances in a knowledge base representation. In ECCV, pages 408\u2013424, 2014."}]}, {"author": ["Arushi Goel", "Keng Teck Ma", "Cheston Tan"], "title": "An End-to-End Network for Generating Social Relationship Graphs", "journal": "CVPR", "year": 2019, "DOI": "", "month": 3, "citations(google scholar)": 0, "abstract": "Socially-intelligent agents are of growing interest in artificial intelligence. To this end, we need systems that can understand social relationships in diverse social contexts. Inferring the social context in a given visual scene not only involves recognizing objects, but also demands a more in-depth understanding of the relationships and attributes of the people involved. To achieve this, one computational approach for representing human relationships and attributes is to use an explicit knowledge graph, which allows for high-level reasoning. We introduce a novel end-to-end-trainable neural network that is capable of generating a Social Relationship Graph - a structured, unified representation of social relationships and attributes - from a given input image. Our Social Relationship Graph Generation Network (SRG-GN) is the first to use memory cells like Gated Recurrent Units (GRUs) to iteratively update the social relationship states in a graph using scene and attribute context. The neural network exploits the recurrent connections among the GRUs to implement message passing between nodes and edges in the graph, and results in significant improvement over previous methods for social relationship recognition.", "keywords": ["None"], "reference_count": 28, "ccfClass": "A", "important": true, "references": [{"ref": "[1] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, G. Irving, M. Isard, et al. Tensorflow: a system for large-scale machine learning. In OSDI, volume 16, pages 265\u2013283, 2016."}, {"ref": "[2] P. Anderson, B. Fernando, M. Johnson, and S. Gould. Spice: Semantic propositional image caption evaluation. In ECCV, 2016."}, {"ref": "[3] D. B. Bugental. Acquisition of the algorithms of social life: A domain-based approach. Psychological Bulletin, 126(2):187\u2013219, 2000."}, {"ref": "[4] I. Chakraborty, H. Cheng, and O. Javed. 3d visual proxemics: Recognizing human interactions in 3d from a single image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3406\u20133413, 2013."}, {"ref": "[5] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. In NIPS 2014 Workshop on Deep Learning, December 2014, 2014."}, {"ref": "[6] R. Fang, K. D. Tang, N. Snavely, and T. Chen. Towards computational models of kinship verification. In Image Processing (ICIP), 2010 17th IEEE International Conference on, pages 1577\u20131580. IEEE, 2010."}, {"ref": "[7] Y. Fang, K. Kuan, J. Lin, C. Tan, and V. Chandrasekhar. Object detection meets knowledge graphs. In Proceedings of the 26th International Joint Conference on Artificial Intelligence, pages 1661\u20131667. AAAI Press, 2017."}, {"ref": "[8] C. Frith. Role of facial expressions in social interactions. Philosophical transactions of the royal society of London B: Biological sciences, 364(1535):3453\u20133458, 2009."}, {"ref": "[9] R. Herzig, M. Raboh, G. Chechik, J. Berant, and A. Globerson. Mapping images to scene graphs with permutationinvariant structured prediction. In Advances in Neural Information Processing Systems (NIPS), 2018."}, {"ref": "[10] J. Johnson, R. Krishna, M. Stark, L.-J. Li, D. A. Shamma, M. S. Bernstein, and L. Fei-Fei. Image retrieval using scene graphs. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, jun 2015."}, {"ref": "[11] R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen, Y. Kalantidis, L.-J. Li, D. A. Shamma, et al. Visual genome: Connecting language and vision using crowdsourced dense image annotations. International Journal of Computer Vision, 123(1):32\u201373, 2017."}, {"ref": "[12] J. Li, Y.Wong, Q. Zhao, and M. S. Kankanhalli. Dual-glance model for deciphering social relationships. In Proceedings of the IEEE International Conference on Computer Vision, pages 2650\u20132659, 2017."}, {"ref": "[13] Y. Li, W. Ouyang, B. Zhou, K. Wang, and X. Wang. Scene graph generation from objects, phrases and region captions. 2017 IEEE International Conference on Computer Vision (ICCV), pages 1270\u20131279, 2017."}, {"ref": "[14] C. Lu, R. Krishna, M. Bernstein, and L. Fei-Fei. Visual relationship detection with language priors. In European Conference on Computer Vision, pages 852\u2013869. Springer, 2016."}, {"ref": "[15] J. Lv, W. Liu, L. Zhou, B. Wu, and H. Ma. Multi-stream fusion model for social relation recognition from videos. In K. Schoeffmann, T. H. Chalidabhongse, C. W. Ngo, S. Aramvith, N. E. O\u2019Connor, Y.-S. Ho, M. Gabbouj, and A. Elgammal, editors, MultiMedia Modeling, pages 355\u2013 368, Cham, 2018. Springer International Publishing."}, {"ref": "[16] K. Marino, R. Salakhutdinov, and A. Gupta. The more you know: Using knowledge graphs for image classification. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, pages 20\u201328. IEEE, 2017."}, {"ref": "[17] S. J. Oh, R. Benenson, M. Fritz, and B. Schiele. Person recognition in personal photo collections. 2015 IEEE International Conference on Computer Vision (ICCV), pages 3862\u20133870, 2015."}, {"ref": "[18] V. Ramanathan, B. Yao, and L. Fei-Fei. Social role discovery in human events. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2475\u20132482, 2013."}, {"ref": "[19] J. P. Robinson, M. Shao, Y. Wu, H. Liu, T. Gillis, and Y. Fu. Visual kinship recognition of families in the wild. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018."}, {"ref": "[20] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. ICLR, 2015."}, {"ref": "[21] E. R. Smith and J. DeCoster. Dual-process models in social and cognitive psychology: Conceptual integration and links to underlying memory systems. Personality and social psychology review, 4(2):108\u2013131, 2000."}, {"ref": "[22] Q. Sun, M. Fritz, and B. Schiele. A domain based approach to social relation recognition. In CVPR, 2017."}, {"ref": "[23] D. Teney, L. Liu, and A. van den Hengel. Graph-structured representations for visual question answering. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3233\u20133241. IEEE, 2017."}, {"ref": "[24] G. Wang, A. Gallagher, J. Luo, and D. Forsyth. Seeing people in social context: Recognizing people and social relationships. In European conference on computer vision, pages 169\u2013182. Springer, 2010."}, {"ref": "[25] D. Xu, Y. Zhu, C. Choy, and L. Fei-Fei. Scene graph generation by iterative message passing. In Computer Vision and Pattern Recognition (CVPR), 2017."}, {"ref": "[26] R. Zellers, M. Yatskar, S. Thomson, and Y. Choi. Neural motifs: Scene graph parsing with global context. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5831\u20135840, 2018."}, {"ref": "[27] Z. Zhang, P. Luo, C.-C. Loy, and X. Tang. Learning social relation traits from face images. In Proceedings of the IEEE International Conference on Computer Vision, pages 3631\u2013 3639, 2015."}, {"ref": "[28] B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva. Learning deep features for scene recognition using places database. In Advances in neural information processing systems, pages 487\u2013495, 2014."}]}, {"author": ["Emanuel S\u00b4anchez Aimar", "Petia Radeva", "Mariella Dimiccoli"], "title": "SOCIAL RELATION RECOGNITION IN EGOCENTRIC PHOTOSTREAMS", "journal": "ICIP", "year": 2019, "DOI": "10.1109/ICIP.2019.8803634", "month": 5, "citations(google scholar)": 0, "abstract": "This paper proposes an approach to automatically categorize the social interactions of a user wearing a photo-camera 2fpm, by relying solely on what the camera is seeing. The problem is challenging due to the overwhelming complexity of social life and the extreme intra-class variability of social interactions captured under unconstrained conditions. We adopt the formalization proposed in Bugental's social theory, that groups human relations into five social domains with related categories. Our method is a new deep learning architecture that exploits the hierarchical structure of the label space and relies on a set of social attributes estimated at frame level to provide a semantic representation of social interactions. Experimental results on the new EgoSocialRelation dataset demonstrate the effectiveness of our proposal.", "keywords": ["Social relation recognition", "egocentric vision", "multi-task learning", "LSTM"], "reference_count": 28, "ccfClass": "C", "important": true, "references": [{"ref": "[1]  Debra Umberson and Jennifer Karas Montez, \"Social relationships and health: A flashpoint for health policy,\" Journal of health and social behavior, vol. 51, no. 1 suppl, pp. S54\u2013S66, 2010."}, {"ref": "[2]  V. Ramanathan, B. Yao, and L. Fei-Fei, \"Social role discovery in human events,\" in IEEE CVPR, 2013, pp. 2475\u20132482."}, {"ref": "[3] Afshin Dehghan, Enrique G Ortiz, Ruben Villegas, and Mubarak Shah, \"Who do i look like? determining parent-offspring resemblance via gated autoencoders,\" in IEEE CVPR, 2014, pp. 1757\u20131764."}, {"ref": "[4] Ana C Murillo, Iljung S Kwak, Lubomir Bourdev, David Kriegman, and Serge Belongie, \"Urban tribes: Analyzing group photos from a social perspective,\" in CVPRW. IEEE, 2012, pp. 28\u201335."}, {"ref": "[5] Ming Shao, Liangyue Li, and Yun Fu, \"What do you do? occupation recognition in a photo via social context,\" in ICCV IEEE, 2013, pp. 3631\u20133638."}, {"ref": "[6] Qianru Sun, Bernt Schiele, and Mario Fritz, \"A domain based approach to social relation recognition,\" in IEEE CVPR, 2017, pp. 21\u201326."}, {"ref": "[7] Maedeh Aghaei, Mariella Dimiccoli, Cristian Canton Ferrer, and Petia Radeva, \"Towards social pattern characterization in egocentric photo-streams,\" Computer Vision and Image Understanding, vol. 171, pp. 104\u2013117, 2018."}, {"ref": "[8] Marc Bolanos, Mariella Dimiccoli, and Petia Radeva, \"Toward storytelling from visual lifelogging: An overview,\" IEEE Transactions on Human-Machine Systems, vol. 47, no. 1, pp. 77\u201390, 2017."}, {"ref": "[9] Daphne Blunt Bugental, \"Acquisition of the algorithms of social life: a domain-based approach.,\" Psychological bulletin, vol. 126 2, pp. 187\u2013219, 2000."}, {"ref": "[10] Alireza Fathi, Jessica Hodgins, and James Rehg, \"Social interactions: A first-person perspective,\" pp. 1226\u2013 1233, 06 2012."}, {"ref": "[11] Jen-An Yang, Chia-Han Lee, Shao-Wen Yang, V Srinivasa Somayazulu, Yen-Kuang Chen, and Shao-Yi Chien, \"Wearable social camera: Egocentric video summarization for social interaction,\" in ICMEW IEEE, 2016, pp. 1\u20136."}, {"ref": "[12] Maedeh Aghaei, Mariella Dimiccoli, and Petia Radeva, \"Towards social interaction detection in egocentric photo-streams,\" in ICMV, 2015, vol. 9875."}, {"ref": "[13] Maedeh Aghaei, Mariella Dimiccoli, and Petia Radeva, \"With whom do i interact? detecting social interactions in egocentric photo-streams,\" in ICPR 2016. IEEE, 2016, pp. 2959\u20132964."}, {"ref": "[14] Sepp Hochreiter and J\u00a8urgen Schmidhuber, \"Long shortterm memory,\" Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997."}, {"ref": "[15] Mariella Dimiccoli, Marc Bola\u02dcnos, Estefania Talavera, Maedeh Aghaei, Stavri G Nikolov, and Petia Radeva, \"Sr-clustering: Semantic regularized clustering for egocentric photo streams segmentation,\" Computer Vision and Image Understanding, vol. 155, pp. 55\u201369, 2017."}, {"ref": "[16] N. Ruiz and J. M. Rehg, \"Dockerface: an easy to install and use Faster R-CNN face detector in a Docker container,\" ArXiv e-prints, Aug. 2017."}, {"ref": "[17] Seong Joon Oh, Rodrigo Benenson, Mario Fritz, and Bernt Schiele, \"Person recognition in personal photo collections,\" in ICCV IEEE, 2015, pp. 3862\u20133870."}, {"ref": "[18] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, \"Deep residual learning for image recognition,\" in IEEE CVPR, 2016, pp. 770\u2013778."}, {"ref": "[19] Alejandro Cartas, Juan Mar\u00b4\u0131n, Petia Radeva, and Mariella Dimiccoli, \"Batch-based activity recognition from egocentric photo-streams revisited,\" Pattern Analysis and Applications, vol. 21, no. 4, pp. 953\u2013965, 2018."}, {"ref": "[20] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell, \"Caffe: Convolutional architecture for fast feature embedding,\" in ACM Multimedia, 2014, pp. 675\u2013678."}, {"ref": "[21] Lubomir Bourdev, Subhransu Maji, and Jitendra Malik, \"Describing people: A poselet-based approach to attribute classification,\" in IEEE ICCV, 2012, pp. 1543\u2013 1550."}, {"ref": "[22] Shankar Setty, Moula Husain, Parisa Beham, Jyothi Gudavalli, Menaka Kandasamy, Radhesyam Vaddi, Vidyagouri Hemadri, JC Karure, Raja Raju, B Rajan, et al., \"Indian movie face database: a benchmark for face recognition under wide variations,\" in CVPRIPG. IEEE, 2013, pp. 1\u20135."}, {"ref": "[23] Li-Jia Li, David A. Shamma, Xiangnan Kong, Sina Jafarpour, Roelof van Zwol, and XuanhuiWang, \"Celebritynet: A social network constructed from large-scale online celebrity images,\" TOMCCAP, vol. 12, pp. 3:1\u2013 3:22, 2015."}, {"ref": "[24] Ricardo Cerri, Rodrigo C Barros, Andr\u00b4e CPLF de Carvalho, and Yaochu Jin, \"Reduction strategies for hierarchical multi-label classification in protein function prediction,\" BMC bioinformatics, vol. 17(1), pp. 373, 2016."}, {"ref": "[25] Sebastian Ruder, \"An overview of multi-task learning in deep neural networks.,\" CoRR, vol. abs/1706.05098, 2017."}, {"ref": "[26] Ron Kohavi, \"A study of cross-validation and bootstrap for accuracy estimation and model selection,\" in IJCAI - Volume 2, 1995, pp. 1137\u20131143."}, {"ref": "[27] Gary King and Langche Zeng, \"Logistic regression in rare events data,\" Political analysis, vol. 9, no. 2, pp. 137\u2013163, 2001."}, {"ref": "[28] Diederik P Kingma and Jimmy Ba, \"Adam: A method for stochastic optimization,\" arXiv preprint arXiv:1412.6980, 2014."}]}, {"author": ["Meng Zhang", "Xinchen Liu", "Wu Liu", "Anfu Zhou", "Huadong Ma", "Tao Mei"], "title": "MULTI-GRANULARITY REASONING FOR SOCIAL RELATION RECOGNITION FROM IMAGES", "journal": "ICME", "year": 2019, "DOI": "10.1109/ICME.2019.00279", "month": 1, "citations(google scholar)": 0, "abstract": "Discovering social relations in images can make machines better interpret the behavior of human beings. However, automatically recognizing social relations in images is a challenging task due to the significant gap between the domains of visual content and social relation. Existing studies separately process various features such as faces expressions, body appearance, and contextual objects, thus they cannot comprehensively capture the multi-granularity semantics, such as scenes, regional cues of persons, and interactions among persons and objects. To bridge the domain gap, we propose a Multi-Granularity Reasoning framework for social relation recognition from images. The global knowledge and mid-level details are learned from the whole scene and the regions of persons and objects, respectively. Most importantly, we explore the fine-granularity pose keypoints of persons to discover the interactions among persons and objects. Specifically, the pose-guided Person-Object Graph and Person-Pose Graph are proposed to model the actions from persons to object and the interactions between paired persons, respectively. Based on the graphs, social relation reasoning is performed by graph convolutional networks. Finally, the global features and reasoned knowledge are integrated as a comprehensive representation for social relation recognition. Extensive experiments on two public datasets show the effectiveness of the proposed framework.", "keywords": ["Social Relation Recognition", "Multi-Granularity Reasoning", "Pose-Guided Graph", "Graph Convolutional"], "reference_count": 28, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Qianru Sun, Bernt Schiele, and Mario Fritz, \"A domain based approach to social relation recognition,\" in CVPR, 2017, pp. 435\u2013444."}, {"ref": "[2] Gang Wang, Andrew C. Gallagher, Jiebo Luo, and David A. Forsyth, \"Seeing people in social context: Recognizing people and social relationships,\" in ECCV, 2010, pp. 169\u2013182."}, {"ref": "[3] Vignesh Ramanathan, Bangpeng Yao, and Fei-Fei Li, \"Social role discovery in human events,\" in CVPR, 2013, pp. 2475\u2013 2482."}, {"ref": "[4] Ting Yu, Ser-Nam Lim, Kedar A. Patwardhan, and Nils Krahnstoever, \"Monitoring, recognizing and discovering social networks,\" in CVPR, 2009, pp. 1462\u20131469."}, {"ref": "[5] Chuang Gan, Tianbao Yang, and Boqing Gong, \"Learning attributes equals multi-source domain generalization,\" in CVPR, 2016, pp. 87\u201397."}, {"ref": "[6] Junnan Li, Yongkang Wong, Qi Zhao, and Mohan S. Kankanhalli, \"Dual-glance model for deciphering social relationships,\" in ICCV, 2017, pp. 2669\u20132678."}, {"ref": "[7] Peng Wu, Weimin Ding, Zhidong Mao, and Daniel Tretter, \"Close & closer: Discover social relationship from photo collections,\" in ICME, 2009, pp. 1652\u20131655."}, {"ref": "[8] Chuang Gan, Naiyan Wang, Yi Yang, Dit-Yan Yeung, and Alex G Hauptmann, \"Devnet: A deep event network for multimedia event detection and evidence recounting,\" in CVPR, 2015, pp. 2568\u20132577."}, {"ref": "[9] Zhouxia Wang, Tianshui Chen, Jimmy S. J. Ren, Weihao Yu, Hui Cheng, and Liang Lin, \"Deep reasoning with knowledge graph for social relationship understanding,\" in IJCAI, 2018, pp. 1021\u20131028."}, {"ref": "[10] Zhanpeng Zhang, Ping Luo, Chen Change Loy, and Xiaoou Tang, \"Learning social relation traits from face images,\" in ICCV, 2015, pp. 3631\u20133639."}, {"ref": "[11] Chuang Gan, Chen Sun, Lixin Duan, and Boqing Gong, \"Webly-supervised video recognition by mutually voting for relevant web images and web video frames,\" in ECCV, 2016, pp. 849\u2013866."}, {"ref": "[12] Zhanpeng Zhang, Ping Luo, Chen Change Loy, and Xiaoou Tang, \"From facial expression recognition to interpersonal relation prediction,\" IJCV, vol. 126, no. 5, pp. 550\u2013569, 2018."}, {"ref": "[13] Lei Ding and Alper Yilmaz, \"Inferring social relations from visual concepts,\" in ICCV, 2011, pp. 699\u2013706."}, {"ref": "[14] Vignesh Ramanathan, Jonathan Huang, Sami Abu-El-Haija, Alexander N. Gorban, Kevin Murphy, and Li Fei-Fei, \"Detecting events and key actors in multi-person videos,\" in CVPR, 2016, pp. 3043\u20133053."}, {"ref": "[15] Timur M. Bagautdinov, Alexandre Alahi, Franc\u00b8ois Fleuret, Pascal Fua, and Silvio Savarese, \"Social scene understanding: End-to-end multi-person action localization and collective activity recognition,\" in CVPR, 2017, pp. 3425\u20133434."}, {"ref": "[16] Daphne Blunt Bugental, \"Acquisition of the algorithms of social life: A domain-based approach.,\" Psychological Bulletin, vol. 126, no. 2, pp. 187\u2013219, 2000."}, {"ref": "[17] Liang Lin, Xiaolong Wang, Wei Yang, and Jian-Huang Lai, \"Discriminatively trained and-or graph models for object shape detection,\" IEEE TPAMI, vol. 37, no. 5, pp. 959\u2013972, 2015."}, {"ref": "[18] Wei Liu, Yu-Gang Jiang, Jiebo Luo, and Shih-Fu Chang, \"Noise resistant graph ranking for improved web image search,\" in CVPR, 2011, pp. 849\u2013856."}, {"ref": "[19] Chuang Gan, Yi Yang, Linchao Zhu, Deli Zhao, and Yueting Zhuang, \"Recognizing an action using its name: A knowledgebased approach,\" International Journal of Computer Vision, vol. 120, no. 1, pp. 61\u201377, 2016."}, {"ref": "[20] Chuang Gan, Boqing Gong, Kun Liu, Hao Su, and Leonidas J Guibas, \"Geometry guided convolutional neural networks for self-supervised video representation learning,\" in CVPR, 2018, pp. 5589\u20135597."}, {"ref": "[21] Thomas N. Kipf and Max Welling, \"Semi-supervised classification with graph convolutional networks,\" in ICLR, 2017."}, {"ref": "[22] Xiaodan Liang, Xiaohui Shen, Jiashi Feng, Liang Lin, and Shuicheng Yan, \"Semantic object parsing with graph LSTM,\" in ECCV, 2016, pp. 125\u2013143."}, {"ref": "[23] Xiaojuan Qi, Renjie Liao, Jiaya Jia, Sanja Fidler, and Raquel Urtasun, \"3d graph neural networks for RGBD semantic segmentation,\" in ICCV, 2017, pp. 5209\u20135218."}, {"ref": "[24] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, \"Deep residual learning for image recognition,\" in CVPR, 2016, pp. 770\u2013778."}, {"ref": "[25] Kaiming He, Georgia Gkioxari, Piotr Doll\u00b4ar, and Ross B. Girshick, \"Mask R-CNN,\" in ICCV, 2017, pp. 2980\u20132988."}, {"ref": "[26] Bin Xiao, Haiping Wu, and Yichen Wei, \"Simple baselines for human pose estimation and tracking,\" in ECCV, 2018, pp. 472\u2013487."}, {"ref": "[27] Cewu Lu, Ranjay Krishna, Michael S. Bernstein, and Fei-Fei Li, \"Visual relationship detection with language priors,\" in ECCV, 2016, pp. 852\u2013869."}, {"ref": "[28] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel, \"Gated graph sequence neural networks,\" in ICLR, 2016."}]}, {"author": ["Chung-Yi Weng", "Wei-Ta Chu", "Ja-Ling Wu"], "title": "RoleNet: Movie Analysis from the Perspective of Social Networks", "journal": "IEEE MM", "year": 2009, "DOI": "10.1109/TMM.2008.2009684", "month": 1, "citations(google scholar)": 145, "abstract": "With the idea of social network analysis, we propose a novel way to analyze movie videos from the perspective of social relationships rather than audiovisual features. To appropriately describe role's relationships in movies, we devise a method to quantify relations and construct role's social networks, called RoleNet. Based on RoleNet, we are able to perform semantic analysis that goes beyond conventional feature-based approaches. In this work, social relations between roles are used to be the context information of video scenes, and leading roles and the corresponding communities can be automatically determined. The results of community identification provide new alternatives in media management and browsing. Moreover, by describing video scenes with role's context, social-relation-based story segmentation method is developed to pave a new way for this widely-studied topic. Experimental results show the effectiveness of leading role determination and community identification. We also demonstrate that the social-based story segmentation approach works much better than the conventional tempo-based method. Finally, we give extensive discussions and state that the proposed ideas provide insights into context-based video analysis.", "keywords": ["Community analysis", "movie understanding", "social network analysis", "story segmentation"], "reference_count": 39, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Z. Rasheed Y. Sheikh M. Shah \"On the use of computable features for film classification\" IEEE Trans. Circuits Syst. Video Technol. vol. 15 no. 1 pp. 52-64 Jan. 2005."}, {"ref": "[2] B. Adams C. Dorai S. Venkatesh \"Toward automatic extraction and expression of expressive elements from motion pictures: Tempo\" IEEE Trans. Multimedia vol. 4 no. 4 pp. 472-481 2002."}, {"ref": "[3] J. Vendrig M. Worring \"Systematic evaluation of logical story unit segmentation\" IEEE Trans. Multimedia vol. 4 no. 4 pp. 492-499 2002."}, {"ref": "[4] Y. Li S.-H. Lee C.-H. Yeh C.-C. J. Kuo \"Techniques for movie content analysis and skimming: Tutorial and overview on video abstraction techniques\" IEEE Signal Process. Mag. vol. 23 no. 2 pp. 79-89 2006."}, {"ref": "[5] B.T. Truong S. Venkatesh \"Video abstraction: A systematic review and classification\" ACM Trans. Multimedia Comput. Commun. and Applic. vol. 3 no. 1 2007."}, {"ref": "[6] B. Jung T. Kwak J. Song Y. Lee \"Narrative abstraction model for story-oriented video\" Proce. ACM Multimedia Conf. pp. 828-835 2004."}, {"ref": "[7] A.F. Smeaton B. Lehane N.E. O'Connor C. Brady G. Craig \"Automatically selecting shots for action movie trailers\" Proc. ACM Int. Workshop on Multimedia Information Retrieval pp. 231-238 2006."}, {"ref": "[8] H.-W. Chen J.-H. Kuo W.-T. Chu J.-L. Wu \"Action movies segmentation and summarization based on tempo analysis\" Proc. ACM SIGMM Int. Workshop on Multimedia Information Retrieval pp. 251-258 2004."}, {"ref": "[9] H.L. Wang L.-F. Cheong \"Affective understanding in film\" IEEE Trans. Circuits Syst. Video Technol. vol. 16 no. 6 pp. 689-704 Jun. 2006."}, {"ref": "[10] A. Hanjalic L.-Q. Xu \"Affective video content representation and modeling\" IEEE Transactions on Multimedia vol. 7 no. 1 pp. 143-154 2005."}, {"ref": "[11] J. Scott Social Network Analysis: A Handbook Newbury Park 1991."}, {"ref": "[12] R. Guimera L. Danon A. Diaz-Guilera F. Giralt A. Arenas \"Self-similar community structure in a network of human interactions\" Phys. Rev. vol. 68 pp. 065103(R) 2003."}, {"ref": "[13] A.E. Krause K.A. Frank D.M. Mason R.E. Ulanowicz W.W. Taylor \"Compartments revealed in food-web structure\" Nature vol. 426 pp. 282-285 2003."}, {"ref": "[14] Y. Boykov V. Kolmogorov \"An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 26 no. 9 pp. 1124-1137 Sep. 2004."}, {"ref": "[15] Z. Rasheed M. Shah \"Scene detection in Hollywood movies and TV shows\" Proc. IEEE Computer Society Confe. Computer Vision and Pattern Recognition vol. 2 pp. 343-348 2003."}, {"ref": "[16] X. Zhu A.K. Elmagarmid X. Xue L. Wu A.C. Catlin \"InsightVideo: Toward hierarchical video content organization for efficient browsing summarization and retrieval\" IEEE Trans. Multimedia vol. 7 no. 4 pp. 648-666 Aug. 2005."}, {"ref": "[17] M. Yeung B.-L. Yeo B. Liu \"Segmentation of video by clustering and graph analysis\" Comput. Vis. Image Understand. vol. 71 no. 1 pp. 94-109 1998."}, {"ref": "[18] W. H. Hsu S.-F. Chang \"A statistical framework for fusing mid-level perceptual features in news story segmentation\" Proc. IEEE Int. Conf. Multimedia &amp; Expo vol. 2 pp. 413-416 2003."}, {"ref": "[19] C. Dorai S. Venkatesh \"Computational media aesthetics: Finding meaning beautiful\" IEEE Multimedia vol. 8 no. 4 pp. 10-12 2001."}, {"ref": "[20] C.-Y. Weng W.-T. Chu J.-L. Wu \"Movie analysis based on roles' social network\" Proc. IEEE Int. Conf. Multimedia &amp; Expo. pp. 1403-1406 2006."}, {"ref": "[21] C.-Y. Weng W.-T. Chu J.-L. Wu \"RoleNet: Treat a movie as a small society\" Proc. ACM SIGMM Int. Workshop on Multimedia Information Retrieval pp. 51-60 2007."}, {"ref": "[22] A. Vinciarelli F. Fernandez S. Favre \"Semantic segmentation of radio programs using social network analysis and duration distribution modeling\" Proc. IEEE Int. Conf. Multimedia &amp; Expo. pp. 779-782 2006."}, {"ref": "[23] A. Vinciarelli S. Favre \"Broadcast news story segmentation using social network analysis and hidden Markov models\" Proc. ACM Multimedia pp. 261-264 2007."}, {"ref": "[24] R. Rienks D. Zhang W. Post \"Detection and application of influence rankings in small group meetings\" Proc. Int. Conf. Multimodal Interfaces pp. 257-264 2006."}, {"ref": "[25] Open Source Computer Vision Library."}, {"ref": "[26] A. V. Nefian M. H. III. Hayes \"An embedded HMM-based approach for face detection and recognition\" Proc. IEEE Int. Conf. Acoustics Speech and Signal Processing vol. 6 pp. 3553-3556 1999."}, {"ref": "[27] Y. Li S. Narayanan C.-C. J. Kuo \"Content-based movie analysis and indexing based on audiovisual cues\" IEEE Trans. Circuits Syst. Video Technol. vol. 14 no. 8 pp. 1073-1085 Aug. 2004."}, {"ref": "[28] W.-T. Chu W.-H. Cheng J. Y.-J. Hsu J.-L. Wu \"Towards semantic indexing and retrieval using hierarchical audio models\" ACM Multimedia Syst. J. vol. 10 no. 6 pp. 570-583 2005."}, {"ref": "[29] H.J. Zhang C.Y. Low S.W. Smoliar J.H. Wu \"Video parsing retrieval and browsing: An integrated and content-based solution\" Proc. ACM Multimedia Conf. pp. 15-24 1995."}, {"ref": "[30] R. Lienhart \"Comparison of automatic shot boundary detection algorithms\" Proc. SPIE vol. 3656 pp. 290-301 1999."}, {"ref": "[31] C. G. M. Snoek M. Worring J.-M. Geusebroek D. C. Koelma F. J. Seinstra A. W. M. Smeulders \"The semantic pathfinder: Using an authoring metaphor for generic multimedia indexing\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 28 no. 10 pp. 1678-1689 Oct. 2006."}, {"ref": "[32] M. Naphade J. R. Smith J. Tesic S.-F. Chang W. Hsu L. Kennedy A. Hauptmann J. Curtis \"Large-scale concept ontology for multimedia\" IEEE Multimedia Mag. vol. 13 no. 3 pp. 86-91 2006."}, {"ref": "[33] L.D. Giannetti Understanding Movies NJ Englewood Cliffs:Prentice-Hall 1999."}, {"ref": "[34] D. Bordwell Narration In The Fiction Film WI Madison:Univ. Wisconsin Press 1985."}, {"ref": "[35] N.P. Garg S. Favre H. Salamin D. Hakkani Tur A. Vinciarelli \"Role recognition for meeting participants: An approach based on lexical information and social network analysis\" Proc. ACM Multimedia Conf. pp. 693-696 2008."}, {"ref": "[36] H. Hung D. Jayagopi C. Yeo G. Friendland S. Ba J. Ramchandran N. Mirghafori D. Gatica-Perez \"Using audio and video features to classify the most dominant person in a group meeting\" Proc. ACM Multimedia Conf. pp. 835-838 2007."}, {"ref": "[37] K. Albrecht Social Intelligence: The New Science of Success New York:Wiley 2005."}, {"ref": "[38] A. Pentland \"Social signal processing\" IEEE Signal Process. Mag. vol. 24 no. 4 pp. 108-111 Jul. 2007."}, {"ref": "[39] A. Vinciarelli M. Pantic H. Bourlard A. Pentland \"Social signal processing: State-of-the-art and future perspectives of an emerging domain\" Proc. ACM Multimedia Conf. pp. 1061-1070 2008."}]}, {"author": ["Lei Ding", "Alper Yilmaz"], "title": "Learning Relations among Movie Characters: A Social Network Perspective", "journal": "ECCV", "year": 2010, "DOI": "10.1007/978-3-642-15561-1_30", "month": 9, "citations(google scholar)": 59, "abstract": "If you have ever watched movies or television shows, you know how easy it is to tell the good characters from the bad ones. Little, however, is known \u201cwhether\u201d or \u201chow\u201d computers can achieve such high-level understanding of movies. In this paper, we take the first step towards learning the relations among movie characters using visual and auditory cues. Specifically, we use support vector regression to estimate local characterization of adverseness at the scene level. Such local properties are then synthesized via statistical learning based on Gaussian processes to derive the affinity between the movie characters. Once the affinity is learned, we perform social network analysis to find communities of characters and identify the leader of each community. We experimentally demonstrate that the relations among characters can be determined with reasonable accuracy from the movie content.", "keywords": ["Social Network", "Support Vector Regression", "Social Network Analysis", "Learn Relation", "Eigenvector Centrality"], "reference_count": 24, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Ali, S., Basharat, A., Shah, M.: Chaotic invariants for human action recognition. In: ICCV (2007)"}, {"ref": "[2] Alon, J., Athitsos, V., Yuan, Q., Sclaroff, S.: A unified framework for gesture recognition and spatiotemporal gesture segmentation. IEEE Trans. on PAMI 31(9), 1685\u20131699 (2009)"}, {"ref": "[3] Arandjelovi\u0107, O., Zisserman, A.: Automatic face recognition for film character retrieval in feature-length films. In: CIVR (2005)"}, {"ref": "[4] Chen, J., Zaiane, O., Goebel, R.: Detecting communities in social networks using max-min modularity. In: SDM (2009)"}, {"ref": "[5] Cour, T., Jordan, C., Miltsakaki, E., Taskar, B.: Movie/script: Alignment and parsingof video and text transcription. In: Forsyth, D., Torr, P., Zisserman, A. (eds.) ECCV 2008, Part IV. LNCS, vol. 5305, pp. 158\u2013171. Springer, Heidelberg (2008)"}, {"ref": "[6] Ding, L., Fan, Q., Hsiao, J., Pankanti, S.: Graph based event detection from realistic videos using weak feature correspondence. In: ICASSP (2010)"}, {"ref": "[7] Efros, A.A., Berg, A.C., Mori, G., Malik, J.: Recognizing action at a distance. In: ICCV (2003)"}, {"ref": "[8] Fathi, A., Mori, G.: Action recognition by learning mid-level motion features. In: CVPR (2008)"}, {"ref": "[9] Freeman, L.: Centrality in social networks: Conceptual clarification. Social Networks 1(3), 215\u2013239 (1979)"}, {"ref": "[10] Ge, W., Collins, R., Ruback, B.: Automatically detecting the small group structure of a crowd. In: WACV (2009)"}, {"ref": "[11] Jiang, H., Fels, S., Little, J.: A linear programming approach for multiple object tracking. In: CVPR (2007)"}, {"ref": "[12] Laptev, I., Lindeberg, T.: Space-time interest points. In: ICCV (2003)"}, {"ref": "[13] Lin, J., Wang, W.: Weakly-supervised violence detection in movies with audio and video based co-training. In: PCM (2009)"}, {"ref": "[14] Lu, Z., Carreira-Perpinan, M.A.: Constrained spectral clustering through affinity propagation. In: CVPR (2008)"}, {"ref": "[15] Lucas, B.D., Kanade, T.: An iterative image registration technique with an application to stereo vision. In: IJCAI (1981)"}, {"ref": "[16] Merriam-Webster: Merriam-webster online dictionary (2010), http://www.merriam-webster.com/dictionary"}, {"ref": "[17] Newman, M.E.J.: Modularity and community structure in networks. PNAS 103(23), 8577\u20138582 (2006)"}, {"ref": "[18] Rasheed, Z., Shah, M.: Movie genre classification by exploiting audio-visual features of previews. In: ICPR (2002)"}, {"ref": "[19] Ruhnau, B.: Eigenvector-centrality? a node-centrality. Social Networks 22(4), 357\u2013365 (2000)"}, {"ref": "[20] Shi, J., Tomasi, C.: Good features to track. In: CVPR (1994)"}, {"ref": "[21] Smola, A.J., Sch\u00f6lkopf, B.: A tutorial on support vector regression. Statistics and Computing 14(3), 199\u2013222 (2004)"}, {"ref": "[22] Wasserman, S., Faust, K., Iacobucci, D.: Social Network Analysis: Methods and Applications. Cambridge University Press, Cambridge (1994)"}, {"ref": "[23] Yu, T., Lim, S.N., Patwardhan, K., Krahnstoever, N.: Monitoring, recognizing and discovering social networks. In: CVPR (2009)"}, {"ref": "[24] Zhai, Y., Shah, M.: Video scene segmentation using markov chain monte carlo. IEEE Trans. on Multimedia 8(4), 686\u2013697 (2006)."}]}, {"author": ["Kun Yuan", "Hongxun Yao", "Rongrong Ji", "Xiaoshuai Sun"], "title": "MINING ACTOR CORRELATIONS WITH HIERARCHICAL CONCURRENCE PARSING", "journal": "ICASSP", "year": 2010, "DOI": "10.1109/ICASSP.2010.5494953", "month": 3, "citations(google scholar)": 5, "abstract": "Mining actor correlations from TV series enables semantic level video understanding and facilitates users to conduct correlation-based query. In this paper, we introduce a graph-based actor correlations mining framework, which serves as the first attempt for effective actor association presentation and concurrence search. We leverage face detection and tracking to locate actors with 2D-PCA detector as pretreatment. To measure the actor association into a unified graph, we propose a context-based actor correlations hierarchical parsing approach, which considers video structure and hierarchical concurrence to refine actor association in our graph modeling. We not only can accomplish actor correlations mining, but also can acquire higher semantic information according to concurrence change. We present the actor correlation mining results in a graph-based interface to enable efficient users' navigation and search.", "keywords": ["Video Content Analysis", "Actor Correlations Analysis", "Video Context"], "reference_count": 10, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Y. Gao T. Wang J. Li \"Cast indexing for videos by ncuts and Page ranking\" ACM CIVR pp. 441-447 2007."}, {"ref": "[2] R. Ji X. Sun H. Yao \"Attention-driven action retrieval with dtw-based 3D descriptor matching\" ACM SIGMM pp. 619-622 2008."}, {"ref": "[3] X. Sun R. Ji H. Yao \"Place retrieval with graph-based place-view model\" ACM MIR pp. 268-275 2008."}, {"ref": "[4] [online] Available: http://renlifang.msra.cn/GuanxiMap.aspx."}, {"ref": "[5] P. Viola M. Jones \"Rapid object detection using a boosted cascade of simple features\" CVPR pp. 511-518 2001."}, {"ref": "[6] D. Ross J. Lim R. S. Lin M-H. Yang \"Incremental learning for robust visual tracking. IJCV\" vol. 77 pp. 1-3 2008."}, {"ref": "[7] J. Yang D. Zhang \"Two-dimensional PCA: a new approach to appearance-based face representation and recognition\" IEEE Trans. on PAMI vol. 26 no. 1 pp. 131-137 2004."}, {"ref": "[8] J. Yuan J Li F Lin B Zhang \"A unified shot boundary detection framework based on graph partition model\" ACM SIGMM pp. 539-542 2005."}, {"ref": "[9] Z. Rasheed M. Shah \"Detection and representation of scenes in videos\" IEEE Trans. on Multimedia vol. 7 no. 6 pp. 1097-1105 2005."}, {"ref": "[10] K. Yuan R. Ji H. Yao \"VisualCor system: Search actor correlations in TV Series\" ACM ICIMCS pp. 227-233 2009."}]}, {"author": ["Mei-Chen Yeh", "Ming-Chi Tseng", "Wen-Po Wu"], "title": "Automatic Social Network Construction from Movies Using Film-Editing Cues", "journal": "ICMEW", "year": 2012, "DOI": "10.1109/ICMEW.2012.48", "month": 7, "citations(google scholar)": 6, "abstract": "In this paper, we investigate the problem of automatically constructing characters' social network from movies. Unlike existing approaches that use co-appearance information to measure the relationship between two characters, we argue that a method that describes the characters' interaction, rather than the co-appearance, makes more sense. We propose a new scheme that quantifies the interaction of characters by the use of film-editing cues, based on which we construct the characters' social network. Experiments on real-world data validate the effectiveness of the proposed method. In addition, we show an application of discovering characters' social clusters enabled by the automatically constructed social network.", "keywords": ["Social network", "face clustering", "social cluster discovery"], "reference_count": 14, "ccfClass": "", "important": true, "references": [{"ref": "[1] T. Ahonen A. Hadid and M. Pietik\u00e4inen \"Face description with local binary pattern: application to face recognition \" IEEE Transactions on Pattern Analysis and Machine Intelligence vol. 28 no. 12 pp. 2037-2041 2006."}, {"ref": "[2] B. Coen and K. Joep \"Algorithm 457: finding all cliques of an undirected graph \" Communications of the ACM vol. 16 pp.575-577 1973."}, {"ref": "[3] T. Cour B. Sapp A. Nagle and B. Taskar \"Taking pictures: temporal grouping and dialog-supervised person recognition \" in Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition 2010."}, {"ref": "[4] B. J. Frey and D. Dueck \"Clustering by passing messages between data points \" Science pp. 972-976 2007."}, {"ref": "[5] C. Liang Y. Zhang J. Cheng C. Xu and H. Lu \"A novel role-based movie scene segmentation method \" in Proceedings of Pacific-Rim Conference on Multimedia pp. 917-922 2009"}, {"ref": "[6] M. Plantie and M. Crampes \"From photo networks to social networks creation and use of a social network derived with photos \" in Proceedings of ACM International Conference on Multimedia 2010."}, {"ref": "[7] T. J. Smith \"An attentional theory of continuity editing \" PhD thesis University of Edinburgh 2005."}, {"ref": "[8] Z. Stone T. Zickler T. Darrell \"Autotagging facebook: social network context improves photo annotation \" in IEEE Workshop on Internet Vision 2008."}, {"ref": "[9] A. Vinciarelli and S. Favre \"Broadcast news story segmentation using social network analysis and hidden Markov models \" in Proceedings of ACM International Conference on Multimedia 2007."}, {"ref": "[10] C. -Y. Weng W. -T. Chu and J. -L. Wu \"RoleNet: movie analysis from the perspective of social network \" IEEE Transactions on Multimedia vol. 11 no. 2 pp. 256-271 2009."}, {"ref": "[11] P. Wu and F. Tang \"Improving face clustering using social context \" in Proceedings of ACM International Conference on Multimedia 2010."}, {"ref": "[12] P. Wu and D. Tretter \"Close &amp; closer: social cluster and closeness from photo collections \" in Proceedings of ACM International Conference on Multimedia 2009."}, {"ref": "[13] K. Yuan H. Yao R. Ji and X. Sun \"Mining actor correlations with hierarchical concurrence parsing \" in Proceedings of IEEE International Conference on Acoustics Speech and Signal Processing 2010."}, {"ref": "[14] Open Source Computer Vision Library. Available: http://www.intel.com/ technology/computing/opencv."}]}, {"author": ["Yi-I Chiu", "Pau-Choo Chung", "Chun-Rong Huang"], "title": "Character Relationship Analysis in Movies Using Face Tracks", "journal": "MVA", "year": 2013, "DOI": "", "month": 5, "citations(google scholar)": 0, "abstract": "In this paper, we propose using face tracks to model faces of the same character under variant head motions and scene illuminations. A novel measurement is developed to assess the similarity between two face tracks with different lengths. Then, based on temporal constraints, the character relationship graph of a movie is built. As shown in the experiments, our method can successfully retrieve character relationships from movies in real-time without any prior information or training.", "keywords": ["None"], "reference_count": 12, "ccfClass": "", "important": true, "references": [{"ref": "[1] C.-Y.Weng, W.-T. Chu, and J.-L.Wu, \"Rolenet: Movie analysis from the perspective of social networks,\" IEEE Trans. on Multimedia, vol. 11, no. 2, February 2009."}, {"ref": "[2] Y.-F. Zhang, C. Xu, H. Lu, and Y.-M. Huang, \"Character identification in feature-length films using global face-name matching,\" IEEE Trans. on Multimedia, 2009."}, {"ref": "[3] L. Xie, A. Natsev, M. Hill, J. R. Kender, and J. R. Smith, \"Visual memes in social media: Tracking realworld news in youtube videos,\" in In Proceedings of the 19th ACM international conference on Multimedia, 2011, pp. 53\u201362."}, {"ref": "[4] Z. Xiong, X. Zhou, Q. Tian, R. Yong, and T. S. Huang, \"Semantic retrieval of video - review of research on video retrieval in meetings, movies and broadcast news, and sports,\" IEEE Signal Processing Magazine, vol. 23, no. 2, pp. 18\u201327, 2006."}, {"ref": "[5] H. Sundaram, L. Xie, M. D. Choudhury, Y.-R. Lin, and A. Natsev, \"Multimedia semantics: Interactions between content and community,\" in Proceeding of the IEEE, vol. 100, no. 9, Sept. 2012, pp. 2737\u20132758."}, {"ref": "[6] M. Everingham, J. Sivic, and A. Zisserman, \"\"hello! my name is... buffy\" \u2013 automatic naming of characters in tv video,\" in Proceedings of the British Machine Vision Conference, 2006."}, {"ref": "[7] M. Xu, X. Yuan, J. Shen, and S. Yan, \"Cast2face: Character identification in movie with actor-character correspondence,\" in in Proceedings of ACM Multimedia, 2010, pp. 831\u2013834."}, {"ref": "[8] Z. Rasheed and M. Shah, \"Detection and representation of scenes in videos,\" IEEE Trans. on Multimedia, vol. 7, no. 6, pp. 1097\u20131105, 2005."}, {"ref": "[9] A. Bjorck and G. H. Golub, Numerical methods for computing angles between linear subspaces. Mathematics of Computation, 1973, vol. 27, no. 579-594."}, {"ref": "[10] B. S. Everitt, S. Landau, and M. Leese, Cluster Analysis. London: Arnold., 2001."}, {"ref": "[11] P. Viola and M. Jones, \"Rapid object detection using a boosted cascade of simple features,\" in IEEE Conference on Computer Vision and Pattern Recognition, 2001."}, {"ref": "[12] C.-R. Huang, C.-S. Chen, and P.-C. Chung, \"Contrast context histogram - an efficient discriminating local descriptor for object recognition and image matching,\" Pattern Recognition, vol. 41, no. 10, pp. 3071\u20133077, 2008."}]}, {"author": ["Jeremiah R. Barr", "Leonardo A. Cament", "Kevin W. Bowyer", "Patrick J. Flynn"], "title": "Active Clustering with Ensembles for Social Structure Extraction", "journal": "WACV", "year": 2014, "DOI": "10.1109/WACV.2014.6835999", "month": 3, "citations(google scholar)": 19, "abstract": "We introduce a method for extracting the social network structure for the persons appearing in a set of video clips. Individuals are unknown, and are not matched against known enrollments. An identity cluster representing an individual is formed by grouping similar-appearing faces from different videos. Each identity cluster is represented by a node in the social network. Two nodes are linked if the faces from their clusters appeared together in one or more video frames. Our approach incorporates a novel active clustering technique to create more accurate identity clusters based on feedback from the user about ambiguously matched faces. The final output consists of one or more network structures that represent the social group(s), and a list of persons who potentially connect multiple social groups. Our results demonstrate the efficacy of the proposed clustering algorithm and network analysis techniques.", "keywords": ["None"], "reference_count": 23, "ccfClass": "", "important": true, "references": [{"ref": "[1] Cisco Flip Video. http://support.theflip.com/ en-us/home/ retrieved August 14 2013."}, {"ref": "[2] VeriLook SDK. http://www.neurotechnology. com/verilook.html retrieved August 13 2013."}, {"ref": "[3] A.Vinciarelli M.Pantic and H.Bourlard. Social signal processing: Survey of an emerging domain. Image and Vision Computing Journal 27(12):1743-1759 2009."}, {"ref": "[4] S. Basu A. Banerjee and R. J. Mooney. Active semisupervision for pairwise constrained clustering. Proc. of the SIAM International Conference on Data Mining pages 333-344 2004."}, {"ref": "[5] L. Ding and A. Yilmaz. Learning relations among movie characters: A social network perspective. Proc. of the Euro-pean Conference on Computer Vision pages 410-423 2010."}, {"ref": "[6] S. Favre H. Salamin J. Dines and A. Vinciarelli. Role recognition in multiparty recordings using social affiliation networks and discrete distributions. Proc. of the ACM Inter-national Conference on Multimodal Interfaces pages 29-36 2008."}, {"ref": "[7] A. Fred. Finding consistent clusters in data partitions. Mul-Tiple Classifier Systems pages 309-318 20014"}, {"ref": "[8] A. Fred and A. Jain. Data clustering using evidence accumulation. Proc. of the International Conference on Pattern Recognition 4:276-280 2002."}, {"ref": "[9] Y. Freund H. Seung E. Shamir and N. Tishby. Selective samping using the query by committee algorithm. Machine Learning (28):133-168 1997."}, {"ref": "[10] N. Grira M. Crucianu and N. Boujemaa. Active semisupervised fuzzy clustering for image database categorization. Proc. of the ACM Workshop on Multimedia Information Retrieval pages 9-16 2005."}, {"ref": "[11] T. Hofmann and J. Buhmann. Active data clustering. Ad-vances in Neural Information Processing Systems (NIPS) 10:528-534 1998."}, {"ref": "[12] Y. Huang and T. Mitchell. Text clustering with extended user feedback. Proc. of the ACM SIGIR Conference on Research and Development in Information Retrieval pages 413-420 2006."}, {"ref": "[13] W. Hwang T. Kim M. Ramanathan and A. Zhang. Bridging centrality: Graph mining from element level to group level. Proc. of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining pages 336-344 2008."}, {"ref": "[14] A. Murillo I. Kwak L. Bourdev D. Kriegman and S. Belongie. Urban tribes: Analyzing group photos from a social perspective. Proc. of the IEEE Conference on Com-puter Vision and Pattern Recognition Workshops pages 28-35 2012."}, {"ref": "[15] M. E. J. Newman. Finding community structure in networks using the eigenvectors of matrices. Physical Review E 74(036104):1-22 2006."}, {"ref": "[16] N.Vretos V.Solachidis and I.Pitas. A robust face clustering algorithm based on mutual information using tracking information. Proc. of the Panhellenic Conference on Informatics 2007."}, {"ref": "[17] B. Settles. Active learning literature survey. University of Wisconsin Madison Tech. Report 2010."}, {"ref": "[18] C. Tomasi and T. Kanade. Detection and tracking of point features. Carnegie Mellon University Technical Report CMU-CS-91-132 1991."}, {"ref": "[19] A. Topchy M. Law A. Jain and A. Fred. Analysis of consensus partition in cluster ensemble. Proc. of the IEEE Inter-national Conference on Data Mining pages 225-232 2004."}, {"ref": "[20] K. Wagstaff. Intelligent clustering with instance-level constraints. Cornell University PhD Thesis 2002."}, {"ref": "[21] S. Wasserman and K. Faust. Social network analysis: Meth-ods and applications volume 8. Cambridge University Press 1994."}, {"ref": "[22] C. Weng W. Chu and J. Wu. Movie analysis based on roles social network. Proc. of IEEE International Conference on Multimedia and Expo pages 1403-1406 2007."}, {"ref": "[23] T. Yu S.-N. Lim K. Patwardhan and N. Krahnstoever. Monitoring recognizing and discovering social networks. Proc. of the Conference on Computer Vision and Pattern Recogni-Tion pages 1462-1469 2009."}]}, {"author": ["Chang-Jun Nan", "Kyung-Min Kim", "and Byoung-Tak Zhang"], "title": "Social Network Analysis of TV Drama Characters via Deep Concept Hierarchies", "journal": "ASONAM", "year": 2015, "DOI": "10.1145/2808797.2809306", "month": 8, "citations(google scholar)": 13, "abstract": "TV drama is a kind of big data, containing enormous knowledge of modern human society. As the character-centered stories unfold, diverse knowledge, such as economics, politics and the culture, is displayed. However, unless we have efficient dynamic multi-modal data processing and picture processing methods, we cannot analyze drama data effectively. Here, we adopt the recently proposed deep concept hierarchies (DCH) and convolutional-recursive neural network (C-RNN) models to analyze the social network between the drama characters. DCH uses multi hierarchies structure to translate the vision-language concepts of drama characters into diversified abstract concepts, and utilizes Markov Chain Monte Carlo algorithm to improve the retrieval efficiency of organizing conceptual spaces. Adopting approximately 4400-minute data of TV drama - Friends, we process face recognition on the characters by using convolutional-recursive deep learning model. Then we establish the social network between the characters by deep concept hierarchies model and analyze their affinity and the change of social network while the stories unfold.", "keywords": ["social network analysis", "concept learning", "deep model", "concept drift"], "reference_count": 21, "ccfClass": "", "important": true, "references": [{"ref": "[1] B. J. Biddle \"Recent development in role theory\" Annual Review of Sociology pp. 12: 67-92 1986."}, {"ref": "[2] J.-W. Ha K.-M. Kim B.-T. Zhang \"Automated construction of visual-linguistic knowledge via concept learning from cartoon videos\" Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence pp. 522-528 2015."}, {"ref": "[3] A. N. Meltzoff \"Toward a Developmental Cognitive Science: The Implications of Cross-modal Matching and Imitation for Development of Representation and Memory in Infancy\" Annual New York Academy Science pp. 608 1990."}, {"ref": "[4] A. Karpathy G. Toderici S. Shetty T. Leung R. Sukthankar L. Fei-Fei \"Large-Scale Video Classification with Convolutional Neural Networks\" IEEE Conference on Computer Vision and Pattern Recognition pp. 1725-1732 2014."}, {"ref": "[5] I.-H. Jhuo D.T. Lee \"Video Event Detection via Multi-modality Deep Learning\" International Conference on Pattern Recognition pp. 666-671 2014."}, {"ref": "[6] H.-W. Chen J.-H. Kuo W.-T. Chu J.-L. Wu \"Action movies segmentation and summarization based on tempo analysis\" the 6th ACM SIGMM international workshop on Multimedia information retrieval pp. 251-258 2004."}, {"ref": "[7] C.-W. Wang W.-H. Cheng J.-C. Chen S.-S. Yang J.-L. Wu \"Film narrative exploration through the analysis of aesthetic elements\" the 13th international conference on Multimedia Modeling - Volume Part I pp. 606-615 2007."}, {"ref": "[8] D. Tran L. Bourdev R. Fergus L. Torresani M. Paluri \"C3D: Generic Features for Video Analysis\" IEEE Conference on Computer Vision and Pattern Recognition 2014."}, {"ref": "[9] V. Ramanathan B. Yao L. Fei-Fei \"Social Role Discovery in Human Events\" IEEE Conference on Computer Vision and Pattern Recognition pp. 2475-2482 2013."}, {"ref": "[10] Y.-F. Zhang C.-S. Xu H.-Q. Lu Y-M Huang \"Character Identification in Feature-Length Films Using Global Face-Name Matching\" IEEE Transactions on Multimedia pp. 1276-1288 2009."}, {"ref": "[11] C.-Y. Weng W.-T. Chu J.-L. Wu \"RoleNet: Movie Analysis from the Perspective of Social Networks\" IEEE Transactions on Multimedia pp. 256-271 2009."}, {"ref": "[12] T. Lan L. Sigal G. Mori \"Social roles in hierarchical models for human activity recognition\" IEEE Conference on Computer Vision and Pattern Recognition pp. 1354-1361 2012."}, {"ref": "[13] T. Yu S.-N. Lim K. Patwardhan N. Krahnstoever \"Monitoring recognizing and discovering social networks\" IEEE Conference on Computer Vision and Pattern Recognition pp. 1462-1469 2009."}, {"ref": "[14] L. Ding A. Yilmaz \"Learning Relations among Movie Characters: A Social Network Perspective\" European Conference on Computer Vision pp. 410-423 2010."}, {"ref": "[15] L. Ding A. Yilmaz \"Inferring social relations from visual concepts\" IEEE International Conference on Computer Vision pp. 699-706 2011."}, {"ref": "[16] G. Wang A. Gallagher J.-B. Luo D. Forsyth \"Seeing People in Social Context: Recognizing People and Social Relationships\" European Conference on Computer Vision pp. 169-182 2010."}, {"ref": "[17] M. Kiefer E. J. Sim B. Herrnberger J. Grothe K. Hoenig \"The sound of concepts: Four markers for a link between auditory and conceptual brain systems\" Journal of Neuroscience pp. 28: 12224-12230 2008."}, {"ref": "[18] B.-T. Zhang J.-W. Ha M. Kang \"Sparse population code models of word learning in concept drift\" Proceedings of Annual Meeting of the Cognitive Science Society pp. 1221-1226 2012."}, {"ref": "[19] R. Socher B. Huval B. Bath C. D. Manning A. Y. Ng \"Convolutional-recursive Deep Learning for 3D Object Classification\" Advances in Neural Information Processing Systems pp. 665-673 2012."}, {"ref": "[20] R. Girshick J. Donahue T. Darrell J. Malik \"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\" Proceedings of International Conference on Pattern Recognition 2014."}, {"ref": "[21] T. Mikolov I. Sutskever K. Chen G. Corrado J. Dean \"Distributed Representations of Words and Phrases and their Compositionality\" Proceedings of Advances in Neural Information Processing Systems 2013."}]}, {"author": ["Lili ZHOU", "Jinna LV", "Bin WU"], "title": "Social Network Construction of the Role Relation in Unstructured Data Based on Multi-view", "journal": "DSC", "year": 2017, "DOI": "10.1109/DSC.2017.78", "month": 6, "citations(google scholar)": 1, "abstract": "Realization of automatically extracting the role relation from massive unstructured data facilitates the deep semantics of mining big data. Nowadays, methods for network construction are mainly either based on structured data, or based on a single view. Therefore social network construction of role relation in unstructured data based on multi-view is still a challenge. In this paper, a method is proposed for social network construction of the role relation in unstructured data based on multi-view. This method firstly automatically extracts the face from video. Secondly, social network of the role relation is constructed based on multi-view which includes video shot and plot, thus forming a multi-view network. Finally, the method is parallel implemented on Spark platform considering the large amount of unstructured data. Comprehensive evaluation on The Big Bang Theory and House of Cards are conducted, and the experimental results demonstrate that the proposed method shows better experimental results in terms of F1 and speedup values, F1 values are 77.66% and 61.32% respectively, speedup are 4.7X and 4X respectively.", "keywords": ["role relation", "unstructured data", "social network construction", "video shot", "plot", "multi-view network", "parallel implemented"], "reference_count": 19, "ccfClass": "", "important": true, "references": [{"ref": "[1] Bott Elizabeth Elizabeth Bott Spillius \"Family and social network: Roles norms and external relationships in ordinary urban families\" Routledge 2014."}, {"ref": "[2] S. Li B. Zhang D. Jiang et al. \"Herb network construction and co-module analysis for uncovering the combination rule of traditional Chinese herbal formulae[J]\" BMC bioinformatics vol. 11 no. 11 pp. S6 2010."}, {"ref": "[3] B. D. Fath U. M. Scharler R. E. Ulanowicz et al. \"Ecological network analysis: network construction[J]\" Ecological modelling vol. 208 no. 1 pp. 49-55 2007."}, {"ref": "[4] J. Cheng D. A. Bell W. Liu \"An algorithm for Bayesian belief network construction from data[C]\" Proceedings of AI &amp; STAT'97 pp. 83-90 1997."}, {"ref": "[5] M E J. Newman \"Scientific collaboration networks. I. Network construction and fundamental results[J]\" Physical review E vol. 64 no. 1 2001."}, {"ref": "[6] S. Yang B. Wu \"Large Scale Video Data Analysis Based on Spark[C]\" Cloud Computing and Big Data (CCBD) 2015 International Conference on. IEEE pp. 209-212 2015."}, {"ref": "[7] I. Kusuma M. A. Ma'sum N. Habibie et al. \"Design of intelligent k-means based on spark for big data clustering[C]\" Big Data and Information Security (IWBIS) International Workshop on. IEEE pp. 89-96 2016."}, {"ref": "[8] F. Cady \"Big Data[J]\" The Data Science Handbook pp. 185-201."}, {"ref": "[9] Y. Ohno S. Morishima H. Matsutani \"Accelerating Spark RDD Operations with Local and Remote GPU Devices[C]\" Proceedings of the International Conference on Parallel and Distributed Systems (ICPADS'16) 2016."}, {"ref": "[10] H. Tan L. Chen \"An approach for fast and parallel video processing on Apache Hadoop clusters[C]\" Multimedia and Expo (ICME) 2014 IEEE International Conference on pp. 1-6 2014."}, {"ref": "[11] J. Ramsingh V. Bhuvaneswari \"Data analytic on diabetic awareness with Hadoop streaming using map reduce in python[C]\" Advances in Computer Applications (ICACA) IEEE International Conference on pp. 346-350 2016."}, {"ref": "[12] A. Heikkinen J. Sarvanko M. Rautiainen M. Ylianttila \"Distributed multimedia content analysis with MapReduce\" IEEE PIMRC 2013."}, {"ref": "[13] Zhu Xiangxin Deva Ramanan \"Face detection pose estimation and landmark localization in the wild\" Computer Vision and Pattern Recognition (CVPR) 2012 IEEE Conference on 2012."}, {"ref": "[14] Hjelm\u00e5s Erik Boon Kee Low \"Face detection: A survey\" Computer vision and image understanding 83 vol. 3 pp. 236-274 2001."}, {"ref": "[15] [online] Available: https://facedetection.com/."}, {"ref": "[16] R. Lienhart J. Maydt \"An extended set of haar-like features for rapid object detection[C]\" Image Processing. 2002. Proceedings. 2002 International Conference on. IEEE vol. 1 pp. 1-1 2002."}, {"ref": "[17] I. Ikon \"Vehicle Speed Detecting App[J]\" 2017."}, {"ref": "[18] Y. Yan Q. Chen F. Lee \"Face recognition using extended vector quantization histogram features[C]\" Signal and Image Processing (ICSIP) IEEE International Conference on pp. 90-95 2016."}, {"ref": "[19] J. L. Minoi A. J. R. Jupit D. F. Gillies et al. \"Facial expressions reconstruction of 3D faces based on real human data[C]\" IEEE International Conference on Computational Intelligence and Cybernetics pp. 185-189 2012."}]}, {"author": ["JINNA LV", "BIN WU", "LILI ZHOU", "HAN WANG"], "title": "StoryRoleNet: Social Network Construction of Role Relationship in Video", "journal": "IEEE ACCESS", "year": 2018, "DOI": "10.1109/ACCESS.2018.2832087", "month": 5, "citations(google scholar)": 2, "abstract": "The automatic extraction of social relationship among individuals from massive quantities of video data is an important aspect of information extraction. However, most existing studies have focused on rough information, which result in inaccurate social network of role relationship. In this paper, the StoryRoleNet model is proposed for constructing an accurate and integral network representing the relationships among roles. First, to avoid the redundancy calculation of the relationships on the segmentation points of neighboring story units, we measure the weights of relationships by a weighted-Gaussian method in each story unit. More importantly, a new story segmentation method for long video is proposed by analyzing hierarchical features of the video. Then, we combine relationship networks constructed from the video and subtitle text. Some missed relationships can be complemented by this way. At last, the final network is analyzed to discover communities and important roles. Comprehensive evaluations were conducted using three movies and one television drama. The results demonstrate that the proposed method outperforms stateof-the-art methods in terms of the F1 accuracy measure and the normalized mutual information value.", "keywords": ["Relationship network construction", "story segmentation", "social network analysis", "community discovery."], "reference_count": 35, "ccfClass": "", "important": true, "references": [{"ref": "[1] Q. D. Tran J. E. Jung \"CoCharNet: Extracting social networks using character co-occurrence in movies\" J. Universal Comput. Sci. vol. 21 pp. 796-815 2015."}, {"ref": "[2] G. Tanisik C. Zalluhoglu N. Ikizler-Cinbis \"Facial descriptors for human interaction recognition in still images\" Pattern Recogn. Lett. vol. 73 pp. 44-51 Apr. 2016."}, {"ref": "[3] C. Y. Weng W. T. Chu J. L. Wu \"RoleNet: Movie analysis from the perspective of social networks\" IEEE Trans. Multimedia vol. 11 no. 2 pp. 256-271 Feb. 2009."}, {"ref": "[4] Q. Sun B. Schiele M. Fritz \"A domain based approach to social relation recognition\" Proc. IEEE CVPR pp. 435-444 Apr. 2017."}, {"ref": "[5] L. Feng B. Bhanu \"Understanding dynamic social grouping behaviors of pedestrians\" IEEE J. Sel. Topics Signal Process. vol. 9 no. 2 pp. 317-329 Mar. 2015."}, {"ref": "[6] C. Chen B. Xu Y. Xiao Q. Shi W. Wang \"Extracting social network from transaction logs\" J. Comput. Res. Dev. vol. 52 no. 11 pp. 2508-2516 2015."}, {"ref": "[7] C. Peng J. Gu L. Qian M. Zhou G. Zhou D. Zhao Q. Liu L. Zou \"Research on tree kernel-based personal relation extraction\" in Natural Language Processing and Chinese Computing Berlin Germany:Springer vol. 333 pp. 225-236 2012."}, {"ref": "[8] F. Li M. Zhang G. Fu D. Ji \"A neural joint model for entity and relation extraction from biomedical text\" BMC Bioinf. vol. 18 no. 1 Mar. 2017."}, {"ref": "[9] K. Yuan H. Yao R. Ji X. Sun \"Mining actor correlations with hierarchical concurrence parsing\" Proc. IEEE ICASSP pp. 798-801 Mar. 2010."}, {"ref": "[10] N. P. Garg S. Favre H. Salamin D. H. T\u00fcr A. Vinciarelli \"Role recognition for meeting participants: An approach based on lexical information and social network analysis\" Proc. ACM MM pp. 693-696 Oct. 2008."}, {"ref": "[11] A. Sapru H. Bourlard \"Automatic recognition of emergent social roles in small group interactions\" IEEE Trans. Multimedia vol. 17 no. 5 pp. 746-760 May 2015."}, {"ref": "[12] C. N. Warren D. Shore J. Otis L. Wang M. Finegold C. Shalizi \"Six degrees of Francis Bacon: A statistical method for reconstructing large historical social networks\" Digit. Humanities Quart. vol. 10 no. 3 2016."}, {"ref": "[13] S. Srivastava S. Chaturvedi T. M. Mitchell \"Inferring interpersonal relations in narrative summaries\" Proc. AAAI pp. 2807-2813 2016."}, {"ref": "[14] R. Vatrapu R. R. Mukkamala A. Hussain B. Flesch \"Social set analysis: A set theoretical approach to big data analytics\" IEEE Access vol. 4 pp. 2542-2571 2016."}, {"ref": "[15] X. He Y. Chen D. Li Y. Hao \"A construction for social network on the basis of project cooperation\" J. Comput. Res. Dev. vol. 53 no. 4 pp. 776-784 2016."}, {"ref": "[16] J. Tang J. Zhang L. Yao J. Li L. Zhang Z. Su \"ArnetMiner: Extraction and mining of academic social networks\" Proc. ACM SIGKDD pp. 990-998 Aug. 2008."}, {"ref": "[17] H. Han C. Yao Y. Fu Y. Yu Y. Zhang S. Xu \"Semantic fingerprints-based author name disambiguation in Chinese documents\" Scientometrics vol. 111 no. 3 pp. 1879-1896 2017."}, {"ref": "[18] Z. Zhang P. Luo C. C. Loy X. Tang \"Learning social relation traits from face images\" Proc. IEEE ICCV pp. 3631-3639 Sep. 2015."}, {"ref": "[19] V. Ramanathan B. Yao L. Fei-Fei \"Social role discovery in human events\" Proc. IEEE CVPR pp. 2475-2482 Jun. 2013."}, {"ref": "[20] C. J. Nan K. M. Kim B.-T. Zhang \"Social network analysis of TV drama characters via deep concept hierarchies\" Proc. IEEE/ACM ASONAM pp. 831-836 Aug. 2016."}, {"ref": "[21] L. Ding A. Yilmaz \"Learning relations among movie characters: A social network perspective\" Proc. IEEE ECCV pp. 410-423 Sep. 2010."}, {"ref": "[22] M. Douze H. J\u00e9gou C. Schmid \"An image-based approach to video copy detection with spatio-temporal post-filtering\" IEEE Trans. Multimedia vol. 12 no. 4 pp. 257-266 Jun. 2010."}, {"ref": "[23] C.-W. Ngo Y.-F. Ma H.-J. Zhang \"Video summarization and scene detection by graph modeling\" IEEE Trans. Circuits Syst. Video Technol. vol. 15 no. 2 pp. 296-305 Feb. 2005."}, {"ref": "[24] Y. Sun X. Wang X. Tang \"Deep convolutional network cascade for facial point detection\" Proc. IEEE CVPR pp. 3476-3483 Jun. 2013."}, {"ref": "[25] Y. Sun X. Wang X. Tang \"Deep learning face representation from predicting 10000 classes\" Proc. IEEE CVPR pp. 1891-1898 Jun. 2014."}, {"ref": "[26] X. Lu C.-C. Leung L. Xie B. Ma H. Li \"Broadcast news story segmentation using latent topics on data manifold\" Proc. IEEE ICASSP pp. 8465-8469 May 2013."}, {"ref": "[27] R. Tapu B. Mocanu T. Zaharia \"TV news retrieval based on story segmentation and concept association\" Proc. SITIS pp. 327-334 Dec. 2016."}, {"ref": "[28] S. B. Park K. J. Oh G. S. Jo \"Social network analysis in a movie using character-net\" Multimedia Tools Appl. vol. 59 no. 2 pp. 601-627 2012."}, {"ref": "[29] R. Harakawa T. Ogawa M. Haseyama \"Extracting hierarchical structure of Web video groups based on sentiment-aware signed network analysis\" IEEE Access vol. 5 pp. 16963-16973 2017."}, {"ref": "[30] J. Lv B. Wu S. Yang B. Jia P. Qiu \"Efficient large scale near-duplicate video detection base on spark\" Proc. IEEE Big Data pp. 957-962 Dec. 2016."}, {"ref": "[31] S. Tippaya S. Sitjongsataporn T. Tan M. M. Khan K. Chamnongthai \"Multi-modal visual features-based video shot boundary detection\" IEEE Access vol. 5 pp. 12563-12575 2017."}, {"ref": "[32] Z. Rasheed M. Shah \"Scene detection in Hollywood movies and TV shows\" Proc. IEEE CVPR vol. 2 pp. II-343-II-348 Jun. 2003."}, {"ref": "[33] J. R. Finkel T. Grenager C. Manning \"Incorporating non-local information into information extraction systems by Gibbs sampling\" Proc. Int. Conf. ACL pp. 363-370 Jun. 2005."}, {"ref": "[34] J. Shen T. Zhou C. F. Lai J. Li X. Li \"Hierarchical trust level evaluation for pervasive social networking\" IEEE Access vol. 5 pp. 1178-1187 2017."}, {"ref": "[35] V. D. Blondel J. L. Guillaume R. Lambiotte E. Lefebvre \"Fast unfolding of communities in large networks\" J. Stat. Mech. Theory E vol. 10 pp. P10008 2008."}]}, {"author": ["Lili Zhou", "Bin Wu", "and Jinna Lv"], "title": "SRE-Net Model for Automatic Social Relation Extraction from Video", "journal": "CCF BigData", "year": 2018, "DOI": "10.1007/978-981-13-2922-7_30", "month": 10, "citations(google scholar)": 0, "abstract": "Videos spread over the Internet contain a huge knowledge of human society. Diversified knowledge is demonstrated as the storyline of the video unfolds. Therefore, realization of automatically constructing social relation network from massive video data facilitates the deep semantics of mining big data, which includes face recognition and social relation recognition. For face recognition, previous studies are focus on high-level features of face and multiple body cues. However, these methods are mostly based on supervised learning and clustering need to specify clusters k, which cannot recognize characters when new video data is input and individual and its numbers are unknown. For social relation recognition, previous studies are concentrated on images and videos. However, these methods are only concentrated on social relations in same frame and incapable of extracting social relation of characters that are not present in the same frame. In this paper, a model named SRE-Net is proposed for building social relation network to address these challenges. First, MoCNR algorithm is introduced by clustering similar-appearing faces from different keyframes of video. As far as we know, it is the first algorithm to identify character nodes using unsupervised double-clustering methods. Second, we propose a scene based social relation recognition method to solve challenges that cannot recognize social relations of characters in different frames. Finally, comprehensive evaluations demonstrate that our model is effective for social relation network construction.", "keywords": ["Deep learning", "face recognition", "scene segmentation", "social relation."], "reference_count": 30, "ccfClass": "", "important": true, "references": [{"ref": "[1] Gopalan, R.: Image clustering under domain shift. In: 2017 IEEE Third International Conference on Multimedia Big Data (BigMM), pp. 74\u201377. IEEE (2017)"}, {"ref": "[2] Lv, J., Liu, W., Zhou, L., Wu, B., Ma, H.: Multi-stream fusion model for social relation recognition from videos. In: Schoeffmann, K., et al. (eds.) MMM 2018. LNCS, vol. 10704, pp. 355\u2013368. Springer, Cham (2018).  https://xs.scihub.ltd/https://doi.org/10.1007/978-3-319-73603-7_29"}, {"ref": "[3] Zhang, K., Zhang, Z., Li, Z., Qiao, Y.: Joint face detection and alignment using multitask cascaded convolutional networks. IEEE Signal Process. Lett. 23(10), 1499\u20131503 (2016)"}, {"ref": "[4] Kumar, N., Rai, P., Pulla, C., Jawahar, C.V.: Video scene segmentation with a semantic similarity. In: IICAI (2014)"}, {"ref": "[5] Amato, F., Moscato, V., Picariello, A., Sperl\u00ed, G.: Recommendation in social media networks. In: 2017 IEEE Third International Conference on Multimedia Big Data (BigMM), pp. 213\u2013216. IEEE (2017)"}, {"ref": "[6] Schmidhuber, J.: Deep learning in neural networks: an overview. Neural Netw. 61, 85\u2013117 (2014)"}, {"ref": "[7] Wang, M., Deng, W.: Deep visual domain adaptation: a survey (2018)"}, {"ref": "[8] Young, T., Hazarika, D., Poria, S., Cambria, E.: Recent trends in deep learning based natural language processing (2017)"}, {"ref": "[9] Schmidhuber, J.: Deep Learning in Neural Networks. Elsevier Science Ltd. (2015)"}, {"ref": "[10] Li, S., Ma, H.: A siamese inception architecture network for person re-identification. Mach. Vis. Appl. 28(7), 725\u2013736 (2017)"}, {"ref": "[11] Zhang, N., Paluri, M., Taigman, Y., Fergus, R.: Beyond frontal faces: improving person recognition using multiple cues. In: Computer Vision and Pattern Recognition, pp. 4804\u20134813. IEEE (2015)"}, {"ref": "[12] Wojke, N., Bewley, A., Paulus, D.: Simple online and realtime tracking with a deep association metric. In: IEEE International Conference on Image Processing, pp. 3645\u20133649. IEEE (2017)"}, {"ref": "[13] Sun, Q., Schiele, B., Fritz, M.: A domain based approach to social relation recognition. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 435\u2013444. IEEE Computer Society (2017)"}, {"ref": "[14] Zhang, Z., Luo, P., Chen, C.L., Tang, X.: From facial expression recognition to interpersonal relation prediction. Int. J. Comput. Vis. 126(5), 1\u201320 (2018)"}, {"ref": "[15] Rohrbach, A., Rohrbach, M., Tang, S., Oh, S.J., Schiele, B.: Generating descriptions with grounded and co-referenced people (2017)"}, {"ref": "[16] Minoi, J.L., Jupit, A.J.R., Gillies, D.F., Arnab, S.: Facial expressions reconstruction of 3D faces based on real human data. In: IEEE International Conference on Computational Intelligence and Cybernetics, pp. 185\u2013189. IEEE (2012)"}, {"ref": "[17] Oh, S.J., Benenson, R., Fritz, M., Schiele, B.: Person recognition in personal photo collections. In: IEEE International Conference on Computer Vision, pp. 3862\u20133870. IEEE Computer Society (2015)"}, {"ref": "[18] Sun, Y., Wang, X., Tang, X.: Deep learning face representation from predicting 10,000 classes. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 1891\u20131898. IEEE Computer Society (2014)"}, {"ref": "[19] Taigman, Y., Yang, M., Ranzato, M., Wolf, L.: DeepFace: closing the gap to human-Level performance in face verification. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 1701\u20131708. IEEE Computer Society (2014)"}, {"ref": "[20] Nan, C.J., Kim, K.M., Zhang, B.T.: Social network analysis of TV drama characters via deep concept hierarchies, pp. 831\u2013836 (2015)"}, {"ref": "[21] Barr, J.R., Cament, L.A., Bowyer, K.W., Flynn, P.J.: Active clustering with ensembles for social structure extraction. In: Applications of Computer Vision, pp. 969\u2013976. IEEE (2014)"}, {"ref": "[22] Zhang, Z., Luo, P., Loy, C.C., Tang, X.: Learning social relation traits from face images. In: IEEE International Conference on Computer Vision, pp. 3631\u20133639. IEEE (2015)"}, {"ref": "[23] Li, J., Wong, Y., Zhao, Q., Kankanhalli, M.S.: Dual-glance model for deciphering social relationships. In: IEEE International Conference on Computer Vision, pp. 2669\u20132678. IEEE (2017)"}, {"ref": "[24] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreitet, J., Jones, L., Gomez, A.N., et al.: Attention is all you need (2017)"}, {"ref": "[25] Deng, J., Dong, W., Socher, R., Li, L., Li, K., Li, F.: ImageNet: a large-scale hierarchical image database. In: IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2009, pp. 248\u2013255. IEEE (2009)"}, {"ref": "[26] Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M.: Learning spatiotemporal features with 3D convolutional networks, pp. 4489\u20134497 (2014)"}, {"ref": "[27] Szegedy, C., Liu, W., Jia, Y., Sermanetet, P., Reed, S., Angueloval, D., et al.: Going deeper with convolutions, pp. 1\u20139 (2014)"}, {"ref": "[28] Zhou, L., Lv, J., Wu, B.: Social network construction of the role relation in unstructured data based on multi-view. In: IEEE Second International Conference on Data Science in Cyberspace, pp. 382\u2013388. IEEE Computer Society (2017)"}, {"ref": "[29] Lecun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature 521(7553), 436 (2015)"}, {"ref": "[30] Schroff, F., Kalenichenko, D., Philbin, J.: Facenet: a unified embedding for face recognition and clustering. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 815\u2013823 (2015)."}]}, {"author": ["Hamdi Dibeklio\u02d8glu"], "title": "Visual Transformation Aided Contrastive Learning for Video-based Kinship Verification", "journal": "ICCV", "year": 2017, "DOI": "10.1109/ICCV.2017.269", "month": 12, "citations(google scholar)": 5, "abstract": "Automatic kinship verification from facial information is a relatively new and open research problem in computer vision. This paper explores the possibility of learning an efficient facial representation for video-based kinship verification by exploiting the visual transformation between facial appearance of kin pairs. To this end, a Siamese-like coupled convolutional encoder-decoder network is proposed. To reveal resemblance patterns of kinship while discarding the similarity patterns that can also be observed between people who do not have a kin relationship, a novel contrastive loss function is defined in the visual appearance space. For further optimization, the learned representation is fine-tuned using a feature-based contrastive loss. An expression matching procedure is employed in the model to minimize the negative influence of expression differences between kin pairs. Each kin video is analyzed by a sliding temporal window to leverage short-term facial dynamics. The effectiveness of the proposed method is assessed on seven different kin relationships using smile videos of kin pairs. On the average, 93:65% verification accuracy is achieved, improving the state of the art.", "keywords": ["None"], "reference_count": 41, "ccfClass": "A", "important": true, "references": [{"ref": "[1] T. Baltru\u02c7saitis, P. Robinson, and L.-P. Morency. Constrained local neural fields for robust facial landmark detection in the wild. In IEEE International Conference on Computer Vision Workshops, pages 354\u2013361, 2013."}, {"ref": "[2] T. Baltru\u02c7saitis, P. Robinson, and L.-P. Morency. Openface: An open source facial behavior analysis toolkit. In IEEE Winter Conference on Applications of Computer Vi- sion, 2016."}, {"ref": "[3] E. Boutellaa, M. B. L\u00b4opez, S. Ait-Aoudia, X. Feng, and A. Hadid. Kinship verification from videos using spatiotemporal texture features and deep learning. In International Conference on Biometrics, pages 1\u20137, 2016."}, {"ref": "[4] Z. Cao, Q. Yin, X. Tang, and J. Sun. Face recognition with learning-based descriptor. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2707\u20132714, 2010."}, {"ref": "[5] J. F. Cohn and K. L. Schmidt. The timing of facial motion in posed and spontaneous smiles. International Jour- nal ofWavelets, Multiresolution and Information Processing, 2(2):121\u2013132, 2004."}, {"ref": "[6] M. F. Dal Martello and L. T. Maloney. Where are kin recognition signals in the human face? Journal of Vision, 6(12), 2006."}, {"ref": "[7] A. Dehghan, E. G. Ortiz, R. Villegas, and M. Shah. Who do I look like? Determining parent-offspring resemblance via gated autoencoders. In International Conference on Com- puter Vision, pages 1757\u20131764, 2014."}, {"ref": "[8] H. Dibeklio\u02d8glu, A. Ali Salah, and T. Gevers. Like father, like son: Facial expression dynamics for kinship verification. In International Conference on Computer Vision, pages 1497\u2013 1504, 2013."}, {"ref": "[9] H. Dibeklio\u02d8glu, A. A. Salah, and T. Gevers. Are you really smiling at me? spontaneous versus posed enjoyment smiles. In European Conference on Computer Vision, pages 525\u2013 538. 2012."}, {"ref": "[10] D. Erhan, Y. Bengio, A. Courville, P.-A. Manzagol, P. Vincent, and S. Bengio. Why does unsupervised pre-training help deep learning? Journal of Machine Learning Research, 11(Feb):625\u2013660, 2010."}, {"ref": "[11] R. Fang, K. D. Tang, N. Snavely, and T. Chen. Towards computational models of kinship verification. In IEEE Interna- tional Conference on Image Processing, pages 1577\u20131580, 2010."}, {"ref": "[12] G. Guo and X.Wang. Kinship measurement on salient facial features. IEEE Trans. on Instrumentation and Measurement, 61(8):2322\u20132325, 2012."}, {"ref": "[13] Y. Guo, H. Dibeklio\u02d8glu, and L. van der Maaten. Graph-based kinship recognition. In International Conference on Pattern Recognition, pages 4287\u20134292, 2014."}, {"ref": "[14] J. Hu, J. Lu, Y.-P. Tan, J. Yuan, and J. Zhou. Local largemargin multi-metric learning for face and kinship verification. IEEE Trans. on Circuits and Systems for Video Tech- nology, 2017."}, {"ref": "[15] J. Hu, J. Lu, J. Yuan, and Y.-P. Tan. Large margin multimetric learning for face and kinship verification in the wild. In Asian Conference on Computer Vision, pages 252\u2013267, 2014."}, {"ref": "[16] N. Kohli, R. Singh, and M. Vatsa. Self-similarity representation of weber faces for kinship classification. In IEEE In- ternational Conference on Biometrics: Theory, Applications, and Systems, pages 245\u2013250, 2012."}, {"ref": "[17] L. Li, X. Feng, X. Wu, Z. Xia, and A. Hadid. Kinship verification from faces via similarity metric based convolutional neural network. In International Conference Image Analysis and Recognition, pages 539\u2013548, 2016."}, {"ref": "[18] J. Lu, J. Hu, V. E. Liong, X. Zhou, A. Bottino, I. U. Islam, T. F. Vieira, X. Qin, X. Tan, S. Chen, et al. The FG 2015 kinship verification in the wild evaluation. In IEEE Interna- tional Conference on Automatic Face and Gesture Recogni- tion Workshops, 2015."}, {"ref": "[19] J. Lu, J. Hu, X. Zhou, Y. Shang, Y.-P. Tan, and G. Wang. Neighborhood repulsed metric learning for kinship verification. In IEEE Conference on Computer Vision and Pattern Recognition, 2012."}, {"ref": "[20] J. Lu, X. Zhou, Y.-P. Tan, Y. Shang, and J. Zhou. Neighborhood repulsed metric learning for kinship verification. IEEE Trans. on Pattern Analysis and Machine Intelligence, 36(2):331\u2013345, 2014."}, {"ref": "[21] I. O\u00a8 nal-Ertug\u02d8 rul and H. Dibekliog\u02d8 lu. What will your future child look like? Modeling and synthesis of hereditary patterns of facial dynamics. In IEEE International Confer- ence on Automatic Face & Gesture Recognition, pages 33\u2013 40, 2017."}, {"ref": "[22] O. M. Parkhi, A. Vedaldi, and A. Zisserman. Deep face recognition. In British Machine Vision Conference, 2015."}, {"ref": "[23] B. Patel, R. Maheshwari, and B. Raman. Evaluation of periocular features for kinship verification in the wild. Computer Vision and Image Understanding, 160:24\u201335, 2017."}, {"ref": "[24] G. Peleg, G. Katzir, O. Peleg, M. Kamara, L. Brodsky, H. Hel-Or, D. Keren, and E. Nevo. Hereditary family signature of facial expression. Proceedings of the National Academy of Sciences, 103(43):15921\u201315926, 2006."}, {"ref": "[25] T. Pfister, X. Li, G. Zhao, and M. Pietikainen. Differentiating spontaneous from posed facial expressions within a generic facial expression recognition framework. In IEEE International Conference on Computer Vision Workshops, pages 868\u2013875, 2011."}, {"ref": "[26] A. Puthenputhussery, Q. Liu, and C. Liu. SIFT flow based genetic fisher vector feature for kinship verification. In IEEE International Conference on Image Processing, pages 2921\u2013 2925, 2016."}, {"ref": "[27] X. Qin, X. Tan, and S. Chen. Tri-subject kinship verification: Understanding the core of a family. IEEE Trans. on Multimedia, 17(10):1855\u20131867, 2015."}, {"ref": "[28] J. P. Robinson, M. Shao, Y. Wu, and Y. Fu. Families in the wild (fiw): Large-scale kinship image database and benchmarks. In ACM Internatiol Conference on Multimedia, pages 242\u2013246, 2016."}, {"ref": "[29] P. F. Velleman. Definition and comparison of robust nonlinear data smoothing algorithms. Journal of the American Statistical Association, 75(371):609\u2013615, 1980."}, {"ref": "[30] M. Wang, Z. Li, X. Shu, and J. Tang. Deep kinship verification. In International Workshop on Multimedia Signal Processing, 2015."}, {"ref": "[31] S. Xia, M. Shao, and Y. Fu. Kinship verification through transfer learning. In International Joint Conference on Arti- ficial Intelligence, 2011."}, {"ref": "[32] S. Xia, M. Shao, and Y. Fu. Toward kinship verification using visual attributes. In International Conference on Pattern Recognition, pages 549\u2013552, 2012."}, {"ref": "[33] S. Xia, M. Shao, J. Luo, and Y. Fu. Understanding kin relationships in a photo. IEEE Trans. on Multimedia, 14(4):1046\u20131056, 2012."}, {"ref": "[34] H. Yan. Kinship verification using neighborhood repulsed correlation metric learning. Image and Vision Computing, 60:91\u201397, 2017."}, {"ref": "[35] H. Yan, J. Lu, W. Deng, and X. Zhou. Discriminative multimetric learning for kinship verification. IEEE Trans. on Information Forensics and Security, 9(7):1169\u20131178, 2014."}, {"ref": "[36] H. Yan, J. Lu, and X. Zhou. Prototype-based discriminative feature learning for kinship verification. IEEE Trans. on Cy- bernetics, 45(11):2535\u20132545, 2015."}, {"ref": "[37] K. Zhang, Y. Huang, C. Song, H. Wu, and L. Wang. Kinship verification with deep convolutional neural networks. In British Machine Vision Conference, 2015."}, {"ref": "[38] X. Zhou, J. Hu, J. Lu, Y. Shang, and Y. Guan. Kinship verification from facial images under uncontrolled conditions. In ACM International Conference on Multimedia, pages 953\u2013 956, 2011."}, {"ref": "[39] X. Zhou, J. Lu, J. Hu, and Y. Shang. Gabor-based gradient orientation pyramid for kinship verification under uncontrolled environments. In ACM International Conference on Multimedia, pages 725\u2013728, 2012."}, {"ref": "[40] X. Zhou, Y. Shang, H. Yan, and G. Guo. Ensemble similarity learning for kinship verification from facial images in the wild. Information Fusion, 32:40\u201348, 2016."}, {"ref": "[41] X. Zhou, H. Yan, and Y. Shang. Kinship verification from facial images by scalable similarity fusion. Neurocomputing, 197:136\u2013142, 2016."}]}, {"author": ["Haibin Yan", "Junlin Hu"], "title": "Video-based kinship verification using distance metric learning", "journal": "Pattern Recognition", "year": 2018, "DOI": "10.1016/j.patcog.2017.03.001", "month": 3, "citations(google scholar)": 19, "abstract": "In this paper, we investigate the problem of video-based kinship verification via human face analysis. While several attempts have been made on facial kinship verification from still images, to our knowledge, the problem of video-based kinship verification has not been formally addressed in the literature. In this paper, we make the two contributions to video-based kinship verification. On one hand, we present a new video face dataset called Kinship Face Videos in the Wild (KFVW) which were captured in wild conditions for the video-based kinship verification study, as well as the standard benchmark. On the other hand, we employ our benchmark to evaluate and compare the performance of several state-of-the-art metric learning based kinship verification methods. Experimental results are presented to demonstrate the efficacy of our proposed dataset and the effectiveness of existing metric learning methods for video-based kinship verification. Lastly, we also evaluate human ability on kinship verification from facial videos and experimental results show that metric learning based computational methods are not as good as that of human observers.", "keywords": ["Kinship verification", "Metric learning", "Face recognition", "Video-based"], "reference_count": 73, "ccfClass": "B", "important": true, "references": [{"ref": "[1] M.F. Dal Martello, L.T. Maloney Where are kin recognition signals in the human face? J. Vision, 6 (12) (2006), pp. 1356-1366"}, {"ref": "[2] A. Alvergne, R. Oda, C. Faurie, A. Matsumoto-Oda, V. Durand, M. Raymond Cross-cultural perceptions of facial resemblance between kin J. Vision, 9 (6) (2009), pp. 1-10"}, {"ref": "[3] L.M. DeBruine, F.G. Smith, B.C. Jones, S. Craig Roberts, M. Petrie, T.D. Spector Kin recognition signals in adult faces Vision Res., 49 (1) (2009), pp. 38-43"}, {"ref": "[4] G. Kaminski, S. Dridi, C. Graff, E. Gentaz Human ability to detect kinship in strangers\u2019 faces: effects of the degree of relatedness Proc. R. Soc. B, 276 (1670) (2009), pp. 3193-3200"}, {"ref": "[5] R. Fang, K.D. Tang, N. Snavely, T. Chen Towards computational models of kinship verification IEEE International Conference on Image Processing (2010), pp. 1577-1580"}, {"ref": "[6] X. Zhou, J. Hu, J. Lu, Y. Shang, Y. Guan Kinship verification from facial images under uncontrolled conditions ACM International Conference on Multimedia (2011), pp. 953-956"}, {"ref": "[7] S. Xia, M. Shao, J. Luo, Y. Fu Understanding kin relationships in a photo IEEE Trans. Multimedia, 14 (4) (2012), pp. 1046-1056"}, {"ref": "[8] S. Xia, M. Shao, Y. Fu Toward kinship verification using visual attributes International Conference on Pattern Recognition (2012), pp. 549-552"}, {"ref": "[9] G. Guo, X. Wang Kinship measurement on salient facial features IEEE Trans. Instrum. Meas., 61 (8) (2012), pp. 2322-2325"}, {"ref": "[10] X. Zhou, J. Lu, J. Hu, Y. Shang Gabor-based gradient orientation pyramid for kinship verification under uncontrolled environments ACM International Conference on Multimedia (2012), pp. 725-728"}, {"ref": "[11] G. Somanath, C. Kambhamettu Can faces verify blood-relations? IEEE International Conference on Biometrics: Theory, Applications and Systems (2012), pp. 105-112"}, {"ref": "[12] R. Fang, A.C. Gallagher, T. Chen, A. Loui Kinship classification by modeling facial feature heredity IEEE International Conference on Image Processing (2013), pp. 2983-2987"}, {"ref": "[13] J. Lu, X. Zhou, Y.-P. Tan, Y. Shang, J. Zhou Neighborhood repulsed metric learning for kinship verification IEEE Trans. Pattern Anal. Mach. Intell., 34 (2) (2014), pp. 331-345"}, {"ref": "[14] Y. Guo, H. Dibeklioglu, L. van der Maaten Graph-based kinship recognition International Conference on Pattern Recognition (2014), pp. 4287-4292"}, {"ref": "[15] H. Yan, J. Lu, W. Deng, X. Zhou Discriminative multimetric learning for kinship verification IEEE Trans. Inf. Forensics Secur., 9 (7) (2014), pp. 1169-1178"}, {"ref": "[16] J. Lu, J. Hu, X. Zhou, J. Zhou, M.C. Santana, J. Lorenzo-Navarro, L. Kou, Y. Shang, A. Bottino, T.F. Vieira Kinship verification in the wild: the first kinship verification competition IEEE International Joint Conference on Biometrics (2014), pp. 1-6"}, {"ref": "[17] J. Lu, J. Hu, V.E. Liong, X. Zhou, A. Bottino, I.U. Islam, T.F. Vieira, X. Qin, X. Tan, S. Chen, S. Mahpod, Y. Keller, L. Zheng, K. Idrissi, C. Garcia, S. Duffner, A. Baskurt, M.C. Santana, J. Lorenzo-Navarro The FG 2015 kinship verification in the wild evaluation IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (2015), pp. 1-7"}, {"ref": "[18] N. Kohli, R. Singh, M. Vatsa Self-similarity representation of weber faces for kinship classification IEEE International Conference on Biometrics: Theory, Applications, and Systems (2012), pp. 245-250"}, {"ref": "[19] H. Dibeklioglu, A.A. Salah, T. Gevers Like father, like son: facial expression dynamics for kinship verification IEEE International Conference on Computer Vision (2013), pp. 1497-1504"}, {"ref": "[20] H. Yan, J. Lu, X. Zhou Prototype-based discriminative feature learning for kinship verification IEEE Trans. Cybern., 45 (11) (2015), pp. 2535-2545"}, {"ref": "[21] S. Xia, M. Shao, Y. Fu Kinship verification through transfer learning International Joint Conference on Artificial Intelligence (2011), pp. 2539-2544"}, {"ref": "[22] M. Shao, S. Xia, Y. Fu Genealogical face recognition based on ub kinface database IEEE Conference on Computer Vision and Pattern Recognition Workshops (2011), pp. 60-65"}, {"ref": "[23] J. Hu, J. Lu, J. Yuan, Y.-P. Tan Large margin multi-metric learning for face and kinship verification in the wild Asian Conference on Computer Vision (2014), pp. 252-267"}, {"ref": "[24] S. Du, R.K. Ward Improved face representation by nonuniform multilevel selection of Gabor convolution features IEEE Trans. Syst. Man Cybern. Part B, 39 (6) (2009), pp. 1408-1419"}, {"ref": "[25] W. Deng, J. Hu, J. Guo Extended src: undersampled face recognition via intraclass variant dictionary IEEE Trans. Pattern Anal. Mach. Intell., 34 (9) (2012), pp. 1864-1870"}, {"ref": "[26] M. Guillaumin, J. Verbeek, C. Schmid Is that you? Metric learning approaches for face identification IEEE International Conference on Computer Vision (2009), pp. 498-505"}, {"ref": "[27] J. Lu, Y.-P. Tan Regularized locality preserving projections and its extensions for face recognition IEEE Trans. Syst. Man Cybern. Part B, 40 (3) (2010), pp. 958-963"}, {"ref": "[28] M. K\u00f6stinger, M. Hirzer, P. Wohlhart, P.M. Roth, H. Bischof Large scale metric learning from equivalence constraints IEEE Conference on Computer Vision and Pattern Recognition (2012), pp. 2288-2295"}, {"ref": "[29] D. Tran, A. Sorokin Human activity recognition with metric learning European Conference on Computer Vision (2008), pp. 548-561"}, {"ref": "[30] B. Xiao, X. Yang, Y. Xu, H. Zha Learning distance metric for regression by semidefinite programming with application to human age estimation ACM International Conference on Multimedia (2009), pp. 451-460"}, {"ref": "[31] W.-S. Zheng, S. Gong, T. Xiang Person re-identification by probabilistic relative distance comparison IEEE Conference on Computer Vision and Pattern Recognition (2011), pp. 649-656"}, {"ref": "[32] A. Mignon, F. Jurie Pcca: a new approach for distance learning from sparse pairwise constraints IEEE Conference on Computer Vision and Pattern Recognition (2012), pp. 2666-2672"}, {"ref": "[33] J. Hu, J. Lu, Y.-P. Tan Discriminative deep metric learning for face verification in the wild IEEE Conference on Computer Vision and Pattern Recognition (2014), pp. 1875-1882"}, {"ref": "[34] J. Lu, G. Wang, P. Moulin Human identity and gender recognition from gait sequences with arbitrary walking directions IEEE Trans. Inf. Forensics Secur., 9 (1) (2014), pp. 51-61"}, {"ref": "[35] J. Lu, Y.-P. Tan, G. Wang Discriminative multimanifold analysis for face recognition from a single training sample per person IEEE Trans. Pattern Anal. Mach. Intell., 35 (1) (2013), pp. 39-51"}, {"ref": "[36] J. Lu, Y.-P. Tan Ordinary preserving manifold analysis for human age and head pose estimation IEEE Trans. Hum. Mach. Syst., 43 (2) (2013), pp. 249-258"}, {"ref": "[37] J. Lu, Y.-P. Tan Uncorrelated discriminant nearest feature line analysis for face recognition IEEE Signal Process. Lett., 17 (2) (2010), pp. 185-188"}, {"ref": "[38] J. Lu, Y.-P. Tan A doubly weighted approach for appearance-based subspace learning methods IEEE Trans. Inf. Forensics Secur., 5 (1) (2010), pp. 71-81"}, {"ref": "[39] J. Lu, Y.-P. Tan Cost-sensitive subspace learning for face recognition IEEE Conference on Computer Vision and Pattern Recognition (2010), pp. 2661-2666"}, {"ref": "[40] J. Lu, Y.-P. Tan Nearest feature space analysis for classification IEEE Signal Process. Lett., 18 (1) (2011), pp. 55-58"}, {"ref": "[41] J. Lu, E. Zhang Gait recognition for human identification based on ica and fuzzy svm through multiple views fusion Pattern Recognit. Lett., 28 (16) (2007), pp. 2401-2411"}, {"ref": "[42] J. Lu, V.E. Liong, X. Zhou, J. Zhou Learning compact binary face descriptor for face recognition IEEE Trans. Pattern Anal. Mach. Intell., 37 (10) (2015), pp. 2041-2056"}, {"ref": "[43] J. Lu, Y.-P. Tan, G. Wang Discriminative multimanifold analysis for face recognition from a single training sample per person IEEE Trans. Pattern Anal. Mach. Intell., 35 (1) (2013), pp. 39-51"}, {"ref": "[44] J. Lu, V.E. Liong, J. Zhou Cost-sensitive local binary feature learning for facial age estimation IEEE Trans. Image Process., 24 (12) (2015), pp. 5356-5368"}, {"ref": "[45] J. Lu, V.E. Liong, G. Wang, P. Moulin Joint feature learning for face recognition IEEE Trans. Inf. Forensics Secur., 10 (7) (2015), pp. 1371-1383"}, {"ref": "[46] J. Lu, G. Wang, W. Deng, K. Jia Reconstruction-based metric learning for unconstrained face verification IEEE Trans. Inf. Forensics Secur., 10 (1) (2015), pp. 79-89"}, {"ref": "[47] J. Lu, Y.-P. Tan Cost-sensitive subspace analysis and extensions for face recognition IEEE Trans. Inf. Forensics Secur., 8 (3) (2013), pp. 510-519"}, {"ref": "[48] J. Lu, X. Zhou, Y.-P. Tan, Y. Shang, J. Zhou Cost-sensitive semi-supervised discriminant analysis for face recognition IEEE Trans. Inf. Forensics Secur., 7 (3) (2012), pp. 944-953"}, {"ref": "[49] J. Lu, V.E. Liong, J. Zhou Simultaneous local binary feature learning and encoding for face recognition 2015  IEEE International Conference on Computer Vision (2015), pp. 3721-3729"}, {"ref": "[50] J. Lu, G. Wang, W. Deng, P. Moulin, J. Zhou Multi-manifold deep metric learning for image set classification IEEE Conference on Computer Vision and Pattern Recognition (2015), pp. 1137-1145"}, {"ref": "[51] V.E. Liong, J. Lu, G. Wang, P. Moulin, J. Zhou Deep hashing for compact binary codes learning IEEE Conference on Computer Vision and Pattern Recognition (2015), pp. 2475-2483"}, {"ref": "[52] H. Liu, J. Lu, J. Feng, J. Zhou Group-aware deep feature learning for facial age estimation Pattern Recognit. (2016, accepted)"}, {"ref": "[53] G. Shakhnarovich, J. Fisher, T. Darrell Face recognition from long-term observations European Conference on Computer Vision (2006), pp. 361-375"}, {"ref": "[54] K.C. Lee, J. Ho, M.H. Yang, D. Kriegman Video-based face recognition using probabilistic appearance manifolds IEEE Conference on Computer Vision and Pattern Recognition (2003), pp. 313-320"}, {"ref": "[55] A. Hadid, M. Pietikainen From still image to video-based face recognition: an experimental analysis IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (2004), pp. 813-818"}, {"ref": "[56] O. Arandjelovic, G. Shakhnarovich, J. Fisher, R. Cipolla, T. Darrell Face recognition with image sets using manifold density divergence IEEE Conference on Computer Vision and Pattern Recognition (2005), pp. 581-588"}, {"ref": "[57] T.K. Kim, J. Kittler, R. Cipolla Discriminative learning and recognition of image set classes using canonical correlations IEEE Trans. Pattern Anal. Mach. Intell., 29 (6) (2007), pp. 1005-1018"}, {"ref": "[58] R. Wang, S. Shan, X. Chen, W. Gao Manifold-manifold distance with application to face recognition based on image set IEEE Conference on Computer Vision and Pattern Recognition (2008), pp. 1-8"}, {"ref": "[59] R. Wang, X. Chen Manifold discriminant analysis IEEE Conference on Computer Vision and Pattern Recognition (2009), pp. 1-8"}, {"ref": "[60] H. Cevikalp, B. Triggs Face recognition based on image sets IEEE Conference on Computer Vision and Pattern Recognition (2010), pp. 2567-2573"}, {"ref": "[61] M.T. Harandi, C. Sanderson, S. Shirazi, B.C. Lovell Graph embedding discriminant analysis on grassmannian manifolds for improved image set matching IEEE Conference on Computer Vision and Pattern Recognition (2011), pp. 2705-2712"}, {"ref": "[62] Y. Hu, A.S. Mian, R. Owens Sparse approximated nearest points for image set classification IEEE Conference on Computer Vision and Pattern Recognition (2011), pp. 121-128"}, {"ref": "[63] Y. Hu, A.S. Mian, R. Owens Face recognition using sparse approximated nearest points between image sets IEEE Trans. Pattern Anal. Mach. Intell., 34 (10) (2012), pp. 1992-2004"}, {"ref": "[64] K. Fan, W. Liu, S. An, X. Chen Margin preserving projection for image set based face recognition International Conference on Neural Information Processing (2011), pp. 681-689"}, {"ref": "[65] J. Lu, G. Wang, P. Moulin Localized multifeature metric learning for image-set-based face recognition IEEE Trans. Circuits Syst. Video Technol., 26 (3) (2016), pp. 529-540"}, {"ref": "[66] X. Qin, X. Tan, S. Chen Tri-subject kinship verification: understanding the core of a family IEEE Trans. Multimedia, 17 (10) (2015), pp. 1855-1867"}, {"ref": "[67] J. Hu, J. Lu, Y.-P. Tan Fine-grained face verification: dataset and baseline results International Conference on Biometrics (2015), pp. 79-84"}, {"ref": "[68] J.V. Davis, B. Kulis, P. Jain, S. Sra, I.S. Dhillon Information-theoretic metric learning International Conference on Machine Learning (2007), pp. 209-216"}, {"ref": "[69] M. Kan, S. Shan, D. Xu, X. Chen Side-information based linear discriminant analysis for face recognition British Machine Vision Conference (2011), pp. 1-12"}, {"ref": "[70] H.V. Nguyen, L. Bai Cosine similarity metric learning for face verification Asian Conference on Computer Vision (2010), pp. 709-720"}, {"ref": "[71] M. Mathias, R. Benenson, M. Pedersoli, L.J.V. Gool Face detection without bells and whistles European Conference on Computer Vision (2014), pp. 720-735"}, {"ref": "[72] T. Ahonen, A. Hadid, M. Pietik\u00e4inen Face description with local binary patterns: application to face recognition IEEE Trans. Pattern Anal. Mach. Intell., 28 (12) (2006), pp. 2037-2041"}, {"ref": "[73] N. Dalal, B. Triggs Histograms of oriented gradients for human detection IEEE Conference on Computer Vision and Pattern Recognition (2005), pp. 886-893."}]}, {"author": ["Naman Kohli", "Daksha Yadav", "Mayank Vatsa", "Richa Singh", "Afzel Noore"], "title": "Supervised Mixed Norm Autoencoder for Kinship Verification in Unconstrained Videos", "journal": "IEEE Transactions on Image Processing", "year": 2018, "DOI": "10.1109/TIP.2018.2840880", "month": 5, "citations(google scholar)": 8, "abstract": "Identifying kinship relations has garnered interest due to several applications such as organizing and tagging the enormous amount of videos being uploaded on the Internet. Existing research in kinship verification primarily focuses on kinship prediction with image pairs. In this research, we propose a new deep learning framework for kinship verification in unconstrained videos using a novel Supervised Mixed Norm AutoEncoder (SMNAE). This new autoencoder formulation introduces class-specific sparsity in the weight matrix. The proposed three-stage SMNAE based kinship verification framework utilizes the learned spatio-temporal representation in the video frames for verifying kinship in a pair of videos. A new kinship video (KIVI) database of more than 500 individuals with variations due to illumination, pose, occlusion, ethnicity, and expression is collected for this research. It comprises a total of 355 true kin video pairs with over 250 000 still frames. The effectiveness of the proposed framework is demonstrated on the KIVI database and six existing kinship databases. On the KIVI database, SMNAE yields video-based kinship verification accuracy of 83.18% which is at least 3.2% better than existing algorithms. The algorithm is also evaluated on six publicly available kinship databases and compared with best reported results. It is observed that the proposed SMNAE consistently yields best results on all the databases.", "keywords": ["None"], "reference_count": 52, "ccfClass": "A", "important": true, "references": [{"ref": "[1] A. Kofman The Troubling Rise of Rapid DNA Testing Nov. 2016 [online] Available: https://goo.gl/UuhZSN."}, {"ref": "[2] K. Wagner Facebook Says Video Is Huge\u2014100-Million-Hours-Per-Day Huge Mar. 2017 [online] Available: https://goo.gl/LvZb51."}, {"ref": "[3] R. Fang K. D. Tang N. Snavely T. Chen \"Towards computational models of kinship verification\" Proc. IEEE Int. Conf. Image Process. pp. 1577-1580 Sep. 2010."}, {"ref": "[4] X. Zhou J. Hu J. Lu Y. Shang Y. Guan \"Kinship verification from facial images under uncontrolled conditions\" Proc. ACM Int. Conf. Multimedia pp. 953-956 2011."}, {"ref": "[5] X. Zhou J. Lu J. Hu Y. Shang \"Gabor-based gradient orientation pyramid for kinship verification under uncontrolled environments\" Proc. ACM Int. Conf. Multimedia pp. 725-728 2012."}, {"ref": "[6] N. Kohli R. Singh M. Vatsa \"Self-similarity representation of Weber faces for kinship classification\" Proc. IEEE Conf. Biometrics Theory Appl. Syst. pp. 245-250 Sep. 2012."}, {"ref": "[7] Q. Liu A. Puthenputhussery C. Liu \"Inheritable Fisher vector feature for kinship verification\" Proc. IEEE Int. Conf. Biometrics Theory Appl. Syst. pp. 1-6 Sep. 2015."}, {"ref": "[8] X. Wu E. Boutellaa M. B. L\u00f3pez X. Feng A. Hadid \"On the usefulness of color for kinship verification from face images\" Proc. IEEE Int. Workshop Inf. Forensics Secur. pp. 1-6 Dec. 2016."}, {"ref": "[9] S. Xia M. Shao Y. Fu \"Kinship verification through transfer learning\" Proc. Int. Joint Conf. Artif. Intell. pp. 2539-2544 2011."}, {"ref": "[10] M. Shao S. Xia Y. Fu \"Genealogical face recognition based on UB KinFace database\" Proc. IEEE Comput. Vis. Pattern Recognit. Workshops pp. 60-65 Jun. 2011."}, {"ref": "[11] S. Xia M. Shao J. Luo Y. Fu \"Understanding kin relationships in a photo\" IEEE Trans. Multimedia vol. 14 no. 4 pp. 1046-1056 Aug. 2012."}, {"ref": "[12] R. Fang A. C. Gallagher T. Chen A. Loui \"Kinship classification by modeling facial feature heredity\" Proc. Int. Conf. Image Process. pp. 2983-2987 Sep. 2013."}, {"ref": "[13] J. Lu X. Zhou Y.-P. Tan Y. Shang J. Zhou \"Neighborhood repulsed metric learning for kinship verification\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 36 no. 2 pp. 331-345 Feb. 2014."}, {"ref": "[14] J. Hu J. Lu J. Yuan Y.-P. Tan \"Large margin multi-metric learning for face and kinship verification in the wild\" Proc. Asian Conf. Comput. Vis. pp. 252-267 2014."}, {"ref": "[15] H. Yan J. Lu W. Deng X. Zhou \"Discriminative multimetric learning for kinship verification\" IEEE Trans. Inf. Forensics Security vol. 9 no. 7 pp. 1169-1178 Jul. 2014."}, {"ref": "[16] A. Dehghan E. G. Ortiz R. Villegas M. Shah \"Who do i look like? Determining parent-offspring resemblance via gated autoencoders\" Proc. IEEE Comput. Vis. Pattern Recognit. pp. 1757-1764 Jun. 2014."}, {"ref": "[17] Y. Guo H. Dibeklioglu L. van der Maaten \"Graph-based kinship recognition\" Proc. IEEE Int. Conf. Pattern Recognit. pp. 4287-4292 Aug. 2014."}, {"ref": "[18] H. Yan J. Lu X. Zhou \"Prototype-based discriminative feature learning for kinship verification\" IEEE Trans. Cybern. vol. 45 no. 11 pp. 2535-2545 Nov. 2015."}, {"ref": "[19] P. Alirezazadeh A. Fathi F. Abdali-Mohammadi \"A genetic algorithm-based feature selection for kinship verification\" IEEE Signal Process. Lett. vol. 22 no. 12 pp. 2459-2463 Dec. 2015."}, {"ref": "[20] X. Qin X. Tan S. Chen \"Tri-subject kinship verification: Understanding the core of a family\" IEEE Trans. Multimedia vol. 17 no. 10 pp. 1855-1867 Oct. 2015."}, {"ref": "[21] X. Zhou Y. Shang H. Yan G. Guo \"Ensemble similarity learning for kinship verification from facial images in the wild\" Inf. Fusion vol. 32 pp. 40-48 Nov. 2016."}, {"ref": "[22] J. P. Robinson M. Shao Y. Wu Y. Fu \"Families in the wild (FIW): Large-scale kinship image database and benchmarks\" Proc. ACM Conf. Multimedia pp. 242-246 2016."}, {"ref": "[23] M. Xu Y. Shang \"Kinship measurement on face images by structured similarity fusion\" IEEE Access vol. 4 pp. 10280-10287 2016."}, {"ref": "[24] H. Yan \"Kinship verification using neighborhood repulsed correlation metric learning\" Image Vis. Comput. vol. 60 pp. 91-97 Apr. 2017."}, {"ref": "[25] M. B. L\u00f3pez E. Boutellaa A. Hadid \"Comments on the \u2018kinship face in the wild\u2019 data sets\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 38 no. 11 pp. 2342-2344 Nov. 2016."}, {"ref": "[26] A. Puthenputhussery Q. Liu C. Liu \"SIFT flow based genetic fisher vector feature for kinship verification\" Proc. Int. Conf. Image Process. pp. 2921-2925 Sep. 2016."}, {"ref": "[27] L. Li X. Feng X. Wu Z. Xia A. Hadid \"Kinship verification from faces via similarity metric based convolutional neural network\" Proc. Int. Conf. Image Anal. Recognit. pp. 539-548 2016."}, {"ref": "[28] S. Wang J. P. Robinson Y. Fu \"Kinship verification on families in the wild with marginalized denoising metric learning\" Proc. IEEE Int. Conf. Autom. Face Gesture Recognit. pp. 216-221 May/Jun. 2017."}, {"ref": "[29] J. Lu J. Hu Y.-P. Tan \"Discriminative deep metric learning for face and kinship verification\" IEEE Trans. Image Process. vol. 26 no. 9 pp. 4269-4282 Sep. 2017."}, {"ref": "[30] H. Liu J. Cheng F. Wang \"Kinship verification based on status-aware projection learning\" Proc. IEEE Int. Conf. Image Process. pp. 1072-1076 Sep. 2017."}, {"ref": "[31] N. Kohli M. Vatsa R. Singh A. Noore A. Majumdar \"Hierarchical representation learning for kinship verification\" IEEE Trans. Image Process. vol. 26 no. 1 pp. 289-302 Jan. 2017."}, {"ref": "[32] S. Mahpod Y. Keller \"Kinship verification using multiview hybrid distance learning\" Comput. Vis. Image Understand. vol. 167 pp. 28-36 Feb. 2018."}, {"ref": "[33] H. Dibeklioglu A. A. Salah T. Gevers \"Like father like son: Facial expression dynamics for kinship verification\" Proc. IEEE Int. Conf. Comput. Vis. pp. 1497-1504 Dec. 2013."}, {"ref": "[34] H. Dibeklioglu \"Visual transformation aided contrastive learning for video-based kinship verification\" Proc. IEEE Conf. Int. Conf. Comput. Vis. pp. 2459-2468 Oct. 2017."}, {"ref": "[35] T. Pfister X. Li G. Zhao M. Pietik\u00e4inen \"Differentiating spontaneous from posed facial expressions within a generic facial expression recognition framework\" Proc. IEEE Int. Conf. Comput. Vis. Workshops pp. 868-875 Nov. 2011."}, {"ref": "[36] A. Ng \"Sparse autoencoder\" in CS294A Lect. Notes pp. 1-19 2011."}, {"ref": "[37] S. Gao Y. Zhang K. Jia J. Lu Y. Zhang \"Single sample face recognition via learning deep supervised autoencoders\" IEEE Trans. Inf. Forensics Security vol. 10 no. 10 pp. 2108-2118 Oct. 2015."}, {"ref": "[38] A. Majumdar R. Singh M. Vatsa \"Face verification via class sparsity based supervised encoding\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 39 no. 6 pp. 1273-1280 Jun. 2017."}, {"ref": "[39] R. Chartrand \"Exact reconstruction of sparse signals via nonconvex minimization\" IEEE Signal Process. Lett. vol. 14 no. 10 pp. 707-710 Oct. 2007."}, {"ref": "[40] R. Chartrand W. Yin \"Iteratively reweighted algorithms for compressive sensing\" Proc. IEEE Int. Conf. Acoust. Speech Signal Process. pp. 3869-3872 Mar./Apr. 2008."}, {"ref": "[41] Y. Yan Z. Xu G. Liu Z. Ma N. Sebe \"Glocal structural feature selection with sparsity for multimedia data understanding\" Proc. ACM Int. Conf. Multimedia pp. 537-540 2013."}, {"ref": "[42] R. Jenatton J. Mairal G. Obozinski F. Bach \"Proximal methods for sparse hierarchical dictionary learning\" Proc. Int. Conf. Mach. Learn. pp. 487-494 2010."}, {"ref": "[43] Y. Nesterov \"Gradient methods for minimizing composite objective function\" 2007."}, {"ref": "[44] M. Zhang C. Ding Y. Zhang F. Nie \"Feature selection at the discrete limit\" Proc. AAAI Conf. Artif. Intell. pp. 1355-1361 2014."}, {"ref": "[45] C. Cortes V. Vapnik \"Support-vector networks\" Mach. Learn. vol. 20 no. 3 pp. 273-297 1995."}, {"ref": "[46] E. Boutellaa M. B. L\u00f3pez S. Ait-Aoudia X. Feng A. Hadid Kinship verification from videos using spatio-temporal texture features and deep learning 2017 [online] Available: https://arxiv.org/abs/1708.04069."}, {"ref": "[47] G. Zhao M. Pietikainen \"Dynamic texture recognition using local binary patterns with an application to facial expressions\" IEEE Trans. Pattern Anal. Mach. Intell. vol. 29 no. 6 pp. 915-928 Jun. 2007."}, {"ref": "[48] O. Parkhi V. Andrea Z. Andrew \"Deep face recognition\" Proc. Brit. Mach. Vis. Conf. pp. 41.1-41.12 2015."}, {"ref": "[49] A. Sankaran M. Vatsa R. Singh A. Majumdar \"Group sparse autoencoder\" Image Vis. Comput. vol. 60 pp. 64-74 2017."}, {"ref": "[50] G. Kaminski S. Dridi C. Graff E. Gentaz \"Human ability to detect kinship in strangers\u2019 faces: Effects of the degree of relatedness\" Proc. Roy. Soc. B Biol. Sci. vol. 276 no. 1670 pp. 3193-3200 2009."}, {"ref": "[51] G. Goswami R. Bhardwaj R. Singh M. Vatsa \"MDLFace: Memorability augmented deep learning for video face recognition\" Proc. IEEE Int. Joint Conf. Biometrics pp. 1-7 2014."}, {"ref": "[52] G. Goswami M. Vatsa R. Singh \"Face verification via learned representation on feature-rich video frames\" IEEE Trans. Inf. Forensics Security vol. 12 no. 7 pp. 1686-1698 2017."}]}, {"author": ["Xiaoting Wu", "Eric Granger", "Tomi H. Kinnunen", "Xiaoyi Feng", "Abdenour Hadid"], "title": "Audio-Visual Kinship Verification in the Wild", "journal": "International Conference on Biometrics", "year": 2019, "DOI": "", "month": 6, "citations(google scholar)": 1, "abstract": "Kinship verification is a challenging problem, where recognition systems are trained to establish a kin relation between two individuals based on facial images or videos. However, due to variations in capture conditions (background, pose, expression, illumination and occlusion), state-of-the-art systems currently provide a low level of accuracy. As in many visual recognition and affective computing applications, kinship verification may benefit from a combination of discriminant information extracted from both video and audio signals. In this paper, we investigate for the first time the fusion audio-visual information from both face and voice modalities to improve kinship verification accuracy. First, we propose a new multi-modal kinship dataset called TALking KINship (TALKIN), that is comprised of several pairs of video sequences with subjects talking. State-of-the-art conventional and deep learning models are assessed and compared for kinship verification using this dataset. Finally, we propose a deep Siamese network for multi-modal fusion of kinship relations. Experiments with the TALKIN dataset indicate that the proposed Siamese network provides a significantly higher level of accuracy over baseline uni-modal and multi-modal fusion techniques for kinship verification. Results also indicate that audio (vocal) information is complementary and useful for kinship verification problem.", "keywords": ["None"], "reference_count": 39, "ccfClass": "", "important": true, "references": [{"ref": "[1] T. Ahonen, A. Hadid, and M. Pietikainen. Face description with local binary patterns: Application to face recognition. IEEE transactions on pattern analysis and machine intelli- gence, 28(12):2037\u20132041, 2006."}, {"ref": "[2] A. Ariyaeeinia, C. Morrison, A. Malegaonkar, and S. Black. A test of the effectiveness of speaker verification for differentiating between identical twins. Science & Justice: Journal of the Forensic Science Society, 48(4):182\u2013186, Dec. 2008."}, {"ref": "[3] T. Baltru\u0161aitis, C. Ahuja, and L.-P. Morency. Multimodal machine learning: A survey and taxonomy. IEEE Transac- tions on Pattern Analysis and Machine Intelligence, 2018."}, {"ref": "[4] A. Chowdhury, Y. Atoum, L. Tran, X. Liu, and A. Ross. Msu-avis dataset: Fusing face and voice modalities for biometric recognition in indoor surveillance videos. In ICPR 2018."}, {"ref": "[5] J. S. Chung, A. Nagrani, and A. Zisserman. Voxceleb2: Deep speaker recognition. In Interspeech 2018."}, {"ref": "[6] L. Cui and B. Ma. Adaptive feature selection for kinship verification. In ICME 20187."}, {"ref": "[7] N. Dehak, P. J. Kenny, R. Dehak, P. Dumouchel, and P. Ouellet. Front-end factor analysis for speaker verification. IEEE Transactions on Audio, Speech, and Language Processing, 19(4):788\u2013798, 2011."}, {"ref": "[8] H. Dibeklio\u02d8glu, A. Salah, and T. Gevers. Are you really smiling at me? spontaneous versus posed enjoyment smiles. In ECCV 2012."}, {"ref": "[9] H. Dibeklio\u02d8glu, A. Salah, and T. Gevers. Like father, like son: Facial expression dynamics for kinship verification. In ICCV 2013."}, {"ref": "[10] R. Fang, A. Gallagher, T. Chen, and A. Loui. Kinship classification by modeling facial feature heredity. In ICIP 2013."}, {"ref": "[11] R. Fang, K. D. Tang, N. Snavely, and T. Chen. Towards computational models of kinship verification. In ICIP 2010."}, {"ref": "[12] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8):1735\u20131780, 1997."}, {"ref": "[13] J. Kannala and E. Rahtu. BSIF: Binarized statistical image features. In ICPR 2012."}, {"ref": "[14] N. Kohli, M. Vatsa, R. Singh, A. Noore, and A. Majumdar. Hierarchical representation learning for kinship verification. IEEE Transactions on Image Processing, 26(1):289\u2013 302, 2017."}, {"ref": "[15] H. K\u00fcnzel. Automatic Speaker Recognition of Identical Twins. International Journal of Speech Language and the Law, 17(2), Feb. 2011."}, {"ref": "[16] L. Li, X. Feng, X. Wu, Z. Xia, and A. Hadid. Kinship verification from faces via similarity metric based convolutional neural network. In International Conference Image Analysis and Recognition, pages 539\u2013548. Springer, 2016."}, {"ref": "[17] J. Liu, Z. Yuan, and C. Wang. Towards good practices for multi-modal fusion in large-scale video classification. In European Conference on Computer Vision, pages 287\u2013296. Springer, 2018."}, {"ref": "[18] J. Lu, J. Hu, and Y.-P. Tan. Discriminative deep metric learning for face and kinship verification. IEEE Transactions on Image Processing, 26(9):4269\u20134282, 2017."}, {"ref": "[19] J. Lu, X. Zhou, Y.-P. Tan, Y. Shang, and J. Zhou. Neighborhood repulsed metric learning for kinship verification. Pat- tern Analysis and Machine Intelligence, IEEE Transactions on, 36(2):331\u2013345, 2014."}, {"ref": "[20] N. Neverova, C. Wolf, G. Taylor, and F. Nebout. Moddrop: adaptive multi-modal gesture recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 38(8):1692\u20131706, 2016."}, {"ref": "[21] T. Ojala, M. Pietik\u00e4inen, and D. Harwood. A comparative study of texture measures with classification based on featured distributions. Pattern recognition, 29(1):51\u201359, 1996."}, {"ref": "[22] V. Ojansivu and J. Heikkil\u00e4. Blur insensitive texture classification using local phase quantization. In Image and Signal Processing, volume 5099, pages 236\u2013243, 2008."}, {"ref": "[23] O. M. Parkhi, A. Vedaldi, and A. Zisserman. Deep face recognition. In British Machine Vision Conf., 2015."}, {"ref": "[24] X. Qin, X. Tan, and S. Chen. Tri-subject kinship verification: Understanding the core of a family. arXiv preprint arXiv:1501.02555, 2015."}, {"ref": "[25] D. A. Reynolds, T. F. Quatieri, and R. B. Dunn. Speaker Verification Using Adapted Gaussian Mixture Models. Digital Signal Processing, 10(1):19\u201341, Jan. 2000."}, {"ref": "[26] J. P. Robinson, M. Shao, Y. Wu, H. Liu, T. Gillis, and Y. Fu. Visual kinship recognition of families in the wild. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018."}, {"ref": "[27] M. Shao, S. Xia, and Y. Fu. Genealogical face recognition based on ub kinface database. In CVPRw 2011."}, {"ref": "[28] E. Simo-Serra, E. Trulls, L. Ferraz, I. Kokkinos, P. Fua, and F. Moreno-Noguer. Discriminative learning of deep convolutional feature point descriptors. In ICCV 2015."}, {"ref": "[29] P. Tzirakis, G. Trigeorgis, M. A. Nicolaou, B. W. Schuller, and S. Zafeiriou. End-to-end multimodal emotion recognition using deep neural networks. IEEE Journal of Selected Topics in Signal Processing, 11(8):1301\u20131309, 2017."}, {"ref": "[30] R. Vergin, D. O\u2019shaughnessy, and A. Farhat. Generalized mel frequency cepstral coefficients for large-vocabulary speaker-independent continuous-speech recognition. IEEE Transactions on speech and audio processing, 7(5):525\u2013532, 1999."}, {"ref": "[31] S. Wang, Z. Ding, and Y. Fu. Cross-generation kinship verification with sparse discriminative metric. IEEE Transac- tions on Pattern Analysis and Machine Intelligence, pages 1\u20131, 2018."}, {"ref": "[32] X. Wu, E. Boutellaa, M. B. L\u00f3pez, X. Feng, and A. Hadid. On the usefulness of color for kinship verification from face images. In WIFS 2016."}, {"ref": "[33] S. Xia, M. Shao, and Y. Fu. Kinship verification through transfer learning. In IJCAI 2011."}, {"ref": "[34] S. Xia, M. Shao, J. Luo, and Y. Fu. Understanding kin relationships in a photo. Multimedia, IEEE Transactions on, 14(4):1046\u20131056, 2012."}, {"ref": "[35] H. Yan and J. Hu. Video-based kinship verification using distance metric learning. Pattern Recognition, 2017."}, {"ref": "[36] Z. Yu, J. Yu, J. Fan, and D. Tao. Multi-modal factorized bilinear pooling with co-attention learning for visual question answering. In ICCV 2017."}, {"ref": "[37] K. Zhang, Y. Huang, C. Song, H. Wu, and L. Wang. Kinship verification with deep convolutional neural networks. In BMVC 2015."}, {"ref": "[38] K. Zhang, Z. Zhang, Z. Li, and Y. Qiao. Joint face detection and alignment using multitask cascaded convolutional networks. IEEE Signal Processing Letters, 23(10):1499\u20131503, Oct 2016."}, {"ref": "[39] G. Zhao and M. Pietikainen. Dynamic texture recognition using local binary patterns with an application to facial expressions. IEEE transactions on pattern analysis and ma- chine intelligence, 29(6):915\u2013928, 2007."}]}, {"author": ["Lei Ding", "Alper Yilmaz"], "title": "Inferring Social Relations from Visual Concepts", "journal": "ICCV", "year": 2011, "DOI": "10.1109/ICCV.2011.6126306", "month": 11, "citations(google scholar)": 37, "abstract": "In this paper, we study the problem of social relational inference using visual concepts which serve as indicators of actors' social interactions. While social network analysis from videos has started to gain attention in the recent years, the existing work either uses proximity or co-occurrence statistics, or exploit a holistic model of the scene content where the relations are assumed to stay constant throughout the video. This work permits changing relations and argues that there exists a relationship between the visual concepts and the social relations among actors, which is a fundamentally new concept in computer vision. Specifically, we leverage the existing large-scale concept detectors to generate concept score vectors to represent the video content, and we further map them to grouping cues that are used to detect the social structure. In our framework, a probabilistic graphical model with temporal smoothing provides a means to analyze social relations among actors and detect communities. Experiments on Youtube videos and theatrical movies validate the proposed framework.", "keywords": ["None"], "reference_count": 26, "ccfClass": "A", "important": true, "references": [{"ref": "[1] R. Chaudhry A. Ravichandran G. Hager and R. Vidal. Histograms of oriented optical flow and binet-cauchy kernels on nonlinear dynamical systems for the recognition of human actions. In CVPR 2009. 7"}, {"ref": "[2] Y. Chi X. Song D. Zhou K. Hino and B. L. Tseng. Evolutionary spectral clustering by incorporating temporal smoothness. In KDD 2007. 6"}, {"ref": "[3] S. Consolvo I. E. Smith T.Matthews A. LaMarca J. Tabert and P. Powledge. Location disclosure to social relations: Why when &amp; what people want to share. In CHI 2005. 1"}, {"ref": "[4] L. Ding Q. Fan J. Hsiao and S. Pankanti. Graph based event detection from realistic videos using weak feature correspondence. In ICASSP 2010. 1"}, {"ref": "[5] L. Ding and A. Yilmaz. Learning relations among movie characters: A social network perspective. In ECCV 2010. 1 2 3 5 6"}, {"ref": "[6] L. Duan D. Xu I.W. Tsang and J. Luo. Visual event recognition in videos by learning from web data. In CVPR 2010. 1"}, {"ref": "[7] N. Eagle A. Pentland and D. Lazer. Inferring social network structure using mobile phone data. PNAS 106(36):15274-15278 2009. 2"}, {"ref": "[8] R. A. Fisher. The use ofmultiplemeasurements in taxonomic problems. Annals of Eugenics 7:179-188 1936. 3"}, {"ref": "[9] W. Ge R. Collins and B. Ruback. Automatically detecting the small group structure of a crowd. In WACV 2009. 2"}, {"ref": "[10] X. He and P. Niyogi. Locality preserving projections. In NIPS 2003. 3"}, {"ref": "[11] S.M. Lynch. Introduction to Applied Bayesian Statistics and Estimation for Social Scientists. Springer New York 2007. 4"}, {"ref": "[12] M. Naphade J. R. Smith J. Tesic S.-F. Chang W. Hsu L. Kennedy A. Hauptmann and J. Curtis. Large-scale concept ontology for multimedia. IEEE Multimedia 13(3) 2006. 2"}, {"ref": "[13] M. E. J. Newman. Modularity and community structure in networks. PNAS 103(23):8577-8582 2006. 2"}, {"ref": "[14] A. Pentland. Honest Signals: How They Shape Our World (Bradford Books). The MIT Press 2008. 1"}, {"ref": "[15] Z. Rasheed and M. Shah. Scene detection in hollywood movies and tv shows. In CVPR 2003. 3"}, {"ref": "[16] A. J. Smola and B. Sch\u00f6lkopf. A tutorial on support vector regression. Statistics and Computing 14(3):199-222 2004. 3"}, {"ref": "[17] M. Sugiyama. Dimensionality reduction of multimodal labeled data by local Fisher discriminant analysis. Journal of Machine Learning Research 8:1027-1061 2007. 3"}, {"ref": "[18] G. Wang A. Gallagher J. Luo and D. Forsyth. Seeing people in social context: Recognizing people and social relationships. In ECCV 2010. 1"}, {"ref": "[19] P.Wang G. D. Abowd and J.M. Rehg. Quasi-periodic event analysis for social game retrieval. In ICCV 2009. 1"}, {"ref": "[20] S. Wasserman K. Faust and D. Iacobucci. Social Network Analysis: Methods and Applications. Cambridge University Press 1994. 1 2"}, {"ref": "[21] C.-Y. Weng W.-T. Chu and J.-L. Wu. Rolenet: Movie analysis from the perspective of social networks. IEEE Transac-tions on Multimedia 11(2):256-271 2009. 1 2"}, {"ref": "[22] D. Xu and S.-F. Chang. Visual event recognition in news video using kernel methods with multi-level temporal alignment. In CVPR 2007. 1 3"}, {"ref": "[23] A. Yanagawa S.-F. Chang L. Kennedy and W. Hsu. Columbia university's baseline detectors for 374 lscom semantic visual concepts. Technical report Columbia U. 2"}, {"ref": "[24] T. Yang Y. Chi S. Zhu Y. Gong and R. Jin. A bayesian approach toward finding communities and their evolutions in dynamic social networks. In SDM 2009. 2 4"}, {"ref": "[25] T. Yu S.-N. Lim K. Patwardhan and N. Krahnstoever. Monitoring recognizing and discovering social networks. In CVPR 2009. 1 2"}, {"ref": "[26] X. Zhou X. Zhuang S. Yan S.-F. Chang M. Hasegawa-Johnson and T. S. Huang. Sift-bag kernel for video event analysis. In MM 2008. 1"}]}, {"author": ["Vignesh Ramanathan", "Bangpeng Yao", "Li Fei-Fei"], "title": "Social Role Discovery in Human Events", "journal": "CVPR", "year": 2013, "DOI": "10.1109/CVPR.2013.320", "month": 10, "citations(google scholar)": 85, "abstract": "We deal with the problem of recognizing social roles played by people in an event. Social roles are governed by human interactions, and form a fundamental component of human event description. We focus on a weakly supervised setting, where we are provided different videos belonging to an event class, without training role labels. Since social roles are described by the interaction between people in an event, we propose a Conditional Random Field to model the inter-role interactions, along with person specific social descriptors. We develop tractable variational inference to simultaneously infer model weights, as well as role assignment to all people in the videos. We also present a novel YouTube social roles dataset with ground truth role annotations, and introduce annotations on a subset of videos from the TRECVID-MED11 [1] event kits for evaluation purposes. The performance of the model is compared against different baseline methods on these datasets.", "keywords": ["None"], "reference_count": 27, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Trecvid multimedia event detection track. 1, 2, 5"}, {"ref": "[2] B. J. Biddle. Recent development in role theory. Annual Review of Sociology, 12:67\u201392, 1986. 1"}, {"ref": "[3] W. Choi and S. Savarese. A unified framework for multitarget tracking and collective activity recognition. In ECCV, 2012. 2"}, {"ref": "[4] L. Ding and A. Yilmaz. Learning relations among movie characters: A social network perspective. In ECCV, 2010. 2"}, {"ref": "[5] L. Ding and A. Yilmaz. Inferring social relations from visual concepts. In ICCV, 2011. 2"}, {"ref": "[6] C. Direkolu and N. OConnor. Team activity recognition in sports. In ECCV. 2012. 2, 3"}, {"ref": "[7] A. Fathi, J. K. Hoggins, and J. M. Rehg. Social interactions: A first person perspective. In CVPR, 2012. 1, 2"}, {"ref": "[8] P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. IEEE Trans. on PAMI, (9), 2010. 4"}, {"ref": "[9] Y. Fu, T. Hospedales, T. Xiang, and S. Gong. Attribute learning for understanding unstructured social activity. In ECCV, 2012. 2"}, {"ref": "[10] A. C. Gallagher and T. Chen. Understanding images of groups of people. In CVPR, 2009. 2"}, {"ref": "[11] A. Kl\u00a8aser, M. Marsza\u0142ek, and C. Schmid. A spatio-temporal descriptor based on 3d-gradients. In BMVC, 2008. 3"}, {"ref": "[12] A. Klaser, C. Schmid, and C.-L. Liu. Action recognition by dense trajectories. In CVPR. 2011. 4"}, {"ref": "[13] T. Lan, L. Sigal, and G. Mori. Social roles in hierarchical models for human activity recognition. In CVPR, 2012. 1, 2, 3"}, {"ref": "[14] T. Lan, Y.Wang,W. Yang, S. Robinovitch, and G. Mori. Discriminative latent models for recognizing contextual group activities. IEEE Trans. on PAMI, 34(8):1549\u20131562, 2012. 2"}, {"ref": "[15] L.-J. Li, H. Su, E. P. Xing, and L. Fei-Fei. Object bank: A high-level image representation for scene classification and semantic feature sparsification. In NIPS, 2010. 4"}, {"ref": "[16] M. Marin-Jimenez, A. Zisserman, and V. Ferrari. \"heres looking at you, kid\"-detecting people looking at each other in videos. In BMVC, 2011. 2"}, {"ref": "[17] A. P. Perez, M. Marszalek, A. Zisserman, and I. Reid. High five: Recognising human interactions in tv shows. In BMVC, 2010. 2"}, {"ref": "[18] Z. Qin and C. R. Shelton. Improving multi-target tracking via social grouping. In CVPR, 2012. 2"}, {"ref": "[19] Z. Song, M. Wang, X. Hua, and S. Yan. Predicting occupation via human clothing and contexts. In ICCV, 2011. 2"}, {"ref": "[20] Z. Stone, T. Zickler, and T. Darrell. Toward large-scale face recognition using social network context. In Proc. of the IEEE, 2010. 2"}, {"ref": "[21] C. Vondrick and D. Ramanan. Video annotation and tracking with active learning. In NIPS, 2011. 5"}, {"ref": "[22] G. Wang, A. Gallagher, J. Luo, and D. Forsyth. Seeing people in social context: recognizing people and social relationships. In ECCV, 2010. 2"}, {"ref": "[23] C.-Y. Weng, W.-T. Chu, and J.-L. Wu. Rolenet: Movie analysis from the perspective of social networks. IEEE Trans. on Multimedia, (2):256\u2013271, 2009. 2"}, {"ref": "[24] Y. Yang, S. Baker, A. Kannan, and D. Ramanan. Recognizing proxemics in personal photos. In CVPR, 2012. 4"}, {"ref": "[25] T. Yu, S.-N. Lim, K. Patwardhan, and N. Krahnstoever. Monitoring, recognizing and discovering social networks. In CVPR, 2009. 2"}, {"ref": "[26] J. Zhu and E. P. Xing. Conditional topic random fields. In ICML, 2010. 4, 5"}, {"ref": "[27] X. Zhu and D. Ramanan. Face detection, pose estimation, and landmark localization in the wild. In CVPR, 2012. 4."}]}, {"author": ["Jinna Lv", "Wu Liu", "Lili Zhou", "Bin Wu", "Huadong Ma"], "title": "Multi-stream Fusion Model for Social Relation Recognition from Videos", "journal": "MMM", "year": 2018, "DOI": "10.1007/978-3-319-73603-7_29", "month": 2, "citations(google scholar)": 7, "abstract": "Social relations are ubiquitous in people\u2019s daily life. Especially, the widespread of video in social media and intelligent surveillance gives us a new chance to discover the social relations among people. Previous researches mostly focus on the recognition of social relations from texts, blogs, or images. However, these methods are only concentrated on limited social relations and incapable of dealing with video data. In this paper, we address the challenges of social relation recognition by employing a multi-stream model to exploit the abundant multimodal information in videos. First of all, we build a video dataset with 16 categories of social relations annotation according to psychology and sociology studies, named Social Relation In Videos (SRIV), which comprises of 3,124 videos. According to our knowledge, it is the first video dataset for the social relation recognition. Secondly, we propose a multi-stream deep learning model as a benchmark for recognizing social relations, which learns high level semantic information of spatial, temporal, and audio of people\u2019s social interactions in videos. Finally, we fuse them with logical regression to achieve accurate recognition. Experimental results show that the multi-stream deep model is effective for social relation recognition on the proposed dataset.", "keywords": ["Social relation", "Video analysis", "Deep learning"], "reference_count": 19, "ccfClass": "C", "important": true, "references": [{"ref": "[1] Luan, M.N.: Context-aware text representation for social relation aided sentiment analysis. In: WWW, pp. 85\u201386 (2016)"}, {"ref": "[2] Xiang, L., Sang, J., Xu, C.: Demographic attribute inference from social multimedia behaviors: a cross-OSN approach. In: Amsaleg, L., Gu\u00f0mundsson, G.\u00de., Gurrin, C., J\u00f3nsson, B.\u00de., Satoh, S. (eds.) MMM 2017. LNCS, vol. 10132, pp. 515\u2013526. Springer, Cham (2017).  https://xs.scihub.ltd/https://doi.org/10.1007/978-3-319-51811-4_42"}, {"ref": "[3] Dai, Q., Carr, P., Sigal, L., Hoiem, D.: Family member identification from photo collections. In: Applications of Computer Vision, pp. 982\u2013989 (2015)"}, {"ref": "[4] Liu, W., Mei, T., Zhang, Y., Che, C., Luo, J.: Multi-task deep visual-semantic embedding for video thumbnail selection. In: CVPR, pp. 3707\u20133715 (2015)"}, {"ref": "[5] Sun, Q., Schiele, B., Fritz, M.: A domain based approach to social relation recognition. In: CVPR, pp. 435\u2013444 (2017)"}, {"ref": "[6] Zhang, Z., Luo, P., Loy, C.-C., Tang, X.: Learning social relation traits from face images. In: ICCV, pp. 3631\u20133639 (2015)"}, {"ref": "[7] Kiesler, D.J.: The 1982 interpersonal circle: a taxonomy for complementarity in human transactions. Psychol. Rev. 90(3), 185 (1983)"}, {"ref": "[8] Ho, D.Y.: Interpersonal relationships and relationship dominance: An analysis based on methodological relationism. Asian J. Soc. Psychol. 1(1), 1\u201316 (1998)"}, {"ref": "[9] Wang, L., Xiong, Y., Wang, Z., Qiao, Y., Lin, D., Tang, X., Van Gool, L.: Temporal segment networks: towards good practices for deep action recognition. In: Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.) ECCV 2016. LNCS, vol. 9912, pp. 20\u201336. Springer, Cham (2016).  https://xs.scihub.ltd/https://doi.org/10.1007/978-3-319-46484-8_2"}, {"ref": "[10] Tanisik, G., Zalluhoglu, C., Ikizler-Cinbis, N.: Facial descriptors for human interaction recognition in still images. Pattern Recogn. Lett. 73, 44\u201351 (2016)"}, {"ref": "[11] Zurrida, S., Mazzarol, G., Galimberti, V., Renne, G., Bassi, F., Iafrate, F., Viale, G.: Automatic recognition of emergent social roles in small group interactions. IEEE Trans. Multimed. 17(5), 746\u2013760 (2015)"}, {"ref": "[12] Ramanathan, V., Huang, J., Abu-El-Haija, S., Gorban, A., Murphy, K., Fei-Fei, L.: Detecting events and key actors in multi-person videos. In: CVPR, pp. 3043\u20133053 (2016)"}, {"ref": "[13] Tran, Q.D., Jung, J.E.: Cocharnet: extracting social networks using character co-occurrence in movies. J. Univers. Comput. Sci. 21(6), 796\u2013815 (2015)"}, {"ref": "[14] Bojanowski, P., Bach, F., Laptev, I., Ponce, J., Schmid, C., Sivic, J.: Finding actors and actions in movies. In: ICCV, pp. 2280\u20132287 (2013)"}, {"ref": "[15] Petscharnig, S., Sch\u00f6ffmann, K.: Deep learning for shot classification in gynecologic surgery videos. In: Amsaleg, L., Gu\u00f0mundsson, G.\u00de., Gurrin, C., J\u00f3nsson, B.\u00de., Satoh, S. (eds.) MMM 2017. LNCS, vol. 10132, pp. 702\u2013713. Springer, Cham (2017).  https://xs.scihub.ltd/https://doi.org/10.1007/978-3-319-51811-4_57"}, {"ref": "[16] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. In: CVPR, pp. 1\u20139 (2015)"}, {"ref": "[17] Wu, Z., Jiang, Y.-G., Wang, X., Ye, H., Xue, X.: Multi-stream multi-class fusion of deep networks for video classification. In: MM, pp. 791\u2013800 (2016)"}, {"ref": "[18] Ioffe, S., Szegedy, C.: Batch normalization: accelerating deep network training by reducing internal covariate shift. In: ICML, pp. 448\u2013456 (2015)"}, {"ref": "[19] Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Li, F.F.: Imagenet: a large-scale hierarchical image database. In: CVPR, pp. 248\u2013255 (2009)."}]}, {"author": ["Xinchen Liu", "Wu Liu", "Meng Zhang", "Jingwen Chen", "Lianli Gao", "Chenggang Yan", "Tao Mei"], "title": "Social Relation Recognition from Videos via Multi-scale Spatial-Temporal Reasoning", "journal": "CVPR", "year": 2019, "DOI": "", "month": 6, "citations(google scholar)": 1, "abstract": "Discovering social relations, e.g., kinship, friendship, etc., from visual contents can make machines better interpret the behaviors and emotions of human beings. Existing studies mainly focus on recognizing social relations from still images while neglecting another important media--video. On one hand, the actions and storylines in videos provide more important cues for social relation recognition. On the other hand, the key persons may appear at arbitrary spatial-temporal locations, even not in one same image from beginning to the end. To overcome these challenges, we propose a Multi-scale Spatial-Temporal Reasoning (MSTR) framework to recognize social relations from videos. For the spatial representation, we not only adopt a temporal segment network to learn global action and scene information, but also design a Triple Graphs model to capture visual relations between persons and objects. For the temporal domain, we propose a Pyramid Graph Convolutional Network to perform temporal reasoning with multi-scale receptive fields, which can obtain both long-term and short-term storylines in videos. By this means, MSTR can comprehensively explore the multi-scale actions and storylines in spatial-temporal dimensions for social relation reasoning in videos. Extensive experiments on a new large-scale Video Social Relation dataset demonstrate the effectiveness of the proposed framework.", "keywords": ["None"], "reference_count": 33, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Alexandre Alahi, Kratarth Goel, Vignesh Ramanathan, Alexandre Robicquet, Fei-Fei Li, and Silvio Savarese. Social LSTM: human trajectory prediction in crowded spaces. In CVPR, pages 961\u2013971, 2016. 2"}, {"ref": "[2] Timur M. Bagautdinov, Alexandre Alahi, Franc\u00b8ois Fleuret, Pascal Fua, and Silvio Savarese. Social scene understanding: End-to-end multi-person action localization and collective activity recognition. In CVPR, pages 3425\u20133434, 2017. 2"}, {"ref": "[3] Daphne Blunt Bugental. Acquisition of the algorithms of social life: A domain-based approach. Psychological Bulletin, 126(2):187, 2000. 2, 5"}, {"ref": "[4] Micha\u00a8el Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. In NIPS, pages 3837\u20133845, 2016. 3"}, {"ref": "[5] Lei Ding and Alper Yilmaz. Learning relations among movie characters: A social network perspective. In ECCV, pages 410\u2013423, 2010. 1, 2"}, {"ref": "[6] Lei Ding and Alper Yilmaz. Inferring social relations from visual concepts. In ICCV, pages 699\u2013706, 2011. 1, 2"}, {"ref": "[7] Pedro F. Felzenszwalb and Daniel P. Huttenlocher. Efficient graph-based image segmentation. International Journal of Computer Vision, 59(2):167\u2013181, 2004. 3"}, {"ref": "[8] Chuang Gan, Boqing Gong, Kun Liu, Hao Su, and Leonidas J. Guibas. Geometry guided convolutional neural networks for self-supervised video representation learning. In CVPR, pages 5589\u20135597, 2018. 2"}, {"ref": "[9] Kaiming He, Georgia Gkioxari, Piotr Doll\u00b4ar, and Ross B. Girshick. Mask R-CNN. In ICCV, pages 2980\u20132988, 2017. 3"}, {"ref": "[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, pages 770\u2013778, 2016. 3, 4"}, {"ref": "[11] Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. CoRR, abs/ 1609.02907, 2016. 3, 4"}, {"ref": "[12] Junnan Li, Yongkang Wong, Qi Zhao, and Mohan S. Kankanhalli. Dual-glance model for deciphering social relationships. In ICCV, pages 2669\u20132678, 2017. 2, 5, 7"}, {"ref": "[13] Xiaodan Liang, Xiaohui Shen, Jiashi Feng, Liang Lin, and Shuicheng Yan. Semantic object parsing with graph LSTM. In ECCV, pages 125\u2013143, 2016. 3"}, {"ref": "[14] Liang Lin, Xiaolong Wang, Wei Yang, and Jian-Huang Lai. Discriminatively trained and-or graph models for object shape detection. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(5):959\u2013972, 2015. 3"}, {"ref": "[15] Tsung-Yi Lin, Michael Maire, Serge J. Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00b4ar, and C. Lawrence Zitnick. Microsoft COCO: common objects in context. In ECCV, pages 740\u2013755, 2014. 3"}, {"ref": "[16] Kun Liu, Wu Liu, Chuang Gan, Mingkui Tan, and Huadong Ma. T-C3D: temporal convolutional 3d network for real-time action recognition. In AAAI, pages 7138\u20137145, 2018. 3"}, {"ref": "[17] Wei Liu, Yu-Gang Jiang, Jiebo Luo, and Shih-Fu Chang. Noise resistant graph ranking for improved web image search. In CVPR, pages 849\u2013856, 2011. 3"}, {"ref": "[18] Xinchen Liu, Wu Liu, Tao Mei, and Huadong Ma. A deep learning-based approach to progressive vehicle reidentification for urban surveillance. In ECCV, pages 869\u2013 884. Springer, 2016. 3"}, {"ref": "[19] Xinchen Liu, Wu Liu, Tao Mei, and Huadong Ma. Provid: Progressive and multimodal vehicle reidentification for large-scale urban surveillance. IEEE Transactions on Multimedia, 20(3):645\u2013658, 2018. 3"}, {"ref": "[20] Jinna Lv, Wu Liu, Lili Zhou, Bin Wu, and Huadong Ma. Multi-stream fusion model for social relation recognition from videos. In MMM, pages 355\u2013368, 2018. 2, 5, 7"}, {"ref": "[21] You-Jin Park and Kun-Nyeong Chang. Individual and group behavior-based customer profile model for personalized product recommendation. Expert Systems with Applications, 36(2):1932\u20131939, 2009. 1"}, {"ref": "[22] Xiaojuan Qi, Renjie Liao, Jiaya Jia, Sanja Fidler, and Raquel Urtasun. 3d graph neural networks for RGBD semantic segmentation. In ICCV, pages 5209\u20135218, 2017. 3"}, {"ref": "[23] Vignesh Ramanathan, Jonathan Huang, Sami Abu-El-Haija, Alexander N. Gorban, Kevin Murphy, and Li Fei-Fei. Detecting events and key actors in multi-person videos. In CVPR, pages 3043\u20133053, 2016. 1, 2"}, {"ref": "[24] Vignesh Ramanathan, Bangpeng Yao, and Fei-Fei Li. Social role discovery in human events. In CVPR, pages 2475\u20132482, 2013. 1, 2"}, {"ref": "[25] Ashtosh Sapru and Herv\u00b4e Bourlard. Automatic recognition of emergent social roles in small group interactions. IEEE Transactions on Multimedia, 17(5):746\u2013760, 2015. 2"}, {"ref": "[26] Qianru Sun, Bernt Schiele, and Mario Fritz. A domain based approach to social relation recognition. In CVPR, pages 435\u2013 444, 2017. 1, 2, 5, 7"}, {"ref": "[27] Gang Wang, Andrew C. Gallagher, Jiebo Luo, and David A. Forsyth. Seeing people in social context: Recognizing people and social relationships. In ECCV, pages 169\u2013182, 2010. 1, 2"}, {"ref": "[28] Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, and Luc Van Gool. Temporal segment networks: Towards good practices for deep action recognition. In ECCV, pages 20\u201336, 2016. 2, 3, 5, 6"}, {"ref": "[29] Xiaolong Wang and Abhinav Gupta. Videos as space-time region graphs. In ECCV, pages 413\u2013431, 2018. 3, 5"}, {"ref": "[30] ZhouxiaWang, Tianshui Chen, Jimmy S. J. Ren,Weihao Yu, Hui Cheng, and Liang Lin. Deep reasoning with knowledge graph for social relationship understanding. In IJCAI, pages 1021\u20131028, 2018. 1, 2, 3, 7"}, {"ref": "[31] Ting Yu, Ser-Nam Lim, Kedar A. Patwardhan, and Nils Krahnstoever. Monitoring, recognizing and discovering social networks. In CVPR, pages 1462\u20131469, 2009. 1, 2"}, {"ref": "[32] Zhanpeng Zhang, Ping Luo, Chen Change Loy, and Xiaoou Tang. Learning social relation traits from face images. In ICCV, pages 3631\u20133639, 2015. 1, 2, 5"}, {"ref": "[33] Zhanpeng Zhang, Ping Luo, Chen Change Loy, and Xiaoou Tang. From facial expression recognition to interpersonal relation prediction. International Journal of Computer Vision, 126(5):550\u2013569, 2018. 1."}]}, {"author": ["Pilin Dai", "Jinna Lv", "Bin Wu"], "title": "TWO-STAGE MODEL FOR SOCIAL RELATIONSHIP UNDERSTANDING FROM VIDEOS", "journal": "ICME", "year": 2019, "DOI": "10.1109/ICME.2019.00198", "month": 8, "citations(google scholar)": 0, "abstract": "Social relationship understanding from videos bears an enormous potential for social media analysis. However, most existing researches only explored spatio-temporal features from videos, ignoring rich contextual information hidden in semantic objects. In this paper, we propose a Two-Stage Model (TSM), first introducing object information for social relationship understanding from videos, to our best knowledge. In the first stage, rich and robust representation for social relationship is obtained by the extraction of both spatio-temporal features and semantic objects information. In the second stage, we utilize a propagated knowledge graph to capture the interaction between semantic objects and video scenes. Specially, an attention mechanism is employed to measure the effectiveness of each semantic object on different scenes. Extensive experiments demonstrate our TSM achieves the state-of-the-art performance on the dataset SRIV.", "keywords": ["Social relationship", "video analysis", "knowledge graph", "attention mechanism"], "reference_count": 20, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Zhouxia Wang Tianshui Chen S. J. Ren Jimmy Weihao Yu Hui Cheng Liang Lin \"Deep reasoning with knowledge graph for social relationship understanding\" IJCAI pp. 1021-1028 2018."}, {"ref": "[2] Wenjing Cai Jia Jia Wentao Han \"Inferring emotions from image social networks using group-based factor graph model\" ICME pp. 1-6 2018."}, {"ref": "[3] Jinna Lv Wu Liu Lili Zhou Bin Wu Huadong Ma \"Multi-stream fusion model for social relation recognition from videos\" MMM pp. 355-368 2018."}, {"ref": "[4] Jinna Lv Bin Wu \"Spatio-temporal attention model based on multi-view for social relation understanding\" MMM pp. 1-12 2019."}, {"ref": "[5] Kai Xu Guorong Li Huijuan Xu Weigang Zhang Qingming Huang \"Edge guided generation network for video prediction\" ICME pp. 1-6 2018."}, {"ref": "[6] Kang Shi Weiqiang Wang Changsheng Xu \"Entity competition network for video classification\" ICME pp. 1-6 2018."}, {"ref": "[7] Junnan Li Yongkang Wong Qi Zhao Mohan S. Kankanhalli \"Dual-glance model for deciphering social relationships\" ICCV pp. 2669-2678 2017."}, {"ref": "[8] Peter Anderson Xiaodong He Chris Buehler Damien Teney Mark Johnson Stephen Gould Lei Zhang \"Bottom-up and top-down attention for image captioning and visual question answering\" CVPR pp. 6077-6086 2018."}, {"ref": "[9] Amir Zadeh Paul Pu Liang Soujanya Poria Prateek Vij Erik Cambria Louis-Philippe Morency \"Multi-attention recurrent network for human communication comprehension\" AAAI pp. 5642-5649 2018."}, {"ref": "[10] Shang-Fu Chen Yi-Chen Chen Chih-Kuan Yeh Yu-Chiang Frank Wang \"Order-free RNN with visual attention for multi-label classification\" AAAI pp. 6714-6721 2018."}, {"ref": "[11] Zheng Zhu Wei Wu Wei Zou Junjie Yan \"End-to-end flow correlation tracking with spatial-temporal attention\" CVPR pp. 548-557 2018."}, {"ref": "[12] Shaoqing Ren Kaiming He Ross B. Girshick Jian Sun \"Faster R-CNN: towards real-time object detection with region proposal networks\" NIPS pp. 91-99 2015."}, {"ref": "[13] Tsung-Yi Lin Michael Maire Serge J. Belongie James Hays Pietro Perona Deva Ramanan Piotr Doll\u00e1r C. Lawrence Zitnick \"Microsoft COCO: common objects in context\" Computer Vision - ECCV 2014 - 13th European Conference pp. 740-755 2014."}, {"ref": "[14] Daniel Beck Gholamreza Haffari Trevor Cohn \"Graph-to-sequence learning using gated graph neural networks\" ACL pp. 273-283 2018."}, {"ref": "[15] Jin-Hwa Kim Kyoung Woon On Woosang Lim Jeonghee Kim JungWoo Ha Byoung-Tak Zhang \"Hadamard product for low-rank bilinear pooling\" CoRR vol. abs/1610.04325 2016."}, {"ref": "[16] Kaiming He Xiangyu Zhang Shaoqing Ren Jian Sun \"Deep residual learning for image recognition\" CVPR pp. 770-778 2016."}, {"ref": "[17] Karen Simonyan Andrew Zisserman \"Very deep convolutional networks for large-scale image recognition\" CoRR vol. abs/1409.1556 2014."}, {"ref": "[18] Kenneth Marino Ruslan Salakhutdinov Abhinav Gupta \"The more you know: Using knowledge graphs for image classification\" CVPR pp. 20-28 2017."}, {"ref": "[19] Fran\u00e7ois Plesse Alexandru Ginsca Bertrand Delezoide Fran\u00e7oise J. Pr\u00eateux \"Visual relationship detection based on guided proposals and semantic knowledge distillation\" ICME pp. 1-6 2018."}, {"ref": "[20] Limin Wang Yuanjun Xiong Zhe Wang Yu Qiao Dahua Lin Xiaoou Tang Luc Van Gool \"Temporal segment networks: Towards good practices for deep action recognition\" ECCV pp. 20-36 2016."}]}, {"author": ["Jinna Lv", "Bin Wu"], "title": "Spatio-Temporal Attention Model Based on Multi-view for Social Relation Understanding", "journal": "MMM", "year": 2019, "DOI": "10.1007/978-3-030-05716-9_32", "month": 1, "citations(google scholar)": 1, "abstract": "Social relation understanding is an increasingly popular research area. Great progress has been achieved by exploiting sentiment or social relation from image data, however, it is also difficult to attain satisfactory performance for social relation analysis from video data. In this paper, we propose a novel Spatio-Temporal attention model based on Multi-View (STMV) for understanding social relations from video. First, in order to obtain rich representation for social relation traits, we introduce different ConvNets to extract multi-view features including RGB, optical flow, and face. Second, we exploit temporal features of multi-view through time using Long Short-Term Memory (LSTM) for social relation understanding. Specially, we propose multiple attention units in our attention module. Through this manner, we can generate an appropriate feature representation focusing on multiple aspects of social relation traits from video, thus excellent mapping function from low-level video pixels to high-level social relation space can be built. Third, we introduce a tensor fusion layer, which learns interactions among multi-view features. Extensive experiments show that our STMV model achieves the state-of-the-art performance on the SRIV video dataset for social relation classification.", "keywords": ["Social relation understanding", "Video analysis", "Deep learning", "Attention mechanism"], "reference_count": 26, "ccfClass": "C", "important": true, "references": [{"ref": "[1] Xiang, L., Sang, J., Xu, C.: Demographic attribute inference from social multimedia behaviors: a cross-OSN approach. In: Amsaleg, L., Gu\u00f0mundsson, G.\u00de., Gurrin, C., J\u00f3nsson, B.\u00de., Satoh, S. (eds.) MMM 2017. LNCS, vol. 10132, pp. 515\u2013526. Springer, Cham (2017).  https://xs.scihub.ltd/https://doi.org/10.1007/978-3-319-51811-4_42"}, {"ref": "[2] Alletto, S., Serra, G., Calderara, S.: Understanding social relationships in egocentric vision. Pattern Recognit. 48(12), 4082\u20134096 (2015)"}, {"ref": "[3] Tran, Q.D., Jung, J.E.: Cocharnet: extracting social networks using character co-occurrence in movies. J. Univers. Comput. 21(6), 796\u2013815 (2015)"}, {"ref": "[4] Weng, C.Y., Chu, W.T., Wu, J.L.: RoleNet: movie analysis from the perspective of social networks. IEEE Trans. Multimed. 11(2), 256\u2013271 (2009)"}, {"ref": "[5] Hirai, T., Morishima, S.: Frame-wise continuity-based video summarization and stretching. In: Tian, Q., Sebe, N., Qi, G.-J., Huet, B., Hong, R., Liu, X. (eds.) MMM 2016. LNCS, vol. 9516, pp. 806\u2013817. Springer, Cham (2016).  https://xs.scihub.ltd/https://doi.org/10.1007/978-3-319-27671-7_67"}, {"ref": "[6] Mahasseni, B., Lam, M., Todorovic, S.: Unsupervised video summarization with adversarial LSTM networks. In: CVPR, pp. 2982\u20132991 (2017)"}, {"ref": "[7] Sun, Q., Schiele, B., Fritz, M.: A domain based approach to social relation recognition. In: CVPR, pp. 435\u2013444 (2017)"}, {"ref": "[8] Zhang, Z., Luo, P., Loy, C.C., Tang, X.: Learning social relation traits from face images. In: ICCV, pp. 3631\u20133639 (2015)"}, {"ref": "[9] Bojanowski, P., Bach, F., Laptev, I., Ponce, J., Schmid, C., Sivic, J., Finding actors and actions in movies. In: ICCV, pp. 2280\u20132287 (2013)"}, {"ref": "[10] Lv, J., Liu, W., Zhou, L., Wu, B., Ma, H.: Multi-stream fusion model for social relation recognition from videos. In: Schoeffmann, K., et al. (eds.) MMM 2018. LNCS, vol. 10704, pp. 355\u2013368. Springer, Cham (2018).  https://xs.scihub.ltd/https://doi.org/10.1007/978-3-319-73603-7_29"}, {"ref": "[11] Zhu, F., Li, H., Ouyang, W., Yu, N., Wang, X.: Learning spatial regularization with image-level supervisions for multi-label image classification. In: CVPR, pp. 2027\u20132036 (2017)"}, {"ref": "[12] You, Q., Jin, H., Wang, Z., Fang, C., Luo, J.: Image captioning with semantic attention. In: CVPR, pp. 4651\u20134659 (2016)"}, {"ref": "[13] Pan, Y., Yao, T., Li, H., Mei, T.: Video captioning with transferred semantic attributes. In: CVPR, pp. 984\u2013992 (2017)"}, {"ref": "[14] Yu, H., Gui, L., Madaio, M., Ogan, A., Cassell, J., Morency, L.P.: Temporally selective attention model for social and affective state recognition in multimedia content. In: MM, pp. 1743\u20131751 (2017)"}, {"ref": "[15] Yang, Y., et al.: Mining competitive relationships by learning across heterogeneous networks. In: CIKM, pp. 1432\u20131441 (2012)"}, {"ref": "[16] Luong, T., Pham, H., Manning, C.D.: Effective approaches to attention-based neural machine translation. In: EMNLP, pp. 1412\u20131421 (2015)"}, {"ref": "[17] Long, X., Gan, C., de Melo, G., Wu, J., Liu, X., Wen, S.: Attention clusters: Purely attention based local feature integration for video classification. CoRR, abs/1711.09550 (2017)"}, {"ref": "[18] Zadeh, A., Liang, P.P., Poria, S., Vij, P., Cambria, E., Morency, L.: Multi-attention recurrent network for human communication comprehension. arXiv:1802.00923 (2018)"}, {"ref": "[19] Pei, W., Baltrusaitis, T., Tax, D.M.J., Morency, L.: Temporal attention-gated model for robust sequence classification. In: CVPR, pp. 820\u2013829 (2017)"}, {"ref": "[20] Xu, C., Tao, D., Xu, C.: A survey on multi-view learning. CoRR, abs/1304.5634 (2013)"}, {"ref": "[21] Poria, S., Chaturvedi, I., Cambria, E., Hussain, A.: Convolutional MKL based multimodal emotion recognition and sentiment analysis. In: ICDM, pp. 439\u2013448 (2016)"}, {"ref": "[22] Nojavanasghari, B., Gopinath, D., Koushik, J., Baltrusaitis, T., Morency, L.: Deep multimodal fusion for persuasiveness prediction. In: ICMI, pp. 284\u2013288 (2016)"}, {"ref": "[23] Du, T., Bourdev, L., Fergus, R., Torresani, L., Paluri, M.: Learning spatiotemporal features with 3D convolutional networks. In: CVPR, pp. 4489\u20134497 (2015)"}, {"ref": "[24] Findler, N.V.: Short note on a heuristic search strategy in long-term memory networks. Inf. Process. Lett. 1(5), 191\u2013196 (1972)"}, {"ref": "[25] Wang, L., et al.: Temporal segment networks: towards good practices for deep action recognition. In: Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.) ECCV 2016. LNCS, vol. 9912, pp. 20\u201336. Springer, Cham (2016).  https://xs.scihub.ltd/https://doi.org/10.1007/978-3-319-46484-8_2"}, {"ref": "[26] Sun, Y., Wang, X., Tang, X.: Deep learning face representation from predicting 10,000 classes. In: CVPR, pp. 1891\u20131898 (2014)."}]}, {"author": ["Gang Wang", "Andrew Gallagher", "Jiebo Luo", "David Forsyth"], "title": "Seeing People in Social Context: Recognizing People and Social Relationships", "journal": "ECCV", "year": 2010, "DOI": "10.1007/978-3-642-15555-0_13", "month": 9, "citations(google scholar)": 121, "abstract": "The people in an image are generally not strangers, but instead often share social relationships such as husband-wife, siblings, grandparent-child, father-child, or mother-child. Further, the social relationship between a pair of people influences the relative position and appearance of the people in the image. This paper explores using familial social relationships as context for recognizing people and for recognizing the social relationships between pairs of people. We introduce a model for representing the interaction between social relationship, facial appearance, and identity. We show that the family relationship a pair of people share influences the relative pairwise features between them. The experiments on a set of personal collections show significant improvement in people recognition is achieved by modeling social relationships, even in a weak label setting that is attractive in practical applications. Furthermore, we show the social relationships are effectively recognized in images from a separate test image collection.", "keywords": ["None"], "reference_count": 20, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Barnard, K., Duygulu, P., Forsyth, D., de Freitas, N., Blei, D.M., Jordan, M.I.: Matching words and pictures. JMLR 3, 1107\u20131135 (2003)"}, {"ref": "[2] Berg, T., Berg, A., Edwards, J., Maire, M., White, R., Teh, Y.W., Learned-Miller, E., Forsyth, D.: Names and faces in the news. In: Proc. CVPR (2004)"}, {"ref": "[3] Chen, L., Hu, B., Zhang, L., Li, M., Zhang, H.J.: Face annotation for family photo album management. IJIG 3(1), 81\u201394 (2003)"}, {"ref": "[4] Divvala, S.K., Hoiem, D., Hays, J., Efros, A., Hebert, M.: An empirical study of context in object detection. In: Proc. CVPR (2009)"}, {"ref": "[5] Gallagher, A., Chen, T.: Estimating age, gender, and identity using first name priors. In: Proc. CVPR (2008)"}, {"ref": "[6] Gallagher, A., Chen, T.: Understanding Images of Groups of People. In: Proc. CVPR (2009)"}, {"ref": "[7] Guo, G., Fu, Y., Dyer, C., Huang, T.: Image-based human age estimation by manifold learning and locally adjusted robust regression. In: IEEE Trans. on Image Proc. (2008)"}, {"ref": "[8] Gupta, A., Davis, L.S.: Beyond nouns: Exploiting prepositions and comparative adjectives for learning visual classifiers. In: Forsyth, D., Torr, P., Zisserman, A. (eds.) ECCV 2008, Part I. LNCS, vol. 5302, pp. 16\u201329. Springer, Heidelberg (2008)"}, {"ref": "[9] Hoiem, D., Efros, A.A., Hebert, M.: Putting objects in perspective. IJCV 80(1), 3\u201315 (2008)"}, {"ref": "[10] Kapoor, A., Hua, G., Akbarzadeh, A., Baker, S.: Which Faces to Tag: AddingPrior Constraints into Active Learning. In: Proc. ICCV (2009)"}, {"ref": "[11] Kumar, N., Berg, A., Belhumeur, P., Nayar, S.: Attribute and simile classifiers for face verification. In: Proc. ICCV (2009)"}, {"ref": "[12] Naaman, M., Yeh, R., Garcia-Molina, H., Paepcke, A.: Leveraging context to resolve identity in photo albums. In: Proc. JCDL (2005)"}, {"ref": "[13] National Center for Health Statistics. CDC growth charts, United States (2007), http://www.cdc.gov/nchs/data/nhanes/growthcharts/zscore/statage.xls"}, {"ref": "[14] O\u2019Hare, N., Smeaton, A.: Context-aware person identification in personal photo collections. IEEE Trans. MM (2009)"}, {"ref": "[15] Parikh, D., Zitnick, L., Chen, T.: From appearance to context-based recognition: Dense labeling in small images. In: Proc. CVPR (2008)"}, {"ref": "[16] Pellegrini, S., Ess, A., Schindler, K., van Gool, L.: You\u2019ll never walk alone: Modeling social behavior for multi-target tracking. In: Proc. ICCV (2009)"}, {"ref": "[17] Song, Y., Leung, T.: Context-aided human recognition- clustering. In: Leonardis, A., Bischof, H., Pinz, A. (eds.) ECCV 2006. LNCS, vol. 3953, pp. 382\u2013395. Springer, Heidelberg (2006)"}, {"ref": "[18] Stone, Z., Zickler, T., Darrell, T.: Autotagging Facebook: Social network context improves photo annotation. In: Proc. CVPR Internet Vision Workshop (2008)"}, {"ref": "[19] Tian, Y., Liu, W., Xian, R., Wen, F., Tang, X.: A face annotation framework with partial clustering and interactive labeling. In: Proc. CVPR (2007)"}, {"ref": "[20] Zhao, M., Teo, Y.W., Liu, S., Chua, T., Jain, R.: Automatic person annotation of family photo album. In: Sundaram, H., Naphade, M., Smith, J.R., Rui, Y. (eds.) CIVR 2006. LNCS, vol. 4071, pp. 163\u2013172. Springer, Heidelberg (2006)."}]}, {"author": ["Tian Lan", "Leonid Sigal", "Greg Mori"], "title": "Social Roles in Hierarchical Models for Human Activity Recognition", "journal": "CVPR", "year": 2012, "DOI": "10.1109/CVPR.2012.6247821", "month": 6, "citations(google scholar)": 169, "abstract": "We present a hierarchical model for human activity recognition in entire multi-person scenes. Our model describes human behaviour at multiple levels of detail, ranging from low-level actions through to high-level events. We also include a model of social roles, the expected behaviours of certain people, or groups of people, in a scene. The hierarchical model includes these varied representations, and various forms of interactions between people present in a scene. The model is trained in a discriminative max-margin framework. Experimental results demonstrate that this model can improve performance at all considered levels of detail, on two challenging datasets.", "keywords": ["None"], "reference_count": 25, "ccfClass": "A", "important": true, "references": [{"ref": "[1] M. R. Amer and S. Todorovic. A chains model for localizing participants of group activities in videos. In ICCV 2011."}, {"ref": "[2] M.-C. Chang N. Krahnstoever S. Lim and T. Yu. Group level activity recognition in crowded environments across multiple cameras. In AMMCSS 2010."}, {"ref": "[3] W. Choi K. Shahid and S. Savarese. What are they doing? : Collective activity classification using spatio-temporal relationship among people. In Visual Surveillance 2009."}, {"ref": "[4] W. Choi K. Shahid and S. Savarese. Learning context for collective activity recognition. In CVPR 2011."}, {"ref": "[5] F. Cupillard F. Bremond and M. Thonnat. Group behavior recognition with multiple cameras. In WACV 2002."}, {"ref": "[6] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In CVPR 2005."}, {"ref": "[7] C. Desai D. Ramanan and C. Fowlkes. Discriminative models for multi-class object layout. In ICCV 2009."}, {"ref": "[8] P. Felzenszwalb D. McAllester and D. Ramanan. A discriminatively trained multiscale deformable part model. In CVPR 2008."}, {"ref": "[9] A. Gupta P. Srinivasan J. Shi and L. S. Davis. Understanding videos constructing plots - learning a visually grounded storyline model from annotated videos. In CVPR 2009."}, {"ref": "[10] S. S. Intille and A. Bobick. Recognizing planned multiperson action. CVIU 81:414-445 2001."}, {"ref": "[11] T. Joachims. Training linear SVMs in linear time. In SIGKDD 2006."}, {"ref": "[12] D. Kuettel M. D. Breitenstein L. V. Gool and V. Ferrari.What's going on? discovering spatio-temporal dependencies in dynamic scenes. In CVPR 2010."}, {"ref": "[13] T. Lan Y.Wang W. Yang S. Robinovitch and G. Mori. Discriminative latent models for recognizing contextual groupactivities. PAMI 2011."}, {"ref": "[14] C. C. Loy T. Xiang and S. Gong. Modelling activityglobal temporal dependencies using time delayed probabilistic graphical model. In ICCV 2009."}, {"ref": "[15] G. Medioni I. Cohen F. Bremond S. Hongeng and R. Nevatia. Event detection and analysis from video streams. PAMI 23(8):873-889 August 2001."}, {"ref": "[16] R. Mehran A. Oyama and M. Shah. Abnormal crowd behavior detection using social force model. In CVPR 2009."}, {"ref": "[17] D. Moore and I. Essa. Recognizing multitasked activities from video using stochastic context-free grammar. In AAAI 2002."}, {"ref": "[18] P. Nillius J. Sullivan and S. Carlsson. Multi-target tracking- linking identities using bayesian network inference. In Proc. CVPR 2006."}, {"ref": "[19] A. Patron-Perez M. Marszalek A. Zisserman and I. D. Reid. High five: Recognising human interactions in tv shows. In BMVC 2010."}, {"ref": "[20] R. Poppe. A survey on vision-based human action recognition. Image and Vision Computing 28:976-990 2010."}, {"ref": "[21] M. Ryoo and J. Aggarwal. Stochastic representation and recognition of high-level group activities. IJCV 2010."}, {"ref": "[22] C. Schuldt I. Laptev and B. Caputo. Recognizing human actions: A local svm approach. In ICPR 2004."}, {"ref": "[23] H. B. Shitrit J. Berclaz F. Fleuret and P. Fua. Tracking multiple people under global appearance constraints. In ICCV 2011."}, {"ref": "[24] X. Wang X. Ma and E. Grimson. Unsupervised activity perception in crowded and complicated scenes using hierarchical bayesian models. PAMI 31(3):539-555 2009."}, {"ref": "[25] Y. Wang and G. Mori. A discriminative latent model of object classes and attributes. In ECCV 2010."}]}, {"author": ["Yi Yang", "Simon Baker", "Anitha Kannan", "Deva Ramanan"], "title": "Recognizing Proxemics in Personal Photos", "journal": "CVPR", "year": 2012, "DOI": "10.1109/CVPR.2012.6248095", "month": 6, "citations(google scholar)": 92, "abstract": "Proxemics is the study of how people interact. We present a computational formulation of visual proxemics by attempting to label each pair of people in an image with a subset of physically based \u201ctouch codes.\u201d A baseline approach would be to first perform pose estimation and then detect the touch codes based on the estimated joint locations. We found that this sequential approach does not perform well because pose estimation step is too unreliable for images of interacting people, due to difficulties with occlusion and limb ambiguities. Instead, we propose a direct approach where we build an articulated model tuned for each touch code. Each such model contains two people, connected in an appropriate manner for the touch code in question. We fit this model to the image and then base classification on the fitting error. Experiments show that this approach significantly outperforms the sequential baseline as well as other related approches.", "keywords": ["None"], "reference_count": 24, "ccfClass": "A", "important": true, "references": [{"ref": "[1] M. Argyle and B. Foss. The psychology of interpersonal behaviour. Penguin Books Middlesex. England 1967. 1"}, {"ref": "[2] W. Choi K. Shahid and S. Savarese. Learning context for collective activity recognition. In CVPR 2011. 2"}, {"ref": "[3] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In CVPR 2005. 4"}, {"ref": "[4] M. Eichner and V. Ferrari. We are family: Joint pose estimation of multiple persons. In ECCV 2010. 2 7"}, {"ref": "[5] M. Everingham L. Van Gool C. K. I. Williams J. Winn and A. Zisserman. The pascal visual object classes (voc) challenge. IJCV 2010. 6"}, {"ref": "[6] P. Felzenszwalb R. Girshick D. McAllester and D. Ramanan. Object detection with discriminatively trained partbased models. IEEE PAMI 32 2009. 2 4 6"}, {"ref": "[7] P. Felzenszwalb and D. Huttenlocher. Pictorial structures for object recognition. IJCV 61(1) 2005. 4"}, {"ref": "[8] A. Gupta A. Kembhavi and L. S. Davis. Observing human-object interactions: Using spatial and functional compatibility for recognition. IEEE PAMI 31(10) 2009. 2"}, {"ref": "[9] E. Hall. A system for the notation of proxemic behavior. American anthropologist 65(5) 1963. 1"}, {"ref": "[10] E. Hall. The hidden dimension volume 6. Doubleday New York 1966. 1 2"}, {"ref": "[11] D. Han L. Bo and C. Sminchisescu. Selection and context for action recognition. In CVPR pages 1933-1940. IEEE 2009. 2"}, {"ref": "[12] I. Haritaoglu D. Harwood and L. Davis. W4: Real-time surveillance of people and their activities. IEEE PAMI 22 2000. 2"}, {"ref": "[13] N. Ikizler R. Cinbis S. Pehlivan and P. Duygulu. Recognizing actions from still images. In ICPR 2008. 2"}, {"ref": "[14] T. Joachims T. Finley and C. Yu. Cutting plane training of structural SVMs. Machine Learning 77 2009. 6"}, {"ref": "[15] T. Lan Y. Wang W. Yang and G. Mori. Beyond actions: Discriminative models for contextual group activities. In NIPS 2010. 2"}, {"ref": "[16] A. Patron-Perez M. Marszalek A. Zisserman and I. Reid. High five: Recognising human interactions in tv shows. BMVC 2010. 1 2"}, {"ref": "[17] J. Platt. Probabilistic outputs for support vector machines. Bartlett P. Schoelkopf B. Schurmans D. Smola AJ editor Advances in Large Margin Classifiers 1999. 6"}, {"ref": "[18] D. Ramanan. Part-based models for finding people and estimating their pose. In T. Moeslund A. Hilton and L. Sigal editors Visual Analysis of Humans. Springer 2011. 2"}, {"ref": "[19] A. Sadeghi and A. Farhadi. Recognition using visual phrases. In CVPR 2011. 2 6"}, {"ref": "[20] P. Viola J. C. Platt and C. Zhang. Multiple instance boosting for object detection. In NIPS 18. MIT Press 2006. 6"}, {"ref": "[21] Y. Wang H. Jiang M. Drew Z. Li and G. Mori. Unsupervised discovery of action classes. In CVPR 2006. 2"}, {"ref": "[22] W. Yang Y.Wang and G. Mori. Recognizing human actions from still images with latent poses. In CVPR pages 2030-2037. IEEE 2010. 2"}, {"ref": "[23] Y. Yang and D. Ramanan. Articulated pose estimation using flexible mixtures of parts. In CVPR 2011. Code available at http://phoenix.ics.uci.edu/ software/pose/. 3 4 5 6"}, {"ref": "[24] B. Yao and L. Fei-Fei. Modeling mutual context of object and human pose in human-object interaction activities. In CVPR 2010. 2."}]}, {"author": ["P. Bojanowski", "F. Bach", "I. Laptev", "J. Ponce", "C. Schmid", "J. Sivic"], "title": "Finding Actors and Actions in Movies", "journal": "ICCV", "year": 2013, "DOI": "10.1109/ICCV.2013.283", "month": 3, "citations(google scholar)": 105, "abstract": "We address the problem of learning a joint model of actors and actions in movies using weak supervision provided by scripts. Specifically, we extract actor/action pairs from the script and use them as constraints in a discriminative clustering framework. The corresponding optimization problem is formulated as a quadratic program under linear constraints. People in video are represented by automatically extracted and tracked faces together with corresponding motion features. First, we apply the proposed framework to the task of learning names of characters in the movie and demonstrate significant improvements over previous methods used for this task. Second, we explore the joint actor/action constraint and show its advantage for weakly supervised action learning. We validate our method in the challenging setting of localizing and recognizing characters and their actions in feature length movies Casablanca and American Beauty.", "keywords": ["None"], "reference_count": 26, "ccfClass": "A", "important": true, "references": [{"ref": "[1] http://www.di.ens.fr/willow/research/actoraction, 2013. 5, 7, 8"}, {"ref": "[2] F. Bach and Z. Harchaoui. Diffrac: a discriminative and flexible framework for clustering. In NIPS, 2007. 2, 3, 4"}, {"ref": "[3] C. F. Baker, C. J. Fillmore, and J. B. Lowe. The berkeley framenet project. In COLING-ACL, 1998. 4"}, {"ref": "[4] K. Barnard, P. Duygulu, N. de Freitas, D. Forsyth, D. Blei, and M. Jordan. Matching words and pictures. J. Machine Learning Research, 2003. 2"}, {"ref": "[5] T. L. Berg, A. C. Berg, J. Edwards, M. Maire, R. White, Y. W. Teh, E. G. Learned-Miller, and D. A. Forsyth. Names and faces in the news. In CVPR, 2004. 1, 2"}, {"ref": "[6] T. Cour, B. Sapp, C. Jordan, and B. Taskar. Learning from ambiguously labeled images. In CVPR, 2009. 1, 2, 5, 6"}, {"ref": "[7] D. Das, A. F. T. Martins, and N. A. Smith. An exact dual decomposition algorithm for shallow semantic parsing with constraints. In SEM, 2012. 4"}, {"ref": "[8] O. Duchenne, I. Laptev, J. Sivic, F. Bach, and J. Ponce. Automatic annotation of human actions in video. In ICCV, 2009. 1, 2"}, {"ref": "[9] M. Everingham, J. Sivic, and A. Zisserman. \"Hello! My name is... Buffy\" \u2013 automatic naming of characters in TV video. In BMVC, 2006. 2, 3, 4, 5"}, {"ref": "[10] A. Farhadi, M. Hejrati, A. Sadeghi, P. Young, C. Rashtchian, J. Hockenmaier, and D. Forsyth. Every picture tells a story: generating sentences for images. In ECCV, 2010. 2"}, {"ref": "[11] M. Guillaumin, T. Mensink, J. Verbeek, and C. Schmid. Tagprop: Discriminative metric learning in nearest neighbor models for image auto-annotation. In CVPR, 2009. 2"}, {"ref": "[12] Y. Guo and D. Schuurmans. Convex relaxations of latent variable training. In NIPS, 2007. 4"}, {"ref": "[13] A. Gupta and L. Davis. Beyond nouns: Exploiting prepositions and comparative adjectives for learning visual classifiers. In ECCV, 2008. 1, 2"}, {"ref": "[14] A. Gupta, P. Srinivasan, J. Shi, and L. Davis. Understanding videos, constructing plots learning a visually grounded storyline model from annotated videos. In CVPR, 2009. 2"}, {"ref": "[15] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller. Labeled faces in the wild: A database for studying face recognition in unconstrained environments. Technical report, 2007. 5"}, {"ref": "[16] A. Joulin, F. Bach, and J. Ponce. Multi-class cosegmentation. In CVPR, 2012. 2"}, {"ref": "[17] A. Joulin, F. R. Bach, and J. Ponce. Discriminative clustering for image co-segmentation. In CVPR, 2010. 2, 4"}, {"ref": "[18] I. Laptev, M. Marszalek, C. Schmid, and B. Rozenfeld. Learning realistic human actions from movies. In CVPR, 2008. 1, 2"}, {"ref": "[19] J. Luo, B. Caputo, and V. Ferrari. Who\u2019s doing what: Joint modeling of names and verbs for simultaneous face and pose annotation. In NIPS, 2009. 1, 2"}, {"ref": "[20] M. Marszalek, I. Laptev, and C. Schmid. Actions in context. In CVPR, 2009. 1, 5"}, {"ref": "[21] V. Ordonez, G. Kulkarni, and T. Berg. Im2text: Describing images using 1 million captioned photographs. In NIPS, 2011. 2"}, {"ref": "[22] J. Sivic, M. Everingham, and A. Zisserman. \"who are you?\" - learning person specific classifiers from video. In CVPR, 2009. 1, 2, 4, 5, 6"}, {"ref": "[23] M. Tapaswi, M. Bauml, and R. Stiefelhagen. \"knock! knock! who is it?\" probabilistic person identification in tv-series. In CVPR, 2012. 1"}, {"ref": "[24] S. Vijayanarasimhan and K. Grauman. Keywords to visual categories: Multiple-instance learning forweakly supervised object categorization. In CVPR, 2008. 3"}, {"ref": "[25] Y. Wang and G. Mori. A discriminative latent model of image region and object tag correspondence. In NIPS, 2010. 2, 4, 5"}, {"ref": "[26] X. Zhu and D. Ramanan. Face detection, pose estimation, and landmark localization in the wild. In CVPR, 2012. 4"}]}, {"author": ["Tianmin Shu", "Dan Xie", "Brandon Rothrock", "Sinisa Todorovic", "Song-Chun Zhu"], "title": "Joint Inference of Groups, Events and Human Roles in Aerial Videos", "journal": "CVPR", "year": 2015, "DOI": "10.1109/CVPR.2015.7299088", "month": 10, "citations(google scholar)": 72, "abstract": "With the advent of drones, aerial video analysis becomes increasingly important; yet, it has received scant attention in the literature. This paper addresses a new problem of parsing low-resolution aerial videos of large spatial areas, in terms of 1) grouping, 2) recognizing events and 3) assigning roles to people engaged in events. We propose a novel framework aimed at conducting joint inference of the above tasks, as reasoning about each in isolation typically fails in our setting. Given noisy tracklets of people and detections of large objects and scene surfaces (e.g., building, grass), we use a spatiotemporal AND-OR graph to drive our joint inference, using Markov Chain Monte Carlo and dynamic programming. We also introduce a new formalism of spatiotemporal templates characterizing latent sub-events. For evaluation, we have collected and released a new aerial videos dataset using a hex-rotor flying over picnic areas rich with group events. Our results demonstrate that we successfully address above inference tasks under challenging conditions.", "keywords": ["None"], "reference_count": 41, "ccfClass": "A", "important": true, "references": [{"ref": "[1] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. S\u00a8usstrunk. Slic superpixels compared to state-of-the-art superpixel methods. IEEE TPAMI, 34(11):2274\u20132282, 2012. 2"}, {"ref": "[2] AFRL. WPAFB, 2009. https://www.sdms.afrl.af.mil/index. php?collection=wpafb2009. 6"}, {"ref": "[3] S. Ali, V. Reilly, and M. Shah. Motion and appearance contexts for tracking and re-acquiring targets in aerial videos. In CVPR, 2007. 6"}, {"ref": "[4] M. R. Amer, D. Xie, M. Zhao, S. Todorovic, and S.-C. Zhu. Cost-sensitive top-down/bottom-up inference for multiscale activity recognition. In ECCV, 2012. 3, 6"}, {"ref": "[5] B. Antic and B. Ommer. Learning latent constituents for recognition of group activities in video. In ECCV, 2014. 3"}, {"ref": "[6] W. Choi, Y.W. Chao, C. Pantofaru, and S. Savarese. Discovering groups of people in images. In ECCV, 2014. 3"}, {"ref": "[7] W. Choi and S. Savarese. Understanding collective activities of people from videos. IEEE TPAMI, 36(6):1242\u20131257, 2014. 2, 3, 7"}, {"ref": "[8] W. Choi, K. Shahid, and S. Savarese. What are they doing?: Collective activity classification using spatio-temporal relationship among people. In CVPR Workshops, 2009. 3, 6, 7"}, {"ref": "[9] A. Fathi, J. K. Hodgins, and J. M. Rehg. Social interactions: A first-person perspective. In CVPR, 2012. 2, 3, 6"}, {"ref": "[10] W. Ge, T. R. Collins, and R. B. Ruback. Vision-based analysis of small groups in pedestrian crowds. IEEE TPAMI, 34(5):1003\u20131016, 2012. 3, 5, 7"}, {"ref": "[11] A. Gupta, P. Srinivasan, J. Shi, and L. S. Davis. Understanding videos, constructing plots learning a visually grounded storyline model from annotated videos. In CVPR, 2009. 3"}, {"ref": "[12] Y. Iwashita, M. Ryoo, T. J. Fuchs, and C. Padgett. Recognizing humans in motion: Trajectory-based aerial video analysis. In BMVC, 2013. 1, 3, 6, 7"}, {"ref": "[13] M. Keck, L. Galup, and C. Stauffer. Real-time tracking of low-resolution vehicles for wide-area persistent surveillance. In WACV, 2013. 1, 3, 6"}, {"ref": "[14] S. Kwak, B. Han, and J. H. Han. Multi-agent event detection: Localization and role assignment. In CVPR, 2013. 3, 6"}, {"ref": "[15] J. Kwon and K. M. Lee. Wang-landau monte carlobased tracking methods for abrupt motions. IEEE TPAMI, 35(4):1011\u20131024, 2012. 2"}, {"ref": "[16] T. Lan, L. Sigal, and G. Mori. Social roles in hierarchical models for human activity recognition. In CVPR, 2012. 2, 3, 6"}, {"ref": "[17] T. Lan, Y. Wang, W. Yang, S. N. Robinovitch, and G. Mori. Discriminative latent models for recognizing contextual group activities. IEEE TPAMI, 34(8):1549\u20131562, 2012. 3"}, {"ref": "[18] R. Li, P. Porfilio, and T. Zickler. Finding group interactions in social clutter. In CVPR, 2013. 3, 6"}, {"ref": "[19] L. Lin, H. Gong, L. Li, and L. Wang. Semantic event representation and recognition using syntactic attribute graph grammar. PRL, 30(2):180\u2013186, 2009. 3"}, {"ref": "[20] C. C. Loy, T. Xiang, and S. Gong. Incremental activity modelling in multiple disjoint cameras. IEEE TPAMI, 34(9):1799\u20131813, 2012. 3"}, {"ref": "[21] R. Nevatia, T. Zhao, and S. Hongeng. Hierarchical languagebased representation of events in video streams. In IEEE Workshop on Event Mining, 2003. 3"}, {"ref": "[22] S. Oh et al. A large-scale benchmark dataset for event recognition in surveillance video. In CVPR, 2011. 6"}, {"ref": "[23] O. Oreifej, R. Mehran, and M. Shah. Human identity recognition in aerial images. In CVPR, 2010. 1, 3, 6"}, {"ref": "[24] M. Pei, Z. Si, B. Yao, and S.-C. Zhu. Video event parsing and learning with goal and intent prediction. CVIU, 117(10):1369\u20131383, 2013. 3"}, {"ref": "[25] S. Pellegrini, A. Ess, K. Schindler, and L. van Gool. You\u2019ll never walk alone: Modeling social behavior for multi-target tracking. In ICCV, 2009. 2"}, {"ref": "[26] H. Pirsiavash and D. Ramanan. Parsing videos of actions with segmental grammars. In CVPR, 2014. 3"}, {"ref": "[27] T. Pollard and M. Antone. Detecting and tracking all moving objects in wide-area aerial video. In CVPRWorkshops, 2012. 3"}, {"ref": "[28] J. Porway, K. Wang, and S.-C. Zhu. A hierarchical and contextual model for aerial image parsing. IJCV, 88(2):254\u2013283, 2010. 8"}, {"ref": "[29] J. Prokaj and M. Gerard. Persistent tracking for wide area aerial surveillance. In CVPR, 2014. 1, 3, 6"}, {"ref": "[30] V. Ramananthan, B. Yao, and L. Fei-Fei. Social role discovery in human events. In CVPR, 2013. 2, 3, 6"}, {"ref": "[31] B. Rothrock, S. Park, and S.-C. Zhu. Integrating grammar and segmentation for human pose estimation. In CVPR, 2013. 2, 7"}, {"ref": "[32] M. S. Ryoo and J. K. Aggarwal. Stochastic representation and recognition of high-level group activities. IJCV, 93(2):183\u2013200, 2011. 2, 3, 6"}, {"ref": "[33] A. Sobral. BGSLibrary: An opencv c++ background subtraction library. In IX Workshop de Vis\u02dcao Computacional (WVC\u20192013), 2013. 7"}, {"ref": "[34] L. Sun, H. Ai, and S. Lao. Activity group localization by modeling the relations among participants. In ECCV, 2014. 3"}, {"ref": "[35] E. Swears, A. Hoogs, Q. Ji, and K. Boyer. Complex activity recognition using granger constrained dbn (gcdbn) in sports and surveillance video. In CVPR, 2014. 3"}, {"ref": "[36] K. Tu, M.Meng, M.W. Lee, T. E. Choi, and S.-C. Zhu. Joint video and text parsing for understanding events and answering queires. IEEE MultiMedia, 21(2):42\u201370, 2014. 3"}, {"ref": "[37] C. Vondrick, D. Patterson, and D. Ramanan. Efficiently scaling up crowdsourced video annotation. IJCV, 101(1):184\u2013 204, 2013. 6"}, {"ref": "[38] J. Xiao, H. Cheng, H. Sawhney, and F. Han. Vehicle detection and tracking in wide field-of-view aerial video. In CVPR, 2010. 3"}, {"ref": "[39] D. Xie, S. Todorovic, and S.-C. Zhu. Inferring \"dark matter\" and \"dark energy\" from videos. In ICCV, 2013. 8"}, {"ref": "[40] J. Yao and J.-M. Odobez. Multi-layer background subtraction based on color and texture. In CVPR Workshops, 2007. 7"}, {"ref": "[41] J. Zhang, W. Hu, B. Z. Yao, Y. Wang, and S.-C. Zhu. Inferring social roles in long timespan video sequence. In ICCV Workshops, 2011. 3, 6."}]}, {"author": ["Ning Zhang", "Manohar Paluri", "Yaniv Taigman", "Rob Fergus", "Lubomir Bourdev"], "title": "Beyond Frontal Faces: Improving Person Recognition Using Multiple Cues", "journal": "CVPR", "year": 2015, "DOI": "10.1109/CVPR.2015.7299113", "month": 10, "citations(google scholar)": 93, "abstract": "We explore the task of recognizing peoples' identities in photo albums in an unconstrained setting. To facilitate this, we introduce the new People In Photo Albums (PIPA) dataset, consisting of over 60000 instances of ~2000 individuals collected from public Flickr photo albums. With only about half of the person images containing a frontal face, the recognition task is very challenging due to the large variations in pose, clothing, camera viewpoint, image resolution and illumination. We propose the Pose Invariant PErson Recognition (PIPER) method, which accumulates the cues of poselet-level person recognizers trained by deep convolutional networks to discount for the pose variations, combined with a face recognizer and a global recognizer. Experiments on three different settings confirm that in our unconstrained setup PIPER significantly improves on the performance of DeepFace, which is one of the best face recognizers as measured on the LFW dataset.", "keywords": ["None"], "reference_count": 40, "ccfClass": "A", "important": true, "references": [{"ref": "[1] D. Anguelov, K. chih Lee, S. B. Gktrk, and B. Sumengen. Contextual identity recognition in personal photo albums. In CVPR, 2007. 3"}, {"ref": "[2] L. Bourdev and J. Malik. Poselets: Body part detectors trained using 3D human pose annotations. In International Conference on Computer Vision (ICCV), 2009. 1, 2, 4, 5"}, {"ref": "[3] L. D. Bourdev, S. Maji, and J. Malik. Describing people: A poselet-based approach to attribute classification. In ICCV, 2011. 2"}, {"ref": "[4] M. Buml, M. Tapaswi, and R. Stiefelhagen. Semi-supervised learning with constraints for person identification in multimedia data. In CVPR\u201913, 2013. 3"}, {"ref": "[5] Z. Cui, W. Li, D. Xu, S. Shan, and X. Chen. Fusing robust face region descriptors via multiple metric learning for face recognition in the wild. In CVPR, 2013. 2"}, {"ref": "[6] J. Deng, W. Dong, R. Socher, L. jia Li, K. Li, and L. Fei-fei. Imagenet: A large-scale hierarchical image database. In In CVPR, 2009. 6"}, {"ref": "[7] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In International Conference in Machine Learning (ICML), 2014. 3, 4"}, {"ref": "[8] M. Everingham, J. Sivic, and A. Zisserman. \"Hello! My name is... Buffy\" \u2013 automatic naming of characters in TV video. In Proceedings of the British Machine Vision Conference, 2006. 3"}, {"ref": "[9] M. Everingham, J. Sivic, and A. Zisserman. Taking the bite out of automated naming of characters in tv video. Image Vision Comput., 27(5):545\u2013559, Apr. 2009. 3"}, {"ref": "[10] M. Farenzena, L. Bazzani, A. Perina, V. Murino, and M. Cristani. Person re-identification by symmetry-driven accumulation of local features. In CVPR, 2010. 3"}, {"ref": "[11] A. Gallagher and T. Chen. Clothing cosegmentation for recognizing people. In Proc. CVPR, 2008. 3"}, {"ref": "[12] A. C. Gallagher and T. Chen. Understanding images of groups of people. In CVPR, 2009. 3"}, {"ref": "[13] R. Garg, D. Ramanan, S. Seitz, and N. Snavely. Where\u2019s waldo: Matching people in images of crowds. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2011. 3"}, {"ref": "[14] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In CVPR, 2014. 3"}, {"ref": "[15] D. Gray, S. Brennan, and H. Tao. Evaluating appearance models for recognition, reacquisition, and tracking. In In IEEE International Workshop on Performance Evaluation for Tracking and Surveillance, Rio de Janeiro, 2007. 3"}, {"ref": "[16] D. Gray and H. Tao. Viewpoint invariant pedestrian recognition with an ensemble of localized features. In Proceedings of the 10th European Conference on Computer Vision: Part I, ECCV \u201908, pages 262\u2013275, 2008. 3"}, {"ref": "[17] M. Guillaumin, J. Verbeek, and C. Schmid. Is that you? metric learning approaches for face identification. In ICCV, Kyoto, Japan, Sept. 2009. 3"}, {"ref": "[18] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller. Labeled faces in the wild: A database for studying face recognition in unconstrained environments. Technical Report 07-49, University of Massachusetts, Amherst, October 2007. 1"}, {"ref": "[19] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Neural Information Processing Systems (NIPS), 2012. 3, 4, 6"}, {"ref": "[20] R. Layne, T. Hospedales, and S. Gong. Person reidentification by attributes. In BMVC\"12, 2012. 3"}, {"ref": "[21] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel. Backpropagation applied to handwritten zip code recognition. Neural Comput., 1(4):541\u2013551, Dec. 1989. 3"}, {"ref": "[22] W. Li, R. Zhao, and X. Wang. Human reidentification with transferred metric learning. In ACCV, volume 7724 of Lecture Notes in Computer Science, pages 31\u201344. Springer, 2012. 3"}, {"ref": "[23] W. Li, R. Zhao, T. Xiao, and X. Wang. Deepreid: Deep filter pairing neural network for person re-identification. In CVPR\u201914, 2014. 3"}, {"ref": "[24] D. Lin, A. Kapoor, G. Hua, and S. Baker. Joint people, event, and location recognition in personal photo collections using cross-domain context. In Proceedings of the 11th European Conference on Computer Vision: Part I, ECCV\u201910, pages 243\u2013256, 2010. 3"}, {"ref": "[25] M. Naaman, H. Garcia-Monlina, A. Paepcke, and R. B. Yeh. Leveraging context to resolve identity in photo albums. In JCDL\u201905, 2005. 3"}, {"ref": "[26] O. Oreifej, R. Mehran, and M. Shah. Human identity recognition in aerial images. In CVPR, pages 709\u2013716, 2010. 3"}, {"ref": "[27] B. Prosser, W. shi Zheng, S. Gong, and T. Xiang. Person reidentification by support vector ranking. In BMVC\u201910, 2010. 3"}, {"ref": "[28] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint, arXiv:1409.1556, 2014. 4"}, {"ref": "[29] J. Sivic, M. Everingham, and A. Zisserman. \"Who are you?\" \u2013 learning person specific classifiers from video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2009. 3"}, {"ref": "[30] J. Sivic, C. L. Zitnick, and R. Szeliski. Finding people in repeated shots of the same scene. In BMVC\u201906, 2006. 3"}, {"ref": "[31] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. arXiv preprint, arXiv:1409.4842, 2014. 4"}, {"ref": "[32] Y. Taigman, M. Yang, M. Ranzato, and L. Wolf. DeepFace: Closing the Gap to Human-Level Performance in Face Verification. In Conference on Computer Vision and Pattern Recognition (CVPR), 2014. 1, 2, 3, 4, 6"}, {"ref": "[33] M. Tapaswi, M. Buml, and R. Stiefelhagen. Knock! knock! who is it? probabilistic person identification in tv-series. In CVPR\u201912, 2012. 3"}, {"ref": "[34] M. Turk and A. Pentland. Eigenfaces for recognition. J. Cognitive Neuroscience, 3(1):71\u201386, Jan. 1991. 2"}, {"ref": "[35] G. Wang, A. Gallagher, J. Luo, and D. Forsyth. Seeing people in social context: Recognizing people and social relationships. In Proceedings of the 11th European Conference on Computer Vision: Part V, ECCV\u201910, pages 169\u2013182, 2010. 3"}, {"ref": "[36] J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma. Robust face recognition via sparse representation. IEEE Trans. Pattern Anal. Mach. Intell., 31(2):210\u2013227, Feb. 2009. 2"}, {"ref": "[37] D. Yi, Z. Lei, and S. Z. Li. Deep metric learning for practical person re-identification. arXiv preprint, arXiv:1407.4979, 2014. 3"}, {"ref": "[38] N. Zhang, M. Paluri, M. Ranzato, T. Darrell, and L. D. Bourdev. PANDA: pose aligned networks for deep attribute modeling. CVPR, 2014. 2"}, {"ref": "[39] R. Zhao, W. Ouyang, and X. Wang. Unsupervised salience learning for person re-identification. In CVPR\u201913, 2013. 3"}, {"ref": "[40] R. Zhao, W. Ouyang, and X. Wang. Learning mid-level filters for person re-identification. In CVPR\u201914, 2014. 3."}]}, {"author": ["Maedeh Aghaei", "Mariella Dimiccoli", "Petia Radeva"], "title": "Towards social interaction detection in egocentric photo-streams", "journal": "ICMV", "year": 2015, "DOI": "10.1117/12.2228606", "month": 12, "citations(google scholar)": 13, "abstract": "Detecting social interaction in videos relying solely on visual cues is a valuable task that is receiving increasing attention in recent years. In this work, we address this problem in the challenging domain of egocentric photo-streams captured by a low temporal resolution wearable camera (2fpm). The major difficulties to be handled in this context are the sparsity of observations as well as unpredictability of camera motion and attention orientation due to the fact that the camera is worn as part of clothing. Our method consists of four steps: multi-faces localization and tracking, 3D localization, pose estimation and analysis of f-formations. By estimating pair-to-pair interaction probabilities over the sequence, our method states the presence or absence of interaction with the camera wearer and specifies which people are more involved in the interaction. We tested our method over a dataset of 18.000 images and we show its reliability on our considered purpose.", "keywords": ["Egocentric photo-streams", "lifelogging", "social interactions detection", "f-formations"], "reference_count": 8, "ccfClass": "", "important": true, "references": [{"ref": "[1] Fathi, A., Hodgins, J. K., & Rehg, J. M. (2012). Social interactions: A first-person perspective. In CVPR, 2012 IEEE Conference on (pp. 1226-1233).Google Scholar"}, {"ref": "[2] Ryoo, M. S., & Matthies, L. (2013). First-person activity recognition: What are they doing to me?, In CVPR, 2013 IEEE Conference on (pp. 2730-2737).Google Scholar"}, {"ref": "[3] Alletto, S., Serra, G., Calderara, S., Solera, F., & Cucchiara, R. (2014). From ego to nos-vision: detecting social relationships in first-person views. In CVPRW, 2014 IEEE Conference on (pp. 594-599).Google Scholar"}, {"ref": "[4] Kendon, A. (1990). Conducting interaction: Patterns of behavior in focused encounters (Vol. 7). CUP Archive.Google Scholar"}, {"ref": "[5] Aghaei, M., Dimiccoli, M., & Radeva, P. (2015). Multi-Face Tracking by Extended Bag-of-Tracklets in Egocentric Videos.arXiv preprint arXiv:1507.04576.Google Scholar"}, {"ref": "[6] Zhu, X., & Ramanan, D. (2012). Face detection, pose estimation, and landmark localization in the wild.In CVPR, 2012 IEEE Conference on (pp. 2879-2886).Google Scholar"}, {"ref": "[7] Cristani, M., Bazzani, L., Paggetti, G., Fossati, A., Tosato, D., Del Bue, A., & Murino, V. (2011). Social interaction discovery by statistical analysis of F-formations. In BMVC (Vol. 2, p. 4).Google Scholar"}, {"ref": "[8] Mantel, N. (1967). The detection of disease clustering and a generalized regression approach.Cancer research, 27(2 Part 1), 209-220.Google Scholar"}]}, {"author": ["Maedeh Aghaei", "Mariella Dimiccoli", "Petia Radeva"], "title": "With Whom Do I Interact? Detecting Social Interactions in Egocentric Photo-streams", "journal": "ICPR", "year": 2016, "DOI": "10.1109/ICPR.2016.7900087", "month": 12, "citations(google scholar)": 16, "abstract": "Given a user wearing a low frame rate wearable camera during a day, this work aims to automatically detect the moments when the user gets engaged into a social interaction solely by reviewing the automatically captured photos by the worn camera. The proposed method, inspired by the sociological concept of F-formation, exploits distance and orientation of the appearing individuals -with respect to the user- in the scene from a bird-view perspective. As a result, the interaction pattern over the sequence can be understood as a two-dimensional time series that corresponds to the temporal evolution of the distance and orientation features over time. A Long-Short Term Memory-based Recurrent Neural Network is then trained to classify each time series. Experimental evaluation over a dataset of 30.000 images has shown promising results on the proposed method for social interaction detection in egocentric photo-streams.", "keywords": ["None"], "reference_count": 28, "ccfClass": "C", "important": true, "references": [{"ref": "[1] E. Goffman et al. The presentation of self in everyday life Harmondsworth 1978."}, {"ref": "[2] D. Umberson J. K. Montez \"Social relationships and health a flashpoint for health policy\" Journal of health and social behavior vol. 51 no. 1 pp. S54-S66 2010."}, {"ref": "[3] D. Gatica-Perez \"Automatic nonverbal analysis of social interaction in small groups: A review\" Image and Vision Computing vol. 27 no. 12 pp. 1775-1787 2009."}, {"ref": "[4] M. Baccouche F. Mamalet C. Wolf C. Garcia A. Baskurt \"Action classification in soccer videos with long short-term memory recurrent neural networks\" Artificial Neural Networks-ICANN pp. 154-159 2010."}, {"ref": "[5] G. Piriou P. Bouthemy J.-F. Yao \"Extraction of semantic dynamic content from videos with probabilistic motion models\" ECCV pp. 145-157 2004."}, {"ref": "[6] Y. Li C. J. Kuo Video content analysis using multimodal information: For movie content extraction indexing and representation Springer Science &amp; Business Media 2013."}, {"ref": "[7] X. Alameda-Pineda J. Staiano R. Subramanian L. Batrinca E. Ricci B. Lepri O. Lanz N. Sebe Salsa: A novel dataset for multimodal group behaviour analysis 2015."}, {"ref": "[8] A. Vinciarelli M. Pantic H. Bourlard \"Social signal processing: Survey of an emerging domain\" Image and Vision Computing vol. 27 no. 12 pp. 1743-1759 2009."}, {"ref": "[9] A. Fathi J. K. Hodgins J. M. Rehg \"Social interactions: A first-person perspective\" CVPR pp. 1226-1233 2012."}, {"ref": "[10] S. Alletto G. Serra S. Calderara F. Solera R. Cucchiara \"From ego to nos-vision: detecting social relationships in first-person views\" CVPRW pp. 580-585 2014."}, {"ref": "[11] M. Ryoo L. Matthies \"First-person activity recognition: What are they doing to me?\" CVPR pp. 2730-2737 2013."}, {"ref": "[12] M. Cristani L. Bazzani G. Paggetti A. Fossati D. Tosato A. Del Bue G. Menegaz V. Murino \"Social interaction discovery by statistical analysis of f-formations\" BMVC vol. 2 pp. 4 2011."}, {"ref": "[13] M. Cristani R. Raghavendra A. Del Bue V. Murino \"Human behavior analysis in video surveillance: A social signal processing perspective\" Neurocomputing vol. 100 pp. 86-97 2013."}, {"ref": "[14] A. Kendon \"Conducting interaction Patterns of behavior in focused encounters\" CUP Archive vol. 7 1990."}, {"ref": "[15] M. Aghaei M. Dimiccoli P. Radeva \"Towards social interaction detection in egocentric photo-streams\" Eighth International conference on Machine Vision pp. 987514-987514 2015."}, {"ref": "[16] M. Aghaei \"Multi-face tracking by extended bag-of-tracklets in egocentric photo-streams\" Computer Vision and Image Understanding vol. 149 pp. 146-156 2016."}, {"ref": "[17] E. Talavera M. Dimiccoli M. Bolanos M. Aghaei P. Radeva \"R-clustering for egocentric video segmentation\" Iberian Conference on Pattern Recognition and Image Analysis pp. 327-336 2015."}, {"ref": "[18] X. Zhu D. Ramanan \"Face detection pose estimation and landmark localization in the wild\" CVPR pp. 2879-2886 2012."}, {"ref": "[19] S. S. Farfade M. J. Saberian L.-J. Li \"Multi-view face detection using deep convolutional neural networks\" Proceedings of the 5th ACM on International conference on Multimedia Retrieval pp. 643-650 2015."}, {"ref": "[20] L. Yao A. Torabi K. Cho N. Ballas C. Pal H. Larochelle A. Courville \"Describing videos by exploiting temporal structure\" ICCV pp. 4507-4515 2015."}, {"ref": "[21] A. Karpathy L. Fei-Fei \"Deep visual-semantic alignments for generating image descriptions\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition pp. 3128-3137 2015."}, {"ref": "[22] S. Hochreiter J. Schmidhuber \"Long short-term memory\" Neural computation vol. 9 no. 8 pp. 1735-1780 1997."}, {"ref": "[23] A. Graves J. Schmidhuber \"Framewise phoneme classification with bidirectional and other neural network architectures\" Neural Networks vol. 18 no. 5 pp. 602-610 2005."}, {"ref": "[24] Q. Lyu J. Zhu \"Revisit long short-term memory: An optimization perspective\" Advances in neural information processing systems workshop on deep Learning and representation Learning 2014."}, {"ref": "[25] J. Nonnemaker H. S. Baird \"Using synthetic data safely in classification\" IS&amp;T/SPIE Electronic Imaging pp. 72470G-72470G 2009."}, {"ref": "[26] F. Hutter H. Hoos K. Leyton-Brown \"An efficient approach for assessing hyperparameter importance\" Proceedings of the 31st International conference on Machine Learning (ICML-14) pp. 754-762 2014."}, {"ref": "[27] K. Eggensperger F. Hutter H. H. Hoos K. Leyton-Brown \"Efficient benchmarking of hyperparameter optimizers via surrogates\" AAAI pp. 1114-1120 2015."}, {"ref": "[28] J. Ngiam A. Coates A. Lahiri B. Prochnow Q. V. Le A. Y. Ng \"On optimization methods for deep learning\" Proceedings of the 28th International conference on Machine Learning (ICML-11) pp. 265-272 2011."}]}, {"author": ["Maedeh Aghaei", "Mariella Dimiccoli", "Cristian Canton Ferrer", "Petia Radeva"], "title": "Towards social pattern characterization in egocentric photo-streams", "journal": "Computer Vision and Image Understanding", "year": 2018, "DOI": "10.1016/j.cviu.2018.05.001", "month": 6, "citations(google scholar)": 10, "abstract": "Following the increasingly popular trend of social interaction analysis in egocentric vision, this article presents a comprehensive pipeline for automatic social pattern characterization of a wearable photo-camera user. The proposed framework relies merely on the visual analysis of egocentric photo-streams and consists of three major steps. The first step is to detect social interactions of the user where the impact of several social signals on the task is explored. The detected social events are inspected in the second step for categorization into different social meetings. These two steps act at event-level where each potential social event is modeled as a multi-dimensional time-series, whose dimensions correspond to a set of relevant features for each task; finally, LSTM is employed to classify the time-series. The last step of the framework is to characterize social patterns of the user. Our goal is to quantify the duration, the diversity and the frequency of the user social relations in various social situations. This goal is achieved by the discovery of recurrences of the same people across the whole set of social events related to the user. Experimental evaluation over EgoSocialStyle - the proposed dataset in this work, and EGO-GROUP demonstrates promising results on the task of social pattern characterization from egocentric photo-streams.", "keywords": ["Social pattern characterization", "Social signal extraction", "Lifelogging", "Convolutional and recurrent neural networks"], "reference_count": 57, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Aghaei, Dimiccoli, Radeva, 2015 M. Aghaei, M. Dimiccoli, P. Radeva Towards social interaction detection in egocentric photo-streams Eighth International Conference on Machine Vision, International Society for Optics and Photonics (2015), pp. 987514-987519"}, {"ref": "[2] Aghaei, Dimiccoli, Radeva, 2016 M. Aghaei, M. Dimiccoli, P. Radeva Multi-face tracking by extended bag-of-tracklets in egocentric photo-streams Comput. Vis. Image Underst., 149 (2016), pp. 146-156"}, {"ref": "[3] Aghaei, Dimiccoli, Radeva, 2016 M. Aghaei, M. Dimiccoli, P. Radeva With whom do I interact? Detecting social interactions in egocentric photo-streams 23rd International Conference on Pattern Recognition, IEEE (2016), pp. 2959-2964"}, {"ref": "[4] Aghaei, Dimiccoli, Radeva, 2017 M. Aghaei, M. Dimiccoli, P. Radeva All the people around me: face discovery in egocentric photo-streams International Conference on Image Processing (2017)"}, {"ref": "[5] Alletto, Serra, Calderara, Cucchiara, 2015 S. Alletto, G. Serra, S. Calderara, R. Cucchiara Understanding social relationships in egocentric vision Pattern Recognit., 48 (12) (2015), pp. 4082-4096"}, {"ref": "[6] Amato, Debole, Falchi, Gennaro, Rabitti, 2016 G. Amato, F. Debole, F. Falchi, C. Gennaro, F. Rabitti Large scale indexing and searching deep convolutional neural network features International Conference on Big Data Analytics and Knowledge Discovery, Springer (2016), pp. 213-224"}, {"ref": "[7] Aung, Matthews, Choudhury, 2017 M.H. Aung, M. Matthews, T. Choudhury Sensing behavioral symptoms of mental health and delivering personalized interventions using mobile technologies Depress. Anxiety (2017)"}, {"ref": "[8] Barsoum, Zhang, Ferrer, Zhang, 2016 E. Barsoum, C. Zhang, C.C. Ferrer, Z. Zhang Training deep networks for facial expression recognition with crowd-sourced label distribution ACM International Conference on Multimodal Interaction (2016)"}, {"ref": "[9] Berry, Hansen, 1996 D.S. Berry, J.S. Hansen Positive affect, negative affect, and social interaction J. Pers. Soc. Psychol., 71 (4) (1996), p. 796"}, {"ref": "[10] Berry, Kapur, Williams, Hodges, Watson, Smyth, Srinivasan, Smith, Wilson, Wood, 2007 E. Berry, N. Kapur, L. Williams, S. Hodges, P. Watson, G. Smyth, J. Srinivasan, R. Smith, B. Wilson, K. Wood The use of a wearable camera, sensecam, as a pictorial diary to improve autobiographical memory in a patient with limbic encephalitis: a preliminary report Neuropsychol. Rehabil., 17 (4\u20135) (2007), pp. 582-601"}, {"ref": "[11] Betancourt, Morerio, Regazzoni, Rauterberg, 2015 A. Betancourt, P. Morerio, C.S. Regazzoni, M. Rauterberg The evolution of first person vision methods: a survey Trans. Circuits Syst. Video Technol., 25 (5) (2015), pp. 744-760"}, {"ref": "[12] Bolanos, Dimiccoli, Radeva, 2017 M. Bolanos, M. Dimiccoli, P. Radeva Toward storytelling from visual lifelogging: an overview Trans. Hum.-Mach. Syst., 47 (1) (2017), pp. 77-90"}, {"ref": "[13] Brown, Blake, Sherman, 2017 N.A. Brown, A.B. Blake, R.A. Sherman A snapshot of the life as lived: wearable cameras in social and personality psychological science Soc. Psychol. Pers. Sci. (2017)"}, {"ref": "[14] Carstensen, 1992 L.L. Carstensen Social and emotional patterns in adulthood: support for socioemotional selectivity theory Psychol. Aging, 7 (3) (1992), p. 331"}, {"ref": "[15] Choi, Chao, Pantofaru, Savarese, 2014 W. Choi, Y.-W. Chao, C. Pantofaru, S. Savarese Discovering groups of people in images European Conference on Computer Vision, Springer (2014), pp. 417-433"}, {"ref": "[16] Chow, Xiong, Fua, Bonelli, Teachman, Barnes Chow, P., Xiong, H., Fua, K., Bonelli, W., Teachman, B. A., Barnes, L. E., 2016. Sad: social anxiety and depression monitoring system for college students."}, {"ref": "[17] Cristani, Bazzani, Paggetti, Fossati, Tosato, Del Bue, Menegaz, Murino, 2011 M. Cristani, L. Bazzani, G. Paggetti, A. Fossati, D. Tosato, A. Del Bue, G. Menegaz, V. Murino Social interaction discovery by statistical analysis of F-formations BMVC, 2 (2011), p. 4"}, {"ref": "[18] Cristani, Raghavendra, Del Bue, Murino, 2013 M. Cristani, R. Raghavendra, A. Del Bue, V. Murino Human behavior analysis in video surveillance: a social signal processing perspective Neurocomputing, 100 (2013), pp. 86-97"}, {"ref": "[19] Deng, Dong, Socher, Li, Li, Fei-Fei, 2009 J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei Imagenet: a large-scale hierarchical image database Conference on Computer Vision and Pattern Recognition, IEEE (2009), pp. 248-255"}, {"ref": "[20] Dhand, Dalton, Luke, Gage, Lee, 2016 A. Dhand, A.E. Dalton, D.A. Luke, B.F. Gage, J.-M. Lee Accuracy of wearable cameras to track social interactions in stroke survivors J. Stroke Cerebrovasc. Dis (2016)"}, {"ref": "[21] Dimiccoli, Bola\u00f1os, Talavera, Aghaei, Nikolov, Radeva, 2016 M. Dimiccoli, M. Bola\u00f1os, E. Talavera, M. Aghaei, S.G. Nikolov, P. Radeva Sr-clustering: semantic regularized clustering for egocentric photo streams segmentation Comput. Vis. Image Underst (2016)"}, {"ref": "[22] Dimitrova, 2016 M. Dimitrova Towards design of high-level synthetic sensors for socially-competent computing systems Revolutionizing Education through Web-Based Instruction (2016), pp. 21-34"}, {"ref": "[23] Fathi, Hodgins, Rehg, 2012 A. Fathi, J.K. Hodgins, J.M. Rehg Social interactions: a first-person perspective Conference on Computer Vision and Pattern Recognition, IEEE (2012), pp. 1226-1233"}, {"ref": "[24] Gan, Wong, Zhang, Kankanhalli, 2013 T. Gan, Y. Wong, D. Zhang, M.S. Kankanhalli Temporal encoded F-formation system for social interaction detection Proceedings of the 21st ACM International Conference on Multimedia, ACM (2013), pp. 937-946"}, {"ref": "[25] Girshick, Donahue, Darrell, Malik, 2014 R. Girshick, J. Donahue, T. Darrell, J. Malik Rich feature hierarchies for accurate object detection and semantic segmentation Proceedings of the Conference on Computer Vision and Pattern Recognition (2014), pp. 580-587"}, {"ref": "[26] Granholm, Ben-Zeev, Fulford, Swendsen, 2013 E. Granholm, D. Ben-Zeev, D. Fulford, J. Swendsen Ecological momentary assessment of social functioning in schizophrenia: impact of performance appraisals and affect on social interactions Schizophr. Res., 145 (1) (2013), pp. 120-124"}, {"ref": "[27] Graves, Schmidhuber, 2005 A. Graves, J. Schmidhuber Framewise phoneme classification with bidirectional LSTM and other neural network architectures Neural Netw., 18 (5) (2005), pp. 602-610"}, {"ref": "[28] Greff, Srivastava, Koutn\u00edk, Steunebrink, Schmidhuber, 2017 K. Greff, R.K. Srivastava, J. Koutn\u00edk, B.R. Steunebrink, J. Schmidhuber LSTM: a search space odyssey IEEE Trans. Neural Netw. Learn. Syst (2017)"}, {"ref": "[29] Groh, Lehmann, Reimers, Frie\u00df, Schwarz, 2010 G. Groh, A. Lehmann, J. Reimers, M.R. Frie\u00df, L. Schwarz Detecting social situations from interaction geometry Second International Conference on Social Computing, IEEE (2010), pp. 1-8"}, {"ref": "[30] Hess, Bourgeois, 2010 U. Hess, P. Bourgeois You smile\u2013I smile: emotion expression in social interaction Biol. Psychol., 84 (3) (2010), pp. 514-520"}, {"ref": "[31] Hochreiter, Schmidhuber, 1997 S. Hochreiter, J. Schmidhuber Long short-term memory Neural Comput., 9 (8) (1997), pp. 1735-1780"}, {"ref": "[32] Hodges, Berry, Wood, 2011 S. Hodges, E. Berry, K. Wood Sensecam: a wearable camera that stimulates and rehabilitates autobiographical memory Memory, 19 (7) (2011), pp. 685-696"}, {"ref": "[33] Hudson, Hudson, Craig Hudson, P. B., Hudson, S. M., Craig, R. F., 2006. Distributing leadership for initiating university-community engagement."}, {"ref": "[34] Hughes, 1968 G. Hughes On the mean accuracy of statistical pattern recognizers Trans. Inf. Theory, 14 (1) (1968), pp. 55-63"}, {"ref": "[35] Hung, Kr\u00f6se, 2011 H. Hung, B. Kr\u00f6se Detecting F-formations as dominant sets Proceedings of the 13th International Conference on Multimodal Interfaces, ACM (2011), pp. 231-238"}, {"ref": "[36] Jia, Gavves, Fernando, Tuytelaars, 2015 X. Jia, E. Gavves, B. Fernando, T. Tuytelaars Guiding the long-short term memory model for image caption generation Proceedings of the International Conference on Computer Vision (2015), pp. 2407-2415"}, {"ref": "[37] Kendon, 1976 A. Kendon The F-formation system: the spatial organization of social encounters Man-Environ. Syst., 6 (1976), pp. 291-296"}, {"ref": "[38] Krizhevsky, Sutskever, Hinton, 2012 A. Krizhevsky, I. Sutskever, G.E. Hinton Imagenet classification with deep convolutional neural networks Advances in Neural Information Processing Systems (2012), pp. 1097-1105"}, {"ref": "[39] Ma, Sigal, Sclaroff, 2016 S. Ma, L. Sigal, S. Sclaroff Learning activity progression in LSTMs for activity detection and early detection Proceedings of the Conference on Computer Vision and Pattern Recognition (2016), pp. 1942-1950"}, {"ref": "[40] Mangrum, Fairley, Wieder, 2001 F.G. Mangrum, M.S. Fairley, D.L. Wieder Informal problem solving in the technology-mediated work place J. Bus. Commun. (1973), 38 (3) (2001), pp. 315-336"}, {"ref": "[41] Muncy, 2001 R. Muncy Disconnecting: social and civic life in America since 1965 Rev. Am. Hist., 29 (1) (2001), pp. 141-149"}, {"ref": "[42] Narayan, Kankanhalli, Ramakrishnan, 2014 S. Narayan, M.S. Kankanhalli, K.R. Ramakrishnan Action and interaction recognition in first-person videos Proceedings of the Conference on Computer Vision and Pattern Recognition Workshops (2014), pp. 512-518"}, {"ref": "[43] Oh, Chung, Labianca, 2004 H. Oh, M.-H. Chung, G. Labianca Group social capital and group effectiveness: the role of informal socializing ties Acad. Manage. J., 47 (6) (2004), pp. 860-875"}, {"ref": "[44] Palispis, 2007 E. Palispis Introduction to Sociology and Anthropology Manila: Rex Book Store, Inc (2007)"}, {"ref": "[45] Park, Shi, 2015 H. Park, J. Shi Social saliency prediction Proceedings of the Conference on Computer Vision and Pattern Recognition (2015), pp. 4777-4785"}, {"ref": "[46] Pascanu, Mikolov, Bengio, 2013 R. Pascanu, T. Mikolov, Y. Bengio On the difficulty of training recurrent neural networks ICML, 28 (3) (2013), pp. 1310-1318"}, {"ref": "[47] Peter Valenzuela MD, 2012 M. Peter Valenzuela MD Applying creativity to health care: learning from innovative companies Physician Exec., 38 (5) (2012), p. 34"}, {"ref": "[48] Setti, Lanz, Ferrario, Murino, Cristani, 2013 F. Setti, O. Lanz, R. Ferrario, V. Murino, M. Cristani Multi-scale F-formation discovery for group detection International Conference on Image Processing, IEEE (2013), pp. 3547-3551"}, {"ref": "[49] Setti, Russell, Bassetti, Cristani, 2015 F. Setti, C. Russell, C. Bassetti, M. Cristani F-formation detection: individuating free-standing conversational groups in images PLoS ONE, 10 (5) (2015), p. e0123783"}, {"ref": "[50] Simonyan, Zisserman Simonyan, K., Zisserman, A., 2014. Very deep convolutional networks for large-scale image recognition. arXiv:1409.1556."}, {"ref": "[51] Steinlin, 2005 M. Steinlin Knowledge management Feng Shui: designing knowledge sharing-friendly office space Knowl. Manage. Dev. J., 1 (2) (2005)"}, {"ref": "[52] Wong, Gatt, Stamatescu, McDonnell, 2016 S.C. Wong, A. Gatt, V. Stamatescu, M.D. McDonnell Understanding data augmentation for classification: when to warp? 2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA), IEEE (2016), pp. 1-6"}, {"ref": "[53] Woodberry, Browne, Hodges, Watson, Kapur, Woodberry, 2015 E. Woodberry, G. Browne, S. Hodges, P. Watson, N. Kapur, K. Woodberry The use of a wearable camera improves autobiographical memory in patients with Alzheimer\u2019s disease Memory, 23 (3) (2015), pp. 340-349"}, {"ref": "[54] Xiong, Quek, 2005 Y. Xiong, F. Quek Meeting room configuration and multiple camera calibration in meeting analysis Proceedings of the 7th International Conference on Multimodal Interfaces, ACM (2005), pp. 37-44"}, {"ref": "[55] Yang, Lee, Yang, Somayazulu, Chen, Chien, 2016 J.-A. Yang, C.-H. Lee, S.-W. Yang, V.S. Somayazulu, Y.-K. Chen, S.-Y. Chien Wearable social camera: egocentric video summarization for social interaction International Conference on Multimedia & Expo Workshops, IEEE (2016), pp. 1-6"}, {"ref": "[56] Yonetani, Kitani, Sato, 2016 R. Yonetani, K.M. Kitani, Y. Sato Recognizing micro-actions and reactions from paired egocentric videos Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2016), pp. 2629-2638"}, {"ref": "[57] Zhou, Lapedriza, Xiao, Torralba, Oliva, 2014 B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, A. Oliva Learning deep features for scene recognition using places database Advances in Neural Information Processing Systems (2014), pp. 487-495."}]}, {"author": ["Junnan Li", "Yongkang Wong", "Qi Zhao", "Mohan S. Kankanhalli"], "title": "Visual Social Relationship Recognition", "journal": "arXiv", "year": 2018, "DOI": "", "month": 12, "citations(google scholar)": 0, "abstract": "Social relationships form the basis of social structure of humans. Developing computational models to understand social relationships from visual data is essential for building intelligent machines that can better interact with humans in a social environment. In this work, we study the problem of visual social relationship recognition in images. We propose a Dual-Glance model for social relationship recognition, where the first glance fixates at the person of interest and the second glance deploys attention mechanism to exploit contextual cues. To enable this study, we curated a large scale People in Social Context (PISC) dataset, which comprises of 23,311 images and 79,244 person pairs with annotated social relationships. Since visually identifying social relationship bears certain degree of uncertainty, we further propose an Adaptive Focal Loss to leverage the ambiguous annotations for more effective learning. We conduct extensive experiments to quantitatively and qualitatively demonstrate the efficacy of our proposed method, which yields state-of-the-art performance on social relationship recognition.", "keywords": ["Social Relationship", "Label Ambiguity", "Context-driven Analysis", "Attention"], "reference_count": 61, "ccfClass": "", "important": true, "references": [{"ref": "[1] Agrawal A, Batra D, Parikh D, Kembhavi A (2018) Don't just assume; look and answer: Overcoming priors for visual question answering. In: CVPR, pp 6904-6913"}, {"ref": "[2] Alahi A, Goel K, Ramanathan V, Robicquet A, Fei-Fei L, Savarese S (2016) Social LSTM: Human trajectory prediction in crowded spaces. In: CVPR, pp 961-971"}, {"ref": "[3] Alameda-Pineda X, Staiano J, Subramanian R, Batrinca LM, Ricci E, Lepri B, Lanz O, Sebe N (2016) SALSA: A novel dataset for multimodal group behavior analysis. IEEE Trans Pattern Anal Mach Intell 38(8):1707-1720"}, {"ref": "[4] Alletto S, Serra G, Calderara S, Solera F, Cucchiara R (2014) From ego to nos-vision: Detecting social relationships in first-person views. In: CVPR Workshops, pp 594-599"}, {"ref": "[5] Chen Y, Hsu WH, Liao HM (2012) Discovering informative social subgraphs and predicting pairwise relationships from group photos. In: ACMMM, pp 669-678"}, {"ref": "[6] Choi W, Savarese S (2012) A unified framework for multitarget tracking and collective activity recognition. In: ECCV, Lecture Notes in Computer Science, vol 7575, pp 215-230"}, {"ref": "[7] Chu X, Ouyang W, Yang W,Wang X (2015) Multi-task recurrent neural network for immediacy prediction. In: ICCV, pp 3352-3360"}, {"ref": "[8] Conte HR, Plutchik R (1981) A circumplex model for interpersonal personality traits. Journal of Personality and Social Psychology 40(4):701"}, {"ref": "[9] Deng Z, Vahdat A, Hu H, Mori G (2016) Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition. In: CVPR, pp 4772- 4781"}, {"ref": "[10] Dibeklioglu H, Salah AA, Gevers T (2013) Like father, like son: Facial expression dynamics for kinship verification. In: ICCV, pp 1497-1504"}, {"ref": "[11] Ding L, Yilmaz A (2014) Learning social relations from videos: Features, models, and analytics. In: Human- Centered Social Media Analytics, pp 21-41"}, {"ref": "[12] Direkoglu C, O'Connor NE (2012) Team activity recognition in sports. In: ECCV, Lecture Notes in Computer Science, vol 7578, pp 69-83"}, {"ref": "[13] Fan L, Chen Y, Wei P, Wang W, Zhu SC (2018) Inferring shared attention in social scene videos. In: CVPR, pp 6460-6468"}, {"ref": "[14] Fang R, Tang KD, Snavely N, Chen T (2010) Towards computational models of kinship verification. In: ICIP, pp 1577-1580"}, {"ref": "[15] Fiske AP (1992) The four elementary forms of sociality: framework for a unified theory of social relations. Psychological review 99(4):689"}, {"ref": "[16] Gallagher AC, Chen T (2009) Understanding images of groups of people. In: CVPR, pp 256-263"}, {"ref": "[17] Gan T, Wong Y, Zhang D, Kankanhalli MS (2013) Temporal encoded F-formation system for social interaction detection. In: ACMMM, pp 937-946"}, {"ref": "[18] Gao B, Xing C, Xie C, Wu J, Geng X (2017) Deep label distribution learning with label ambiguity. IEEE Trans Image Processing 26(6):2825-2838"}, {"ref": "[19] Gkioxari G, Girshick RB, Malik J (2015) Contextual action recognition with R*CNN. In: ICCV, pp 1080-1088"}, {"ref": "[20] Goyal Y, Khot T, Summers-Stay D, Batra D, Parikh D (2017) Making the V in VQA matter: Elevating the role of image understanding in visual question answering. In: CVPR, pp 6325-6334"}, {"ref": "[21] Guo Y, Dibeklioglu H, van der Maaten L (2014) Graph-based kinship recognition. In: ICPR, pp 4287-4292"}, {"ref": "[22] Hall ET (1959) The silent language, vol 3. Doubleday New York"}, {"ref": "[23] Haslam N (1994) Categories of social relationship. Cognition 53(1):59-90"}, {"ref": "[24] Haslam N, Fiske AP (1992) Implicit relationship prototypes: Investigating five theories of the cognitive organization of social relationships. Journal of Experimental Social Psychology 28(5):441-474"}, {"ref": "[25] He K, Zhang X, Ren S, Sun J (2016) Deep residual learning for image recognition. In: CVPR, pp 770-778"}, {"ref": "[26] Hung H, Jayagopi DB, Yeo C, Friedland G, Ba SO, Odobez J, Ramchandran K, Mirghafori N, Gatica-Perez D (2007) Using audio and video features to classify the most dominant person in a group meeting. In: ACMMM, pp 835-838"}, {"ref": "[27] Johnson J, Karpathy A, Fei-Fei L (2016) Densecap: Fully convolutional localization networks for dense captioning. In: CVPR, pp 4565-4574"}, {"ref": "[28] Krishna R, Zhu Y, Groth O, Johnson J, Hata K, Kravitz J, Chen S, Kalantidis Y, Li L, Shamma DA, Bernstein MS, Fei-Fei L (2017) Visual genome: Connecting language and vision using crowdsourced dense image annotations. International Journal of Computer vision 123(1):32-73"}, {"ref": "[29] Lan T, Sigal L, Mori G (2012a) Social roles in hierarchical models for human activity recognition. In: CVPR, pp 1354-1361"}, {"ref": "[30] Lan T, Wang Y, Yang W, Robinovitch SN, Mori G (2012b) Discriminative latent models for recognizing contextual group activities. IEEE Trans Pattern Anal Mach Intell 34(8):1549-1562"}, {"ref": "[31] Li J, Wong Y, Zhao Q, Kankanhalli MS (2017a) Dual-glance model for deciphering social relationships. In: ICCV, pp 2650-2659"}, {"ref": "[32] Li Y, Ouyang W, Zhou B, Wang K, Wang X (2017b) Scene graph generation from objects, phrases and region captions. In: ICCV, pp 1261-1270"}, {"ref": "[33] Lin T, Maire M, Belongie SJ, Hays J, Perona P, Ramanan D, Dollar P, Zitnick CL (2014) Microsoft COCO: common objects in context. In: ECCV, Lecture Notes in Computer Science, vol 8693, pp 740-755"}, {"ref": "[34] Lin T, Goyal P, Girshick RB, He K, Dollar P (2017) Focal loss for dense object detection. In: ICCV, pp 2980-2988"}, {"ref": "[35] Lu C, Krishna R, Bernstein MS, Fei-Fei L (2016) Visual relationship detection with language priors. In: ECCV, Lecture Notes in Computer Science, vol 9905, pp 852-869"}, {"ref": "[36] Lv J, Liu W, Zhou L, Wu B, Ma H (2018) Multi-stream fusion model for social relation recognition from videos. In: MMM, pp 355-368"}, {"ref": "[37] Marin-Jimenez MJ, Zisserman A, Eichner M, Ferrari V (2014) Detecting people looking at each other in videos. International Journal of Computer Vision 106(3):282-296"}, {"ref": "[38] Maron O, Lozano-Perez T (1997) A framework for multipleinstance learning. In: NIPS, pp 570-576"}, {"ref": "[39] Orekondy T, Schiele B, Fritz M (2017) Towards a visual privacy advisor: Understanding and predicting privacy risks in images. In: ICCV, pp 3686-3695"}, {"ref": "[40] Qin Z, Shelton CR (2016) Social grouping for multi-target tracking and head pose estimation in video. IEEE Trans Pattern Anal Mach Intell 38(10):2082-2095"}, {"ref": "[41] Ramanathan V, Yao B, Fei-Fei L (2013) Social role discovery in human events. In: CVPR, pp 2475-2482"}, {"ref": "[42] Ren S, He K, Girshick RB, Sun J (2015) Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS, pp 91-99"}, {"ref": "[43] Rienks R, Zhang D, Gatica-Perez D, Post W (2006) Detection and application of in uence rankings in small group meetings. In: ICMI, pp 257-264"}, {"ref": "[44] Robicquet A, Sadeghian A, Alahi A, Savarese S (2016) Learning social etiquette: Human trajectory understanding in crowded scenes. In: ECCV, Lecture Notes in Computer Science, vol 9912, pp 549-565"}, {"ref": "[45] Russakovsky O, Deng J, Su H, Krause J, Satheesh S, Ma S, Huang Z, Karpathy A, Khosla A, Bernstein MS, Berg AC, Fei-Fei L (2015) ImageNet large scale visual recognition challenge. International Journal of Computer Vision 115(3):211-252"}, {"ref": "[46] Salamin H, Favre S, Vinciarelli A (2009) Automatic role recognition in multiparty recordings: Using social affiliation networks for feature extraction. IEEE Trans Multimedia 11(7):1373-1380"}, {"ref": "[47] Shao M, Li L, Fu Y (2013) What do you do? occupation recognition in a photo via social context. In: ICCV, pp 3631-3638"}, {"ref": "[48] Shao M, Xia S, Fu Y (2014) Identity and kinship relations in group pictures. In: Human-Centered Social Media Analytics, pp 175-190"}, {"ref": "[49] Sun Q, Schiele B, Fritz M (2017) A domain based approach to social relation recognition. In: CVPR, pp 3481-3490"}, {"ref": "[50] Thomee B, Shamma DA, Friedland G, Elizalde B, Ni K, Poland D, Borth D, Li L (2016) YFCC100M: the new data in multimedia research. Commun ACM 59(2):64-73"}, {"ref": "[51] Vicol P, Tapaswi M, Castrejon L, Fidler S (2018) Moviegraphs: Towards understanding human-centric situations from videos. In: CVPR, pp 8581-8590"}, {"ref": "[52] Vinciarelli A, Pantic M, Heylen D, Pelachaud C, Poggi I, D'Errico F, Schr\u007foder M (2012) Bridging the gap between social animal and unsocial machine: A survey of social signal processing. IEEE Trans Affective Computing 3(1):69- 87"}, {"ref": "[53] Wang G, Gallagher AC, Luo J, Forsyth DA (2010) Seeing people in social context: Recognizing people and social relationships. In: ECCV, Lecture Notes in Computer Science, vol 6315, pp 169-182"}, {"ref": "[54] Xia S, Shao M, Luo J, Fu Y (2012) Understanding kin relationships in a photo. IEEE Trans Multimedia 14(4):1046- 1056"}, {"ref": "[55] Xiao T, Xu Y, Yang K, Zhang J, Peng Y, Zhang Z (2015) The application of two-level attention models in deep convolutional neural network for fine-grained image classification. In: CVPR, pp 842-850"}, {"ref": "[56] Xu K, Ba J, Kiros R, Cho K, Courville AC, Salakhutdinov R, Zemel RS, Bengio Y (2015) Show, attend and tell: Neural image caption generation with visual attention. In: ICML, pp 2048-2057"}, {"ref": "[57] Yang Y, Baker S, Kannan A, Ramanan D (2012) Recognizing proxemics in personal photos. In: CVPR, pp 3522-3529 Yang Z, He X, Gao J, Deng L, Smola A (2016) Stacked attention networks for image question answering. In: CVPR, pp 21-29"}, {"ref": "[58] You Q, Jin H, Wang Z, Fang C, Luo J (2016) Image captioning with semantic attention. In: CVPR, pp 4651-4659"}, {"ref": "[59] Yun K, Honorio J, Chattopadhyay D, Berg TL, Samaras D (2012) Two-person interaction detection using body-pose features and multiple instance learning. In: CVPR Workshops, pp 28-35"}, {"ref": "[60] Zhang N, Paluri M, Taigman Y, Fergus R, Bourdev LD (2015a) Beyond frontal faces: Improving person recognition using multiple cues. In: CVPR, pp 4804-4813"}, {"ref": "[61] Zhang Z, Luo P, Loy CC, Tang X (2015b) Learning social relation traits from face images. In: ICCV, pp 3631-3639."}]}, {"author": ["Tung Duy Dinh", "Hieu Dinh Nguyen", "Minh-Triet Tran"], "title": "Social Relation Trait Discovery from Visual LifeLog Data", "journal": "ICPRAM", "year": 2018, "DOI": "10.5220/0006749206650674", "month": 1, "citations(google scholar)": 3, "abstract": "Social relation defines the status of interactions among individuals or groups. Although people\u2019s happiness is significantly affected by the quality of social relationships, there are few studies focusing on this aspect. This motivates us to propose a method to discover potential social relation traits, the interpersonal feelings between two people, from visual lifelog data to improve the status of our relationships. We propose Facial Multi-Attribute Framework (FMAF), a flexible network that can embed different sets of multiple pre-trained Facial Single-Attribute Networks to capture various facial features such as head pose, expression, age, and gender for social trait evaluation. We adopt the architecture of Inception-Resnet-V2 to each single attribute component to utilize the flexibility of Inception model and avoid the degradation problem with the residual module. We use a Siamese network with two FMAFs to evaluate social relation traits for two main persons in an image. Our experiment on the social relation trait dataset by Zhangpeng Zhang et.al shows that our method achieves the accuracy of 77.30%, which is 4.10% higher than the state-of-the-art result (73.20%). We also develop a prototype system integrated into Facebook to analyse and visualize the chronological changes in social traits between a user with friends in daily lives via uploaded photos and video clips.", "keywords": ["Social Relation Trait", "Visual LifeLog Data", "Facial Multi-Attribute Framework"], "reference_count": 25, "ccfClass": "", "important": true, "references": [{"ref": "[1] Bettadapura, V. (2012). Face expression recognition and analysis: The state of the art. Computer Vision and Pattern Recognition."}, {"ref": "[2] Ding, L. and Yilmaz, A. (2010). Learning Relations among Movie Characters: A Social Network Perspective, pages 410\u2013423. Springer Berlin Heidelberg, Berlin, Heidelberg."}, {"ref": "[3] Dodge, M. and Kitchin, R. (2007). outlines of a world coming into existence: Pervasive computing and the ethics of forgetting. Environment and Planning B: Planning and Design, 34(3):431\u2013445."}, {"ref": "[4] Fathi, A., Hodgins, J. K., and Rehg, J. M. (2012). Social interactions: A first-person perspective. In 2012 IEEE Conference on Computer Vision and Pattern Recognition, pages 1226\u20131233."}, {"ref": "[5] Gurrin, C. (2016). A guide to creating and managing lifelogs. In ACM MM 2016 Tutorial, November 15, 2016, Amsterdam."}, {"ref": "[6] Gurrin, C., Smeaton, A. F., and Doherty, A. R. (2014)."}, {"ref": "[7] Lifelogging: Personal big data. Foundations and Trends in Information Retrieval, 8(1):1\u2013125."}, {"ref": "[8] Kaggle (2017). Challenges in representation learning facial expression recognition challenge."}, {"ref": "[9] Kiesler, D. J. (1983). The 1982 Interpersonal Circle: A taxonomy for complementarity in human transactions. Psychological Review."}, {"ref": "[10] Koestinger, M., Wohlhart, P., Roth, P. M., and Bischof, H. (2011). Annotated facial landmarks in the wild: A large-scale, real-world database for facial landmark localization. In Proc. First IEEE International Workshop on Benchmarking Facial Image Analysis Technologies."}, {"ref": "[11] Lan, T., Sigal, L., and Mori, G. (2012). Social roles in hierarchical models for human activity recognition. In 2012 IEEE Conference on Computer Vision and Pattern Recognition, pages 1354\u20131361."}, {"ref": "[12] Lopes, T., de Aguiar, E., Souza, A. F. D., and Oliveira- Santos, T. (2016). Facial expression recognition with convolutional neural networks: Coping with few data and the training sample order. Pattern Recognition."}, {"ref": "[13] Nguyen, V., Le, K., Tran, M., and Fjeld, M. (2016)."}, {"ref": "[14] NowAndThen: a social network-based photo recommendation tool supporting reminiscence. In Proceedings of the 15th International Conference on Mobile and Ubiquitous Multimedia, Rovaniemi, Finland, December 12-15, 2016, pages 159\u2013168."}, {"ref": "[15] Nguyen, V., Ngo, T. D., Le, D., Tran, M., Duong, D. A., and Satoh, S. (2017). Semantic extraction and object proposal for video search. In MultiMedia Modeling - 23rd International Conference, MMM 2017, Reykjavik, Iceland, January 4-6, 2017, Proceedings, Part II, pages 475\u2013479."}, {"ref": "[16] Parkhi, O. M., Vedaldi, A., and Zisserman, A. (2015). Deep face recognition. In British Machine Vision Conference."}, {"ref": "[17] Rothe, R., Timofte, R., and Gool, L. V. (2016). Deep expectation of real and apparent age from a single image without facial landmarks. International Journal of Computer Vision (IJCV)."}, {"ref": "[18] Salvador, A., i Nieto, X. G., Marqus, F., and Satoh, S. (2016). Faster R-CNN features for instance search. In 2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pages 394\u2013 401."}, {"ref": "[19] Schroff, F., Kalenichenko, D., and Philbin, J. (2015)."}, {"ref": "[20] Facenet: A unified embedding for face recognition and clustering. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)."}, {"ref": "[21] Szegedy, C., Ioffe, S., and Vanhoucke, V. (2016). Inceptionv4, inception-resnet and the impact of residual connections on learning. Computer Vision and Pattern Recognition."}, {"ref": "[22] Valstar, M. F., Jiang, B., and Mehu, M. (2011). The first facial expression recognition and analysis challenge. Automatic Face & Gesture Recognition and Workshops (FG 2011)."}, {"ref": "[23] Wen, Y., Zhang, K., Li, Z., and Qiao, Y. (2016). A Discriminative Feature Learning Approach for Deep Face Recognition, pages 499\u2013515. Springer International Publishing, Cham."}, {"ref": "[24] Zhang, Z., Luo, P., Loy, C. C., and Tang, X. (2015). Learning social relation traits from face images. 2015 IEEE International Conference on Computer Vision."}, {"ref": "[25] Zhou, L. M., Gurrin, C., Yang, C., and Qiu, Z. (2013). From lifelog to diary: a timeline view for memory reminiscence. In Irish HCI conference 2013, Ireland, Dundalk."}]}, {"author": ["Stefano Alletto", "Marcella Cornia", "Lorenzo Baraldi", "Giuseppe Serra", "Rita Cucchiara"], "title": "Recognizing social relationships from an egocentric vision perspective", "journal": "BOOK", "year": 2019, "DOI": "10.1016/B978-0-12-814601-9.00015-8", "month": 1, "citations(google scholar)": 0, "abstract": "In this chapter we address the problem of partitioning social gatherings into interacting groups in egocentric scenarios. People in the scene are tracked, and their head pose and 3D location are estimated. Following the formalism of the f-formation, we define as regards the orientation and distance inherently social pairwise features capable of describing how two people stand in relation to one another. We present a structural SVM-based approach to learn how to weight each component of the feature vector depending on the social situation being applied to. To better understand the social dynamics, we also estimate what we call the social relevance of each subject in a group using a saliency attentive model. Extensive tests on two publicly available datasets show that our solution achieves encouraging results when detecting social groups and their relevant subjects in challenging egocentric scenarios.", "keywords": ["Egocentric vision", "Group detection", "F-formation", "Social interaction"], "reference_count": 36, "ccfClass": "", "important": true, "references": [{"ref": "[1] Maedeh Aghaei, Mariella Dimiccoli, Cristian Canton Ferrer, Petia Radeva, Towards social pattern characterization in egocentric photo-streams, arXiv preprint, arXiv: 1709.01424, 2017."}, {"ref": "[2] Nikhil Bansal, Avrim Blum, Shuchi Chawla, Correlation clustering, Mach. Learn. 56 (2004) 89\u2013113."}, {"ref": "[3] Leo Breiman, Random forests, Mach. Learn. 45 (1) (2001) 5\u201332."}, {"ref": "[4] Zoya Bylinskii, Tilke Judd, Ali Borji, Laurent Itti, Fr\u00e9do Durand, Aude Oliva, Antonio Torralba, MIT saliency benchmark, http://saliency.mit.edu/, 2017."}, {"ref": "[5] Claire Cardie, Kiri Wagstaff, Noun phrase coreference as clustering, in: Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, 1999."}, {"ref": "[6] William S. Cleveland, Robust locally weighted regression and smoothing scatterplots, J. Am. Stat. Assoc. 74 (368) (1979) 829\u2013836."}, {"ref": "[7] Marcella Cornia, Lorenzo Baraldi, Giuseppe Serra, Rita Cucchiara, A deep multilevel network for saliency prediction, in: International Conference on Pattern Recognition, 2016."}, {"ref": "[8] Marcella Cornia, Lorenzo Baraldi, Giuseppe Serra, Rita Cucchiara, Predicting human eye fixations via an LSTM-based saliency attentive model, IEEE Trans. Image Process. 27 (10) (2018) 5142\u20135154."}, {"ref": "[9] Marco Cristani, Loris Bazzani, Giulia Paggetti, Andrea Fossati, Diego Tosato, Alessio Del Bue, Gloria Menegaz, Vittorio Murino, Social interaction discovery by statistical analysis of F-formations, in: British Machine Vision Conference, 2011."}, {"ref": "[10] Matthias Dantone, Juergen Gall, Gabriele Fanelli, Luc Van Gool, Real-time facial feature detection using conditional regression forests, in: IEEE International Conference on Computer Vision and Pattern Recognition, 2012."}, {"ref": "[11] Alircza Fathi, Jessica K. Hodgins, James M. Rehg, Social interactions: a first-person perspective, in: IEEE International Conference on Computer Vision and Pattern Recognition, 2012."}, {"ref": "[12] Kohsia S. Huang, Mohan M. Trivedi, Robust real-time detection, tracking and pose estimation of faces in video streams, in: International Conference on Pattern Recognition, 2004."}, {"ref": "[13] Xun Huang, Chengyao Shen, Xavier Boix, Qi Zhao, SALICON: reducing the semantic gap in saliency prediction by adapting deep neural networks, in: IEEE International Conference on Computer Vision, 2015."}, {"ref": "[14] Hayley Hung, Ben Kr\u00f6se, Detecting F-formations as dominant sets, in: ACM International Conference on Multimodal Interaction, 2011."}, {"ref": "[15] Laurent Itti, Christof Koch, Ernst Niebur, et al., A model of saliency-based visual attention for rapid scene analysis, IEEE Trans. Pattern Anal. Mach. Intell. 20 (11) (1998) 1254\u20131259."}, {"ref": "[16] Ming Jiang, Shengsheng Huang, Juanyong Duan, Qi Zhao, SALICON: saliency in context, in: IEEE International Conference on Computer Vision and Pattern Recognition, 2015."}, {"ref": "[17] Zdenek Kalal, Krystian Mikolajczyk, Jiri Matas, Tracking-learning-detection, IEEE Trans. Pattern Anal. Mach. Intell. 34 (7) (2012) 1409\u20131422."}, {"ref": "[18] Adam Kendon, Studies in the Behavior of Social Interaction, vol. 6, Humanities Press Intl, 1977."}, {"ref": "[19] Antonis Lambrou, Harris Papadopoulos, Ilia Nouretdinov, Alexander Gammerman, Reliable probability estimates based on support vector machines for large multiclass datasets, in: Artificial Intelligence Applications and Innovations, vol. 382, 2012, pp. 182\u2013191."}, {"ref": "[20] Deqiang Li,Witold Pedrycz, A central profile-based 3d face pose estimation, Pattern Recognit. 47 (2) (2014) 525\u2013534."}, {"ref": "[21] Bingpeng Ma, Wenchao Zhang, Shiguang Shan, Xilin Chen, Wen Gao, Robust head pose estimation using LGBP, in: International Conference on Pattern Recognition, 2006."}, {"ref": "[22] Erik Murphy-Chutorian, Mohan Manubhai Trivedi, Head pose estimation in computer vision: a survey, IEEE Trans. Pattern Anal.Mach. Intell. 31 (4) (2008) 607\u2013626."}, {"ref": "[23] Rhys Newman, Yoshio Matsumoto, Sebastien Rougeaux, Alexander Zelinsky, Realtime stereo tracking for head pose and gaze estimation, in: International Conference on Automatic Face and Gesture Recognition, 2000."}, {"ref": "[24] Nicoletta Noceti, Francesca Odone, Humans in groups: the importance of contextual information for understanding collective activities, Pattern Recognit. 47 (11) (2014) 3535\u20133551."}, {"ref": "[25] Shay Ohayon, Ehud Rivlin, Robust 3D head tracking using camera pose estimation, in: International Conference on Pattern Recognition, 2006."}, {"ref": "[26] Javier Orozco, Shaogang Gong, Tao Xiang, Head pose classification in crowded scenes, in: British Machine Vision Conference, 2009."}, {"ref": "[27] Carsten Rother, Vladimir Kolmogorov, Andrew Blake, \"GrabCut\": interactive foreground extraction using iterated graph cuts, ACM Trans. Graph. 23 (3) (2004) 309\u2013314."}, {"ref": "[28] Brandon M. Smith, Jonathan Brandt, Zhe Lin, Li Zhang, Nonparametric context modeling of local appearance for pose- and expression-robust facial landmark localization, in: IEEE International Conference on Computer Vision and Pattern Recognition, 2014."}, {"ref": "[29] Ioannis Tsochantaridis, Thomas Hofmann, Thorsten Joachims, Yasemin Altun, Support vector machine learning for interdependent and structured output spaces, in: International Conference on Machine Learning, 2004."}, {"ref": "[30] Marc Vilain, John Burger, John Aberdeen, Dennis Connolly, Lynette Hirschman, A model-theoretic coreference scoring scheme, in: Message Understanding Conference, 1995."}, {"ref": "[31] JunwenWu, JensM. Pedersen, D. Putthividhya, Daniel Norgaard, MohanM. Trivedi, A two-level pose estimation framework using majority voting of gabor wavelets and bunch graph analysis, in: International Conference on Pattern Recognition Workshops, 2004."}, {"ref": "[32] Xuehan Xiong, Fernando De la Torre, Supervised descentmethod and its applications to face alignment, in: IEEE International Conference on Computer Vision and Pattern Recognition, 2013."}, {"ref": "[33] Xu Yan, Ioannis A. Kakadiaris, Shishir K. Shah, Modeling local behavior for predicting social interactions towards human tracking, Pattern Recognit. 47 (4) (2014) 1626\u20131641."}, {"ref": "[34] Ryo Yonetani, Kris M. Kitani, Yoichi Sato, Recognizing micro-actions and reactions from paired egocentric videos, in: IEEE International Conference on Computer Vision and Pattern Recognition, 2016."}, {"ref": "[35] Ting Yu, Ser-Nam Lim, Kedar Patwardhan, Nils Krahnstoever,Monitoring, recognizing and discovering social networks, in: IEEE International Conference on Computer Vision and Pattern Recognition, 2009."}, {"ref": "[36] Xiangxin Zhu, Deva Ramanan, Face detection, pose estimation and landmark localization in the wild, in: IEEE International Conference on Computer Vision and Pattern Recognition, 2012."}]}]