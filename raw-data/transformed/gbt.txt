{"topic": {"en": "Dynamic Embedding (Temporal)", "cn": "动态嵌入"}, "sta": {"missing": {"ccfClass": 9}}, "papers": [{"author": ["Xiaodong Jiang", "Pengsheng Ji", "Sheng Li"], "title": "CensNet: Convolution with Edge-Node Switching in Graph Neural Networks", "journal": "International Joint Conference on Artificial Intelligence", "year": 2019, "DOI": "10.24963/ijcai.2019/369", "month": 8, "citations(google scholar)": 0, "abstract": "In this paper, we present CensNet, Convolution with Edge-Node Switching graph neural network, for semi-supervised classification and regression in graph-structured data with both node and edge features. CensNet is a general graph embedding framework, which embeds both nodes and edges to a latent feature space. By using line graph of the original undirected graph, the role of nodes and edges are switched, and two novel graph convolution operations are proposed for feature propagation. Experimental results on real-world academic citation networks and quantum chemistry graphs show that our approach has achieved or matched the state-of-the-art performance.", "keywords": ["Relational Learning", "Semi-Supervised Learning", "Deep Learning", "Other Applications"], "reference_count": 25, "ccfClass": "A", "important": true, "references": [{"ref": "[Bronstein et al., 2017] Michael M Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre Vandergheynst. Geometric deep learning: going beyond euclidean data. IEEE Signal Processing Magazine, 34(4):18–42, 2017."}, {"ref": "[Defferrard et al., 2016a] Michae ̈l Defferrard, Xavier Bres- son, and Pierre Vandergheynst. Convolutional neural net- works on graphs with fast localized spectral filtering. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Information Pro- cessing Systems 29, pages 3844–3852. Curran Associates, Inc., 2016."}, {"ref": "[Defferrard et al., 2016b] Michae ̈l Defferrard, Xavier Bres- son, and Pierre Vandergheynst. Convolutional neural net- works on graphs with fast localized spectral filtering. In NIPS, 2016."}, {"ref": "[Hamilton et al., 2017] William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In NIPS, 2017."}, {"ref": "[Harary and Norman, 1960] Frank Harary and Robert Z. Norman. Some properties of line digraphs. Rendiconti del Circolo Matematico di Palermo, 1960."}, {"ref": "[He et al., 2016] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog- nition. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770–778, 2016."}, {"ref": "[Ji and Jin, 2016] Pengsheng Ji and Jiashun Jin. Coauthor- ship and citation networks for statisticians. The Annals of Applied Statistics, 10(4):1779–1812, 2016."}, {"ref": "[Kingma and Ba, 2014] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014."}, {"ref": "[Kipf and Welling, 2017] Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Rep- resentations, 2017."}, {"ref": "[Krizhevsky et al., 2012] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In Proceedings of the 25th International Conference on Neural Information Process- ing Systems - Volume 1, NIPS’12, pages 1097–1105, USA, 2012. Curran Associates Inc."}, {"ref": "[LeCun et al., 2015] Yann LeCun, Yoshua Bengio, and Ge- offrey Hinton. Deep learning. Nature, 521(7553):436– 444, 5 2015."}, {"ref": "[Li and Fu, 2015] Sheng Li and Yun Fu. Learning balanced and unbalanced graphs via low-rank coding. IEEE Trans- actions on Knowledge and Data Engineering, 27(5):1274– 1287, 2015."}, {"ref": "[Li et al., 2017] Sheng Li, Hongfu Liu, Zhiqiang Tao, and Yun Fu. Multi-view graph learning with adaptive label propagation. In IEEE International Conference on Big Data, pages 110–115. IEEE, 2017."}, {"ref": "[Liao et al., 2019] Renjie Liao, Zhizhen Zhao, Raquel Urta- sun, and Richard Zemel. Lanczosnet: Multi-scale deep graph convolutional networks. In International Confer- ence on Learning Representations, 2019."}, {"ref": "[Monti et al., 2017] Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodola, Jan Svoboda, and Michael M. Bronstein. Geometric deep learning on graphs and manifolds using mixture model cnns. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017."}, {"ref": "[Namata et al., 2012] Galileo Mark Namata, Ben London, Lise Getoor, and Bert Huang. Query-driven active survey- ing for collective classification. In Workshop on Mining and Learning with Graphs (MLG), 2012."}, {"ref": "[Paszke et al., 2017] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary De- Vito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. NIPS- W, 2017."}, {"ref": "[Pedregosa et al., 2011] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blon- del, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830, 2011."}, {"ref": "[Scarselli et al., 2009] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini. The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61–80, Jan 2009."}, {"ref": "[Schlichtkrull et al., 2018] Michael Sejr Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. In ESWC, 2018."}, {"ref": "[Sen et al., 2008] Prithviraj Sen, Galileo Mark Namata, Mustafa Bilgic, Lise Getoor, Brian Gallagher, and Tina Eliassi-Rad. Collective classification in network data. AI Magazine, 29(3):93–106, 2008."}, {"ref": "[Shchur et al., 2018] Oleksandr Shchur, Maximil- ian Mumme, Aleksandar Bojchevski, and Stephan Gu ̈nnemann. Pitfalls of graph neural network evaluation. CoRR, abs/1811.05868, 2018."}, {"ref": "[Velicˇkovic ́ et al., 2018] Petar Velicˇkovic ́, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio`, and Yoshua Bengio. Graph attention networks. In Interna- tional Conference on Learning Representations, 2018."}, {"ref": "[Wu et al., 2018] Zhenqin Wu, Bharath Ramsundar, Evan N. Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S. Pappu, Karl Leswing, and Vijay Pande. Moleculenet: a benchmark for molecular machine learning. Chem. Sci., 9:513–530, 2018."}, {"ref": "[Zhou et al., 2018] Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, and Maosong Sun. Graph neural networks: A review of methods and applications. CoRR, abs/1812.08434, 2018."}]}, {"author": ["Yuan Zuo", "Guannan Liu", "Hao Lin", "Jia Guo", "Xiaoqian Hu", "Junjie Wu"], "title": "Embedding Temporal Network via Neighborhood Formation", "journal": "ACM Knowledge Discovery and Data Mining", "year": 2018, "DOI": "10.1145/3219819.3220054", "month": 8, "citations(google scholar)": 15, "abstract": "Given the rich real-life applications of network mining as well as the surge of representation learning in recent years, network embedding has become the focal point of increasing research interests in both academic and industrial domains. Nevertheless, the complete temporal formation process of networks characterized by sequential interactive events between nodes has yet seldom been modeled in the existing studies, which calls for further research on the so-called temporal network embedding problem. In light of this, in this paper, we introduce the concept of neighborhood formation sequence to describe the evolution of a node, where temporal excitation effects exist between neighbors in the sequence, and thus we propose a Hawkes process based Temporal Network Embedding (HTNE) method. HTNE well integrates the Hawkes process into network embedding so as to capture the influence of historical neighbors on the current neighbors. In particular, the interactions of low-dimensional vectors are fed into the Hawkes process as base rate and temporal influence, respectively. In addition, attention mechanism is also integrated into HTNE to better determine the influence of historical neighbors on current neighbors of a node. Experiments on three large-scale real-life networks demonstrate that the embeddings learned from the proposed HTNE model achieve better performance than state-of-the-art methods in various tasks including node classification, link prediction, and embedding visualization. In particular, temporal recommendation based on arrival rate inferred from node embeddings shows excellent predictive power of the proposed model.", "keywords": ["Temporal Network", "Network Embedding", "Learning Representation", "Hawkes Process"], "reference_count": 30, "ccfClass": "A", "important": true, "references": [{"ref": "[1] AmrAhmed,NinoShervashidze,ShravanNarayanamurthy,VanjaJosifovski,and Alexander J. Smola. 2013. Distributed Large-scale Natural Graph Factorization. In WWW. ACM, New York, NY, USA, 37–48."}, {"ref": "[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural ma- chine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473."}, {"ref": "[3] Mikhail Belkin and Partha Niyogi. 2001. Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering. In NIPS. MIT Press, Cambridge, MA, USA, 585–591."}, {"ref": "[4] HongYun Cai, Vincent W. Zheng, and Kevin Chen-Chuan Chang. 2017. A Com- prehensive Survey of Graph Embedding: Problems, Techniques and Applications. CoRR abs/1709.07604 (2017)."}, {"ref": "[5] SandroCavallari,VincentW.Zheng,HongyunCai,KevinChen-ChuanChang, and Erik Cambria. 2017. Learning Community Embedding with Community Detection and Node Embedding on Graphs. In CIKM. 377–386."}, {"ref": "[6] Quanyu Dai, Qiang Li, Jian Tang, and Dan Wang. 2017. Adversarial Network Embedding. CoRR abs/1711.07838 (2017)."}, {"ref": "[7] Nan Du, Yichen Wang, Niao He, and Le Song. 2015. Time-sensitive Recommen- dation from Recurrent User Activities. In NIPS. 3492–3500."}, {"ref": "[8] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde- Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative Adversarial Nets. In NIPS. MIT Press, Cambridge, MA, USA, 2672–2680."}, {"ref": "[9] Aditya Grover and Jure Leskovec. 2016. Node2Vec: Scalable Feature Learning for Networks. In SIGKDD. ACM, New York, NY, USA, 855–864."}, {"ref": "[10] William L. Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. CoRR abs/1706.02216 (2017)."}, {"ref": "[11] Alan G Hawkes. 1971. Spectra of some self-exciting and mutually exciting point processes. Biometrika 58, 1 (1971), 83–90."}, {"ref": "[12] Petter Holme and Jari SaramÃďki. 2012. Temporal networks. Physics Reports 519, 3 (2012), 97 – 125."}, {"ref": "[13] Joseph B Kruskal and Myron Wish. 1978. Multidimensional Scaling. CRC press. 875–878 pages."}, {"ref": "[14] RÃľmi Lemonnier, Kevin Scaman, and Argyris Kalogeratos. 2017. Multivariate Hawkes Processes for Large-Scale Inference. In AAAI."}, {"ref": "[15] Remi Lemonnier and Nicolas Vayatis. 2014. Nonparametric Markovian Learning of Triggering Kernels for Mutually Exciting and Mutually Inhibiting Multivariate Hawkes Processes. In Machine Learning and Knowledge Discovery in Databases. 161–176."}, {"ref": "[16] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. CoRR abs/1301.3781 (2013)."}, {"ref": "[17] TomasMikolov,IlyaSutskever,KaiChen,GregCorrado,andJeffreyDean.2013. Distributed Representations of Words and Phrases and Their Compositionality. In NIPS. Curran Associates Inc., USA, 3111–3119."}, {"ref": "[18] TomasMikolov,IlyaSutskever,KaiChen,GregSCorrado,andJeffDean.2013. Distributed Representations of Words and Phrases and their Compositionality. In NIPS. 3111–3119."}, {"ref": "[19] Shirui Pan, Jia Wu, Xingquan Zhu, Chengqi Zhang, and Yang Wang. 2016. Tri- party Deep Network Representation. In IJCAI. AAAI Press, 1895–1901."}, {"ref": "[20] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: Online Learn- ing of Social Representations. In SIGKDD. ACM, New York, NY, USA, 701–710."}, {"ref": "[21] Sam T. Roweis and Lawrence K. Saul. 2000. Nonlinear Dimensionality Reduction by Locally Linear Embedding. Science 290, 5500 (2000), 2323–2326."}, {"ref": "[22] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale Information Network Embedding. In WWW. International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, 1067–1077."}, {"ref": "[23] Joshua B. Tenenbaum, Vin de Silva, and John C. Langford. 2000. A Global Geometric Framework for Nonlinear Dimensionality Reduction. Science 290, 5500 (2000), 2319–2323."}, {"ref": "[24] Laurens van der Maaten and Geoffrey E. Hinton. 2008. Visualizing High- Dimensional Data Using t-SNE. JMLR 9 (2008), 2579–2605."}, {"ref": "[25] Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural Deep Network Em- bedding. In SIGKDD. ACM, New York, NY, USA, 1225–1234."}, {"ref": "[26] Hongwei Wang, Jia Wang, Jialin Wang, Miao Zhao, Weinan Zhang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2017. GraphGAN: Graph Representation Learning with Generative Adversarial Nets. CoRR abs/1711.08267 (2017)."}, {"ref": "[27] JingyuanWang,FeiGao,PengCui,ChaoLi,andZhangXiong.2014.Discovering urban spatio-temporal structure from time-evolving traffic networks. In Proceed- ings of the 16th Asia-Pacific Web Conference. Springer International Publishing, 93–104."}, {"ref": "[28] XiaoWang,PengCui,JingWang,JianPei,WenwuZhu,andShiqiangYang.2017. Community Preserving Network Embedding."}, {"ref": "[29] Lekui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. 2018. Dy- namic Network Embedding by Modeling Triadic Closure Process. In The AAAI Conference on Artificial Intelligence."}, {"ref": "[30] L. Zhu, D. Guo, J. Yin, G. V. Steeg, and A. Galstyan. 2016. Scalable Temporal Latent Space Inference for Link Prediction in Dynamic Social Networks. IEEE Transactions on Knowledge and Data Engineering 28, 10 (Oct 2016), 2765–2777."}]}, {"author": ["Franco Manessi", "Alessandro Rozza", "Mario Manzo"], "title": "Dynamic graph convolutional networks", "journal": "Pattern Recognition", "year": 2019, "DOI": "10.1016/j.patcog.2019.107000", "month": 8, "citations(google scholar)": 17, "abstract": "In many different classification tasks it is required to manage structured data, which are usually mod- eled as graphs. Moreover, these graphs can be dynamic, meaning that the vertices/edges of each graph may change over time. The goal is to exploit existing neural network architectures to model datasets that are best represented with graph structures that change over time. To the best of the authors’ knowl- edge, this task has not been addressed using these kinds of architectures. Two novel approaches are pro- posed, which combine Long Short-Term Memory networks and Graph Convolutional Networks to learn long short-term dependencies together with graph structure. The advantage provided by the proposed methods is confirmed by the results achieved on four real world datasets: an increase of up to 12 per- centage points in Accuracy and F1 scores for vertex-based semi-supervised classification and up to 2 percentage points in Accuracy and F1 scores for graph-based supervised classification.", "keywords": ["Long Short-Term Memory", "Graph Convolutional Networks", "classification"], "reference_count": 41, "ccfClass": "B", "important": true, "references": [{"ref": "[1] F. Scarselli, M. Gori, A.C. Tsoi, M. Hagenbuchner, G. Monfardini, The graph neu- ral network model, IEEE Trans. Neural Netw. 20 (1) (2009) 61–80."}, {"ref": "[2] M. Bianchini, M. Maggini, L. Sarti, F. Scarselli, Recursive neural networks learn to localize faces, Pattern Recognit. Lett. 26 (12) (2005) 1885–1895."}, {"ref": "[3] J. Liu, M. Li, Q. Liu, H. Lu, S. Ma, Image annotation via graph learning, Pattern Recognit. 42 (2) (2009) 218–228."}, {"ref": "[4] A. Srinivasan, S. Muggleton, R.D. King, M.J. Sternberg, Mutagenesis: ILP experi- ments in a non-determinate biological domain, in: Proceedings of the 4th In- ternational Workshop on Inductive Logic Programming, vol. 237, Citeseer, 1994, pp. 217–232."}, {"ref": "[5] A. Jain, A.R. Zamir, S. Savarese, A. Saxena, Structural-RNN: deep learning on spatio-temporal graphs, in: CVPR, IEEE, 2016, pp. 5308–5317."}, {"ref": "[6] Y. Yuan, X. Liang, X. Wang, D.-Y. Yeung, A. Gupta, Temporal dynamic graph LSTM for action-driven video object detection, in: Proceedings of the IEEE In- ternational Conference on Computer Vision, 2017, pp. 1801–1810."}, {"ref": "[7] A. Rozza, M. Manzo, A. Petrosino, A novel graph-based fisher kernel method for semi-supervised learning, in: ICPR, 2014, pp. 3786–3791."}, {"ref": "18 F. Manessi, A. Rozza and M. Manzo/Pattern Recognition 97 (2020) 107000"}, {"ref": "[8] H. Xu, Y. Yang, L. Wang, W. Liu, Node classification in social network via a factor graph model, in: PAKDD, 2013, pp. 213–224."}, {"ref": "[9] Y. Zhao, G. Wang, P.S. Yu, S. Liu, S. Zhang, Inferring social roles and statuses in social networks, in: ACM SIGKDD, ACM, 2013, pp. 695–703."}, {"ref": "[10] Y. Dong, Y. Yang, J. Tang, Y. Yang, N.V. Chawla, Inferring user demographics and social strategies in mobile social networks, in: KDD ’14, ACM, 2014, pp. 15–24."}, {"ref": "[11] J. Bruna, W. Zaremba, A. Szlam, Y. LeCun, Spectral networks and locally connected networks on graphs, ICLR, 2013."}, {"ref": "[12] M. Defferrard, X. Bresson, P. Vandergheynst, Convolutional neural networks on graphs with fast localized spectral filtering, NIPS, 2016."}, {"ref": "[13] D.K. Duvenaud, D. Maclaurin, J. Iparraguirre, R. Bombarell, T. Hirzel, A. Aspu-ru-Guzik, R.P. Adams, Convolutional networks on graphs for learning molecular fingerprints, NIPS, 2015."}, {"ref": "[14] T.N. Kipf, M. Welling, Semi-supervised classification with graph convolutional networks, ICLR, 2017."}, {"ref": "[15] Y. Li, D. Tarlow, M. Brockschmidt, R.S. Zemel, Gated graph sequence neural networks, ICLR, 2016."}, {"ref": "[16] S. Hochreiter, J. Schmidhuber, Long short-term memory, Neural Comput. 9 (8)(1997) 1735–1780."}, {"ref": "[17] L.C. Jain, L.R. Medsker, Recurrent Neural Networks: Design and Applications,1st ed., CRC Press, Inc., 1999."}, {"ref": "[18] Y. Lecun, L. Bottou, Y. Bengio, P. Haffner, Gradient-based learning applied to document recognition, in: Proceedings of the IEEE, 1998, pp. 2278–2324."}, {"ref": "[19] X. Zhu, Z. Ghahramani, J. Lafferty, et al., Semi-supervised learning using gaussian fields and harmonic functions, in: ICML, vol. 3, 2003, pp. 912–919."}, {"ref": "[20] Y. Boykov, O. Veksler, R. Zabih, Fast approximate energy minimization via graph cuts, IEEE Trans. Pattern Anal. Mach. Intell. 23 (11) (2001) 1222–1239."}, {"ref": "[21] B. Wang, J. Tsotsos, Dynamic label propagation for semi-supervised multi-class multi-label classification, Pattern Recognit. 52 (2016) 75–84."}, {"ref": "[22] A. Grover, J. Leskovec, node2vec: Scalable feature learning for networks, in:ACM SIGKDD, ACM, 2016, pp. 855–864."}, {"ref": "[23] B. Perozzi, R. Al-Rfou, S. Skiena, DeepWalk: online learning of social representations, in: ACM SIGKDD, ACM, 2014, pp. 701–710."}, {"ref": "[24] F.B. Silva, R.d.O. Werneck, S. Goldenstein, S. Tabbone, R.d.S. Torres, Graph-based bag-of-words for classification, Pattern Recognit. 74 (2018) 266–285."}, {"ref": "[25] K. Li, S. Guo, N. Du, J. Gao, A. Zhang, Learning, analyzing and predicting object roles on dynamic networks, in: IEEE ICDM, 2013, pp. 428–437."}, {"ref": "[26] Y. Yao, L. Holder, Scalable SVM-based classification in dynamic graphs, in: IEEE ICDM, 2014, pp. 650–659."}, {"ref": "[27] Y. Pei, J. Zhang, G.H. Fletcher, M. Pechenizkiy, Node classification in dynamic social networks, in: AALTD 2016: 2nd ECML-PKDD International Workshop on Advanced Analytics and Learning on Temporal Data, 2016, pp. 54–93."}, {"ref": "[28] M. Gori, G. Monfardini, F. Scarselli, A new model for learning in graph domains, in: Proceedings of the 2005 IEEE International Joint Conference on Neural Networks, vol. 2, 2005, pp. 729–734."}, {"ref": "[29] K. Cho, B. van Merriënboer, Ç. Gülçehre, D. Bahdanau, F. Bougares, H. Schwenk,Y. Bengio, Learning phrase representations using RNN encoder–decoder for statistical machine translation, in: EMNLP, 2014, pp. 1724–1734."}, {"ref": "[30] D.K. Hammond, P. Vandergheynst, R. Gribonval, Wavelets on graphs via spectral graph theory, Appl. Comput. Harmon. Anal. 30 (2) (2011) 129–150."}, {"ref": "[31] Y. Seo, M. Defferrard, P. Vandergheynst, X. Bresson, Structured sequence mod- eling with graph convolutional recurrent networks, in: International Confer- ence on Neural Information Processing, Springer, 2018, pp. 362–373."}, {"ref": "[32] F. Monti, M. Bronstein, X. Bresson, Geometric matrix completion with recur- rent multi-graph neural networks, in: NIPS 30, 2017, pp. 3697–3707."}, {"ref": "[33] I. Goodfellow, Y. Bengio, A. Courville, Deep Learning, MIT Press, 2016."}, {"ref": "[34] M. Defferrard, X. Bresson, P. Vandergheynst, Convolutional neural networks on graphs with fast localized spectral filtering, in: NIPS, 2016, pp. 3844–3852. [35] M. Génois, C.L. Vestergaard, J. Fournet, A. Panisson, I. Bonmarin, A. Barrat, Data on face-to-face contacts in an office building suggest a low-cost vaccination strategy based on community linkers, Netw. Sci. 3 (2015) 326–347."}, {"ref": "[36] M. Hashemian, W. Qian, K.G. Stanley, N.D. Osgood, Temporal aggregation im- pacts on epidemiological simulations employing microcontact data, BMC Med.Inf. Decis. Making 12 (1) (2012) 132."}, {"ref": "[37] H.S. Koppula, R. Gupta, A. Saxena, Learning human activities and object affordances from RGB-D videos, Int. J. Rob. Res. 32 (8) (2013) 951–970."}, {"ref": "[38] D.G. Lowe, Object recognition from local scale-invariant features, in: ICCV,IEEE, 1999, pp. 1150–1157."}, {"ref": "[39] M. Müller, T. Röder, M. Clausen, B. Eberhardt, B. Krüger, A. Weber, Documentation Mocap Database HDM05, Technical Report, Universität Bonn, 2007."}, {"ref": "[40] D. Kingma, J. Ba, Adam: a method for stochastic optimization, ICLR, 2015."}, {"ref": "[41] F. Manessi, A. Rozza, S. Bianco, P. Napoletano, R. Schettini, Automated pruning for deep neural network compression, in: Proceedings of the 24th International Conference on Pattern Recognition, 2018, pp. 657–664."}]}, {"author": ["Lekui Zhou", "Yang Yang", "Xiang Ren", "Fei Wu", "Yueting Zhuang"], "title": "Dynamic Network Embedding by Modeling Triadic Closure Process", "journal": "AAAI Conference on Artificial Intelligence", "year": 2018, "DOI": "", "month": 4, "citations(google scholar)": 59, "abstract": "Network embedding, which aims to learn the low-dimensional representations of vertices, is an important task and has attracted considerable research efforts recently. In real world, networks, like social network and biological networks, are dynamic and evolving over time. However, almost all the existing network embedding methods focus on static networks while ignore network dynamics. In this paper, we present a novel representation learning approach, DynamicTriad, to preserve both structural information and evolution patterns of a given network. The general idea of our approach is to impose triad, which is a group of three vertices and is one of the basic units of networks. In particular, we model how a closed triad, which consists of three vertices connected with each other, develops from an open triad that has two of three vertices not connected with each other. This triadic closure process is a fundamental mechanism in the formation and evolution of networks, thereby makes our model being able to capture the network dynamics and to learn representation vectors for each vertex at different time steps. Experimental results on three real-world networks demonstrate that, compared with several state-of-the-art techniques, DynamicTriad achieves substantial gains in several application scenarios. For example, our approach can effectively be applied and help to identify telephone frauds in a mobile network, and to predict whether a user will repay her loans or not in a loan network.", "keywords": ["Network Embedding", "Dynamic Networkß", "Triad Closure Process"], "reference_count": 30, "ccfClass": "A", "important": true, "references": [{"ref": "Belkin, M., and Niyogi, P. 2001. Laplacian eigenmaps and spectral techniques for embedding and clustering. In NIPS, volume 14, 585–591."}, {"ref": "Coleman, J. S. 1994. Foundations of social theory. American Political Science Review 85(1):263."}, {"ref": "Dempster, A. P.; Laird, N. M.; and Rubin, D. B. 1977. Maxi- mum likelihood from incomplete data via the em algorithm. JOURNAL OF THE ROYAL STATISTICAL SOCIETY, SE- RIES B 39(1):1–38."}, {"ref": "Dong, Y.; Chawla, N. V.; and Swami, A. 2017. metap- ath2vec: Scalable representation learning for heterogeneous networks. In Proceedings of the 23rd ACM SIGKDD In- ternational Conference on Knowledge Discovery and Data Mining, 135–144. ACM."}, {"ref": "Duchi, J.; Hazan, E.; and Singer, Y. 2011. Adaptive subgra- dient methods for online learning and stochastic optimiza- tion. Journal of Machine Learning Research 12(Jul):2121– 2159."}, {"ref": "Erds, D.; Gemulla, R.; and Terzi, E. 2014. Reconstruct- ing graphs from neighborhood data. ACM Transactions on Knowledge Discovery From Data 8(4):23."}, {"ref": "Grover, A., and Leskovec, J. 2016. node2vec: Scalable fea- ture learning for networks. In KDD’16, 855–864."}, {"ref": "Ho, Q.; Yin, J.; and Xing, E. P. 2016. Latent space inference of internet-scale networks. Journal of Machine Learning Research 17(78):1–41."}, {"ref": "Hoff, P. D.; Raftery, A. E.; and Handcock, M. S. 2012. La- tent space approaches to social network analysis. Journal of the American Statistical Association 97(460):1090–1098."}, {"ref": "Huang, H.; Tang, J.; Liu, L.; Luo, J.; and Fu, X. 2015. Tri- adic closure pattern analysis and prediction in social net- works. IEEE Transactions on Knowledge and Data Engi- neering 27(12):3374–3389."}, {"ref": "Jolliffe, I. 2002. Principal component analysis. Wiley On- line Library."}, {"ref": "Kossinets, G., and Watts, D. J. 2006. Empirical analysis of an evolving social network. science 311(5757):88–90."}, {"ref": "Kruskal, J. B. 1964. Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis. Psychometrika 29(1):1–27."}, {"ref": "Maaten, L. v. d., and Hinton, G. 2008. Visualizing data using t-sne. Journal of Machine Learning Research 9(Nov):2579– 2605."}, {"ref": "Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; and Dean, J. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems, 3111–3119."}, {"ref": "Perozzi, B.; Al-Rfou, R.; and Skiena, S. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD International Conference on Knowl- edge Discovery and Data Mining, KDD ’14, 701–710. New York, NY, USA: ACM."}, {"ref": "Qi, G.; Aggarwal, C. C.; and Huang, T. S. 2013. Link pre- diction across networks by biased cross-network sampling. In ECML/PKDD’13, 793–804."}, {"ref": "Roweis, S. T., and Saul, L. K. 2000. Nonlinear dimen- sionality reduction by locally linear embedding. science 290(5500):2323–2326."}, {"ref": "Sarkar, P., and Moore, A. W. 2005. Dynamic social network analysis using latent space models. ACM SIGKDD Explo- rations Newsletter 7(2):31–40."}, {"ref": "Sun, J.; Faloutsos, C.; Papadimitriou, S.; and Yu, P. S. 2007. Graphscope: parameter-free mining of large time-evolving graphs. In Proceedings of the 13th ACM SIGKDD interna- tional conference on Knowledge discovery and data mining, 687–696. ACM."}, {"ref": "Tang, J.; Zhang, J.; Yao, L.; Li, J.; Zhang, L.; and Su, Z. 2008. Arnetminer: extraction and mining of academic so- cial networks. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, 990–998. ACM."}, {"ref": "Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, Q. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web, 1067–1077. ACM."}, {"ref": "Tantipathananandh, C.; Berger-Wolf, T.; and Kempe, D. 2007. A framework for community identification in dynamic social networks. In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining, 717–726. ACM."}, {"ref": "Tenenbaum, J. B.; De Silva, V.; and Langford, J. C. 2000. A global geometric framework for nonlinear dimensionality reduction. science 290(5500):2319–2323."}, {"ref": "Wang, Z.; Zhang, J.; Feng, J.; and Chen, Z. 2014. Knowl- edge graph embedding by translating on hyperplanes. In AAAI, 1112–1119. Citeseer."}, {"ref": "Wang, D.; Cui, P.; and Zhu, W. 2016. Structural deep net- work embedding. In KDD’16, 1225–1234."}, {"ref": "Zhang, T.; Cui, P.; Faloutsos, C.; Lu, Y.; Ye, H.; Zhu, W.; and Yang, S. 2016. Come-and-go patterns of group evolu- tion: A dynamic model. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discov- ery and Data Mining, 1355–1364. ACM."}, {"ref": "Zhu, L.; Guo, D.; Yin, J.; Steeg, G. V.; and Galstyan, A. 2014. Scalable link prediction in dynamic net- works via non-negative matrix factorization. arXiv preprint arXiv:1411.3675."}, {"ref": "Zhu, L.; Guo, D.; Yin, J.; Ver Steeg, G.; and Galstyan, A. 2016. Scalable temporal latent space inference for link pre- diction in dynamic social networks. IEEE Transactions on Knowledge and Data Engineering 28(10):2765–2777."}, {"ref": "Zhuang, H.; Sun, Y.; Tang, J.; Zhang, J.; and Sun, X. 2013. Influence maximization in dynamic social networks. In Data Mining (ICDM), 2013 IEEE 13th International Conference on, 1313–1318. IEEE."}]}, {"author": ["Xi Liu", "Ping-Chun Hsieh", "Nick Duffield", "Rui Chen", "Muhe Xie", "Xidao Wen"], "title": "Real-Time Streaming Graph Embedding Through Local Actions", "journal": "International World Wide Web Conferences", "year": 2019, "DOI": "10.1145/3308560.3316585", "month": 5, "citations(google scholar)": 1, "abstract": "Recently, considerable research attention has been paid to graph embedding, a popular approach to construct representations of vertices in latent space. Due to the curse of dimensionality and sparsity in graphical datasets, this approach has become indispensable for machine learning tasks over large networks. The majority of the existing literature has considered this technique under the assumption that the network is static. However, networks in many applications, including social networks, collaboration networks, and recommender systems, nodes, and edges accrue to a growing network as streaming. A small number of very recent results have addressed the problem of embedding for dynamic networks. However, they either rely on knowledge of vertex attributes, suffer high-time complexity or need to be re-trained without closed-form expression. Thus the approach of adapting the existing methods designed for static networks or dynamic networks to the streaming environment faces non-trivial technical challenges.These challenges motivate developing new approaches to the problems of streaming graph embedding. In this paper, we propose a new framework that is able to generate latent representations for new vertices with high efficiency and low complexity under specified iteration rounds. We formulate a constrained optimization problem for the modification of the representation resulting from a stream arrival. We show this problem has no closed-form solution and instead develop an online approximation solution. Our solution follows three steps: (1) identify vertices affected by newly arrived ones, (2) generating latent features for new vertices, and (3) updating the latent features of the most affected vertices. The new representations are guaranteed to be feasible in the original constrained optimization problem. Meanwhile, the solution only brings about a small change to existing representations and only slightly changes the value of the objective function. Multi-class classification and clustering on five real-world networks demonstrate that our model can efficiently update vertex representations and simultaneously achieve comparable or even better performance compared with model retraining.", "keywords": ["Streaming Graph Embedding", "Local Actions", "latent representations"], "reference_count": 30, "ccfClass": "A", "important": true, "references": [{"ref": "[1] William L Hamilton, Rex Ying, and Jure Leskovec. Representation learning on graphs: Methods and applications. IEEE Data Engineering Bulletin, 2017."}, {"ref": "[2] Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for net- works. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 855–864, 2016."}, {"ref": "[3] Ye Li, Chaofeng Sha, Xin Huang, and Yanchun Zhang. Community detection in attributed graphs: An embedding approach. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, pages 338–345, 2018."}, {"ref": "[4] Zhu Cao, Linlin Wang, and Gerard de Melo. Link prediction via subgraph embedding-based convex matrix completion. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, pages 2803–2810, 2018."}, {"ref": "[5] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. Line: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web, pages 1067–1077, 2015."}, {"ref": "[6] Daixin Wang, Peng Cui, and Wenwu Zhu. Structural deep network embedding. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1225–1234, 2016."}, {"ref": "[7] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 701–710, 2014."}, {"ref": "[8] Leonardo FR Ribeiro, Pedro HP Saverese, and Daniel R Figueiredo. struc2vec: Learning node representations from structural identity. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 385–394, 2017."}, {"ref": "[9] Claire Donnat, Marinka Zitnik, David Hallac, and Jure Leskovec. Learning structural node embeddings via diffusion wavelets. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1320–1329, 2018."}, {"ref": "[10] ShiyuChang,YangZhang,JiliangTang,DaweiYin,YiChang,MarkAHasegawa- Johnson, and Thomas S Huang. Positive-unlabeled learning in streaming net- works. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 755–764, 2016."}, {"ref": "[11] Lun Du, Yun Wang, Guojie Song, Zhicong Lu, and Junshan Wang. Dynamic network embedding: An extended approach for skip-gram based network em- bedding. In Proceedings of the 17th International Joint Conferences on Artificial Intelligence, pages 2086–2092, 2018."}, {"ref": "[12] WillHamilton,ZhitaoYing,andJureLeskovec.Inductiverepresentationlearning on large graphs. In Advances in Neural Information Processing Systems, pages 1024–1034, 2017."}, {"ref": "[13] XiLiu,MuheXie,XidaoWen,RuiChen,YongGe,NickDuffield,andNaWang. A semi-supervised and inductive embedding model for churn prediction of large- scale mobile games. In IEEE International Conference on Data Mining (ICDM), 2018."}, {"ref": "[14] Jianxin Ma, Peng Cui, and Wenwu Zhu. Depthlgp: Learning embeddings of out-of-sample nodes in dynamic networks. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, pages 370–377, 2018."}, {"ref": "[15] GiangHoangNguyen,JohnBoazLee,RyanARossi,NesreenKAhmed,Eunyee Koh, and Sungchul Kim. Continuous-time dynamic network embeddings. In Companion of the The Web Conference 2018 on The Web Conference 2018, pages 969–976. International World Wide Web Conferences Steering Committee, 2018."}, {"ref": "[16] Qixiang Wang, Shanfeng Wang, Maoguo Gong, and Yue Wu. Feature hashing for network representation learning. In IJCAI, pages 2812–2818, 2018."}, {"ref": "[17] JundongLi,HarshDani,XiaHu,JiliangTang,YiChang,andHuanLiu.Attributed network embedding for learning in a dynamic environment. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, pages 387–396, 2017."}, {"ref": "[18] Ling Jian, Jundong Li, and Huan Liu. Toward online node classification on streaming networks. Data Mining and Knowledge Discovery, 32(1):231–257, 2018."}, {"ref": "[19] Dingyuan Zhu, Peng Cui, Ziwei Zhang, Jian Pei, and Wenwu Zhu. High-order proximity preserved embedding for dynamic networks. IEEE Transactions on Knowledge and Data Engineering, 2018."}, {"ref": "[20] Palash Goyal and Emilio Ferrara. Graph embedding techniques, applications, and performance: A survey. Knowledge-Based Systems, 151:78–94, 2018."}, {"ref": "[21] Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps and spectral techniques for embedding and clustering. In Advances in Neural Information Processing Systems, pages 585–591, 2002."}, {"ref": "[22] Johann Paratte and Lionel Martin. Fast eigenspace approximation using random signals. EPFL-ARTICLE, 2017."}, {"ref": "[23] Zhiqiang Xu and Xin Gao. On truly block eigensolvers via riemannian optimization. In International Conference on Artificial Intelligence and Statistics, pages 168–177, 2018."}, {"ref": "[24] HuikangLiu,WeijieWu,and Anthony Man-ChoSo.Quadratic optimization with orthogonality constraints: explicit łojasiewicz exponent and linear convergence of line-search methods. In Proceedings of the 33rd International Conference on International Conference on Machine Learning, pages 1158–1167, 2016."}, {"ref": "[25] SanchengPeng,YongmeiZhou,LihongCao,ShuiYu,JianweiNiu,andWeijiaJia. Influence analysis in social networks: a survey. Journal of Network and Computer Applications, pages 17–32, 2018."}, {"ref": "[26] YuanZhang,TianshuLyu,andYanZhang.Cosine:Community-preservingsocial network embedding from information diffusion cascades. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, pages 2620–2627, 2018."}, {"ref": "[27] Franco Manessi, Alessandro Rozza, and Mario Manzo. Dynamic graph convolu- tional networks. arXiv preprint arXiv:1704.06199, 2017."}, {"ref": "[28] Rakshit Trivedi, Mehrdad Farajtbar, Prasenjeet Biswal, and Hongyuan Zha. Rep- resentation learning over dynamic graphs. arXiv preprint arXiv:1803.04051, 2018. [29] Le-kui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. Dynamic network embedding by modeling triadic closure process. In Proceedings of the32nd AAAI Conference on Artificial Intelligence, pages 571–578, 2018."}, {"ref": "[30] Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, and Jie Tang. Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec. In Proceedings of the 11th ACM International Conference on Web Search and Data Mining, pages 459–467, 2018."}]}, {"author": ["Hogun Park", "Jennifer Neville"], "title": "Exploiting Interaction Links for Node Classification with Deep Graph Neural Networks", "journal": "International Joint Conference on Artificial Intelligence", "year": 2019, "DOI": "10.24963/ijcai.2019/447", "month": 8, "citations(google scholar)": 0, "abstract": "Node classification is an important problem in re- lational machine learning. However, in scenarios where graph edges represent interactions among the entities (e.g., over time), the majority of cur- rent methods either summarize the interaction in- formation into link weights or aggregate the links to produce a static graph. In this paper, we propose a neural network architecture that jointly captures both temporal and static interaction patterns, which we call Temporal-Static-Graph-Net (TSGNet). Our key insight is that leveraging both a static neigh- bor encoder, which can learn aggregate neighbor patterns, and a graph neural network-based recur- rent unit, which can capture complex interaction patterns, improve the performance of node clas- sification. In our experiments on node classifica- tion tasks, TSGNet produces significant gains com- pared to state-of-the-art methods—reducing clas- sification error up to 24% and an average of 10% compared to the best competitor on four real-world networks and one synthetic dataset.", "keywords": ["Interaction Links", "Node Classification", "Deep Graph Neural Networks", "Temporal-Static-Graph-Net"], "reference_count": 22, "ccfClass": "A", "important": true, "references": [{"ref": "[Chen et al., 2018] Jie Chen, Tengfei Ma, and Cao Xiao. Fastgcn: fast learning with graph convolutional networks via importance sampling. In Proceedings of International Conference on Learning Representations (ICLR), 2018."}, {"ref": "[Grover and Leskovec, 2016] Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In Proceedings of SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 855–864, 2016."}, {"ref": "[Hamilton et al., 2017] William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Proceedings of Conference on Neural Infor- mation Processing Systems (NeurIPS), pages 1024–1034, 2017."}, {"ref": "[Hochreiter and Schmidhuber, 1997] Sepp Hochreiter and Ju ̈rgen Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735–1780, 1997."}, {"ref": "[Hornik, 1991] Kurt Hornik. Approximation capabilities of multilayer feedforward networks. Neural networks, 4(2):251–257, 1991."}, {"ref": "[Jensen et al., 2004] David Jensen, Jennifer Neville, and Brian Gallagher. Why collective inference improves re- lational classification. In Proceedings of SIGKDD Inter- national Conference on Knowledge Discovery and Data Mining, pages 593–598, 2004."}, {"ref": "[Kingma and Ba, 2014] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Proceed- ings of International Conference on Learning Representa- tions (ICLR), 2014."}, {"ref": "[Kipf and Welling, 2016] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In Proceedings of International Conference on Learning Representations (ICLR), 2016."}, {"ref": "[Liaoetal.,2018] LiziLiao,XiangnanHe,HanwangZhang, and Tat-Seng Chua. Attributed social network embedding. IEEE Transactions on Knowledge and Data Engineering, 30(12):2257–2270, 2018."}, {"ref": "[Lu and Getoor, 2003] Qing Lu and Lise Getoor. Link-based classification. In Proceedings of International Conference on Machine Learning (ICML), pages 496–503, 2003."}, {"ref": "[Ma et al., 2018] Jianxin Ma, Peng Cui, and Wenwu Zhu. Depthlgp: learning embeddings of out-of-sample nodes in dynamic networks. In Proceedings of AAAI Conference on Artificial Intelligence, 2018."}, {"ref": "[Murphy et al., 2019] Ryan L Murphy, Balasubramaniam Srinivasan, Vinayak Rao, and Bruno Ribeiro. Janossy pooling: Learning deep permutation-invariant functions for variable-size inputs. In Proceedings of International Conference on Learning Representations (ICLR), 2019."}, {"ref": "[Nguyen et al., 2018] Giang Hoang Nguyen, John Boaz Lee, Ryan A Rossi, Nesreen K Ahmed, Eunyee Koh, and Sungchul Kim. Continuous-time dynamic network em- beddings. In Proceedings of BigNet Workshop in The Web Conference (WWW), 2018."}, {"ref": "[Park et al., 2017] Hogun Park, John Moore, and Jennifer Neville. Deep dynamic relational classifiers: Exploiting dynamic neighborhoods in complex networks. In Proceed- ings of MAISoN Workshop in International Conference on Web Search and Data Mining (WSDM), 2017."}, {"ref": "[Pfeiffer et al., 2015] Joseph J. Pfeiffer, III, Jennifer Neville, and Paul N. Bennett. Overcoming relational learning bi- ases to accurately predict preferences in large scale net- works. In Proceedings of International World Wide Web Conference (WWW), pages 853–863, 2015."}, {"ref": "[Rossi and Neville, 2012] Ryan Rossi and Jennifer Neville. Time-evolving relational classification and ensemble methods. In Proceedings of Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), pages 1–13, 2012."}, {"ref": "[Sharan and Neville, 2008] Umang Sharan and Jennifer Neville. Temporal-relational classifiers for prediction in evolving domains. In Proceedings of International Con- ference on Data Mining (ICDM), pages 540–549, 2008."}, {"ref": "[Xuetal.,2019] KeyuluXu,WeihuaHu,JureLeskovec,and Stefanie Jegelka. How powerful are graph neural net- works? In Proceedings of International Conference on Learning Representations (ICLR), 2019."}, {"ref": "[Yang et al., 2011] Tianbao Yang, Yun Chi, Shenghuo Zhu, Yihong Gong, and Rong Jin. Detecting communities and their evolutions in dynamic social networks – a bayesian approach. Machine learning, 82(2):157–189, 2011."}, {"ref": "[Zhang et al., 2018] Ziwei Zhang, Peng Cui, Jian Pei, Xiao Wang, and Wenwu Zhu. Timers: Error-bounded svd restart on dynamic networks. In Proceedings of AAAI Conference on Artificial Intelligence, 2018."}, {"ref": "[Zhou et al., 2018] Lekui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. Dynamic network embedding by modeling triadic closure process. In Proceedings of AAAI Conference on Artificial Intelligence, 2018."}, {"ref": "[Zhu et al., 2018] Dingyuan Zhu, Peng Cui, Ziwei Zhang, Jian Pei, and Wenwu Zhu. High-order proximity pre- served embedding for dynamic networks. IEEE Transac- tions on Knowledge and Data Engineering, 30(11):2134– 2144, 2018."}]}, {"author": ["Aynaz Taheri", "Kevin Gimpel", "Tanya Y. Berger-Wolf"], "title": "Learning to Represent the Evolution of Dynamic Graphs with Recurrent Models", "journal": "International World Wide Web Conferences", "year": 2019, "DOI": "10.1145/3308560.3316581", "month": 5, "citations(google scholar)": 0, "abstract": "Graph representation learning for static graphs is a well studied topic. Recently, a few studies have focused on learning temporal information in addition to the topology of a graph. Most of these studies have relied on learning to represent nodes and substructures in dynamic graphs. However, the representation learning problem for entire graphs in a dynamic context is yet to be addressed. In this paper, we propose an unsupervised representation learning architecture for dynamic graphs, designed to learn both the topological and temporal features of the graphs that evolve over time. The approach consists of a sequence-to-sequence encoder-decoder model embedded with gated graph neural networks (GGNNs) and long short-term memory networks (LSTMs). The GGNN is able to learn the topology of the graph at each time step, while LSTMs are leveraged to propagate the temporal information among the time steps. Moreover, an encoder learns the temporal dynamics of an evolving graph and a decoder reconstructs the dynamics over the same period of time using the encoded representation provided by the encoder. We demonstrate that our approach is capable of learning the representation of a dynamic graph through time by applying the embeddings to dynamic graph classification using a real world dataset of animal behaviour.", "keywords": ["dynamic graph", "representation learning", "recurrent models"], "reference_count": 42, "ccfClass": "A", "important": true, "references": [{"ref": "[1] B. Adhikari, Y. Zhang, N. Ramakrishnan, and B. A. Prakash. 2017. Distributed Representations of Subgraphs. In DaMNet."}, {"ref": "[2] Chainarong Amornbunchornvej, Ivan Brugere, Ariana Strandburg-Peshkin, Damien R. Farine, Margaret C. Crofoot, and Tanya Y. Berger-Wolf. 2018. Coordi- nation Event Detection and Initiator Identification in Time Series Data. ACM Trans. Knowl. Discov. Data 12, 5 (2018), 53:1–53:33."}, {"ref": "[3] Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2013. Spectral Networks and Locally Connected Networks on Graphs. CoRR (2013)."}, {"ref": "[4] Chih-ChungChangandChih-JenLin.2011.LIBSVM:alibraryforsupportvector machines. ACM TIST 2 (2011)."}, {"ref": "[5] Jinyin Chen, Xuanheng Xu, Yangyang Wu, and Haibin Zheng. 2018. GC-LSTM: Graph Convolution Embedded LSTM for Dynamic Link Prediction. arXiv preprint arXiv:1812.04206 (2018)."}, {"ref": "[6] Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 (2014)."}, {"ref": "[7] MCCrofoot,RWKays,andWikelskiM.2015.Datafrom:Shareddecision-making drives collective movement in wild baboons. Movebank Data Repository (2015)."}, {"ref": "[8] Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convo- lutional neural networks on graphs with fast localized spectral filtering. arXiv (2016)."}, {"ref": "[9] LunDu,YunWang,GuojieSong,ZhicongLu,andJunshanWang.2018.Dynamic Network Embedding: An Extended Approach for Skip-gram based Network Embedding.. In IJCAI."}, {"ref": "[10] Nan Du, Hanjun Dai, Rakshit Trivedi, Utkarsh Upadhyay, Manuel Gomez- Rodriguez, and Le Song. 2016. Recurrent marked temporal point processes: Embedding event history to vector. In Proceedings of the 22nd ACM SIGKDD Inter- national Conference on Knowledge Discovery and Data Mining. ACM, 1555–1564."}, {"ref": "[11] DavidDuvenaud,DougalMaclaurin,JorgeIparraguirre,RafaelBombarell,Timo- thy Hirzel, Alán Aspuru-Guzik, and Ryan P Adams. 2015. Convolutional networks on graphs for learning molecular fingerprints. In NIPS."}, {"ref": "[12] JustinGilmer,SamuelS.Schoenholz,PatrickF.Riley,OriolVinyals,andGeorgeE. Dahl. 2017. Neural Message Passing for Quantum Chemistry. CoRR (2017)."}, {"ref": "[13] JustinGilmer,SamuelSSchoenholz,PatrickFRiley,OriolVinyals,andGeorgeE Dahl. 2017. Neural message passing for quantum chemistry. arXiv preprint arXiv:1704.01212 (2017)."}, {"ref": "[14] Marco Gori, Gabriele Monfardini, and Franco Scarselli. [n. d.]. A new model for learning in graph domains. In Proceedings of the 2005 IEEE International Joint Conference on Neural Networks (IJCNN’05), Vol. 2. IEEE, 729–734."}, {"ref": "[15] PalashGoyal,SujitRokkaChhetri,andArquimedesCanedo.2018.dyngraph2vec: Capturing network dynamics using dynamic graph representation learning. arXiv preprint arXiv:1809.02657 (2018)."}, {"ref": "[16] Palash Goyal, Nitin Kamra, Xinran He, and Yan Liu. 2017. DynGEM: Deep Embedding Method for Dynamic Graphs. CoRR abs/1805.11273 (2017)."}, {"ref": "[17] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In KDD."}, {"ref": "[18] M. Henaff, J. Bruna, and Y. LeCun. 2015. Deep convolutional networks on graph- structured data. arXiv (2015)."}, {"ref": "[19] Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based recommendations with recurrent neural networks. In ICLR."}, {"ref": "[20] S. Hochreiter and J. Schmidhuber. 1997. Long short-term memory. Neural computation (1997)."}, {"ref": "[21] Petter Holme and Jari Saramäki. 2012. Temporal networks. Physics reports 519, 3 (2012), 97–125."}, {"ref": "[22] David Kempe, Jon Kleinberg, and Amit Kumar. 2002. Connectivity and inference problems for temporal networks. J. Comput. System Sci. 64, 4 (2002), 820–842."}, {"ref": "[23] John Boaz Lee, Ryan Rossi, and Xiangnan Kong. 2018. Graph classification using structural attention. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 1666–1674."}, {"ref": "[24] Jia Li, Kaiser Asif, Hong Wang, Brian D Ziebart, and Tanya Y Berger-Wolf. 2016. Adversarial Sequence Tagging.. In IJCAI."}, {"ref": "[25] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. 2016. Gated graph sequence neural networks. In ICLR."}, {"ref": "[26] Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. JMLR (2008)."}, {"ref": "[27] AnnamalaiNarayanan,MahinthanChandramohan,LihuiChen,YangLiu,and Santhoshkumar Saminathan. 2016. subgraph2vec: Learning distributed represen- tations of rooted sub-graphs from large graphs. MLG (2016)."}, {"ref": "[28] AnnamalaiNarayanan,MahinthanChandramohan,RajasekarVenkatesan,Lihui Chen, Yang Liu, and Shantanu Jaiswal. 2017. graph2vec: Learning Distributed Representations of Graphs. In MLG."}, {"ref": "[29] GiangHoangNguyen,JohnBoazLee,RyanARossi,NesreenKAhmed,Eunyee Koh, and Sungchul Kim. 2018. Continuous-time dynamic network embeddings. In International Workshop on Learning Representations for Big Networks at The Web Conference."}, {"ref": "[30] Mathias Niepert, Mohamed Ahmed, and Konstantin Kutzkov. 2016. Learning Convolutional Neural Networks for Graphs. In ICML."}, {"ref": "[31] B. Perozzi, R. Al-Rfou, and S Skiena. 2014. DeepWalk: Online learning of social representations. In KDD."}, {"ref": "[32] Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, and Hao Yang. 2018. Dynamic Graph Representation Learning via Self-Attention Networks. arXiv preprint arXiv:1812.09430 (2018)."}, {"ref": "[33] FrancoScarselli,MarcoGori,AhChungTsoi,MarkusHagenbuchner,andGabriele Monfardini. 2009. The graph neural network model. IEEE Transactions on Neural Networks 20, 1 (2009), 61–80."}, {"ref": "[34] Ariana Strandburg-Peshkin, Damien R Farine, Iain D Couzin, and Margaret C Crofoot. 2015. Shared decision-making drives collective movement in wild baboons. Science 348, 6241 (2015), 1358–1361."}, {"ref": "[35] Aynaz Taheri, Kevin Gimpel, and Tanya Berger-Wolf. 2018. Learning Graph Representations with Recurrent Neural Network Autoencoders. In KDD Deep Learning Day."}, {"ref": "[36] Rakshit Trivedi, Hanjun Dai, Yichen Wang, and Le Song. 2017. Know-evolve: Deep temporal reasoning for dynamic knowledge graphs. In ICML."}, {"ref": "[37] Rakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, and Hongyuan Zha. 2019. DyRep: Learning Representations over Dynamic Graphs. In International Conference on Learning Representations."}, {"ref": "[38] PengyangWang,YanjieFu,JiaweiZhang,PengfeiWang,YuZheng,andCharu Aggarwal. 2018. You are how you drive: Peer and temporal-aware representation learning for driving behavior analysis. In KDD. ACM."}, {"ref": "[39] Quan Wang, Zhendong Mao, Bin Wang, and Li Guo. 2017. Knowledge graph embedding: A survey of approaches and applications. IEEE Transactions on Knowledge and Data Engineering 29, 12 (2017), 2724–2743."}, {"ref": "[40] Pinar Yanardag and SVN Vishwanathan. 2015. Deep graph kernels. In KDD."}, {"ref": "[41] Muhan Zhang, Zhicheng Cui, Marion Neumann, and Yixin Chen. 2018. An End-to-End Deep Learning Architecture for Graph Classification. In AAAI."}, {"ref": "[42] Le-kuiZhou,YangYang,XiangRen,FeiWu,andYuetingZhuang.2018.Dynamic Network Embedding by Modeling Triadic Closure Process.. In AAAI."}]}, {"author": ["Hong Huang", "Jie Tang", "Lu Liu", "Jarder Luo", "Xiaoming Fu"], "title": "Triadic Closure Pattern Analysis and Prediction in Social Networks", "journal": "IEEE Transactions on Knowledge and Data Engineering", "year": 2015, "DOI": "10.1109/TKDE.2015.2453956", "month": 12, "citations(google scholar)": 24, "abstract": "We study the problem of group formation in online social networks. In particular, we focus on one of the most important human groups-the triad-and try to understand how closed triads are formed in dynamic networks, by employing data from a large microblogging network as the basis of our study. We formally define the problem of triadic closure prediction and conduct a systematic investigation. The study reveals how user demographics, network characteristics, and social properties influence the formation of triadic closure. We also present a probabilistic graphical model to predict whether three persons will form a closed triad in a dynamic network. Different kernel functions are incorporated into the proposed graphical model to quantify the similarity between triads. Our experimental results with the large microblogging dataset demonstrate the effectiveness (+10 percent over alternative methods in terms of F1-Score) of the proposed model for the prediction of triadic closure formation.", "keywords": ["Social network services", "Predictive models", "Social factors", "Graphical models", "Probabilistic logic"], "reference_count": 46, "ccfClass": "A", "important": true, "references": [{"ref": "1. L. Backstrom, D. Huttenlocher, J. Kleinberg, X. Lan, \"Group formation in large social networks: Membership growth and evolution\", Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 44-54, 2006."}, {"ref": "2. J. Coleman, Foundations of Social Theory, Cambridge, MA, USA:Harvard, 1990."}, {"ref": "3. D. Easley, J. Kleinberg, Networks Crowds and Markets, Cambridge, U.K.:Cambridge Univ. Press, pp. 6-1, 2010."}, {"ref": "4. J. Leskovec, L. Backstrom, R. Kumar, A. Tomkins, \"Microscopic evolution of social networks\", Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 462-470, 2008."}, {"ref": "5. P. W. Holland, S. Leinhardt, \"Transitivity in structural models of small groups\", Comparative Group Stud., vol. 2, no. 2, pp. 107-124, 1971."}, {"ref": "6. S. Wasserman, Social Network Analysis: Methods and Applications, Cambridge, MA, USA:Cambridge Univ. Press, vol. 8, 1994."}, {"ref": "7. J.-P. Eckmann, E. Moses, \"Curvature of co-links uncovers hidden thematic layers in the world wide web\", Proc. Nat. Acad. Sci., vol. 99, no. 9, pp. 5825-5829, 2002."}, {"ref": "8. E. Zheleva, H. Sharara, L. Getoor, \"Co-evolution of social and affiliation networks\", Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 1007-1016, 2009."}, {"ref": "9. A. Sala, L. Cao, C. Wilson, R. Zablit, H. Zheng, B. Y. Zhao, \"Measurement-calibrated graph models for social network experiments\", Proc. Int. Conf. World Wide Web, pp. 861-870, 2010."}, {"ref": "10. N. Z. Gong, W. Xu, L. Huang, P. Mittal, E. Stefanov, V. Sekar, D. Song, \"Evolution of social-attribute networks: Measurements modeling and implications using google+\", Proc. ACM Conf. Internet Meas. Conf., pp. 131-144, 2012."}, {"ref": "11. R. Milo, S. Itzkovitz, N. Kashtan, R. Levitt, S. Shen-Orr, I. Ayzenshtat, M. Sheffer, U. Alon, \"Superfamilies of evolved and designed networks\", Science, vol. 303, no. 5663, pp. 1538-1542, 2004."}, {"ref": "12. R. Milo, S. Shen Orr, S. Itzkovitz, N. Kashtan, D. Chklovskii, U. Alon, \"Network motifs: Simple building blocks of complex networks\", Science, vol. 298, pp. 824-827, 2002."}, {"ref": "13. D. M. Romero, J. Kleinberg, \"The directed closure process in hybrid social-information networks with an analysis of link formation on twitter\", Statistics, vol. 1050, pp. 12, 2010."}, {"ref": "14. T. Lou, J. Tang, J. Hopcroft, Z. Fang, X. Ding, \"Learning to predict reciprocity and triadic closure in social networks\", ACM Trans. Knowl. Discovery Data, vol. 7, no. 2, pp. 5, 2013."}, {"ref": "15. H. Huang, J. Tang, S. Wu, L. Liu, X. Fu, \"Mining triadic closure patterns in social networks\", Proc. Companion Publication 23rd Int. Conf. World Wide Web Companion, pp. 499-504, 2014."}, {"ref": "16. H. Kwak, C. Lee, H. Park, S. Moon, Proc. 19th Int. Conf. World Wide Web, pp. 591-600, 2010."}, {"ref": "17. L. Page, S. Brin, R. Motwani, T. Winograd, \"The pagerank citation ranking: Bringing order to the web\", 1998."}, {"ref": "18. S. Wu, J. M. Hofman, W. A. Mason, D. J. Watts, \"Who says what to whom on twitter\", Proc. Int. Conf. World Wide Web, pp. 705-714, 2011."}, {"ref": "19. R. S. Burt, \"The social structure of competition\", Explorations Econ. Sociol., vol. 65, pp. 103, 1993."}, {"ref": "20. T. Lou, J. Tang, \"Mining structural hole spanners through information diffusion in social networks\", Proc. Int. Conf. World Wide Web, pp. 837-848, 2013."}, {"ref": "21. K. C. Cook, R. S. Burt, N. Lin, \"Structural holes versus network closure as social capital\" in Social Capital: Theory and Research, Piscataway, NJ, USA:Transaction Publishers, 2001."}, {"ref": "22. Z. Sasovova, A. Mehra, S. P. Borgatti, M. C. Schippers, \"Network churn: The effects of self-monitoring personality on brokerage dynamics\", Administ. Sci. Quart., vol. 55, no. 4, pp. 639-670, 2010."}, {"ref": "23. D. Obstfeld, \"Social networks the tertius iungens orientation and involvement in innovation\", Administ. Sci. Quart., vol. 50, no. 1, pp. 100-130, 2005."}, {"ref": "24. J. Leskovec, D. Huttenlocher, J. Kleinberg, \"Signed networks in social media\", Proc. SIGCHI Conf. Human Factors Comput. Syst., pp. 1361-1370, 2010."}, {"ref": "25. J. Zhang, B. Liu, J. Tang, T. Chen, J. Li, \"Social influence locality for modeling retweeting behaviors\", Proc. 23rd Int. Joint Conf. Artif. Intell., pp. 2761-2767, 2013."}, {"ref": "26. J. M. Hammersley, P. Clifford, \"Markov field on finite graphs and lattices\", 1971."}, {"ref": "27. J. Lafferty, A. McCallum, F. C. Pereira, \"Conditional random fields: Probabilistic models for segmenting and labeling sequence data\", Proc. Int. Conf. Mach. Learn., pp. 282-289, 2001."}, {"ref": "28. J. Shawe Taylor, N. Cristianini, Kernel Methods for Pattern Analysis, Cambridge, MA, USA:Cambridge Univ. Press, 2004."}, {"ref": "29. M.-H. Yang, \"Kernel eigenfaces vs. kernel fisherfaces: Face recognition using kernel methods\", Proc. 5th IEEE Int. Conf. Automatic Face Gesture Recog., pp. 0215-0215, 2002.Show Context View Article Full Text: PDF\t(336KB) Google Scholar"}, {"ref": "30. A. Ben-Hur, W. S. Noble, \"Kernel methods for predicting protein–protein interactions\", Bioinformatics, vol. 21, no. suppl 1, pp. i38-i46, 2005."}, {"ref": "31. L. Wasserman, All of Statistics: A Concise Course in Statistical Inference, New York, NY, USA:Springer, 2004."}, {"ref": "32. B. Schweizer, A. Sklar, Probabilistic Metric Spaces, Mineola, NY, USA:Courier Dover Publications, 2011."}, {"ref": "33. M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, I. H. Witten, \"The weka data mining software: An update\", ACM SIGKDD Explorations Newslett., vol. 11, no. 1, pp. 10-18, 2009."}, {"ref": "34. J. Hopcroft, T. Lou, J. Tang, \"Who will follow you back?reciprocal relationship prediction\", Proc. ACM Conf. Inf. Knowl. Manage., pp. 1137-1146, 2011."}, {"ref": "35. P. Klimek, S. Thurner, \"Triadic closure dynamics drives scaling laws in social multiplex networks\", New J. Phys., vol. 15, no. 6, pp. 063008, 2013."}, {"ref": "36. M. Li, H. Zou, S. Guan, X. Gong, K. Li, Z. Di, C.-H. Lai, \"A coevolving model based on preferential triadic closure for social media networks\", Sci. Rep., vol. 3, pp. 2512, 2013."}, {"ref": "37. Y. Dong, J. Tang, S. Wu, J. Tian, N. V. Chawla, J. Rao, H. Cao, \"Link prediction and recommendation across heterogeneous social networks\", Proc. Int. Conf. Data Mining, pp. 181-190, 2012."}, {"ref": "38. Y. Dong, Y. Yang, J. Tang, Y. Yang, N. V. Chawla, \"Inferring user demographics and social strategies in mobile social networks\", Proc. 20th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 15-24, 2014."}, {"ref": "39. J. Zhang, Z. Fang, W. Chen, J. Tang, \"Diffusion of following links in microblogging networks\", IEEE trans. Knowl. Data Eng., 2015."}, {"ref": "40. M. Zignani, S. Gaito, G. P. Rossi, X. Zhao, H. Zheng, B. Y. Zhao, \"Link and triadic closure delay: Temporal metrics for social network dynamics\", Proc. 8th Int. AAAI Conf. Weblogs Social Media, pp. 564-573, 2014."}, {"ref": "41. M. E. Newman, \"Clustering and preferential attachment in growing networks\", Phys. Rev. E, vol. 64, no. 2, pp. 025102, 2001."}, {"ref": "42. L. Katz, \"A new status index derived from sociometric analysis\", Psychometrika, vol. 18, no. 1, pp. 39-43, 1953."}, {"ref": "43. R. N. Lichtenwalter, J. T. Lussier, N. V. Chawla, \"New perspectives and methods in link prediction\", Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 243-252, 2010."}, {"ref": "44. D. Liben-Nowell, J. Kleinberg, \"The link-prediction problem for social networks\", J. Amer. Soc. Inf. Sci. Technol., vol. 58, no. 7, pp. 1019-1031, 2007."}, {"ref": "45. L. Backstrom, J. Leskovec, \"Supervised random walks: Predicting and recommending links in social networks\", Proc. ACM Int. Conf. Web Search Data Mining, pp. 635-644, 2011."}, {"ref": "46. J. Leskovec, D. Huttenlocher, J. Kleinberg, \"Predicting positive and negative links in online social networks\", Proc. Int. Conf. World Wide Web, pp. 641-650, 2010."}]}, {"author": ["Yue Meng", "Peng Wang", "Junyan Xiao", "Xiaoyu Zhou"], "title": "NeLSTM: A New Model for Temporal Link Prediction in Social Networks", "journal": "ICSC", "year": 2019, "DOI": "10.1109/ICOSC.2019.8665664", "month": 1, "citations(google scholar)": 1, "abstract": "The dynamic nature of social networks has a huge impact on temporal link prediction problem, in which we are given snapshots of a network at different timestamps and need to predict the possible link between a node pair in the future or whether there are some missing links. The core issue is how to effectively use topology and timing information to improve performance. This paper proposes a model called NeLSTM combining network embedding with Long Short-Term Memory(LSTM) network to predict temporal network topology structure, which is represented by node vectors. First, to measure the impact of a past link on the future network, we add a time attenuation coefficient to the weight of a node pair. Then, network embedding is able to preserve the network topology information and based on its output, LSTM can characterize the continuous network evolution. Finally, NeLSTM obtains the similarity of a node pair via calculating the inner product, which exactly represents the possibility that a link occurs. Experimental results show that NeLSTM performs well in real world networks.", "keywords": ["Attenuation", "Predictive models", "Network topology", "Aging", "Facebook", "Task analysis"], "reference_count": 18, "ccfClass": "", "important": true, "references": [{"ref": "[1] GetoorL,DiehlCP.Linkmining:asurvey.ACMSIGKDD Explorations Newsletter. Vol 7, No. 2 . 2005. pp. 3-12."}, {"ref": "[2] Wang P, Xu B W, Wu Y R, et al. Link prediction in social networks: the state-of-the-art. Science China:Information Science. Vol 58, No. 1. 2015. pp. 1-38."}, {"ref": "[3] Liben-Nowell D, Kleinberg J. The link-prediction problem for social networks. Journal of the American Society for Information Science and Technology. Vol 58, No. 7. 2007. pp. 1019-1031."}, {"ref": "[4] Oyama S, Hayashi K, Kashima H. Cross-Temporal Link Prediction IEEE, International Conference on Data Mining. Proceedings of the 2011 IEEE 11th International Conference on Data Mining. Washington, DC, USA. 2011. pp. 1188-1193."}, {"ref": "[5] Dunlavy D M, Kolda T G, Acar E. Temporal Link Prediction Using Matrix and Tensor Factorizations. ACM Transactions on Knowledge Discovery from Data. Vol 5, No. 2. 2011. pp. 1-27."}, {"ref": "[6] Gao S, Denoyer L, Gallinari P. Temporal link prediction by integrating content and structure information. Proceedings of the 20th ACM international conference on Information and knowledge management. Glasgow, Scotland, UK. 2011. pp. 1169-1174."}, {"ref": "[7] XuHH,ZhangLJ.ApplicationofLinkPredictioninTemporalNetworks. Advanced Materials Research. Vol 756-759. 2013. pp. 2231-2236."}, {"ref": "[8] Munasinghe L, Ichise R. Time Score : A New Feature for Link Prediction in Social Networks. IEICE Transactions on Information and Systems.Vol 95, No. 3. 2012. pp. 821-828."}, {"ref": "[9] Jahanbakhsh K, King V, Shoja G C. Predicting missing contacts in mobile social networks. Pervasive and Mobile Computing. Vol 8, No. 5.2012. pp. 698-716."}, {"ref": "[10] Tylenda T, Angelova R, Bedathur S. Towards time-aware link prediction in evolving social networks. Proceedings of the 3rd Workshop on Social Network Mining and Analysis. Paris, France. 2009. pp. 1-10."}, {"ref": "[11] Richard E, Baskiotis N, Evgeniou T, et al. Link Discovery using Graph Feature Tracking. Advances in Neural Information Processing Systems. Vancouver, Canada. 2010. pp. 1966-1974."}, {"ref": "[12] Zhu L, Guo D, Yin J, et al. Scalable Temporal Latent Space Inference for Link Prediction in Dynamic Social Networks. IEEE Transactions on Knowledge and Data Engineering. Vol 28, No. 10. 2016. pp. 2765-2777."}, {"ref": "[13] Yu W, Cheng W, Aggarwal C C, et al. Link Prediction with Spatial and Temporal Consistency in Dynamic Networks. Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence. Melbourne, Australia. 2017. pp. 3343-3349."}, {"ref": "[14] Perozzi B, Al-Rfou R, Skiena S. 2014. Deepwalk: Online learning of social representations. Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. New York, New York, USA. 2014. pp. 701-710."}, {"ref": "[15] Tang J, Qu M, Wang M, et al. LINE: Large-scale Information Network Embedding. Proceedings of the 24th International Conference on World Wide Web. Florence, Italy. 2015. pp. 1067-1077."}, {"ref": "[16] Hochreiter S, Schmidhuber J. Long Short-Term Memory. Neural Com- putation. Vol 9, No.8. 1997. pp. 1735-1780."}, {"ref": "[17] Mueller J, Thyagarajan A. Siamese recurrent architectures for learning sentence similarity. Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. Phoenix, Arizona, USA. 2016. pp. 2786-2792."}, {"ref": "[18] Graves A. Supervised Sequence Labelling with Recurrent Neural Networks. Springer Press. Berlin, Heidelberg. 2012. behavioral networks. Journal of Theoretical Biology. Vol 271, No. 1. 2011. pp. 166-180."}]}, {"author": ["Aldo Pareja", "Giacomo Domeniconi", "Jian Jhen Chen", "Tengfei Ma", "Toyotaro Suzumura", "Hiroki Kanezashi", "Tim Kaler", "Charles E. Leisersen"], "title": "EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs", "journal": "ArXiv", "year": 2019, "DOI": "arXiv:1902.10191", "month": 9, "citations(google scholar)": 6, "abstract": "Graph representation learning resurges as a trending research subject owing to the widespread use of deep learning for Euclidean data, which inspire various creative designs of neural networks in the non-Euclidean domain, particularly graphs. With the success of these graph neural networks (GNN) in the static setting, we approach further practical scenarios where the graph dynamically evolves. For this case, combining the GNN with a recurrent neural network (RNN, broadly speaking) is a natural idea. Existing approaches typically learn one single graph model for all the graphs, by using the RNN to capture the dynamism of the output node embeddings and to implicitly regulate the graph model. In this work, we propose a different approach, coined EvolveGCN, that uses the RNN to evolve the graph model itself over time. This model adaptation approach is model oriented rather than node oriented, and hence is advantageous in the flexibility on the input. For example, in the extreme case, the model can handle at a new time step, a completely new set of nodes whose historical information is unknown, because the dynamism has been carried over to the GNN parameters. We evaluate the proposed approach on tasks including node classification, edge classification, and link prediction. The experimental results indicate a generally higher performance of EvolveGCN compared with related approaches.", "keywords": ["EvolveGCN", "RNN", "Node Classification"], "reference_count": 32, "ccfClass": "", "important": true, "references": [{"ref": "[Belkin and Niyogi 2002] Belkin, M., and Niyogi, P. 2002. Laplacian eigenmaps and spectral techniques for embedding and clustering. In NIPS."}, {"ref": "[Bruna et al. 2014] Bruna, J.; Zaremba, W.; Szlam, A.; and LeCun, Y. 2014. Spectral networks and locally connected networks on graphs. In ICLR."}, {"ref": "[Cangea et al. 2018] Cangea, C.; Velicˇkovic ́, P.; Jovanovic ́, N.; and Thomas Kipf, P. L. 2018. Towards sparse hierar- chical graph classifiers. In NIPS Workshop on Relational Representation Learning."}, {"ref": "[Cao, Lu, and Xu 2015] Cao, S.; Lu, W.; and Xu, Q. 2015. GraRep: Learning graph representations with global struc- tural information. In CIKM."}, {"ref": "[Chen, Ma, and Xiao 2018] Chen, J.; Ma, T.; and Xiao, C. 2018. FastGCN: Fast learning with graph convolutional net- works via importance sampling. In ICLR."}, {"ref": "[Defferrard, Bresson, and Vandergheynst 2016] Defferrard, M.; Bresson, X.; and Vandergheynst, P. 2016. Convolu- tional neural networks on graphs with fast localized spectral filtering. In NIPS."}, {"ref": "[Duvenaud et al. 2015] Duvenaud, D.; Maclaurin, D.; Aguilera-Iparraguirre, J.; Go ́mez-Bombarelli, R.; Hirzel, T.; Aspuru-Guzik, A.; and Adams, R. P. 2015. Convolutional networks on graphs for learning molecular fingerprints. In NIPS."}, {"ref": "[Gao and Ji 2019] Gao, H., and Ji, S. 2019. Graph U-Nets. In ICML."}, {"ref": "[Gilmer et al. 2017] Gilmer, J.; Schoenholz, S. S.; Riley, P. F.; Vinyals, O.; and Dahl, G. E. 2017. Neural message passing for quantum chemistry. In ICML."}, {"ref": "[Goyal et al. 2017] Goyal, P.; Kamra, N.; He, X.; and Liu, Y. 2017. DynGEM: Deep embedding method for dynamic graphs. In IJCAI Workshop on Representation Learning for Graphs."}, {"ref": "[Goyal, Chhetri, and Canedo 2019] Goyal, P.; Chhetri, S. R.; and Canedo, A. 2019. dyngraph2vec: Capturing net- work dynamics using dynamic graph representation learn- ing. Knowledge-Based Systems."}, {"ref": "[Grover and Leskovec 2016] Grover, A., and Leskovec, J. 2016. node2vec: Scalable feature learning for networks. In KDD."}, {"ref": "[Hamilton, Ying, and Leskovec 2017] Hamilton, W. L.; Ying, R.; and Leskovec, J. 2017. Inductive representation learning on large graphs. In NIPS."}, {"ref": "[Jin et al. 2017] Jin, W.; Coley, C. W.; Barzilay, R.; and Jaakkola, T. 2017. Predicting organic reaction outcomes with Weisfeiler-Lehman network. In NIPS."}, {"ref": "[Kipf and Welling 2017] Kipf, T. N., and Welling, M. 2017. Semi-supervised classification with graph convolutional net- works. In ICLR."}, {"ref": "[Li et al. 2016] Li, Y.; Tarlow, D.; Brockschmidt, M.; and Zemel, R. 2016. Gated graph sequence neural networks. In ICLR."}, {"ref": "[Li et al. 2017] Li, J.; Dani, H.; Hu, X.; Tang, J.; Chang, Y.; and Liu, H. 2017. Attributed network embedding for learn- ing in a dynamic environment. In CIKM."}, {"ref": "[Manessia, Rozza, and Manzo 2017] Manessia, F.; Rozza, A.; and Manzo, M. 2017. Dynamic graph convolutional networks. arXiv:1704.06199."}, {"ref": "[Narayan and Roe 2018] Narayan, A., and Roe, P. H. O. 2018. Learning graph dynamics using deep neural networks. IFAC-PapersOnLine 51(2):433–438."}, {"ref": "[Nguyen et al. 2018] Nguyen, G. H.; Lee, J. B.; Rossi, R. A.; Ahmed, N. K.; Koh, E.; and Kim, S. 2018. Continuous-time dynamic network embeddings. In WWW."}, {"ref": "[Ou et al. 2016] Ou, M.; Cui, P.; Pei, J.; Zhang, Z.; and Zhu, W. 2016. Asymmetric transitivity preserving graph embed- ding. In KDD."}, {"ref": "[Perozzi, Al-Rfou, and Skiena 2014] Perozzi, B.; Al-Rfou, R.; and Skiena, S. 2014. DeepWalk: Online learning of social representations. In KDD."}, {"ref": "[Roweis and Saul 2000] Roweis, S. T., and Saul, L. K. 2000. Nonlinear dimensionality reduction by locally linear embed- ding. Science 290(5500):2323–2326."}, {"ref": "[Seo et al. 2016] Seo, Y.; Defferrard, M.; Vandergheynst, P.; and Bresson, X. 2016. Structured sequence modeling with graph convolutional recurrent networks. arXiv:1612.07659."}, {"ref": "[Tang et al. 2015] Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, Q. 2015. LINE: Large-scale information network embedding. In WWW."}, {"ref": "[Trivedi et al. 2017] Trivedi, R.; Dai, H.; Wang, Y.; and Song, L. 2017. Know-Evolve: Deep temporal reasoning for dynamic knowledge graphs. In ICML."}, {"ref": "[Trivedi et al. 2018] Trivedi, R.; Farajtabar, M.; Biswal, P.; and Zha, H. 2018. Representation learning over dynamic graphs. arXiv:1803.04051."}, {"ref": "[Velic ̆kovic ́ et al. 2018] Velic ̆kovic ́, P.; Cucurull, G.; Casanova, A.; Romero, A.; Lio`, P.; and Bengio, Y. 2018. Graph attention networks. In ICLR."}, {"ref": "[Yu et al. 2018] Yu, W.; Cheng, W.; Aggarwal, C.; Zhang, K.; Chen, H.; and Wang, W. 2018. NetWalk: A flexible deep embedding approach for anomaly detection in dynamic networks. In KDD."}, {"ref": "[Yu, Yin, and Zhu 2018] Yu, B.; Yin, H.; and Zhu, Z. 2018. Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting. In IJCAI."}, {"ref": "[Zhou et al. 2018] Zhou, L.; Yang, Y.; Ren, X.; Wu, F.; and Zhuang, Y. 2018. Dynamic network embedding by model- ing triadic closure process. In AAAI."}, {"ref": "[Zuo et al. 2018] Zuo, Y.; Liu, G.; Lin, H.; Guo, J.; Hu, X.; and Wu, J. 2018. Embedding temporal network via neigh- borhood formation. In KDD."}]}, {"author": ["Seyed Amjad Seyedi", "Parham Moradi", "Fardin Akhlaghian Tab"], "title": "A weakly-supervised factorization method with dynamic graph embedding", "journal": "Artificial Intelligence and Signal Processing Conference", "year": 2017, "DOI": "10.1109/AISP.2017.8324084", "month": 10, "citations(google scholar)": 1, "abstract": "Nonnegative matrix factorization (NMF) is an effective method to learn a vigorous representation of nonnegative data and has been successfully applied in different machine learning tasks. Using NMF in semi-supervised classification problems, its factors are the label matrix and the membership values of data points. In this paper, a dynamic weakly supervised factorization is proposed to learn a classifier using NMF framework and partially supervised data. Also, a label propagation mechanism is used to initialize the label matrix factor of NMF. Besides a graph based method is used to dynamically update the partially labeled data in each iteration. This mechanism leads to enriching the supervised information in each iteration and consequently improves the classification performance. Several experiments were performed to evaluate the performance of the proposed method and the results show its superiority compared to a state-of-the-art method.", "keywords": ["Semi-supervised learning", "Semi nonnegative matrix factorization", "Graph Regularization Label propagation"], "reference_count": 25, "ccfClass": "B", "important": true, "references": [{"ref": "[1] O. Chapelle, B. Scholkopf, A. Zien, Semi-Supervised Learning, MIT Press, 2006."}, {"ref": "[2] X. Zhu, \"Semi-supervised learning\" in Encyclopedia of Machine Learning, Springer, pp. 892-897, 2011."}, {"ref": "[3] X. Zhu, Semi-supervised learning with graphs, 2005."}, {"ref": "[4] I. Diaz-Valenzuela, M.A. Vila, M.J. Martin-Bautista, \"On the Use of Fuzzy Constraints in Semisupervised Clustering\", IEEE Transactions on Fuzzy Systems, vol. 24, no. 4, pp. 992-999, 2016."}, {"ref": "[5] B. Wang, Z. Tu, J.K. Tsotsos, \"Dynamic label propagation for semi-supervised multi-class multi-label classification\", Proceedings of the IEEE International Conference on Computer Vision, pp. 425-432, 2013."}, {"ref": "[6] D.D. Lee, H.S. Seung, \"Learning the parts of objects by non-negative matrix factorization\", Nature, vol. 401, no. 6755, pp. 788-791, 1999."}, {"ref": "[7] W. Xu, X. Liu, Y. Gong, \"Document clustering based on nonnegative matrix factorization\", Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, pp. 267-273, 2003."}, {"ref": "[8] A. Cichocki, H. Lee, Y.-D. Kim, S. Choi, \" Non-negative matrix factorization with \\$alpha\\$ -divergence \", Pattern Recognition Letters, vol. 29, no. 9, pp. 1433-1440, 2008."}, {"ref": "[9] A. Cichocki, Y. Washizawa, T. Rutkowski, H. Bakardjian, A.-H. Phan, S. Choi, H. Lee, Q. Zhao, L. Zhang, Y. Li, \"Noninvasive BCIs: Multiway signal-processing array decompositions\", Computer, vol. 41, no. 10, 2008."}, {"ref": "[10] JD.Z. Navgaran, P. Moradi, F. Akhlaghian, \"Evolutionary based matrix factorization method for collaborative filtering systems\", 2013 21st Iranian Conference on Electrical Engineering (ICEE), pp. 1-5, 2013."}, {"ref": "[11] M. Ranjbar, P. Moradi, M. Azami, M. Jalili, \"An imputation-based matrix factorization method for improving accuracy of collaborative filtering systems\", Engineering Applications of Artificial Intelligence, vol. 46, pp. 58-66, 2015."}, {"ref": "[12] Z. Shajarian, S.A. Seyedi, P. Moradi, \"A clustering-based matrix factorization method to improve the accuracy of recommendation systems\", 2017 Iranian Conference on Electrical Engineering (ICEE), pp. 2241-2246, 2017."}, {"ref": "[13]  H. Lee, J. Yoo, S. Choi, \"Semi-supervised nonnegative matrix factorization\", IEEE Signal Processing Letters, vol. 17, no. 1, pp. 4-7, 2010."}, {"ref": "[14] D. Wang, X. Gao, X. Wang, \"Semi-supervised nonnegative matrix factorization via constraint propagation\", IEEE transactions on cybernetics, vol. 46, no. 1, pp. 233-244, 2016."}, {"ref": "[15] C. Ding, T. Li, W. Peng, Nonnegative matrix factorization and probabilistic latent semantic indexing: Equivalence chi-square statistic and a hybrid method, American Association for Artificial Intelligence, pp. 137-143, 2006."}, {"ref": "[16] C.H. Ding, T. Li, M.I. Jordan, \"Convex and semi-nonnegative matrix factorizations\", IEEE transactions on pattern analysis and machine intelligence, vol. 32, no. 1, pp. 45-55, 2010.International Conference on Knowledge Discovery and Data Mining. ACM, 2015, pp. 119–128."}, {"ref": "[17] G. Trigeorgis, K. Bousmalis, S. Zafeiriou, B.W. Schuller, \"A Deep Semi-NMF Model for Learning Hidden Representations\", Proceedings of the 31th International conference on Machine learning, pp. 1692-1700, 2014."}, {"ref": "[18] G. Trigeorgis, K. Bousmalis, S. Zafeiriou, B.W. Schuller, \"A Deep Semi-NMF Model for Learning Hidden Representations\", Proceedings of the 31th International conference on Machine learning, pp. 1692-1700, 2014."}, {"ref": "[19] Y.-X. Wang, Y.-J. Zhang, \"Nonnegative matrix factorization: A comprehensive review\", IEEE Transactions on Knowledge and Data Engineering, vol. 25, no. 6, pp. 1336-1353, 2013."}, {"ref": "[20] M. Belkin, P. Niyogi, \"Using manifold stucture for partially labeled classification\", Advances in neural information processing systems, pp. 953-960, 2003."}, {"ref": "[21] M. Belkin, P. Niyogi, V. Sindhwani, \"Manifold regularization: A geometric framework for learning from labeled and unlabeled examples\", Journal of machine learning research, vol. 7, pp. 2399-2434, Nov 2006."}, {"ref": "[22] D. Cai, X. He, J. Han, T.S. Huang, \"Graph regularized nonnegative matrix factorization for data representation\", IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 33, no. 8, pp. 1548-1560, 2011."}, {"ref": "[23] X. Yang, X. Bai, L. Latecki, Z. Tu, \"Improving shape retrieval by learning graph transduction\", 10th European Conference on Computer Vision, pp. 788-801, 2008."}, {"ref": "[24] K. Bache, M. Lichman, UCI machine learning repository, I. University of California, School of Information and Computer Sciences, 2013."}, {"ref": "[25] D.M.W. Powers, \"Evaluation: from precision recall and F-measure to ROC informedness markedness and correlation\", International Journal of Machine Learning Technology, vol. 2, no. 1, pp. 37-63, 2011."}]}, {"author": ["Jundong Li", "Harsh Dani", "Xia Hu", "Jiliang Tang", "Yi Chang", "Huan Liu"], "title": "Attributed Network Embedding for Learning in a Dynamic Environment", "journal": "Proceedings of the 2017 ACM on Conference on Information and Knowledge Management", "year": 2017, "DOI": "10.1145/3132847.3132919", "month": 11, "citations(google scholar)": 91, "abstract": "Network embedding leverages the node proximity manifested to learn a low-dimensional node vector representation for each node in the network. The learned embeddings could advance various learning tasks such as node classification, network clustering, and link prediction. Most, if not all, of the existing works, are overwhelmingly performed in the context of plain and static networks. Nonetheless, in reality, network structure often evolves over time with addition/deletion of links and nodes. Also, a vast majority of real-world networks are associated with a rich set of node attributes, and their attribute values are also naturally changing, with the emerging of new content patterns and the fading of old content patterns. These changing characteristics motivate us to seek an effective embedding representation to capture network and attribute evolving patterns, which is of fundamental importance for learning in a dynamic environment. To our best knowledge, we are the first to tackle this problem with the following two challenges: (1) the inherently correlated network and node attributes could be noisy and incomplete, it necessitates a robust consensus representation to capture their individual properties and correlations; (2) the embedding learning needs to be performed in an online fashion to adapt to the changes accordingly. In this paper, we tackle this problem by proposing a novel dynamic attributed network embedding framework - DANE. In particular, DANE first provides an offline method for a consensus embedding and then leverages matrix perturbation theory to maintain the freshness of the end embedding results in an online manner. We perform extensive experiments on both synthetic and real attributed networks to corroborate the effectiveness and efficiency of the proposed framework.", "keywords": ["Dynamic Networks", "Attributed Networks", "Network Embedding"], "reference_count": 56, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Lada A Adamic and Bernardo A Huberman. 2000. Power-Law Distribution of the World Wide Web. Science 287, 5461 (2000), 2115–2115."}, {"ref": "[2] Charu Aggarwal and Karthik Subbian. 2014. Evolutionary Network Analysis: A Survey. Comput. Surveys 47, 1 (2014), 10."}, {"ref": "[3] Charu C Aggarwal and Nan Li. 2011. On Node Classication in Dynamic Contentbased Networks. In SDM. SIAM, 355–366."}, {"ref": "[4] Nicola Barbieri, Francesco Bonchi, and Giuseppe Manco. 2014. Who to Follow and Why: Link Prediction with Explanations. In KDD. ACM, 1266–1275."}, {"ref": "[5] Mikhail Belkin and Partha Niyogi. 2001. Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering. In NIPS. 585–591."}, {"ref": "[6] Smriti Bhagat, Graham Cormode, and S Muthukrishnan. 2011. Node Classication in Social Networks. In Social Network Data Analytics. 115–148."}, {"ref": "[7] Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2015. Grarep: Learning Graph Representations with Global Structural Information. In CIKM. ACM, 891–900."}, {"ref": "[8] Shiyu Chang, Wei Han, Jiliang Tang, Guo-Jun Qi, Charu C Aggarwal, and omas S Huang. 2015. Heterogeneous Network Embedding via Deep Architectures. In KDD. ACM, 119–128."}, {"ref": "[9] Chen Chen and Hanghang Tong. 2015. Fast Eigen-Functions Tracking on Dynamic Graphs. In SDM. SIAM, 559–567. [10] Chen Chen and Hanghang Tong. 2017. On the Eigen-Functions of Dynamic Graphs: Fast Tracking and Aribution Algorithms. Statistical Analysis and Data Mining: e ASA Data Science Journal 10, 2 (2017), 121–135."}, {"ref": "[11] Mo Chen, Qiong Yang, and Xiaoou Tang. 2007. Directed Graph Embedding. In IJCAI. 2707–2712."}, {"ref": "[12] Kewei Cheng, Jundong Li, and Huan Liu. 2017. Unsupervised Feature Selection in Signed Social Networks. In KDD. ACM, 777–786."}, {"ref": "[13] Yun Chi, Xiaodan Song, Dengyong Zhou, Koji Hino, and Belle L Tseng. 2007. Evolutionary Spectral Clustering by Incorporating Temporal Smoothness. In KDD. ACM, 153–162."}, {"ref": "[14] Janez Demsar. 2006. Statistical Comparisons of Classiers over Multiple Data ˇ Sets. JMLR 7 (2006), 1–30."}, {"ref": "[15] Gene H Golub and Charles F Van Loan. 2012. Matrix Computations. Vol. 3."}, {"ref": "[16] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In KDD. ACM, 855–864."}, {"ref": "[17] David R Hardoon, Sandor Szedmak, and John Shawe-Taylor. 2004. Canonical Correlation Analysis: An Overview with Application to Learning Methods. Neural Computation 16, 12 (2004), 2639–2664."}, {"ref": "[18] Yuan He, Cheng Wang, and Changjun Jiang. 2017. Modeling Document Networks with Tree-Averaged Copula Regularization. In WSDM. ACM, 691–699."}, {"ref": "[19] Xiao Huang, Jundong Li, and Xia Hu. 2017. Accelerated Aributed Network Embedding. In SDM. SIAM, 633–641."}, {"ref": "[20] Xiao Huang, Jundong Li, and Xia Hu. 2017. Label Informed Aributed Network Embedding. In WSDM. ACM, 731–739."}, {"ref": "[21] Yann Jacob, Ludovic Denoyer, and Patrick Gallinari. 2014. Learning Latent Representations of Nodes for Classifying in Heterogeneous Social Networks. In WSDM. ACM, 373–382."}, {"ref": "[22] Ling Jian, Jundong Li, and Huan Liu. 2017. Toward Online Node Classication on Streaming Networks. DMKD (2017), 1–27."}, {"ref": "[23] Abhishek Kumar, Piyush Rai, and Hal Daume. 2011. Co-Regularized Multi-view Spectral Clustering. In NIPS. 1413–1421."}, {"ref": "[24] Jundong Li, Harsh Dani, Xia Hu, and Huan Liu. 2017. Radar: Residual Analysis for Anomaly Detection in Aributed Networks. In IJCAI. 2152–2158."}, {"ref": "[25] Jundong Li, Xia Hu, Ling Jian, and Huan Liu. 2016. Toward Time-Evolving Feature Selection on Dynamic Networks. In ICDM. IEEE, 1003–1008."}, {"ref": "[26] Jundong Li, Xia Hu, Jiliang Tang, and Huan Liu. 2015. Unsupervised Streaming Feature Selection in Social Media. In CIKM. ACM, 1041–1050."}, {"ref": "[27] Jundong Li, Xia Hu, Liang Wu, and Huan Liu. 2016. Robust Unsupervised Feature Selection on Networked Data. In SDM. SIAM, 387–395."}, {"ref": "[28] Jundong Li, Liang Wu, Osmar R Za¨ıane, and Huan Liu. 2017. Toward Personalized Relational Learning. In SDM. SIAM, 444–452."}, {"ref": "[29] David Liben-Nowell and Jon Kleinberg. 2007. e Link-Prediction Problem for Social Networks. JASIST 58, 7 (2007), 1019–1031."}, {"ref": "[30] Peter V Marsden and Noah E Friedkin. 1993. Network Studies of Social Inuence. Sociological Methods & Research 22, 1 (1993), 127–151. [31] Miller McPherson, Lynn Smith-Lovin, and James M Cook. 2001. Birds of A Feather: Homophily in Social Networks. Annual Review of Sociology (2001), 415–444."}, {"ref": "[32] Huazhong Ning, Wei Xu, Yun Chi, Yihong Gong, and omas S Huang. 2007. Incremental Spectral Clustering With Application to Monitoring of Evolving Blog Communities. In SDM. SIAM, 261–272."}, {"ref": "[33] Beresford N Parle. 1980. e Symmetric Eigenvalue Problem. Vol. 7."}, {"ref": "[34] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of Social Representations. In KDD. ACM, 701–710."}, {"ref": "[35] Joseph J Pfeier III, Sebastian Moreno, Timothy La Fond, Jennifer Neville, and Brian Gallagher. 2014. Aributed Graph Models: Modeling Network Structure with Correlated Aributes. In WWW. ACM, 831–842."}, {"ref": "[36] Meng , Jian Tang, Jingbo Shang, Xiang Ren, Min Zhang, and Jiawei Han. 2017. An Aention-based Collaboration Framework for Multi-View Network Representation Learning. In CIKM. ACM."}, {"ref": "[37] Sam T Roweis and Lawrence K Saul. 2000. Nonlinear Dimensionality Reduction by Locally Linear Embedding. Science (2000)."}, {"ref": "[38] Cosma Rohilla Shalizi and Andrew C omas. 2011. Homophily and Contagion areGenericallyConfoundedinObservationalSocialNetworkStudies. Sociological Methods & Research 40, 2 (2011), 211–239."}, {"ref": "[39] Gilbert W Stewart. 1990. Matrix Perturbation eory. (1990)."}, {"ref": "[40] Jiliang Tang and Huan Liu. 2012. Unsupervised Feature Selection for Linked Social Media Data. In KDD. ACM, 904–912."}, {"ref": "[41] Jian Tang, Meng , Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-Scale Information Network Embedding. In WWW. ACM, 1067–1077."}, {"ref": "[42] Lei Tang, Huan Liu, Jianping Zhang, and Zohreh Nazeri. 2008. Community Evolution in Dynamic Multi-Mode Networks. In KDD. ACM, 677–685."}, {"ref": "[43] Joshua B Tenenbaum, Vin De Silva, and John C Langford. 2000. A Global Geometric Framework for Nonlinear Dimensionality Reduction. Science 290, 5500 (2000), 2319–2323. [44] Hanghang Tong, Spiros Papadimitriou, Jimeng Sun, Philip S Yu, and Christos Faloutsos. 2008. Colibri: Fast Mining of Large Static and Dynamic Graphs. In KDD. ACM, 686–694."}, {"ref": "[45] Ulrike Von Luxburg. 2007. A Tutorial on Spectral Clustering. Statistics and Computing 17, 4 (2007), 395–416."}, {"ref": "[46] Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural Deep Network Embedding. In KDD. ACM, 1225–1234."}, {"ref": "[47] Dashun Wang, Dino Pedreschi, Chaoming Song, Fosca Giannoi, and AlbertLaszlo Barabasi. 2011. Human Mobility, Social Ties, and Link Prediction. In KDD. ACM, 1100–1108."}, {"ref": "[48] Xin Wang, Roger Donaldson, Christopher Nell, Peter Gorniak, Martin Ester, and Jiajun Bu. 2016. Recommending Groups to Users Using User-Group Engagement and Time-Dependent Matrix Factorization.. In AAAI. 1331–1337."}, {"ref": "[49] Chang Xu, Dacheng Tao, and Chao Xu. 2013. A Survey on Multi-View Learning. arXiv preprint arXiv:1304.5634 (2013)."}, {"ref": "[50] Cheng Yang, Zhiyuan Liu, Deli Zhao, Maosong Sun, and Edward Y Chang. 2015. Network Representation Learning with Rich Text Information. In IJCAI. 2111– 2117. [51] Tianbao Yang, Rong Jin, Yun Chi, and Shenghuo Zhu. 2009. Combining Link and Content for Community Detection: A Discriminative Approach. In KDD. ACM, 927–936. [52] Zhilin Yang, William Cohen, and Ruslan Salakhudinov. 2016. Revisiting SemiSupervised Learning with Graph Embeddings. In ICML. 40–48."}, {"ref": "[53] Chao Zhang, Keyang Zhang, an Yuan, Fangbo Tao, Luming Zhang, Tim Hanray, and Jiawei Han. 2017. ReAct: Online Multimodal Embedding for Recency-Aware Spatiotemporal Activity Modeling. In SIGIR. ACM, 245–254."}, {"ref": "[54] Daokun Zhang, Jie Yin, Xingquan Zhu, and Chengqi Zhang. 2016. Collective Classication via Discriminative Matrix Factorization on Sparsely Labeled Networks. In CIKM. ACM, 1563–1572."}, {"ref": "[55] Dawei Zhou, Kangyang Wang, Nan Cao, and Jingrui He. 2015. Rare Category Detection on Time-Evolving Graphs. In ICDM. IEEE, 1135–1140."}, {"ref": "[56] Shenghuo Zhu, Kai Yu, Yun Chi, and Yihong Gong. 2007. Combining Content and Link for Classication Using Matrix Factorization. In SIGIR. ACM, 487–494."}]}, {"author": ["Xiao Wang", "Peng Cui", "Jing Wang", "Jian Pei", "Wenwu Zhu", "Shiqiang Yang"], "title": "Community Preserving Network Embedding", "journal": "The 31st AAAI Conference on Artificial Intelligence. 2017.", "year": 2017, "DOI": "", "month": 2, "citations(google scholar)": 240, "abstract": "Network embedding, aiming to learn the low-dimensional representations of nodes in networks, is of paramount importance in many real applications. One basic requirement of network embedding is to preserve the structure and inherent properties of the networks. While previous network embedding methods primarily preserve the microscopic structure, such as the first- and second-order proximities of nodes, the mesoscopic community structure, which is one of the most prominent feature of networks, is largely ignored. In this paper, we propose a novel Modularized Nonnegative Matrix Factorization (M-NMF) model to incorporate the community structure into network embedding. We exploit the consensus relationship between the representations of nodes and community structure, and then jointly optimize NMF based representation learning model and modularity based community detection model in a unified framework, which enables the learned representations of nodes to preserve both of the microscopic and community structures. We also provide efficient updating rules to infer the parameters of our model, together with the correctness and convergence guarantees. Extensive experimental results on a variety of real-world networks show the superior performance of the proposed method over the state-of-the-arts.", "keywords": ["Network embedding", "community structure", "nonnegative matrix factorization"], "reference_count": 29, "ccfClass": "B", "important": true, "references": [{"ref": "[1]Adamic, L. A., and Glance, N. 2005. The political blogosphere and the 2004 us election: divided they blog. In Proceedings of the 3rd international workshop on Link discovery, 36–43. ACM."}, {"ref": "[2]Akata, Z.; Thurau, C.; and Bauckhage, C. 2011. Nonnegative matrix factorization in multimodality data for segmentation and label prediction. In 16th Computer vision winter workshop."}, {"ref": "[3]Bhagat, S.; Cormode, G.; and Muthukrishnan, S. 2011. Node classification in social networks. In Social network data analytics. Springer. 115–148."}, {"ref": "[4]Cai, D.; He, X.; Han, J.; and Huang, T. S. 2011. Graph regularized nonnegative matrix factorization for data representation. IEEE Transactions on Pattern Analysis and Machine Intelligence 33(8):1548–1560."}, {"ref": "[5]Cao, S.; Lu, W.; and Xu, Q. 2015. Grarep: Learning graph representations with global structural information. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, 891–900. ACM."}, {"ref": "[6]Fan, R.-E.; Chang, K.-W.; Hsieh, C.-J.; Wang, X.-R.; and Lin, C.-J. 2008. Liblinear: A library for large linear classification. Journal of machine learning research 9(Aug):1871– 1874. Fortunato,"}, {"ref": "[7]S., and Hric, D. 2016. Community detection in networks: A user guide. arXiv preprint arXiv:1608.00163."}, {"ref": "[8]Girvan, M., and Newman, M. E. 2002. Community structure in social and biological networks. Proceedings of the national academy of sciences 99(12):7821–7826."}, {"ref": "[9]Gopalan, P. K., and Blei, D. M. 2013. Efficient discovery of overlapping communities in massive networks. Proceedings of the National Academy of Sciences 110(36):14534–14539."}, {"ref": "[10]Grover, A., and Leskovec, J. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, 1225–1234. ACM."}, {"ref": "[11]Jin, D.; Wang, H.; Dang, J.; He, D.; and Zhang, W. 2016. Detect overlapping communities via ranking node popularities. In Thirtieth AAAI Conference on Artificial Intelligence."}, {"ref": "[12]Karrer, B., and Newman, M. E. 2011. Stochastic blockmodels and community structure in networks. Physical Review E 83(1):016107."}, {"ref": "[13]Lancichinetti, A.; Fortunato, S.; and Kertesz, J. 2009. De- ´ tecting the overlapping and hierarchical community structure in complex networks. New Journal of Physics 11(3):033015."}, {"ref": "[14]Lee, D. D., and Seung, H. S. 2001. Algorithms for nonnegative matrix factorization. In Advances in neural information processing systems, 556–562."}, {"ref": "[15]Mikolov, T.; Chen, K.; Corrado, G.; and Dean, J. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781."}, {"ref": "[16]Newman, M. E. 2006a. Finding community structure in networks using the eigenvectors of matrices. Physical review E 74(3):036104."}, {"ref": "[17]Newman, M. E. 2006b. Modularity and community structure in networks. Proceedings of the national academy of sciences 103(23):8577–8582."}, {"ref": "[18]Ou, M.; Cui, P.; Pei, J.; Zhang, Z.; and Zhu, W. 2016. Asymmetric transitivity preserving graph embedding. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, 672–681. ACM."}, {"ref": "[19]Perozzi, B.; Al-Rfou, R.; and Skiena, S. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, 701–710. ACM."}, {"ref": "[20]Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, Q. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web, 1067–1077. ACM."}, {"ref": "[21]Tenenbaum, J. B.; De Silva, V.; and Langford, J. C. 2000. A global geometric framework for nonlinear dimensionality reduction. science 290(5500):2319–2323."}, {"ref": "[22]Traud, A. L.; Mucha, P. J.; and Porter, M. A. 2012. Social structure of facebook networks. Physica A: Statistical Mechanics and its Applications 391(16):4165–4180."}, {"ref": "[23]Tu, C.; Zhang, W.; Liu, Z.; and Sun, M. 2016. Max-margin deepwalk: Discriminative learning of network representation. In Thirtieth AAAI Conference on Artificial Intelligence."}, {"ref": "[24]Wang, F.; Li, T.; Wang, X.; Zhu, S.; and Ding, C. 2011. Community discovery using nonnegative matrix factorization. Data Mining and Knowledge Discovery 22(3):493– 521."}, {"ref": "[25]Wang, X.; Jin, D.; Cao, X.; Yang, L.; and Zhang, W. 2016. Semantic community identification in large attribute networks. In Thirtieth AAAI Conference on Artificial Intelligence."}, {"ref": "[26]Wang, D.; Cui, P.; and Zhu, W. 2016. Structural deep network embedding. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, 1225–1234. ACM."}, {"ref": "[27]Xie, J.; Kelley, S.; and Szymanski, B. K. 2013. Overlapping community detection in networks: The state-of-theart and comparative study. ACM Computing Surveys (csur) 45(4):43."}, {"ref": "[28]Yang, C.; Liu, Z.; Zhao, D.; Sun, M.; and Chang, E. Y. 2015. Network representation learning with rich text information. In Proceedings of the 24th International Joint Conference on Artificial Intelligence, Buenos Aires, Argentina, 2111–2117."}, {"ref": "[29]Yu, X.; Ren, X.; Sun, Y.; Gu, Q.; Sturt, B.; Khandelwal, U.; Norick, B.; and Han, J. 2014. Personalized entity recommendation: A heterogeneous information network approach. In Proceedings of the 7th ACM international conference on Web search and data mining, 283–292. ACM."}]}, {"author": ["Nahla Mohamed Ahmed", "Ling Chen", "Yulong Wang", "Bin Li", "Yun Li", "Wei Liu"], "title": "DEEPEYE: Link Prediction in Dynamic Networks Based on Non-negative Matrix Factorization", "journal": "Big data minging and analytics", "year": 2018, "DOI": "10.26599/bdma.2017.9020002", "month": 3, "citations(google scholar)": 6, "abstract": "A Non-negative Matrix Factorization (NMF)-based method is proposed to solve the link prediction problem in dynamic graphs. The method learns latent features from the temporal and topological structure of a dynamic network and can obtain higher prediction results. We present novel iterative rules to construct matrix factors that carry important network features and prove the convergence and correctness of these algorithms. Finally, we demonstrate how latent NMF features can express network dynamics efficiently rather than by static representation, thereby yielding better performance. The amalgamation of time and structural information makes the method achieve prediction results that are more accurate. Empirical results on real-world networks show that the proposed algorithm can achieve higher accuracy prediction results in dynamic networks in comparison to other algorithms.", "keywords": ["dynamic network", "link prediction", "matrix factorization"], "reference_count": 49, "ccfClass": "", "important": true, "references": [{"ref": "[1] N. M. Ahmed and L. Chen, An efficient algorithm for link prediction in temporal uncertain social networks, Inf. Sci., vol. 331, pp. 120–136, 2016."}, {"ref": "[2] F. Buccafurri, L. Fotia, G. Lax, and V. Saraswat, Analysispreserving protection of user privacy against information leakage of social-network Likes, Inf. Sci., vol. 328, pp. 340–358, 2016."}, {"ref": "[3] M. Jankowski-Lorek, S. Jaroszewicz, Ł Ostrowski, and A. Wierzbicki, Verifying social network models of Wikipedia knowledge community, Inf. Sci., vol. 339, pp. 158–174, 2016."}, {"ref": "[4] K. Saito, M. Kimura, K. Ohara, and H. Motoda, Super mediator—A new centrality measure of node importance for information diffusion over social network, Inf. Sci., vol. 329, pp. 985–1000, 2016."}, {"ref": "[5] M. H. Bhuyan, D. K. Bhattacharyya, and J. K. Kalita, A multi-step outlier-based anomaly detection approach to network-wide traffic, Inf. Sci., vol. 348, pp. 243–271, 2016."}, {"ref": "[6] H. Liao, A. Zeng, and Y. C. Zhang, Predicting missing links via correlation between nodes, Physica A Stat. Mech. Appl., vol. 436, pp. 216–223, 2015."}, {"ref": "[7] P. Wang, B. W. Xu, Y. R. Wu, and X. Y. Zhou, Link prediction in social networks: The state-of-the-art, Sci. China Inf. Sci., vol. 58, no. 1, pp. 1–38, 2015.dvances in neural information processing systems, 556–562."}, {"ref": "[8] X. M. Wang, Y. Liu, and F. Xiong, Improved personalized recommendation based on a similarity network, Physica A Stat. Mech. Appl., vol. 456, pp. 271–280, 2016."}, {"ref": "[9] B. Kaya and M. Poyraz, Age-series based link prediction in evolving disease networks, Comput. Biol. Med., vol. 63, pp. 1–10, 2015."}, {"ref": "[10] R. Guimera, M. Sales-Pardo, and H. E. Stanley, Missing and spurious interactions and the reconstruction of complex networks, Proc. Natl. Acad. Sci. USA, vol. 106, no. 52, pp. 22073–22078, 2009."}, {"ref": "[11] A. Nigam and N. V. Chawla, Link prediction in a semi-bipartite network for recommendation, in Intelligent Information and Database Systems, N. T. Nguyen, B. Trawi ki, H. Fujita, and T. P. Hong, eds. Springer, 2016, pp. 127–135."}, {"ref": "[12] F. Xie, Z. Chen, J. X. Shang, X. P. Feng, and J. Li, A link prediction approach for item recommendation with complex number, Knowl-Based Syst., vol. 81, pp. 148–158, 2015."}, {"ref": "[13] Z. Sun, Q. K. Peng, J. Lv, and J. Zhang, A prediction model of post subjects based on information lifecycle in forum, Inf. Sci., vols. 337&338, pp. 59–71, 2016."}, {"ref": "[14] P. Klimek, A. S. Jovanovic, R. Egloff, and R. Schneider, Successful fish go with the flow: Citation impact prediction based on centrality measures for term–document networks, Scientometrics, vol. 107, no. 3, pp. 1265–1282, 2016."}, {"ref": "[15] B. Kaya and M. Poyraz, Unsupervised link prediction in evolving abnormal medical parameter networks, Int.J . Mach. Learn. Cybern., vol. 7, no. 1, pp. 145–155, 2016."}, {"ref": "[16] M. Q. Ge, A. Li, and M. H. Wang, A bipartite networkbased method for prediction of long non-coding RNA– protein interactions, Genomics Proteomics Bioinformatics, vol. 14, no. 1, pp. 62–71, 2016."}, {"ref": "[17] F. Buccafurri, G. Lax, A. Nocera, and D. Ursino, Discovering missing me edges across social networks, Inf. Sci., vol. 319, pp. 18–37, 2015."}, {"ref": "[18] J. Fournet and A. Barrat, Contact patterns among high school students, PLoS One, vol. 9, no. 9, p. 107878, 2014."}, {"ref": "[19] N. M. A. Ibrahim and L. Chen, Link prediction in dynamic social networks by integrating different types of information, Appl. Intell., vol. 42, no. 4, pp. 738–750, 2015."}, {"ref": "[20] A. Papadimitriou, P. Symeonidis, and Y. Manolopoulos, Fast and accurate link prediction in social networking systems, J . Syst. Softw., vol. 85, no. 9, pp. 2119–2132, 2012."}, {"ref": "[21] Y. Z. Sun, R. Barber, M. Gupta, C. C. Aggarwal, and J. W. Han, Co-author relationship prediction in heterogeneous bibliographic networks, in Proc. 2011 Int. Conf. Advances in Social Networks Analysis and Mining (ASONAM 2011), Kaohsiung, China, 2011, pp. 121–128."}, {"ref": "[22] J. Li, L. L. Zhang, F. Meng, and F. H. Li, Recommendation algorithm based on link prediction and domain knowledge in retail transactions, Procedia Comput. Sci., vol. 31, pp. 875–881, 2014."}, {"ref": "[23] X. Li and H. Chen, Recommendation as link prediction in bipartite graphs: A graph kernel-based machine learning approach, Decis. Supp. Syst., vol. 54, no. 2, pp. 880–890, 2013."}, {"ref": "[24] A. Vidmer, A. Zeng, M. Medo, and Y. C. Zhang, Prediction in complex systems: The case of the international trade network, Physica A Stat. Mech. Appl., vol. 436, pp. 188– 199, 2015."}, {"ref": "[25] B. Kaya and M. Poyraz, Supervised link prediction in symptom networks with evolving case, Measurement, vol. 56, pp. 231–238, 2014."}, {"ref": "[26] X. Ma, J. L. Liao, S. M. Djouadi, and Q. Cao, LIPS: Link prediction as a service for data aggregation applications, Ad Hoc Networks, vol. 19, pp. 43–58, 2014."}, {"ref": "[27] L. M. Aiello, A. Barrat, R. Schifanella, C. Cattuto, B. Markines, and F. Menczer, Friendship prediction and homophily in social media, ACM Trans. Web (TWEB), vol. 6, no. 2, p. 9, 2012."}, {"ref": "[28] M. W. Ahn and W. S. Jung, Accuracy test for link prediction in terms of similarity index: The case of WS and BA models, Phys. A Stat. Mech. Appl., vol. 429, pp. 177–183, 2015."}, {"ref": "[29] M. Hoffman, D. Steinley, and M. J. Brusco, A note on using the adjusted rand index for link prediction in networks, Soc. Networks, vol. 42, pp. 72–79, 2015."}, {"ref": "[30] L. Y. Lu and T. Zhou, Link prediction in complex networks: ¨ A survey, Phys. A Stat. Mech. Appl., vol. 390, no. 6, pp. 1150–1170, 2011."}, {"ref": "[31] X. J. Wang, X. Zhang, C. L. Zhao, Z. Xie, S. J. Zhang, and D. Y. Yi, Predicting link directions using local directed path, Phys. A Stat. Mech. Appl., vol. 419, pp. 260–267, 2015."}, {"ref": "[32] A. Das Sarma, A. R. Molla, and G. Pandurangan, Distributed computation in dynamic networks via random walks, Theor. Comput. Sci., vol. 581, pp. 45–66, 2015."}, {"ref": "[33] W. P. Liu and L. Y. Lu, Link prediction based on local ¨ random walk, Europhys Lett, vol. 89, no. 5, p. 58007, 2010."}, {"ref": "[34] F. Y. Hu and H. S. Wong, Labeling of human motion based on cbga and probabilistic model, Int.J . Smart Sens. Intell. Syst., vol. 6, no. 2, pp. 583–609, 2013."}, {"ref": "[35] N. Barbieri, F. Bonchi, and G. Manco, Who to follow and why: Link prediction with explanations, in Proc. 20th ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining, New York, NY, USA, 2014, pp. 1266–1275."}, {"ref": "[36] S. Gao, L. Denoyer, and P. Gallinari, Temporal link prediction by integrating content and structure information, in Proc. 20th ACM Int. Conf. Information and Knowledge Management, 2011, pp. 1169–1174."}, {"ref": "[37] Z. Z. Zeng, K. J. Chen, S. B. Zhang, and H. J. Zhang, A link prediction approach using semi-supervised learning in dynamic networks, in Proc. Sixth Int. Conf. Advanced Computational Intelligence (ICACI), Hangzhou, China, 2013, pp. 276–280."}, {"ref": "[38] M. Pujari and R. Kanawati, Supervised rank aggregation approach for link prediction in complex networks, in Proc. 21st Int. Conf. World Wide Web, Lyon, France, 2012, pp. 1189–1196."}, {"ref": "[39] Z. F. Bao, Y. Zeng, and Y. C. Tay, sonLP: Social network link prediction by principal component regression, in Proc. 2013 IEEE/ACM Int. Conf. Advances in Social Networks Analysis and Mining, Niagara Falls, Canada, 2013, pp. 364–371."}, {"ref": "[40] Y. L. He, J. N. K. Liu, Y. X. Hu, and X. Z. Wang, OWA operator based link prediction ensemble for social network, Expert Syst. Appl., vol. 42, no. 1, pp. 21–50, 2015."}, {"ref": "[41] C. A. Bliss, M. R. Frank, C. M. Danforth, and P. S. Dodds, An evolutionary algorithm approach to link prediction in dynamic social networks, J . Comput. Sci., vol. 5, no. 5, pp. 750–764, 2014."}, {"ref": "[42] E. Sherkat, M. Rahgozar, and M. Asadpour, Structural link prediction based on ant colony approach in social networks, Phys. A Stat. Mech. Appl., vol. 419, pp. 80–94, 2015"}, {"ref": "[43] B. L. Chen, L. Chen, and B. Li, A fast algorithm for predicting links to nodes of interest, Inf. Sci., vol. 329, pp. 552–567, 2016."}, {"ref": "[44] J. Y. Ding, L. C. Jiao, J. S. Wu, Y. T. Hou, and Y. T. Qi, Prediction of missing links based on multi-resolution community division, Phys. A Stat. Mech. Appl., vol. 417, pp. 76–85, 2015."}, {"ref": "[45] D. Q. Vu, A. U. Asuncion, D. R. Hunter, and P. Smyth, Continuous-time regression models for longitudinal networks, in Advances in Neural Information Processing Systems 24, Proc. 25th Annual Conf. Neural Information Processing Systems, 2011, pp. 1–9."}, {"ref": "[46] http://www.cs.cmu.edu/\u0018enron/, 2017."}, {"ref": "[47] http://konect.uni-koblenz.de/networks/enron, 2017."}, {"ref": "[48] http://nodobo.com/release.html, 2017."}, {"ref": "[49] SocioPatterns. DATASET: INFECTIOUS SocioPatterns dynamic contact networks, http://www.sociopatterns.org/ datasets/infectious-sociopatterns-dynamic-contactnetworks, 2011"}]}, {"author": ["Chen Chen", "Hanghang Tong"], "title": "Fast Eigen-Functions Tracking on Dynamic Graphs", "journal": "Proceedings of the 2015 SIAM International Conference on Data Mining", "year": 2015, "DOI": "10.1137/1.9781611974010.63", "month": 5, "citations(google scholar)": 16, "abstract": "Many important graph parameters can be expressed as eigenfunctions of its adjacency matrix. Examples include epidemic threshold, graph robustness, etc. It is often of key importance to accurately monitor these parameters. For example, knowing that Ebola virus has already been brought to the US continent, to avoid the virus from spreading away, it is important to know which emerging connections among related people would cause great reduction on the epidemic threshold of the network. However, most, if not all, of the existing algorithms computing these measures assume that the input graph is static, despite the fact that almost all real graphs are evolving over time. In this paper, we propose two online algorithms to track the eigen-functions of a dynamic graph with linear complexity wrt the number of nodes and number of changed edges in the graph. The key idea is to leverage matrix perturbation theory to efficiently update the top eigen-pairs of the underlying graph without recomputing them from scratch at each time stamp. Experiment results demonstrate that our methods can reach up to 20× speedup with precision more than 80% for fairly long period of time.", "keywords": ["dynamic graph", "connectivity; graph spectrum", "attribution analysis"], "reference_count": 31, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Charu Aggarwal and Karthik Subbian. Evolutionary network analysis: A survey. ACM Computing Surveys (CSUR), 47(1):10, 2014."}, {"ref": "[2] Reka Albert, Hawoong Jeong, and Albert-Laszlo Barabasi. Error and attack tolerance of complex networks. Nature, 406(6794):378–382, 2000."}, {"ref": "[3] Andrew Barron, Jorma Rissanen, and Bin Yu. The minimum description length principle in coding and modeling. Information Theory, IEEE Transactions on, 44(6):2743–2760, 1998."}, {"ref": "[4] Deepayan Chakrabarti, Yang Wang, Chenxi Wang, Jurij Leskovec, and Christos Faloutsos. Epidemic thresholds in real networks. ACM Transactions on Information and System Security (TISSEC), 10(4):1, 2008."}, {"ref": "[5] Hau Chan, Leman Akoglu, and Hanghang Tong. Make it or break it: Manipulating robustness in large networks. [6] Fan RK Chung. Spectral graph theory, volume 92. American Mathematical Soc., 1997."}, {"ref": "[7] Jure Ferlez, Christos Faloutsos, Jure Leskovec, Dunja Mladenic, and Marko Grobelnik. Monitoring network evolution using mdl. In Data Engineering, 2008. ICDE 2008. IEEE 24th International Conference on, pages 1328–1330. IEEE, 2008."}, {"ref": "[8] H. Frank and I. Frisch. Analysis and Design of Survivable Networks. Communication Technology, IEEE Transactions on, 18(5):501–519, October 1970."}, {"ref": "[9] Ayalvadi Ganesh, Laurent Massoulie, and Don Towsley. The ´ effect of network topology on the spread of epidemics. In INFOCOM 2005. 24th Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings IEEE, volume 2, pages 1455–1466. IEEE, 2005."}, {"ref": "[10] Frank Harary and Allen Schwenk. The spectral approach to determining the number of walks in a graph. Pacific Journal of Mathematics, 80(2):443–449, 1979."}, {"ref": "[11] Tsuyoshi Ide and Hisashi Kashima. Eigenspace-based ´ anomaly detection in computer systems. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 440–449. ACM, 2004."}, {"ref": "[12] Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. Graphs over time: densification laws, shrinking diameters and possible explanations. In Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining, pages 177–187. ACM, 2005."}, {"ref": "[13] Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. Graph evolution: Densification and shrinking diameters. ACM Transactions on Knowledge Discovery from Data (TKDD), 1(1):2, 2007."}, {"ref": "[14] Fragkiskos D Malliaros, Vasileios Megalooikonomou, and Christos Faloutsos. Fast robustness estimation in large social graphs: Communities and anomaly detection. In SDM, volume 12, pages 942–953. SIAM, 2012."}, {"ref": "[15] Mark EJ Newman. The mathematics of networks. [16] Mark EJ Newman. Finding community structure in networks using the eigenvectors of matrices. Physical review E, 74(3):036104, 2006."}, {"ref": "[17] Mark EJ Newman. Modularity and community structure in networks. Proceedings of the National Academy of Sciences, 103(23):8577–8582, 2006."}, {"ref": "[18] Huazhong Ning, Wei Xu, Yun Chi, Yihong Gong, and Thomas S Huang. Incremental spectral clustering by efficiently updating the eigen-system. Pattern Recognition, 43(1):113–127, 2010."}, {"ref": "[19] University of Oregon Route View Project. Online data and reports. http://www.routeviews.org."}, {"ref": "[20] B Aditya Prakash, Deepayan Chakrabarti, Nicholas C Valler, Michalis Faloutsos, and Christos Faloutsos. Threshold conditions for arbitrary cascade models on arbitrary networks. Knowledge and information systems, 33(3):549–575, 2012."}, {"ref": "[21] B. Aditya Prakash, Ashwin Sridharan, Mukund Seshadri, Sridhar Machiraju, and Christos Faloutsos. Eigenspokes: Surprising patterns and scalable community chipping in large graphs. In Advances in Knowledge Discovery and Data Mining, 14th Pacific-Asia Conference, PAKDD 2010, Hyderabad, India, June 21-24, 2010. Proceedings. Part II, pages 435–448, 2010."}, {"ref": "[22] G. W. Stewart and Ji-Guang Sun. Matrix Perturbation Theory. Academic Press, 1990."}, {"ref": "[23] Hanghang Tong, Spiros Papadimitriou, Philip S Yu, and Christos Faloutsos. Fast monitoring proximity and centrality on time-evolving bipartite graphs. Statistical Analysis and Data Mining, 1(3):142–156, 2008."}, {"ref": "[24] Hanghang Tong, B Aditya Prakash, Tina Eliassi-Rad, Michalis Faloutsos, and Christos Faloutsos. Gelling, and melting, large graphs by edge manipulation. In Proceedings of the 21st ACM international conference on Information and knowledge management, pages 245–254. ACM, 2012."}, {"ref": "[25] Hanghang Tong, B Aditya Prakash, Charalampos Tsourakakis, Tina Eliassi-Rad, Christos Faloutsos, and Duen Horng Chau. On the vulnerability of large graphs. In Data Mining (ICDM), 2010 IEEE 10th International Conference on, pages 1091–1096. IEEE, 2010."}, {"ref": "[26] Charalampos E Tsourakakis. Fast counting of triangles in large real networks without counting: Algorithms and laws. In Data Mining, 2008. ICDM’08. Eighth IEEE International Conference on, pages 608–617. IEEE, 2008."}, {"ref": "[27] Charalampos E Tsourakakis. Counting triangles in real-world networks using projections. Knowledge and Information Systems, 26(3):501–520, 2011."}, {"ref": "[28] Yang Wang, Deepayan Chakrabarti, Chenxi Wang, and Christos Faloutsos. Epidemic spreading in real networks: An eigenvalue viewpoint. In Reliable Distributed Systems, 2003. Proceedings. 22nd International Symposium on, pages 25–34. IEEE, 2003."}, {"ref": "[29] Stanley Wasserman. Social network analysis: Methods and applications, volume 8. Cambridge university press, 1994."}, {"ref": "[30] V Vassilevska Williams. Breaking the coppersmith-winograd barrier."}, {"ref": "[31] Jun Wu, Barahona Mauricio, Yue-Jin Tan, and Hong-Zhong Deng. Natural connectivity of complex networks. Chinese Physics Letters, 27(7):78902, 2010."}]}, {"author": ["Dingyuan Zhu", "Peng Cui", "Ziwei Zhang", "Jian Pei", "Wenwu Zhu"], "title": "High-Order Proximity Preserved Embedding for Dynamic Networks", "journal": "IEEE Transactions on Knowledge and Data Engineering", "year": 2018, "DOI": "10.1109/TKDE.2018.2822283", "month": 4, "citations(google scholar)": 19, "abstract": "Network embedding, aiming to embed a network into a low dimensional vector space while preserving the inherent structural properties of the network, has attracted considerable attention. However, most existing embedding methods focus on the static network while neglecting the evolving characteristic of real-world networks. Meanwhile, most of previous methods cannot well preserve the high-order proximity, which is a critical structural property of networks. These problems motivate us to seek an effective and efficient way to preserve the high-order proximity in embedding vectors when the networks evolve over time. In this paper, we propose a novel method of Dynamic High-order Proximity preserved Embedding (DHPE). Specifically, we adopt the generalized SVD (GSVD) to preserve the high-order proximity. Then, by transforming the GSVD problem to a generalized eigenvalue problem, we propose a generalized eigen perturbation to incrementally update the results of GSVD to incorporate the changes of dynamic networks. Further, we propose an accelerated solution to the DHPE model so that it achieves a linear time complexity with respect to the number of nodes and number of changed edges in the network. Our empirical experiments on one synthetic network and several real-world networks demonstrate the effectiveness and efficiency of the proposed method.", "keywords": ["Dynamic Network，High-order Proximity，Network Embedding"], "reference_count": 37, "ccfClass": "A", "important": true, "references": [{"ref": "[1] D. Wang, P. Cui, and W. Zhu, \"Structural deep network embedding,\" in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2016, pp. 1225–1234."}, {"ref": "[2] J. Chen, Q. Zhang, and X. Huang, \"Incorporate group information to enhance network embedding,\" in Proc. 25th ACM Int. Conf. Inf. Knowl. Manage., 2016, pp. 1901–1904."}, {"ref": "[3] Z. Yang, W. W. Cohen, and R. Salakhutdinov, \"Revisiting semisupervised learning with graph embeddings,\" arXiv:1603.08861, 2016."}, {"ref": "[4] Z. Huang and N. Mamoulis, \"Heterogeneous information network embedding for meta path based proximity,\" arXiv:1701.05291, 2017."}, {"ref": "[5] S. Chen, S. Niu, L. Akoglu, J. Kova\u0002 cevi\u0003 c, and C. Faloutsos, \"Fast, warped graph embedding: Unifying framework and one-click algorithm,\" arXiv:1702.05764, 2017."}, {"ref": "[6] X. Wang, P. Cui, J. Wang, J. Pei, W. Zhu, and S. Yang, \"Community preserving network embedding,\" in Proc. 31st AAAI Conf. Artif. Intell., 2017, 203–209."}, {"ref": "[7] F. Nie, W. Zhu, and X. Li, \"Unsupervised large graph embedding,\" in Proc. 31st AAAI Conf. Artif. Intell., 2017, pp. 2422–2428."}, {"ref": "[8] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei, \"Line: Large-scale information network embedding,\" in Proc. 24th Int. Conf. World Wide Web, 2015, pp. 1067–1077."}, {"ref": "[9] B. Perozzi, R. Al-Rfou, and S. Skiena, \"Deepwalk: Online learning of social representations,\" in Proc. 20th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2014, pp. 701–710."}, {"ref": "[10] M. Ou, P. Cui, J. Pei, Z. Zhang, and W. Zhu, \"Asymmetric transitivity preserving graph embedding,\" in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2016, pp. 1105–1114."}, {"ref": "[11] L. Katz, \"A new status index derived from sociometric analysis,\" Psychometrika, vol. 18, no. 1, pp. 39–43, 1953."}, {"ref": "[12] S. T. Roweis and L. K. Saul, \"Nonlinear dimensionality reduction by locally linear embedding,\" Sci., vol. 290, no. 5500, pp. 2323– 2326, 2000."}, {"ref": "[13] J. B. Tenenbaum, V. De Silva, and J. C. Langford, \"A global geometric framework for nonlinear dimensionality reduction,\" Sci., vol. 290, no. 5500, pp. 2319–2323, 2000."}, {"ref": "[14] M. Belkin and P. Niyogi, \"Laplacian eigenmaps and spectral techniques for embedding and clustering,\" in Proc. 14th Int. Conf. Neural Inf. Process. Syst., 2001, pp. 585–591."}, {"ref": "[15] S. Yan, D. Xu, B. Zhang, H.-J. Zhang, Q. Yang, and S. Lin, \"Graph embedding and extensions: A general framework for dimensionality reduction,\" IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 1, pp. 40–51, Jan. 2007."}, {"ref": "[16] P. D. Hoff, A. E. Raftery, and M. S. Handcock, \"Latent space approaches to social network analysis,\" J. Amer. Statistical Assoc., vol. 97, no. 460, pp. 1090–1098, 2002."}, {"ref": "[17] P. D. Hoff, \"Multiplicative latent factor models for description and prediction of social networks,\" Comput. Math. Org. Theory, vol. 15, no. 4, pp. 261–272, 2009."}, {"ref": "[18] M. S. Handcock, A. E. Raftery, and J. M. Tantrum, \"Model-based clustering for social networks,\" J. Roy. Statistical Soc.: Series A (Statist. Soc.), vol. 170, no. 2, pp. 301–354, 2007."}, {"ref": "[19] S. Zhu, K. Yu, Y. Chi, and Y. Gong, \"Combining content and link for classification using matrix factorization,\" in Proc. 30th Annu. Int. ACM SIGIR Conf. Res. Develop. Inf. Retrieval, 2007, pp. 487–494."}, {"ref": "[20] A. Grover and J. Leskovec, \"node2vec: Scalable feature learning for networks,\" in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2016, pp. 855–864."}, {"ref": "[21] S. Cao, W. Lu, and Q. Xu, \"GraRep: Learning graph representations with global structural information,\" in Proc. 24th ACM Int. Conf. Inf. Knowl. Manage., 2015, pp. 891–900."}, {"ref": "[22] K. Tu, P. Cui, X. Wang, F. Wang, and W. Zhu, \"Structural deep embedding for hyper-networks,\" arXiv:1711.10146, 2017."}, {"ref": "[23] Y. Chen and C. Wang, \"HINE: Heterogeneous information network embedding,\" in Proc. Int. Conf. Database Syst. Adv. Appl., 2017, pp. 180–195."}, {"ref": "[24] X. Sun, J. Guo, X. Ding, and T. Liu, \"A general framework for content-enhanced network representation learning,\" arXiv:1610.02906, 2016."}, {"ref": "[25] P. Cui, X. Wang, J. Pei, and W. Zhu, \"A survey on network embedding,\" arXiv:1711.08752, 2017."}, {"ref": "[26] Z. Zhang, P. Cui, J. Pei, X. Wang, and W. Zhu, \"Timers: Errorbounded SVD restart on dynamic networks,\" arXiv:1711.09541, 2017."}, {"ref": "[27] C. Chen and H. Tong, \"Fast eigen-functions tracking on dynamic graphs,\" in Proc. SIAM Int. Conf. Data Mining, 2015, pp. 559–567."}, {"ref": "[28] C. C. Paige and M. A. Saunders, \"Towards a generalized singular value decomposition,\" SIAM J. Numerical Anal., vol. 18, no. 3, pp. 398–405, 1981."}, {"ref": "[29] G. Strang, G. Strang, G. Strang, and G. Strang, Introduction to Linear Algebra. Wellesley, MA, USA: Wellesley-Cambridge Press, 1993."}, {"ref": "[30] G. H. Golub and C. F. Van Loan, Matrix Computations. Baltimore, MD, USA: JHU Press, 2012."}, {"ref": "[31] G. W. Stewart and J.-G. Sun, \"Matrix perturbation theory (computer science and scientific computing),\" 1990."}, {"ref": "[32] Z. Reza and L. Huan, \"Social computing data repository,\" 2009."}, {"ref": "[33] J. Leskovec, J. Kleinberg, and C. Faloutsos, \"Graphs over time: Densification laws, shrinking diameters and possible explanations,\" in Proc. 11th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2005, pp. 177–187."}, {"ref": "[34] L. Tang and H. Liu, \"Relational learning via latent social dimensions,\" in Proc. 15th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2009, pp. 817–826."}, {"ref": "[35] L. Tang and H. Liu, \"Scalable learning of collective behavior based on sparse social dimensions,\" in Proc. 18th ACM Conf. Inf. Knowl. Manage., 2009, pp. 1107–1116."}, {"ref": "[36] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin, \"LIBLINEAR: A library for large linear classification,\" J. Mach. Learn. Res., vol. 9, no. Aug, pp. 1871–1874, 2008."}, {"ref": "[37] L. V. D. Maaten and G. Hinton, \"Visualizing data using t-SNE,\" J. Mach. Learn. Res., vol. 9, no. Nov, pp. 2579–2605, 2008."}]}, {"author": ["Peng Liu", "Lemei Zhang", "Jon Atle Gulla"], "title": "Learning Multi-granularity Dynamic Network Representations for Social Recommendation", "journal": "IEEE Transactions on Knowledge and Data Engineering", "year": 2018, "DOI": "10.1007/978-3-030-10928-8_41", "month": 9, "citations(google scholar)": 5, "abstract": "With the rapid proliferation of online social networks, personalized social recommendation has become an important means to help people discover useful information over time. However, the cold-start issue and the special properties of social networks, such as rich temporal dynamics, heterogeneous and complex structures with millions of nodes, render the most commonly used recommendation approaches (e.g. Collaborative Filtering) inefficient. In this paper, we propose a novel multi-granularity dynamic network embedding (m-DNE) model for the social recommendation which is capable of recommending relevant users and interested items. In order to support online recommendation, we construct a heterogeneous user-item (HUI) network and incrementally maintain it as the social network evolves. m-DNE jointly captures the temporal semantic effects, social relationships and user behavior sequential patterns in a unified way by embedding the HUI network into a shared low dimensional space. Meanwhile, multi-granularity proximities which include the second-order proximity and the community-aware high-order proximity of nodes, are introduced to learn more informative and robust network representations. Then, with an efficient search method, we use the encoded representation of temporal contexts to generate recommendations. Experimental results on several real large-scale datasets show its advantages over other state-of-the-art methods.", "keywords": ["Social recommendation", "Heterogeneous social network", "Network embedding", "Temporal context", "Community detection"], "reference_count": 26, "ccfClass": "A", "important": true, "references": [{"ref": "[1]Sedhain, S., Sanner, S., Braziunas, D., Xie, L., Christensen, J.: Social collaborative filtering for cold-start recommendations. In: RecSys, pp. 345–348 (2014)"}, {"ref": "[2]Kouki, P., Fakhraei, S., Foulds, J., Eirinaki, M., Getoor, L.: Hyper: a flexible and extensible probabilistic framework for hybrid recommender systems. In: RecSys, pp. 99–106. ACM (2015)"}, {"ref": "[4]Covington, P., Adams, J., Sargin, E.: Deep neural networks for youtube recommendations. In: RecSys, pp. 191–198. ACM (2016)"}, {"ref": "[5]Tang, J., Qu, M., Wang, M., Zhang, M., Yan, J., Mei, Q.: Line: large-scale information network embedding. In: WWW, pp. 1067–1077 (2015)"}, {"ref": "[6]Perozzi, B., Al-Rfou, R., Skiena, S.: Deepwalk: online learning of social representations. In: SIGKDD, pp. 701–710. ACM (2014)"}, {"ref": "[7]Cavallari, S., Zheng, V.W., Cai, H., Chang, K.C.C., Cambria, E.: Learning community embedding with community detection and node embedding on graphs. In: CIKM, pp. 377–386. ACM (2017)"}, {"ref": "[8]Li, J., Dani, H., Hu, X., Tang, J., Chang, Y., Liu, H.: Attributed network embedding for learning in a dynamic environment. In: CIKM, pp. 387–396 (2017)"}, {"ref": "[9]Wang, X., Cui, P., Wang, J., Pei, J., Zhu, W., Yang, S.: Community preserving network embedding. In: AAAI, pp. 203–209 (2017)"}, {"ref": "[10]Agarwal, D., Chen, B.C., Elango, P.: Fast online learning through offline initialization for time-sensitive recommendation. In: SIGKDD, pp. 703–712 (2010)"}, {"ref": "[11]Diaz-Aviles, E., Drumond, L., Schmidt-Thieme, L., Nejdl, W.: Real-time top-n recommendation in social streams. In: RecSys, pp. 59–66. ACM (2012)"}, {"ref": "[12]Huang, Y., Cui, B., Zhang, W., Jiang, J., Xu, Y.: Tencentrec: real-time stream recommendation in practice. In: SIGMOD, pp. 227–238. ACM (2015)"}, {"ref": "[13]Subbian, K., Aggarwal, C., Hegde, K.: Recommendations for streaming data. In: CIKM, pp. 2185–2190. ACM (2016)"}, {"ref": "[14]Grover, A., Leskovec, J.: node2vec: scalable feature learning for networks. In: SIGKDD, pp. 855–864. ACM (2016)"}, {"ref": "[15]Dong, Y., Chawla, N.V., Swami, A.: metapath2vec: scalable representation learning for heterogeneous networks. In: SIGKDD, pp. 135–144. ACM (2017)"}, {"ref": "[16]Tang, J., Qu, M., Mei, Q.: Pte: predictive text embedding through large-scale heterogeneous text networks. In: SIGKDD, pp. 1165–1174. ACM (2015)"}, {"ref": "[17]Le, Q., Mikolov, T.: Distributed representations of sentences and documents. In: ICML, pp. 1188–1196 (2014)"}, {"ref": "[18]Li, Y., Patra, J.C.: Genome-wide inferring gene-phenotype relationship by walking on the heterogeneous network. Bioinformatics 26(9), 1219–1224 (2010)"}, {"ref": "[19]Gao, Y., Chen, J., Zhu, J.: Streaming Gibbs sampling for LDA model. arXiv preprint arXiv:1601.01142 (2016)"}, {"ref": "[20]Blei, D.M., Ng, A.Y., Jordan, M.I.: Latent Dirichlet allocation. J. Mach. Learn. Res. 3(1), 993–1022 (2003)"}, {"ref": "[21]Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J.: Distributed representations of words and phrases and their compositionality. In: NIPS (2013)"}, {"ref": "[22]Recht, B., Re, C., Wright, S., Niu, F.: Hogwild: a lock-free approach to parallelizing stochastic gradient descent. In: NIPS (2011)"}, {"ref": "[23]Fagin, R., Lotem, A., Naor, M.: Optimal aggregation algorithms for middleware. J. Comput. Syst. Sci. 66(4), 614–656 (2003)"}, {"ref": "[24]Hu, Y., Koren, Y., Volinsky, C.: Collaborative filtering for implicit feedback datasets. In: ICDM, pp. 263–272. IEEE (2008)"}, {"ref": "[25]Cremonesi, P., Koren, Y., Turrin, R.: Performance of recommender algorithms on top-n recommendation tasks. In: RecSys, pp. 39–46. ACM (2010)"}, {"ref": "[26]Deshpande, M., Karypis, G.: Item-based top-n recommendation algorithms. TOIS 22(1), 143–177 (2004)"}]}, {"author": ["Aakas Zhiyuli", "Xun Liang", "Yanfang Chen", "Xiaoyong Du"], "title": "Modeling Large-Scale Dynamic Social Networks via Node Embeddings", "journal": "IEEE Transactions on Knowledge and Data Engineering", "year": 2019, "DOI": "10.1109/tkde.2018.2872602", "month": 10, "citations(google scholar)": 0, "abstract": "Given the edge list of a social network, the node embedding method learns the structural features for every node and embeds the features into a vector space. The current related work on node embedding exploits only a portion of existing networks, e.g., static networks. However, social networks are inherently hierarchical and dynamic systems in which the topology changes constantly and the strength of influence of information among neighbors varies with different numbers of hops. We propose a highly efficient node embedding method, DNPS, that is faster and more accurate than state-of-the-art methods and that can further boost the training progress, especially under dynamic conditions. In this paper, we attempt to model the hierarchical and dynamic features of social networks by designing a damping-based sampling algorithm corresponding to a local search-based incremental learning algorithm, which can easily be extended to large-scale scenarios. We conduct extensive experiments on six real-world social networks with three challenging tasks, including missing link prediction, dynamic link prediction, and multi-label classification. The results of the experiments on these tasks demonstrate that the proposed method significantly outperforms the existing methods with different settings.", "keywords": ["Node embeddings", "distributed representation", "dynamic social networks", "link analysis"], "reference_count": 49, "ccfClass": "A", "important": true, "references": [{"ref": "[1] M. Bogun ~\u0002 a, R. Pastor-Satorras, A. D\u0002 ıaz-Guilera, and A. Arenas, \"Models of social networks based on social distance attachment,\" Phys. Rev. E, vol. 70, no. 5, 2004, Art. no. 056122."}, {"ref": "[2] L. Lu and T. Zhou, \"Link prediction in complex networks: € A survey,\" Physica A: Statistical Mech. Appl., vol. 390, no. 6, pp. 1150–1170, 2011."}, {"ref": "[3] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei, \"LINE: Large-scale information network embedding,\" in Proc. 24th Int. Conf. World Wide Web, 2015, pp. 1067–1077."}, {"ref": "[4] B. Perozzi, R. Al-Rfou, and S. Skiena, \"DeepWalk: Online learning of social representations,\" in Proc. 20th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2014, pp. 701–710."}, {"ref": "[5] S. Cao, W. Lu, and Q. Xu, \"GraRep: Learning graph representations with global structural information,\" in Proc. 24th ACM Int. Conf. Inf. Knowl. Manage, 2015, pp. 891–900."}, {"ref": "[6] Z. Aakas, X. Liang, X. Zhou, and Y. Ma, \"A link prediction method for large-scale networks,\" Chin. J. Comput., vol. 39, no. Online Publishing No.42, pp. 1–18, 2016."}, {"ref": "[7] A. Garcia-Duran, A. Bordes, N. Usunier, and Y. Grandvalet, \"Combining two and three-way embedding models for link prediction in knowl. bases,\" J. Artif. Intell. Res., vol. 55, pp. 715–742, 2016."}, {"ref": "[8] Y. Ren, Y. Zhang, M. Zhang, and D. Ji, \"Improving twitter sentiment classification using topic-enriched multi-prototype word embedding,\" in Proc. 30th AAAI Conf. Artif. Intell., 2016, pp. 3038–3044."}, {"ref": "[9] W. Hu and J. Tsujii, \"A latent concept topic model for robust topic inference using word embeddings,\" in Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, 2016, Art. no. 380."}, {"ref": "[10] T. Mikolov, K. Chen, G. Corrado, and J. Dean, \"Efficient estimation of word representations in vector space,\" arXiv.org, vol. cs.CL, pp. 1–12, Jan. 2013."}, {"ref": "[11] T. Mikolov and J. Dean, \"Distributed representations of words and phrases and their compositionality,\" in Proc. 26th Int. Conf. Neural Inf. Process. Syst., 2013, pp. 3111–3119."}, {"ref": "[12] Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin, \"A neural probabilistic language model,\" J. Mach. Learn. Res., vol. 3, pp. 1137–1155, 2003."}, {"ref": "[13] D. Liben-Nowell and J. Kleinberg, \"The link-prediction problem for social networks,\" J. Amer. Soc. Inf. Sci. Technol., vol. 58, no. 7, pp. 1019–1031, 2007."}, {"ref": "[14] S. Bhagat, G. Cormode, B. Krishnamurthy, and D. Srivastava, \"Privacy in dynamic social networks,\" in Proc. 19th Int. Conf. World Wide Web, Apr. 26-30, 2010, pp. 1059–1060."}, {"ref": "[15] P. Wang, B. Xu, Y. Wu, and X. Zhou, \"Link prediction in social networks: The state-of-the-art,\" Sci. China Inf. Sci., vol. 58, no. 1, pp. 1–38, 2015."}, {"ref": "[16] C. Fang, M. Kohram, and A. L. Ralescu, \"Spectral regression with low-rank approximation for dynamic graph link prediction,\" IEEE Intell. Syst., vol. 26, no. 4, pp. 48–53, Jul./Aug. 2011."}, {"ref": "[17] G. E. Hinton, \"Learning distributed representations of concepts,\" in Proc. 8th Annu. Conf. Cogn. Sci. Soc., 1986, Art. no. 12."}, {"ref": "[18] L. Tang and H. Liu, \"Relational learning via latent social dimensions,\" in Proc. 15th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2009, pp. 817–826."}, {"ref": "[19] X. Zhou, X. Liang, H. Zhang, and Y. Ma, \"Cross-platform identification of anonymous identical users in multiple social media networks,\" IEEE Trans. Knowl. Data Eng., vol. 28, no. 2, pp. 411–424, Feb. 2016."}, {"ref": "[20] Y. LeCun, Y. Bengio, and G. Hinton, \"Deep learning,\" Nature, vol. 521, no. 7553, pp. 436–444, 2015. [21] A. Mnih and G. E. Hinton, \"A scalable hierarchical distributed language model,\" in Proc. 21st Int. Conf. Neural Inf. Process. Syst., Dec. 8–11, 2009, pp. 1081–1088."}, {"ref": "[22] Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu, \"Learning entity and relation embeddings for knowledge graph completion,\" in Proc. 29th AAAI Conf. Artif. Intell., 2015, pp. 2181–2187."}, {"ref": "[23] Y. Yu, X. Wan, and X. Zhou, \"User embedding for scholarly microblog recommendation,\" in Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, Aug. 7–12, 2016, pp. 449–453."}, {"ref": "[24] A. Benton, R. Arora, and M. Dredze, \"Learning multiview embeddings of twitter users,\" in Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, Aug. 7–12, 2016, pp. 14–19."}, {"ref": "[25] J. B. Tenenbaum, V. de Silva, and J. C. Langford, \"A global geometric framework for nonlinear dimensionality reduction,\" Science, vol. 290, no. 5500, pp. 2319–2323, 2000."}, {"ref": "[26] S. T. Roweis and L. K. Saul, \"Nonlinear dimensionality reduction by locally linear embedding,\" Science, vol. 290, 2000, Art. no. 2323."}, {"ref": "[27] M. Belkin and P. Niyogi, \"Laplacian eigenmaps and spectral techniques for embedding and clustering,\" in Proc. 14th Int. Conf. Neural Inf. Process. Syst., 2002, pp. 585–591."}, {"ref": "[28] P. Cui, X. Wang, J. Pei, and W. Zhu, \"A survey on network embedding,\" IEEE Trans. Knowl. Data Eng., to be published, doi: 10.1109/TKDE.2018.2849727."}, {"ref": "[29] D. Wang, P. Cui, and W. Zhu, \"Structural deep network embedding,\" in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2016, pp. 1225–1234."}, {"ref": "[30] A. Grover and J. Leskovec, \"node2vec: Scalable feature learning for networks,\" in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2016, pp. 855–864."}, {"ref": "[31] S. Chang, W. Han, J. Tang, G.-J. Qi, C. C. Aggarwal, and T. S. Huang, \"Heterogeneous network embedding via deep architectures,\" in Proc. 21th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2015, pp. 119–128."}, {"ref": "[32] J. Tang, M. Qu, and Q. Mei, \"PTE: Predictive text embedding through large-scale heterogeneous text networks,\" in Proc. 21th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2015, pp. 1165–1174."}, {"ref": "[33] L. Dos Santos, B. Piwowarski, and P. Gallinari, \"Multilabel classification on heterogeneous graphs with gaussian embeddings,\" in Proc. Joint Eur. Conf. Mach. Learn. Knowl. Discovery Databases, 2016, pp. 606–622."}, {"ref": "[34] C. Yang, Z. Liu, D. Zhao, M. Sun, and E. Y. Chang, \"Network representation learning with rich text information,\" in Proc. 24th Int. Joint Conf. Artif. Intell., 2015, pp. 2111–2117."}, {"ref": "[35] M. Ochi, Y. Nakashio, Y. Yamashita, I. Sakata, K. Asatani, M. Ruttley, and J. Mori, \"Representation learning for geospatial areas using large-scale mobility data from smart card,\" in Proc. ACM Int. Joint Conf. Pervasive Ubiquitous Comput.: Adjunct, 2016, pp. 1381–1389."}, {"ref": "[36] D. Zhu, P. Cui, Z. Zhang, J. Pei, and W. Zhu, \"High-order proximity preserved embedding for dynamic networks,\" IEEE Trans. Knowl. Data Eng., vol. 30, no. 11, pp. 2134–2144, Nov. 2018."}, {"ref": "[37] A. Clauset, C. Moore, and M. E. Newman, \"Hierarchical structure and the prediction of missing links in networks,\" Nature, vol. 453, no. 7191, pp. 98–101, 2008."}, {"ref": "[38] Z. Aakas, X. Liang, and X. Zhou, \"Learning structural features of nodes in large-scale networks for link prediction,\" in Proc. 30th AAAI Conf. Artif. Intell., Feb. 2016, pp. 4286–4287."}, {"ref": "[39] M. Gutmann and A. Hyv€ arinen, \"Noise-contrastive estimation: A new estimation principle for unnormalized statistical models,\" in Proc. 13th Int. Conf. Artif. Intell. Statist., 2010, Art. no. 6."}, {"ref": "[40] L. Bottou, \"Stochastic gradient learning in neural networks,\" Proc. Neuro-N{mes, vol. 91, no. 8, 1991, pp. 1–12."}, {"ref": "[41] A. Mnih and K. Kavukcuoglu, \"Learning word embeddings efficiently with noise-contrastive estimation,\" in Proc. 26th Int. Conf. Neural Inf. Process. Syst., 2013, pp. 2265–2273."}, {"ref": "[42] A. Mislove, H. S. Koppula, K. P. Gummadi, P. Druschel, and B. Bhattacharjee, \"Growth of the flickr social network,\" in Proc. 1st ACM SIGCOMM Workshop Social Netw., Aug. 2008, pp. 25–30."}, {"ref": "[43] T. Hogg and K. Lerman, \"Social dynamics of digg,\" EPJ Data Sci., vol. 1, no. 1, pp. 1–26, 2012. [44] M. E. Newman, \"Clustering and preferential attachment in growing networks,\" Phys. Rev. E, vol. 64, no. 2, 2001, Art. no. 025102."}, {"ref": "[45] L. A. Adamic and E. Adar, \"Friends and neighbors on the web,\" Soc. Netw., vol. 25, no. 3, pp. 211–230, 2003."}, {"ref": "[46] A. L. Barabasi and R. Albert, \"Emergence of scaling in random networks,\" Sci., vol. 286, no. 5439, pp. 509–512, 1999."}, {"ref": "[47] R. N. Lichtenwalter and N. V. Chawla, \"LPmade: Link prediction made easy,\" J. Mach. Learn. Res., vol. 12, pp. 2489–2492, 2011."}, {"ref": "[48] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, \"Scikit-learn: Machine learning in Python,\" J. Mach. Learn. Res., vol. 12, pp. 2825–2830, 2011."}, {"ref": "[49] Y. Yuan, X. Lian, L. Chen, Y. Sun, and G. Wang, \"RSkNN: kNN search on road networks by incorporating social influence,\" IEEE Trans. Knowl. Data Eng., vol. 28, no. 6, pp. 1575–1588, Jun. 2016."}]}, {"author": ["Linhong Zhu", "Dong Guo", "Junming Yin", "Greg Ver Steeg", "Aram Galstyan"], "title": "Scalable Temporal Latent Space Inference for Link Prediction in Dynamic Social Networks", "journal": "IEEE Transactions on Knowledge and Data Engineering", "year": 2016, "DOI": "10.1109/icde.2017.35", "month": 10, "citations(google scholar)": 84, "abstract": "We propose a temporal latent space model for link prediction in dynamic social networks, where the goal is to predict links over time based on a sequence of previous graph snapshots. The model assumes that each user lies in an unobserved latent space, and interactions are more likely to occur between similar users in the latent space representation. In addition, the model allows each user to gradually move its position in the latent space as the network structure evolves over time. We present a global optimization algorithm to effectively infer the temporal latent space. Two alternative optimization algorithms with local and incremental updates are also proposed, allowing the model to scale to larger networks without compromising prediction accuracy. Empirically, we demonstrate that our model, when evaluated on a number of real-world dynamic networks, significantly outperforms existing approaches for temporal link prediction in terms of both scalability and predictive power.", "keywords": ["Latent space model", "link prediction", "non-negative matrix factorization", "social network analysis"], "reference_count": 49, "ccfClass": "A", "important": true, "references": [{"ref": "[1] M. A. Hasan and M. J. Zaki, \"A survey of link prediction in social networks,\" in Social Network Data Analytics. New York, NY, USA: Springer, 2011, pp. 243–275."}, {"ref": "[2] D. Liben-Nowell andJ. Kleinberg, \"The link prediction problem for social networks,\" in Proc. 12th Int. Conf. Inf. Knowl. Manage., 2003, pp. 556–559."}, {"ref": "[3] M. Mcpherson, L. Smith-Lovin, and J. M. Cook, \"Birds of a feather: Homophily in social networks,\" Annu. Rev. Sociology, vol. 27, pp. 415–444, 2001."}, {"ref": "[4] P. D. Hoff, A. E. Raftery, and M. S. Handcock, \"Latent space approaches to social network analysis,\" J. Amer. Statistical Assoc., vol. 97, pp. 1090–1098, 2002."}, {"ref": "[5] J. Yin, Q. Ho, and E. P. Xing, \"A scalable approach to probabilistic latent space inference of large-scale networks,\" in Proc. Adv. Neural Inf. Process. Syst. Conf., 2013, pp. 422–430."}, {"ref": "[6] P. Sarkar and A. W. Moore, \"Dynamic social network analysis using latent space models,\" ACM SIGKDD Explorations Newslett., vol. 7, no. 2, pp. 31–40, 2005."}, {"ref": "[7] A. K. Menon and C. Elkan, \"Link prediction via matrix factorization,\" in Proc. Eur. Conf. Mach. Learn. Knowl. Discovery Databases, 2011, pp. 437–452."}, {"ref": "[8] G.-J. Qi, C. C. Aggarwal, and T. Huang, \"Link prediction across networks by biased cross-network sampling,\" in Proc. 29th Int. Conf. Data Eng., 2013, pp. 793–804."}, {"ref": "[9] S. Gao, L. Denoyer, and P. Gallinari, \"Temporal link prediction by integrating content and structure information,\" in Proc. 20th ACM Int. Conf. Inf. Knowl. Manage., 2011, pp. 1169–1174."}, {"ref": "[10] J. Ye, H. Cheng, Z. Zhu, and M. Chen, \"Predicting positive and negative links in signed social networks by transfer learning,\" in Proc. 22nd Int. Conf. World Wide Web, 2013, pp. 1477–1488."}, {"ref": "[11] Y. Zhang, M. Zhang, Y. Liu, S. Ma, and S. Feng, \"Localized matrix factorization for recommendation based on matrix block diagonal forms,\" in Proc. 22nd Int. Conf. World Wide Web, 2013, pp. 1511–1520."}, {"ref": "[12] D. Erdo \u0002 \u0002s, R. Gemulla, and E. Terzi, \"Reconstructing graphs from neighborhood data,\" ACM Trans. Knowl. Discovery Data, vol. 8, no. 4, pp. 23:1–23:22, Oct. 2014."}, {"ref": "[13] E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing, \"Mixed membership stochastic blockmodels,\" J. Mach. Learn. Res., vol. 9, pp. 1981–2014, 2008."}, {"ref": "[14] P. Gupta, et al., \"Real-time twitter recommendation: Online motif detection in large dynamic graphs,\" Proc. VLDB Endowment, vol. 7, no. 13, pp. 1379–1380, 2014."}, {"ref": "[15] C. Tantipathananandh, T. Berger-Wolf, and D. Kempe, \"A framework for community identification in dynamic social networks,\" in Proc. 13th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2007, pp. 717–726."}, {"ref": "[16] J. Sun, C. Faloutsos, S. Papadimitriou, and P. S. Yu, \"Graphscope: Parameter-free mining of large time-evolving graphs,\" in Proc. 13th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2007, pp. 687–696."}, {"ref": "[17] D. M. Dunlavy, T. G. Kolda, and E. Acar, \"Temporal link prediction using matrix and tensor factorizations,\" ACM Trans. Knowl. Discovery Data, vol. 5, no. 2, pp. 10:1–10:27, 2011."}, {"ref": "[18] L. Zhu, A. Galstyan, J. Cheng, and K. Lerman, \"Tripartite graph clustering for dynamic sentiment analysis on social media,\" in Proc. ACM SIGMOD Int. Conf. Manage. Data, 2014, pp. 1531–1542."}, {"ref": "[19] J. Zhang, C. Wang, J. Wang, and J. X. Yu, \"Inferring continuous dynamic social influence and personal preference for temporal behavior prediction,\" Proc. VLDB Endowment, vol. 8, no. 3, pp. 269–280, 2014."}, {"ref": "[20] M. W. Berry, M. Browne, A. N. Langville, V. P. Pauca, and R. J. Plemmons, \"Algorithms and applications for approximate nonnegative matrix factorization,\" Comput. Statist. Data Anal., vol. 52, no. 1, pp. 155–173, 2007."}, {"ref": "[21] P. Tseng and S. Yun, \"A coordinate gradient descent method for nonsmooth separable minimization,\" Math. Program., vol. 117, no. 1/2, pp. 387–423, 2009."}, {"ref": "[22] J. Yang and J. Leskovec, \"Overlapping community detection at scale: A nonnegative matrix factorization approach,\" in Proc. 6th ACM Int. Conf. Web Search Data Mining, 2013, pp. 587–596."}, {"ref": "[23] C. Tantipathananandh and T. Y. Berger-Wolf, \"Finding communities in dynamic social networks,\" in Proc. 11th IEEE Int. Conf. Data Mining, 2011, pp. 1236–1241."}, {"ref": "[24] D. D. Lee and H. S. Seung, \"Learning the parts of objects by nonnegative matrix factorization,\" Nature, vol. 401, pp. 788–791, 1999."}, {"ref": "[25] P. Sarkar, D. Chakrabarti, and M. I. Jordan, \"Nonparametric link prediction in dynamic networks,\" in Proc. 29th Int. Conf. Mach. Learn., 2012, pp. 1687–1694."}, {"ref": "[26] S. A. Vavasis, \"On the complexity of nonnegative matrix factorization,\" J. Optimization, vol. 20, no. 3, pp. 1364–1377, 2009."}, {"ref": "[27] S. Arora, R. Ge, R. Kannan, and A. Moitra, \"Computing a nonnegative matrix factorization—provably,\" in Proc. 44th Annu. ACM Symp. Theory Comput., 2012, pp. 145–162."}, {"ref": "[28] B. Recht, C. Re, J. A. Tropp, and V. Bittorf, \"Factoring nonnegative matrices with linear programs,\" in Proc. Adv. Neural Inf. Process. Syst. Conf., 2012, pp. 1223–1231."}, {"ref": "[29] Y. Nesterov, Introductory Lectures on Convex Optimization : A Basic Course. Berlin, Germany: Kluwer, 2004."}, {"ref": "[30] N. Guan, D. Tao, Z. Luo, and B. Yuan, \"NeNMF: An optimal gradient method for nonnegative matrix factorization,\" IEEE Trans. Signal Process., vol. 60, no. 6, pp. 2882–2898, Jun. 2012."}, {"ref": "[31] A. Beck and M. Teboulle, \"A fast iterative shrinkage-thresholding algorithm for linear inverse problems,\" SIAM J. Imaging Sci., vol. 2, no. 1, pp. 183–202, 2009."}, {"ref": "[32] D. Gibson, R. Kumar, and A. Tomkins, \"Discovering large dense subgraphs in massive graphs,\" in Proc. 31st Int. Conf. Very Large Data Bases, 2005, pp. 721–732."}, {"ref": "[33] J. Kunegis, \"KONECT—The Koblenz network collection,\" in Proc. 22nd Int. Conf. World Wide Web, 2013, pp. 1343–1350."}, {"ref": "[34] L. Isella, J. Stehl\u0002 e, A. Barrat, C. Cattuto, J.-F. Pinton, and W. V. den Broeck, \"What’s in a crowd? analysis of face-to-face behavioral networks,\" J. Theoretical Biol., vol. 271, no. 1, pp. 166–180, 2011."}, {"ref": "[35] B. Viswanath, A. Mislove, M. Cha, and K. P. Gummadi, \"On the evolution of user interaction in Facebook,\" in Proc. 2nd ACM Workshop Online Social Netw., 2009, pp. 37–42."}, {"ref": "[36] J. Leskovec, J. Kleinberg, and C. Faloutsos, \"Graph evolution: Densification and shrinking diameters,\" ACM Trans. Knowl. Discovery Data, vol. 1, no. 1, pp. 1–40, 2007."}, {"ref": "[37] \"DBLP network dataset—KONECT,\" May 2015. [Online]. Available: http://konect.uni-koblenz.de/networks/dblp_coauthor"}, {"ref": "[38] A. Mislove, \"Online social networks: Measurement, analysis, and applications to distributed information systems,\" Ph.D. dissertation, Department of Computer Science, Rice University, Houston, TX, 2009."}, {"ref": "[39] W. Fu, L. Song, and E. P. Xing, \"Dynamic mixed membership blockmodel for evolving networks,\" in Proc. 26th Annu. Int. Conf. Mach. Learn., 2009, pp. 329–336."}, {"ref": "[40] Z. Yang, T. Hao, O. Dikmen, X. Chen, and E. Oja, \"Clustering by nonnegative matrix factorization using graph random walk,\" in Proc. Adv. Neural Inf. Process. Syst., 2012, pp. 1088–1096."}, {"ref": "[41] J. Xie, M. Chen, and B. K. Szymanski, \"LabelRankT: Incremental community detection in dynamic networks via label propagation,\" CoRR, vol. abs/1305.2006, 2013."}, {"ref": "[42] L. A. Adamic and E. Adar, \"Friends and neighbors on the Web,\" Social Netw., vol. 25, pp. 211–230, 2001."}, {"ref": "[43] S. Cohen and N. Cohen-Tzemach, \"Implementing link-prediction for social networks in a database system,\" in Proc. ACM SIGMOD Workshop Databases Social Netw., 2013, pp. 37–42."}, {"ref": "[44] L. Zhu and K. Lerman, \"A visibility-based model for link prediction in social media,\" in Proc. ASE/IEEE Conf. Social Comput., 2014."}, {"ref": "[45] P. Symeonidis, E. Tiakas, and Y. Manolopoulos, \"Transitive node similarity for link prediction in social networks with positive and negative links,\" in Proc. 4th ACM Conf. Recommender Syst., 2010, pp. 183–190."}, {"ref": "[46] L. Katz, \"A new status index derived from sociometric analysis,\" Psychometrika, vol. P-18, no. 1, pp. 39–43, Mar. 1953."}, {"ref": "[47] G. Jeh and J. Widom, \"SimRank: A measure of structural-context similarity,\" in Proc. 8th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2002, pp. 538–543."}, {"ref": "[48] D. K. Sewell and Y. Chen, \"Latent space models for dynamic networks,\" J. Amer. Statistical Assoc., vol. 110, no. 512, pp. 1646– 1657, 2015."}, {"ref": "[49] F. Huang, U. N. Niranjan, M. U. Hakeem, P. Verma, and A. Anandkumar, \"Fast detection of overlapping communities via online tensor methods on GPUs,\" CoRR, vol. abs/1309.0787, 2013."}]}, {"author": ["Ziwei Zhang", "Peng Cui", "Jian Pei", "Xiao Wang", "Wenwu Zhu"], "title": "TIMERS: Error-Bounded SVD Restart on Dynamic Networks", "journal": "Thirty-Second AAAI Conference on Artificial Intelligence", "year": 2018, "DOI": "arXiv:1711.09541v1", "month": 4, "citations(google scholar)": 18, "abstract": "Singular Value Decomposition (SVD) is a popular approach in various network applications, such as link prediction and network parameter characterization. Incremental SVD approaches are proposed to process newly changed nodes and edges in dynamic networks. However, incremental SVD approaches suffer from serious error accumulation inevitably due to approximation on incremental updates. SVD restart is an effective approach to reset the aggregated error, but when to restart SVD for dynamic networks is not addressed in literature. In this paper, we propose TIMERS, Theoretically Instructed Maximum-Error-bounded Restart of SVD, a novel approach which optimally sets the restart time in order to reduce error accumulation in time. Specifically, we monitor the margin between reconstruction loss of incremental updates and the minimum loss in SVD model. To reduce the complexity of monitoring, we theoretically develop a lower bound of SVD minimum loss for dynamic networks and use the bound to replace the minimum loss in monitoring. By setting a maximum tolerated error as a threshold, we can trigger SVD restart automatically when the margin exceeds this threshold. We prove that the time complexity of our method is linear with respect to the number of local dynamic changes, and our method is general across different types of dynamic networks. We conduct extensive experiments on several synthetic and real dynamic networks. The experimental results demonstrate that our proposed method significantly outperforms the existing methods by reducing 27% to 42% in terms of the maximum error for dynamic network reconstruction when fixing the number of restarts. Our method reduces the number of restarts by 25% to 50% when fixing the maximum error tolerated.", "keywords": ["0"], "reference_count": 20, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Barab ´ asi, A.-L., and Albert, R. ´ 1999. Emergence of scaling in random networks. Science 286(5439):509–512."}, {"ref": "[2] Belkin, M., and Niyogi, P. 2001. Laplacian eigenmaps and spectral techniques for embedding and clustering. In Advances in Neural Information Processing Systems, volume 14, 585–591."}, {"ref": "[3] Brand, M. 2002. Incremental singular value decomposition of uncertain data with missing values. In European Conference on Computer Vision, 707–720. Springer."}, {"ref": "[4] Brand, M. 2006. Fast low-rank modifications of the thin singular value decomposition. Linear algebra and its applications 415(1):20–30."}, {"ref": "[5] Chen, X., and Candan, K. S. 2014. Lwisvd: low-rank, windowed, incremental singular value decompositions on time-evolving data sets. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge Discovery and Data mining, 987–996. ACM."}, {"ref": "[6] Chen, C., and Tong, H. 2015. Fast eigenfunctions tracking on dynamic graphs. In Society for Industrial and Applied Mathematics Publications, 559–567. SIAM."}, {"ref": "[7] Cohen, M. B.; Elder, S.; Musco, C.; Musco, C.; and Persu, M. 2015. Dimensionality reduction for k-means clustering and low rank approximation. In Proceedings of the fortyseventh annual ACM symposium on Theory of computing, 163– 172. ACM."}, {"ref": "[8] Eckart, C., and Young, G. 1936. The approximation of one matrix by another of lower rank. Psychometrika 1(3):211–218."}, {"ref": "[9] Erdos, P., and R ´ enyi, A. 1960. On the ´ evolution of random graphs. Publ. Math. Inst. Hung. Acad. Sci 5(1):17–60."}, {"ref": "[10] Lanczos, C. 1950. An iteration method for the solution of the eigenvalue problem of linear differential and integral operators1. Journal of Research of the National Bureau of Standards 45(4)."}, {"ref": "[11] Levinson, N. 1946. The wiener (root mean square) error criterion in filter design and prediction. Studies in Applied Mathematics 25(1-4):261–278."}, {"ref": "[12] Li, J.; Dani, H.; Hu, X.; Tang, J.; Chang, Y.; and Liu, H. 2017. Attributed network embedding for learning in a dynamic environment. arXiv preprint arXiv:1706.01860."}, {"ref": "[13] Liberty, E. 2013. Simple and deterministic matrix sketching. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 581–588. ACM."}, {"ref": "[14] Ou, M.; Cui, P.; Wang, F.; Wang, J.; and Zhu, W. 2015. Non-transitive hashing with latent similarity components. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 895–904. ACM."}, {"ref": "[15] Ou, M.; Cui, P.; Pei, J.; Zhang, Z.; and Zhu, W. 2016. Asymmetric transitivity preserving graph embedding. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1105–1114. ACM."}, {"ref": "[16] Sarwar, B.; Karypis, G.; Konstan, J.; and Riedl, J. 2002. Incremental singular value decomposition algorithms for highly scalable recommender systems. In Fifth International Conference on Computer and Information Science, 27–28. Citeseer."}, {"ref": "[17] Stewart, G. W. 1990. Matrix perturbation theory. Citeseer."}, {"ref": "[18] Wang, X.; Cui, P.; Wang, J.; Pei, J.; Zhu, W.; and Yang, S. 2017. Community preserving network embedding. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, 203–209."}, {"ref": "[19] Wang, D.; Cui, P.; and Zhu, W. 2016. Structural deep network embedding. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, 1225–1234. ACM."}, {"ref": "[20] Xu, C.; Tao, D.; and Xu, C. 2016. Robust extreme multi-label learning. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1275–1284."}]}, {"author": ["Lun Du", "Yun Wang", "Guojie Song", "Zhicong Lu", "Junshan Wan"], "title": "Dynamic Network Embedding : An Extended Approach for Skip-gram based Network Embedding", "journal": "International Joint Conference on Artificial Intelligence", "year": 2018, "DOI": "10.24963/ijcai.2018/288", "month": 7, "citations(google scholar)": 29, "abstract": "Network embedding, as an approach to learn low-dimensional representations of vertices, has been proved extremely useful in many applications. Lots of state-of-the-art network embedding methods based on Skip-gram framework are efficient and effective. However, these methods mainly focus on the static network embedding and cannot naturally generalize to the dynamic environment. In this paper, we propose a stable dynamic embed- ding framework with high efficiency. It is an extension for the Skip-gram based network embedding methods, which can keep the optimality of the objective in the Skip-gram based methods in theory. Our model can not only generalize to the new ver- tex representation, but also update the most affected original vertex representations during the evolvement of the network. Multi-class classification on three real-world networks demonstrates that, our model can update the vertex representations efficiently and achieve the performance of retraining simultaneously. Besides, the visualization experimental result illustrates that, our model is capable of avoiding the embedding space drifting.", "keywords": ["Machine Learning: Unsupervised Learning", "Machine Learning Applications: Networks"], "reference_count": 25, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Belkin and Niyogi, 2001. Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps and spectral techniques for embedding and clustering. pages 585–591, 2001."}, {"ref": "[2] Cao et al., 2015. Shaosheng Cao, Wei Lu, and Qiongkai Xu. Grarep: Learning graph representations with global structural information. In ACM International on Conference on Information and Knowledge Management, pages 891–900, 2015."}, {"ref": "[3] Cao et al., 2016. Shaosheng Cao, Wei Lu, and Qiongkai Xu. Deep neural networks for learning graph representations. In Association for the Advancement of Artificial Intelligence Conference, pages 1145–1152, 2016."}, {"ref": "[4] Cui et al., 2017. P. Cui, X. Wang, J. Pei, and W. Zhu. A Survey on Network Embedding. ArXiv e-prints, Novem- ber 2017."}, {"ref": "[5] Grover and Leskovec, 2016. Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. Knowledge Discovery and Data mining, pages 855–864, 2016."}, {"ref": "[6] Hamiltonetal.,2017. Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems, pages 1025–1035, 2017."}, {"ref": "[7] He et al., 2012. Xinran He, Guojie Song, Wei Chen, and Qingye Jiang. Influence blocking maximization in social networks under the competitive linear threshold model. pages 463–474, 2012."}, {"ref": "[8] Henderson et al., 2012. Keith Henderson, Brian Gallagher, Tina Eliassi-Rad, Hanghang Tong, Sugato Basu, Leman Akoglu, Danai Koutra, Christos Faloutsos, and Lei Li. Rolx: structural role extraction &#38; mining in large graphs. In ACM Knowledge Discovery and Data Mining, pages 1231–1239, 2012."}, {"ref": "[9] Kipf and Welling, 2016. Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. CoRR, abs/1609.02907, 2016."}, {"ref": "[10] Levy and Goldberg, 2014. Omer Levy and Yoav Goldberg. Neural word embedding as implicit matrix factorization. In Advances in neural information processing systems, pages 2177–2185, 2014."}, {"ref": "[11] Li et al., 2015. Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. Gated graph sequence neural networks. CoRR, abs/1511.05493, 2015."}, {"ref": "[12] Li et al., 2017. Jundong Li, Harsh Dani, Xia Hu, Jiliang Tang, Yi Chang, and Huan Liu. Attributed network em- bedding for learning in a dynamic environment. CoRR, abs/1706.01860, 2017."}, {"ref": "[13] Ma et al., 2018. Jianxin Ma, Peng Cui, and Wenwu Zhu. Depthlgp: Learning embeddings of out-of-sample nodes in dynamic networks. In Association for the Advancement of Artificial Intelligence Conference, pages 1–9, 2018."}, {"ref": "[14] Mikolov et al., 2013. Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S Corrado, and Jeffrey Dean. Distributed representations of words and phrases and their compositionality. Neural Information Processing Systems, pages 3111–3119, 2013."}, {"ref": "[15] Perozzi et al., 2014. Bryan Perozzi, Rami Alrfou, and Steven Skiena. Deepwalk: online learning of social representations. Knowledge Discovery and Data mining, pages 701–710, 2014."}, {"ref": "[16] Ribeiro et al., 2017. Leonardo F.R. Ribeiro, Pedro H.P. Saverese, and Daniel R. Figueiredo. Struc2vec: Learning node representations from structural identity. In ACM Knowledge Discovery and Data Mining, pages 385–394, 2017."}, {"ref": "[17] Rushing et al., 2005. John Rushing, Udaysankar Nair, Ron Welch, Ron Welch, and Hong Lin. Adam: a data mining toolkit for scientists and engineers. Computers and Geosciences, 31(5):607–618, 2005."}, {"ref": "[18] Song et al., 2015. Guojie Song, Xiabing Zhou, Yu Wang, and Kunqing Xie. Influence maximization on large-scale mobile social network: A divide-and-conquer method. IEEE Transactions on Parallel and Distributed Systems, 26(5):1379–1392, 2015."}, {"ref": "[19] Tang et al., 2015. Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. Line: Large-scale information network embedding. In International Conference on World Wide Web, pages 1067–1077, 2015."}, {"ref": "[20] Traud et al., 2012. Amanda L. Traud, Peter J. Mucha, and Mason A. Porter. Social structure of facebook networks. Social Science Electronic Publishing, 391(16):4165–4180, 2012."}, {"ref": "[21] Wang et al., 2016. Daixin Wang, Peng Cui, and Wenwu Zhu. Structural deep network embedding. In ACM Knowledge Discovery and Data Mining, pages 1225–1234, 2016."}, {"ref": "[22] Zachary, 1977. Wayne W Zachary. An information flow model for conflict and fission in small groups. Journal of anthropological research, 33(4):452–473, 1977."}, {"ref": "[23] Zhang et al., 2017. Ziwei Zhang, Peng Cui, Jian Pei, Xiao Wang, and Wenwu Zhu. Timers: Error-bounded svd restart on dynamic networks. In Association for the Advancement of Artificial Intelligence Conference, pages 1–8, 2017."}, {"ref": "[24] Zhou et al., 2018. Lekui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. Dynamic network embedding by modeling triadic closure process. In Association for the Advancement of Artificial Intelligence Conference, 2018."}, {"ref": "[25] Zhu et al., 2018. Dingyuan Zhu, Peng Cui, Ziwei Zhang, Jian Pei, and Wenwu Zhu. High-order proximity preserved embedding for dynamic networks. IEEE Transactions on Knowledge & Data Engineering, PP(99):1–1, 2018."}]}, {"author": ["Giang Hoang Nguyen", "John Boaz Lee", "Ryan A. Rossi", "Nesreen K. Ahmed", "Eunyee Koh", "Sungchul Kim"], "title": "Continuous-Time Dynamic Network Embeddings", "journal": "International World Wide Web Conference", "year": 2018, "DOI": "10.1145/3184558.3191526", "month": 4, "citations(google scholar)": 40, "abstract": "Networks evolve continuously over time with the addition, deletion, and changing of links and nodes. Although many networks contain this type of temporal information, the majority of research in network representation learning has focused on static snapshots of the graph and has largely ignored the temporal dynamics of the network. In this work, we describe a general framework for incorporating temporal information into network embedding methods. The framework gives rise to methods for learning time-respecting embeddings from continuous-time dynamic networks. Overall, the experiments demonstrate the effectiveness of the proposed framework and dynamic network embedding approach as it achieves an average gain of 11.9% across all methods and graphs. The results indicate that modeling temporal dependencies in graphs is important for learning appropriate and meaningful network representations.", "keywords": ["dynamic network embeddings", "temporal node embeddings", "dynamic networks", "network representation learning", "temporal random walks", "continuous-time dynamic network", "graph stream", "feature learning", "temporal networks"], "reference_count": 67, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Charu Aggarwal and Karthik Subbian. 2014. Evolutionary network analysis: A survey. CSUR 47, 1 (2014), 10."}, {"ref": "[2] Charu C Aggarwal, Yao Li, Philip S Yu, and Ruoming Jin. 2010. On dense pattern mining in graph streams. VLDB 3, 1-2 (2010), 975–984."}, {"ref": "[3] Charu C Aggarwal, Yuchen Zhao, and S Yu Philip. 2011. Outlier detection in graph streams. In ICDE. IEEE, 399–409."}, {"ref": "[4] Amr Ahmed, Nino Shervashidze, Shravan Narayanamurthy, Vanja Josifovski, and Alexander S. Smola. 2013. Distributed large-scale natural graph factorization. In WWW. 37–48."}, {"ref": "[5] NesreenK. Ahmed, Nick Duffield, TheodoreL.Willke, and RyanA.Rossi.2017. On Sampling from Massive Graph Streams. In VLDB. 1430–1441."}, {"ref": "[6] Nesreen Kamel Ahmed and Ryan Anthony Rossi. 2015. Interactive Visual Graph Analytics on the Web.. In ICWSM. 566–569."}, {"ref": "[7] NesreenK. Ahmed, RyanA. Rossi, Rong Zhou, John BoazLee, Xiangnan Kong, Theodore L. Willke, and Hoda Eldardiry. 2017. Inductive Representation Learning in Large Attributed Graphs. In WiML NIPS."}, {"ref": "[8] R. Albert, H. Jeong, and A. L. Barabási. 1999. Internet:Diameteroftheworld-wide web. Nature 401, 6749 (1999), 130–131."}, {"ref": "[9] Mikhail Belkin and Partha Niyogi. 2002.Laplacian Eigen maps for Dimensionality Reduction and Data Representation. Neural Computation 15 (2002), 1373–1396."}, {"ref": "[10] Toine Bogers. 2010. Movie recommendation using random walks over the contextual graph. In Context-Aware Recommender Systems."}, {"ref": "[11] A. Broder, R. Kumar, F. Maghoul, P. Raghavan, S. Rajagopalan, R. Stata, A. Tomkins, and J. Wiener. 2000. Graph structure in the web. Computer Networks 33, 1-6 (2000), 309–320."}, {"ref": "[12] Zhuhua Cai, Dionysios Logothetis, and Georgos Siganos. 2012. Facilitating real-time graph mining. In Proceedings of the Fourth International Workshop on Cloud Data Management. 8."}, {"ref": "[13] J. Camacho, R. Guimerà, and L.A. Nunes Amaral. 2002. Robust patterns in food web structure. Physical Review Letters 88, 22 (2002), 228102: 1–4."}, {"ref": "[14] Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2015. GraRep: Learning graph representations with global structural information. In CIKM. ACM, 891–900."}, {"ref": "[15] Sandro Cavallari, Vincent W Zheng, Hongyun Cai, Kevin Chen-Chuan Chang, and Erik Cambria. 2017. Learning community embedding with community detection and node embedding on graphs. In CIKM. 377–386."}, {"ref": "[16] Rémy Cazabet and Frédéric Amblard. 2014. Dynamic community detection. In ESNAM. Springer, 404–414."}, {"ref": "[17] Fan Chung. 2007. Random walks and local cuts in graphs. Linear Algebra and its applications 423, 1 (2007), 22–32."}, {"ref": "[18] Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable Representation Learning for Heterogeneous Networks. In SIGKDD. 135– 144."}, {"ref": "[19] Daniel M Dunlavy, Tamara G Kolda, and Evrim Acar. 2011. Temporal link prediction using matrix and tensor factorizations. TKDD 5, 2 (2011), 10."}, {"ref": "[20] J.A. Dunne, R.J. Williams, and N.D. Martinez. 2002. Food-web structure and network theory: The role of connectance and size. Proceedings of the National Academy of Sciences of the United States of America 99, 20 (2002), 12917."}, {"ref": "[21] M. Faloutsos, P. Faloutsos, and C. Faloutsos. 1999. On power-law relationships of the internet topology. In Proceedings of the ACM SIGCOMM International Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication. 251–262."}, {"ref": "[22] Wenjie Fu, Le Song, and Eric P Xing. 2009. Dynamic mixed membership block- model for evolving networks. In Proceedings of the 26th Annual International Conference on Machine Learning. 329–336."}, {"ref": "[23] David F. Gleich and Ryan A. Rossi. 2014. A Dynamical System for PageRank with Time-Dependent Teleportation. Internet Mathematics (2014), 188–217."}, {"ref": "[24] A. Goyal, F. Bonchi, and L.V.S. Lakshmanan. 2010. Learning influence probabilities in social networks. In WSDM. ACM, 241–250."}, {"ref": "[25] Leo Grady. 2006. Random walks for image segmentation. TPAMI 28, 11 (2006), 1768–1783."}, {"ref": "[26] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In SIGKDD. 855–864."}, {"ref": "[27] Sudipto Guha and Andrew McGregor. 2012. Graph synopses, sketches, and streams: A survey. VLDB 5, 12 (2012), 2030–2031."}, {"ref": "[28] Ryohei Hisano. 2016. Semi-supervised Graph Embedding Approach to Dynamic Link Prediction. arXiv preprint arXiv:1610.04351 (2016)."}, {"ref": "[29] P. Holme and J. Saramäki. 2012. Temporal networks. Physics Reports (2012)."}, {"ref": "[30] Akshay Java, Pranam Kolari, Tim Finin, and Tim Oates. 2006. Modeling the spread of influence on the blogosphere. In WWW. 22–26."}, {"ref": "[31] H. Jeong, S.P. Mason, A.L. Barabasi, and Z.N. Oltvai. 2001. Lethality and centrality in protein networks. arXiv preprint cond-mat/0105306 (2001)."}, {"ref": "[32] H. Jeong, B. Tombor, R. Albert, Z.N. Oltvai, and A.L. Barabási. 2000. The large-scale organization of metabolic networks. Nature 407, 6804 (2000), 651–654."}, {"ref": "[33] Nitin Kamra, Umang Gupta, and Yan Liu. 2017. Deep Generative Dual Memory Network for Continual Learning. arXiv preprint, arXiv:1710.10368 (2017)."}, {"ref": "[34] A. Kleczkowski and B.T. Grenfell. 1999. Mean-field-type equations for spread of epidemics: The small world model. Physica A: Statistical Mechanics and its Applications 274, 1-2 (1999), 355–360."}, {"ref": "[35] V.E. Krebs. 2002. Mapping networks of terrorist cells. Connections 24, 3 (2002), 43–52."}, {"ref": "[36] Jean-Louis Lassez, Ryan Rossi, and Kumar Jeev. 2008. Ranking Links on the Web: Search and Surf Engines. In IEA/AIE. 199–208."}, {"ref": "[37] John Boaz Lee, Ryan Rossi, and Xiangnan Kong. 2017. Deep Graph Attention Model. In arXiv:1709.06075."}, {"ref": "[38] Lizi Liao, Xiangnan He, Hanwang Zhang, and Tat-Seng Chua. 2017. Attributed Social Network Embedding. arXiv preprint arXiv:1705.04969 (2017)."}, {"ref": "[39] W. Liu and L. Lü. 2010. Link prediction based on local random walk. Europhysics Letters 89 (2010), 58007."}, {"ref": "[40] László Lovász. 1993. Random walks on graphs. Combinatorics 2 (1993), 1–46."}, {"ref": "[41] S. Maslov and K. Sneppen. 2002. Specificity and stability in topology of protein networks. Science 296, 5569 (2002), 910–913."}, {"ref": "[42] R.M. May and A.L. Lloyd. 2001. Infection dynamics on scale-free networks. Physical Review E 64, 6 (2001), 66112."}, {"ref": "[43] A. McGovern, L. Friedland, M. Hay, B. Gallagher, A. Fast, J. Neville, and D. Jensen. 2003. Exploiting Relational Structure to Understand Publication Patterns in High-Energy Physics. SIGKDD Explorations 5, 2 (2003), 165–172."}, {"ref": "[44] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. In ICLR Workshop. 10."}, {"ref": "[45] C. Moore and M.E.J. Newman. 2000. Epidemics and percolation in small-world networks. Physical Review E 61, 5 (2000), 5678–5682."}, {"ref": "[46] J. Neville, O. Simsek, D. Jensen, J. Komoroske, K. Palmer, and H. Goldberg. 2005. Using relational knowledge discovery to prevent securities fraud. In Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining. 449–458."}, {"ref": "[47] M.E.J. Newman. 2001. The structure of scientific collaboration networks. Proceedings of the National Academy of Sciences 98, 2 (2001), 404–409."}, {"ref": "[48] Andrew Y Ng, Michael I Jordan, and Yair Weiss. 2002. On spectral clustering: Analysis and an algorithm. In NIPS. 849–856."}, {"ref": "[49] J. O’Madadhain, J. Hutchins, and P. Smyth. 2005. Prediction and ranking algorithms for event-based network data. SIGKDD Explorations 7, 2 (2005), 30."}, {"ref": "[50] L. Page, S. Brin, R. Motwani, and T. Winograd. 1998. PageRank citation ranking: Bringing order to the web. Stanford Tech. Report (1998)."}, {"ref": "[51] R. Pastor-Satorras and A. Vespignani. 2001. Epidemic spreading in scale-free networks. Physical Review Letters 86, 14 (2001), 3200–3203."}, {"ref": "[52] Bryan Perozzi, RamiAl-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In SIGKDD. 701–710."}, {"ref": "[53] Robert Pienta, James Abello, Minsuk Kahng, and Duen Horng Chau.2015.Scalable graph exploration and visualization: Sense making challenges and opportunities. In BigComp. 271–278."}, {"ref": "[54] Pascal Pons and Matthieu Latapy. 2006. Computing communities in large networks using random walks. J. Graph Alg. Appl. 10, 2 (2006), 191–218."}, {"ref": "[55] Stephen Ranshous, ShitianShen, DanaiKoutra, Steve Harenberg, Christos Faloutsos, and Nagiza F Samatova. 2015. Anomaly detection in dynamic networks: a survey. Wiley Interdisc. Rev.: Comp. Stat. 7, 3 (2015), 223–247."}, {"ref": "[56] Leonardo F.R. Ribeiro, Pedro H.P. Saverese, and Daniel R. Figueiredo. 2017. Struc2Vec: Learning Node Representations from Structural Identity. In SIGKDD. 385–394."}, {"ref": "[57] Ryan Rossi and Jennifer Neville. 2012. Time-evolving Relational Classification and Ensemble Methods. In PAKDD. 13."}, {"ref": "[58] Ryan A. Rossi and Nesreen K. Ahmed. 2015. The Network Data Repository with Interactive Graph Analytics and Visualization.InAAAI.4292–4293. http://networkrepository.com"}, {"ref": "[59] Ryan A. Rossi, Brian Gallagher, Jennifer Neville, and Keith Henderson. 2013. Modeling Dynamic Behavior in Large Evolving Graphs. In WSDM. ACM, 667– 676."}, {"ref": "[60] Ryan A. Rossi and Jennifer Neville. 2010. Modeling the Evolution of Discussion Topics and Communication to Improve Relational Classification. In SIGKDD SOMA. 89–97."}, {"ref": "[61] Ryan A. Rossi, Rong Zhou, and Nesreen K. Ahmed. 2017. Deep Feature Learning for Graphs. In arXiv:1704.08829."}, {"ref": "[62] Sergio D Servetto and Guillermo Barrenechea. 2002. Constrained random walks on random graphs: routing algorithms for large scale wireless sensor networks. In Wireless Sensor Networks & App. 12–21."}, {"ref": "[63] Sucheta Soundarajan, Acar Tamersoy, Elias B Khalil, Tina Eliassi-Rad, Duen Horng Chau, Brian Gallagher, and Kevin Roundy. 2016. Generating graph snapshots from streaming edge data. In Proceedings of the 25th International Conference Companion on World Wide Web. 109–110."}, {"ref": "[64] Jimeng Sun, Christos Faloutsos, Spiros Papadimitriou, and Philip S Yu. 2007. GraphScope: parameter-free mining of large time-evolving graphs. In SIGKDD. 687–696."}, {"ref": "[65] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale Information Network Embedding. In WWW. 1067–1077."}, {"ref": "[66] A. Wagner and D.A. Fell. 2001. The small world inside large metabolic networks. Proceedings of the Royal Society of London. Series B: Biological Sciences 268, 1478 (2001), 1803–1810."}, {"ref": "[67] D.J. Watts and S.H. Strogatz. 1998. Collective dynamics of small-world networks. Nature 393, 6684 (1998), 440–442."}]}, {"author": ["Yuan Zuo", "Guannan Liu", "Hao Lin", "Jia Guo", "Xiaoqian Hu", "Junjie Wu"], "title": "Embedding Temporal Network via Neighborhood Formation", "journal": "ACM Knowledge Discovery and Data Mining", "year": 2018, "DOI": "10.1145/3219819.3220054", "month": 8, "citations(google scholar)": 11, "abstract": "Given the rich real-life applications of network mining as well as the surge of representation learning in recent years, network embedding has become the focal point of increasing research interests in both academic and industrial domains. Nevertheless, the complete temporal formation process of networks characterized by sequential interactive events between nodes has yet seldom been modeled in the existing studies, which calls for further research on the so-called temporal network embedding problem. In light of this, in this paper, we introduce the concept of neighborhood formation sequence to describe the evolution of a node, where temporal excitation effects exist between neighbors in the sequence, and thus we propose a Hawkes process based Temporal Network Embedding (HTNE) method. HTNE well integrates the Hawkes process into network embedding so as to capture the influence of historical neighbors on the current neighbors. In particular, the interactions of low-dimensional vectors are fed into the Hawkes process as base rate and temporal influence, respectively. In addition, attention mechanism is also integrated into HTNE to better determine the influence of historical neighbors on current neighbors of a node. Experiments on three large-scale real-life networks demonstrate that the embeddings learned from the proposed HTNE model achieve better performance than state-of-the-art methods in various tasks including node classification, link prediction, and embedding visualization. In particular, temporal recommendation based on arrival rate inferred from node embeddings shows excellent predictive power of the proposed model.", "keywords": ["Temporal Network", "Network Embedding", "Learning Representation", "Hawkes Process"], "reference_count": 30, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Amr Ahmed, Nino Shervashidze, Shravan Narayanamurthy, Vanja Josifovski, and Alexander J. Smola. 2013. Distributed Large-scale Natural Graph Factorization. In WWW. ACM, New York, NY, USA, 37–48."}, {"ref": "[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473."}, {"ref": "[3] Mikhail Belkin and Partha Niyogi. 2001. Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering. In NIPS. MIT Press, Cambridge, MA, USA, 585–591."}, {"ref": "[4] HongYun Cai, Vincent W. Zheng, and Kevin Chen-Chuan Chang. 2017. A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications. CoRR abs/1709.07604 (2017)."}, {"ref": "[5] Sandro Cavallari, Vincent W.Zheng, Hongyun Cai, Kevin Chen-ChuanChang, and Erik Cambria. 2017. Learning Community Embedding with Community Detection and Node Embedding on Graphs. In CIKM. 377–386."}, {"ref": "[6] Quanyu Dai, Qiang Li, Jian Tang, and Dan Wang. 2017. Adversarial Network Embedding. CoRR abs/1711.07838 (2017)."}, {"ref": "[7] Nan Du, Yichen Wang, Niao He, and Le Song. 2015. Time-sensitive Recommendation from Recurrent User Activities. In NIPS. 3492–3500."}, {"ref": "[8] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative Adversarial Nets. In NIPS. MIT Press, Cambridge, MA, USA, 2672–2680."}, {"ref": "[9] Aditya Grover and Jure Leskovec. 2016. Node2Vec: Scalable Feature Learning for Networks. In SIGKDD. ACM, New York, NY, USA, 855–864."}, {"ref": "[10] William L. Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. CoRR abs/1706.02216 (2017)."}, {"ref": "[11] Alan G Hawkes. 1971. Spectra of some self-exciting and mutually exciting point processes. Biometrika 58, 1 (1971), 83–90."}, {"ref": "[12] Petter Holme and Jari SaramÃďki. 2012. Temporal networks. Physics Reports 519, 3 (2012), 97 – 125."}, {"ref": "[13] Joseph B Kruskal and Myron Wish. 1978. Multidimensional Scaling. CRC press. 875–878 pages."}, {"ref": "[14] RÃľmi Lemonnier, Kevin Scaman, and Argyris Kalogeratos. 2017. Multivariate Hawkes Processes for Large-Scale Inference. In AAAI."}, {"ref": "[15] Remi Lemonnier and Nicolas Vayatis. 2014. Nonparametric Markovian Learning of Triggering Kernels for Mutually Exciting and Mutually Inhibiting Multivariate Hawkes Processes. In Machine Learning and Knowledge Discovery in Databases. 161–176."}, {"ref": "[16] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. CoRR abs/1301.3781 (2013)."}, {"ref": "[17] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean.2013. Distributed Representations of Words and Phrases and Their Compositionality. In NIPS. Curran Associates Inc., USA, 3111–3119."}, {"ref": "[18] Tomas Mikolov, Ilya Sutskever, Kai Chen, GregSCorrado, and JeffDean.2013. Distributed Representations of Words and Phrases and their Compositionality. In NIPS. 3111–3119."}, {"ref": "[19] Shirui Pan, Jia Wu, Xingquan Zhu, Chengqi Zhang, and Yang Wang. 2016. Triparty Deep Network Representation. In IJCAI. AAAI Press, 1895–1901."}, {"ref": "[20] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: Online Learn- ing of Social Representations. In SIGKDD. ACM, New York, NY, USA, 701–710."}, {"ref": "[21] Sam T. Roweis and Lawrence K. Saul. 2000. Nonlinear Dimensionality Reduction by Locally Linear Embedding. Science 290, 5500 (2000), 2323–2326."}, {"ref": "[22] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale Information Network Embedding. In WWW. International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, 1067–1077."}, {"ref": "[23] Joshua B. Tenenbaum, Vin de Silva, and John C. Langford. 2000. A Global Geometric Framework for Nonlinear Dimensionality Reduction. Science 290, 5500 (2000), 2319–2323."}, {"ref": "[24] Laurens van der Maaten and Geoffrey E. Hinton. 2008. Visualizing High- Dimensional Data Using t-SNE. JMLR 9 (2008), 2579–2605."}, {"ref": "[25] Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural Deep Network Em- bedding. In SIGKDD. ACM, New York, NY, USA, 1225–1234."}, {"ref": "[26] Hongwei Wang, Jia Wang, Jialin Wang, Miao Zhao, Weinan Zhang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2017. GraphGAN: Graph Representation Learning with Generative Adversarial Nets. CoRR abs/1711.08267 (2017)."}, {"ref": "[27] Jingyuan Wang, Fei Gao, Peng Cui, Chao Li, and Zhang Xiong. 2014. Discovering urban spatiotemporal structure from time-evolving traffic networks. In Proceedings of the 16th Asia-Pacific Web Conference. Springer International Publishing, 93–104."}, {"ref": "[28] Xiao Wang, Peng Cui, Jing Wang, Jian Pei, Wenwu Zhu, and Shiqiang Yang. 2017. Community Preserving Network Embedding."}, {"ref": "[29] Lekui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. 2018. Dynamic Network Embedding by Modeling Triadic Closure Process. In The AAAI Conference on Artificial Intelligence."}, {"ref": "[30] L. Zhu, D. Guo, J. Yin, G. V. Steeg, and A. Galstyan. 2016. Scalable Temporal Latent Space Inference for Link Prediction in Dynamic Social Networks. IEEE Transactions on Knowledge and Data Engineering 28, 10 (Oct 2016), 2765–2777."}]}, {"author": ["Wenchao Yu", "Wei Cheng", "Charu C. Aggarwal", "Kai Zhang", "Haifeng Chen", "Wei Wang"], "title": "NetWalk: A Flexible Deep Embedding Approach for Anomaly Detection in Dynamic Networks", "journal": "ACM Knowledge Discovery and Data Mining", "year": 2018, "DOI": "10.1145/3219819.3220024", "month": 8, "citations(google scholar)": 15, "abstract": "Massive and dynamic networks arise in many practical applications such as social media, security and public health. Given an evolutionary network, it is crucial to detect structural anomalies, such as vertices and edges whose “behaviors” deviate from underlying majority of the network, in a real-time fashion. Recently, network embedding has proven a powerful tool in learning the low-dimensional representations of vertices in networks that can capture and preserve the network structure. However, most existing network embedding approaches are designed for static networks, and thus may not be perfectly suited for a dynamic environment in which the network representation has to be constantly updated. In this paper, we propose a novel approach, NetWalk, for anomaly detection in dynamic networks by learning network representations which can be updated dynamically as the network evolves. We first encode the vertices of the dynamic network to vector representations by clique embedding, which jointly minimizes the pairwise distance of vertex representations of each walk derived from the dynamic networks, and the deep autoencoder reconstruction error serving as a global regularization. The vector representations can be computed with constant space requirements using reservoir sampling. On the basis of the learned low-dimensional vertex representations, a clustering-based technique is employed to incrementally and dynamically detect network anomalies. Compared with existing approaches, NetWalk has several advantages: 1) the network embedding can be updated dynamically, 2) streaming network nodes and edges can be encoded efficiently with constant memory space usage, 3). flexible to be applied on different types of networks, and 4) network anomalies can be detected in real- time. Extensive experiments on four real datasets demonstrate the effectiveness of NetWalk.", "keywords": ["Anomaly detection", "dynamic network embedding", "deep autoencoder", "clique embedding"], "reference_count": 44, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Charu C Aggarwal. 2013. Outlier Analysis. Springer."}, {"ref": "[2] Charu C Aggarwal, Yuchen Zhao, and S Yu Philip. 2010. On Clustering Graph Streams.. In SDM. SIAM, 478–489."}, {"ref": "[3] Charu C Aggarwal, Yuchen Zhao, and S Yu Philip. 2011. Outlier detection in graph streams. In ICDE. IEEE, 399–409."}, {"ref": "[4] Nir Ailon, Ragesh Jaiswal, and Claire Monteleoni. 2009. Streaming k-means approximation. In NIPS. 10–18."}, {"ref": "[5] LemanAkogluandChristosFaloutsos.2013.Anomaly,event,andfrauddetection in large network datasets. In WSDM. ACM, 773–774."}, {"ref": "[6] LemanAkoglu,MaryMcGlohon,andChristosFaloutsos.2010.Oddball:Spotting anomalies in weighted graphs. In PAKDD. Springer, 410–421."}, {"ref": "[7] Leman Akoglu, Hanghang Tong, and Danai Koutra. 2015. Graph based anomaly detection and description: a survey. Data Mining and Knowledge Discovery 29, 3 (2015), 626–688."}, {"ref": "[8] Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and Christian Jauvin. 2003. A neural probabilistic language model. JMLR 3, Feb (2003), 1137–1155."}, {"ref": "[9] Shiyu Chang, Wei Han, Jiliang Tang, Guo-Jun Qi, Charu C Aggarwal, and Thomas S Huang. 2015. Heterogeneous network embedding via deep archi-tectures. In SIGKDD. ACM, 119–128."}, {"ref": "[10] WeiCheng,KaiZhang,HaifengChen,GuofeiJiang,andWeiWang.2016.Ranking Causal Anomalies via Temporal and Dynamical Analysis on Vanishing Correla-tions. In SIGKDD."}, {"ref": "[11] Graham Cormode and S Muthukrishnan. 2005. An improved data stream sum-mary: the count-min sketch and its applications. Journal of Algorithms 55, 1 (2005), 58–75."}, {"ref": "[12] Aaron Defazio, Francis R. Bach, and Simon Lacoste-Julien. 2014. SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives. In NIPS. 1646–1654."}, {"ref": "[13] William Eberle and Lawrence Holder. 2007. Anomaly detection in data repre- sented as graphs. Intelligent Data Analysis 11, 6 (2007), 663–689."}, {"ref": "[14] Jing Gao, Feng Liang, Wei Fan, Chi Wang, Yizhou Sun, and Jiawei Han. 2010. On community outliers and their efficient detection in information networks. In SIGKDD. ACM, 813–822."}, {"ref": "[15] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. (2016)."}, {"ref": "[16] Manish Gupta, Jing Gao, Charu C Aggarwal, and Jiawei Han. 2014. Outlier Detection for Temporal Data: A Survey. TKDE 9, 26 (2014), 2250–2267."}, {"ref": "[17] Manish Gupta, Jing Gao, Yizhou Sun, and Jiawei Han. 2012. Community trend outlier detection using soft temporal pattern mining. In ECML/PKDD. Springer, 692–708."}, {"ref": "[18] Manish Gupta, Jing Gao, Yizhou Sun, and Jiawei Han. 2012. Integrating community matching and outlier detection for mining evolutionary community outliers. In SIGKDD. ACM, 859–867."}, {"ref": "[19] ManishGupta,ArunMallya,SubhroRoy,JasonHDCho,andJiaweiHan.2014. Local Learning for Mining Outlier Subgraphs from Network Datasets. In SDM. 73–81."}, {"ref": "[20] Piotr Indyk and Rajeev Motwani. 1998. Approximate nearest neighbors: towards removing the curse of dimensionality. In ACM Symposium on Theory of Computing. ACM, 604–613."}, {"ref": "[21] Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. 2007. Graph evolution: Densification and shrinking diameters. TKDD 1, 1 (2007), 2."}, {"ref": "[22] Omer Levy and Yoav Goldberg. 2014. Neural word embedding as implicit matrix factorization. In NIPS. 2177–2185."}, {"ref": "[23] Emaad A Manzoor, Sadegh Momeni, Venkat N Venkatakrishnan, and Leman Akoglu. 2016. Fast Memory-efficient Anomaly Detection in Streaming Heterogeneous Graphs. In KDD."}, {"ref": "[24] Ryan McConville, Weiru Liu, and Paul Miller. 2015. Vertex clustering of augmented graph streams. SDM (2015)."}, {"ref": "[25] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 (2013)."}, {"ref": "[26] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In NIPS. 3111–3119."}, {"ref": "[27] Andrew Ng. 2011. Sparse autoencoder. CS294A Lecture notes 72, 2011 (2011), 1–19."}, {"ref": "[28] ToreOpsahlandPietroPanzarasa.2009.Clusteringinweightednetworks.Social networks (2009), 155–163."}, {"ref": "[29] Bryan Perozzi and Leman Akoglu. 2016. Scalable anomaly ranking of attributed neighborhoods. In SDM. SIAM, 207–215."}, {"ref": "[30] BryanPerozzi,LemanAkoglu,PatriciaIglesiasSánchez,andEmmanuelMüller. 2014. Focused Clustering and Outlier Detection in Large Attributed Graphs. In SIGKDD. 1346–1355."}, {"ref": "[31] BryanPerozzi,RamiAl-Rfou,andStevenSkiena.2014.Deepwalk:Onlinelearning of social representations. In SIGKDD. ACM, 701–710."}, {"ref": "[32] StephenRanshous,SteveHarenberg,KshitijSharma,NagizaFSamatova,etal. 2016. A Scalable Approach for Outlier Detection in Edge Streams Using Sketch- based Approximations. In SDM."}, {"ref": "[33] StephenRanshous,ShitianShen,DanaiKoutra,SteveHarenberg,ChristosFalout- sos, and Nagiza F Samatova. 2015. Anomaly detection in dynamic networks: a survey. Wiley Interdisciplinary Reviews: Computational Statistics 7, 3 (2015), 223–247."}, {"ref": "[34] David E Rumelhart, Geoffrey E Hinton, Ronald J Williams, et al. 1988. Learning representations by back-propagating errors. Cognitive modeling 5, 3 (1988), 1."}, {"ref": "[35] JimengSun,HuimingQu,DeepayanChakrabarti,andChristosFaloutsos.2005. Neighborhood formation and anomaly detection in bipartite graphs. In ICDM. IEEE, 8–17."}, {"ref": "[36] JianTang,MengQu,MingzheWang,MingZhang,JunYan,andQiaozhuMei.2015. Line: Large-scale information network embedding. In WWW. ACM, 1067–1077."}, {"ref": "[37] FeiTian,BinGao,QingCui,EnhongChen,andTie-YanLiu.2014.Learning Deep Representations for Graph Clustering.. In AAAI. 1293–1299."}, {"ref": "[38] Ulrike Von Luxburg. 2007. A tutorial on spectral clustering. Statistics and computing 17, 4 (2007), 395–416."}, {"ref": "[39] Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural deep network embedding. In SIGKDD. ACM, 1225–1234."}, {"ref": "[40] Wenchao Yu, Charu C Aggarwal, and Wei Wang. 2017. Temporally factorized network modeling for evolutionary network analysis. In WSDM. ACM, 455–464."}, {"ref": "[41] Wenchao Yu, Guangxiang Zeng, Ping Luo, Fuzhen Zhuang, Qing He, and Zhongzhi Shi. 2013. Embedding with autoencoder regularization. In ECML/PKDD. Springer, 208–223."}, {"ref": "[42] Wayne W Zachary. 1977. An information flow model for conflict and fission in small groups. Journal of Anthropological Research (1977), 452–473."}, {"ref": "[43] Yuchen Zhao and Philip Yu. 2013. On graph stream clustering with side information. In SDM. SIAM, 139–150."}, {"ref": "[44] Lekui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. 2018. Dynamic Network Embedding by Modeling Triadic Closure Process. (2018)."}]}, {"author": ["Ying Yin", "Li Xin Ji", "Jian Peng Zhang", "Yu Long Pei"], "title": "DHNE: Network Representation Learning Method for Dynamic Heterogeneous Networks", "journal": "IEEE Access", "year": 2019, "DOI": "10.1109/access.2019.2942221", "month": 8, "citations(google scholar)": 0, "abstract": "Analyzing the rich information behind heterogeneous networks through network representation learning methods is significant for many application tasks such as link prediction, node classification and similarity research. As the networks evolve over times, the interactions among the nodes in networks make heterogeneous networks exhibit dynamic characteristics. However, almost all the existing heterogeneous network representation learning methods focus on static networks which ignore dynamic characteristics. In this paper, we propose a novel approach DHNE to learn the representations of nodes in dynamic heterogeneous networks. The key idea of our approach is to construct comprehensive historical-current networks based on subgraphs of snapshots in time step to capture both the historical and current information in the dynamic heterogeneous network. And then under the guidance of meta paths, DHNE performs random walks on the constructed historical-current graphs to capture semantic information. After getting the node sequences through random walks, we propose the dynamic heterogeneous skip-gram model to learn the embeddings. Experiments on large-scale real-world networks demonstrate that the embeddings learned by the proposed DHNE model achieve better performances than state-of-the-art methods in various downstream tasks including node classification and visualization.", "keywords": ["Dynamic heterogeneous networks", "network representation learning", "random walk", "skip-gram model"], "reference_count": 29, "ccfClass": "", "important": true, "references": [{"ref": "[1] C. Luo, R. Guan, Z. Wang, and C. Lin, ‘‘HetPathMine: A novel transductive classification algorithm on heterogeneous information networks,’’ in Proc. Eur. Conf. Inf. Retr., Cologne, Germany, 2014, pp. 210–221."}, {"ref": "[2] Y.Sun,J.Han,X.Yan,P.S.Yu,andT.Wu,‘‘PathSim: Metapath-based top-K similarity search in heterogeneous information networks,’’ Proc. VLDB Endowment, vol. 4, no. 11, pp. 992–1003, 2011."}, {"ref": "[3] Y. Sun, R. Barber, M. Gupta, C. C. Aggarwal, and J. Han, ‘‘Co-author relationship prediction in heterogeneous bibliographic networks,’’ in Proc. Int. Conf. Adv. Social Netw. Anal. Mining, Kaohsiung, Taiwan, Jul. 2011, pp. 121–128."}, {"ref": "[4] Y. Dong, N. V. Chawla, and A. Swami, ‘‘Metapath2vec: Scalable representation learning for heterogeneous networks,’’ in Proc. 23rd ACM SIGKDD Int. Conf. Knowl. Discovery Data, Halifax, NS, Canada, 2017, pp. 135–144."}, {"ref": "[5] J. Tang, M. Qu, and Q. Mei, ‘‘PTE: Predictive text embedding through large-scale heterogeneous text networks,’’ in Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, Sydney, NSW, Australia, 2015, pp. 1165–1174."}, {"ref": "[6] B. Perozzi, R. Al-Rfou, and S. Skiena, ‘‘DeepWalk: Online learning of social representations,’’ in Proc. 20th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, New York, NY, USA, 2014, pp. 701–710."}, {"ref": "[7] T.Mikolov,K.Chen,G.Corrado,andJ.Dean,‘‘Efcientestimationofword representations in vector space,’’ in Proc. Int. Conf. Learn. Represent., Scottsdale, AZ, USA, 2013, pp. 1–12."}, {"ref": "[8] A. Grover and J. Leskovec, ‘‘Node2vec: Scalable feature learning for networks,’’ in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery data Mining, New York, NY, USA, 2016, pp. 855–864."}, {"ref": "[9] D. Wang, P. Cui, and W. Zhu, ‘‘Structural deep network embedding,’’ in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, New York, NY, USA, 2016, pp. 1225–1234."}, {"ref": "[10] H. Wang, J. Wang, J. Wang, M. Zhao, W. Zhang, F. Zhang, X. Xie, and M. Guo, ‘‘GraphGAN: Graph representation learning with generative adversarial nets,’’ in Proc. 32nd AAAI Conf. Artif. Intell., New Orleans, LA, USA, 2018, pp. 2508–2515."}, {"ref": "[11] Q.Dai,Q.Li,J.Tang,andD.Wang,‘‘Adversarialnetworkembedding,’’ in Proc. 32nd AAAI Conf. Artif. Intell., New Orleans, LA, USA, 2018, pp. 2167–2174."}, {"ref": "[12] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, ‘‘Generative adversarial nets,’’ in Proc. Adv. Neural Inf. Process. Syst., Montreal, QC, Canada, 2014, pp. 2672–2680."}, {"ref": "[13] J.Li,H.Dani,X.Hu,J.Tang,Y.Chang,andH.Liu,‘‘Attributednetwork embedding for learning in a dynamic environment,’’ in Proc. ACM Conf. Inf. Knowl. Manage., Singapore, 2017, pp. 387–396."}, {"ref": "[14] D. Zhu, C. Peng, Z. Zhang, P. Jian, and W. Zhu, ‘‘High-order proximity preserved embedding for dynamic networks,’’ IEEE Trans. Knowl. Data Eng., vol. 30, no. 11, pp. 2134–2144, Nov. 2018."}, {"ref": "[15] L.Du,Y.Wang,G.Song,Z.Lu,andJ.Wang,‘‘Dynamicnetworkembed- ding: An extended approach for skip-gram based network embedding,’’ in Proc. 27th Int. Joint Conf. Artif. Intell., Stockholm, Sweden, 2018, pp. 2086–2092."}, {"ref": "[16] G. H. Nguyen, J. B. Lee, R. A. Rossi, N. K. Ahmed, and S. Kim, ‘‘Continuous-time dynamic network embeddings,’’ in Proc. Companion Web Conf. Int. World Wide Web Conf., Lyon, France, 2018, pp. 969–976."}, {"ref": "[17] P.Cui,X.Wang,J.Pei,andW.Zhu,‘‘Asurveyonnetworkembedding,’’ IEEE Trans. Knowl. Data Eng., vol. 31, no. 5, pp. 833–852, May 2018."}, {"ref": "[18] P. Goyal and E. Ferrara, ‘‘Graph embedding techniques, applications, and performance: A survey,’’ Knowl.-Based Syst., vol. 151, pp. 78–94, Jul. 2018."}, {"ref": "[19] W. L. Hamilton, R. Ying, and J. Leskovec, ‘‘Representation learning on graphs: Methods and applications,’’ IEEE Data Eng. Bulletin., vol. 40, no. 3, pp. 52–74, 2017."}, {"ref": "[20] J. Tang, M. Qu, M. Z. Wang, M. Zhang, J. Yan, and Q. Z. Mei, ‘‘Line: Large-scale information network embedding,’’ in Proc. 24th Int. Conf. World Wide Web, Florence, Italy, 2015, pp. 1067–1077."}, {"ref": "[21] S.Y.Chang,W.Han,J.Tang,G.J.Qi,C.C.Aggarwal,andS.THuang, ‘‘Heterogeneous network embedding via deep architectures,’’ in Proc. 21th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, Sydney, NSW, Australia, 2015, pp. 119–128."}, {"ref": "[22] C. Shi, C. Zhou, X. Kong, P. Yu, G. Liu, and B. Wang, ‘‘HeteRecom: A semantic-based recommendation system in heterogeneous networks,’’ in Proc. 18th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, Beijing, China, 2012, pp. 1552–1555."}, {"ref": "[23] T. Chen and Y. Sun, ‘‘Task-guided and path-augmented heterogeneous network embedding for author identification,’’ in Proc. 10th ACM Int. Conf. Web Search Data Mining, Cambridge, U.K., 2017, pp. 295–304."}, {"ref": "[24] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, ‘‘Dis- tributed representations of words and phrases and their compositionality,’’ in Proc. Adv. Neural Inf. Process. Syst., Lake Tahoe, CA, USA, 2013, pp. 3111–3119."}, {"ref": "[25] L.Bottou,‘‘Stochasticgradientlearninginneuralnetworks,’’Proc.Neuro- Nımes, vol. 91, no. 8, p. 12, 1991."}, {"ref": "[26] C.Moreira,P.Calado,andB.Martins,‘‘Learningtorankacademicexperts in the DBLP dataset,’’ Expert Syst., vol. 32, no. 4, pp. 477–493, 2015."}, {"ref": "[27] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su, ‘‘Arnetminer: Extraction and mining of academic social networks,’’ in Proc. 14th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, Las Vegas, NV, USA, 2008, pp. 990–998."}, {"ref": "[28] Y. Zuo, G. N. Liu, H. Lin, J. Guo, X. Hu, and J. Wu, ‘‘Embedding temporal network via neighborhood formation,’’ in Proc. 24th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, London, U.K., 2018, pp. 2857–2866."}, {"ref": "[29] S. Fortunato, ‘‘Community detection in graphs,’’ Phys. Rep., vol. 486, nos. 3–5, pp. 75–174, 2010."}]}, {"author": ["Hao Peng", "Jianxin Li", "Hao Yan", "Qiran Gong", "Senzhang Wang", "Lin Liu", "Lihong Wang", "Xiang Ren"], "title": "Dynamic Network Embedding via Incremental Skip-gram with Negative Sampling", "journal": "Science China Information Sciences", "year": 2019, "DOI": "arXiv:1906.03586v1", "month": 6, "citations(google scholar)": 0, "abstract": "Network representation learning, as an approach to learn low dimensional representations of vertices, has attracted considerable research attention recently. It has been proven extremely useful in many machine learning tasks over large graph. Most existing methods focus on learning the structural representations of vertices in a static network, but cannot guarantee an accurate and efficient embedding in a dynamic network scenario. The fundamental problem of continuously capturing the dynamic properties in an efficient way for a dynamic network remains unsolved. To address this issue, we present an efficient incremental skip-gram algorithm with negative sampling for dynamic network embedding, and provide a set of theoretical analyses to characterize the performance guarantee. Specifically, we first partition a dynamic network into the updated, including addition/deletion of links and vertices, and the retained networks over time. Then we factorize the objective function of network embedding into the added, vanished and retained parts of the network. Next we provide a new stochastic gradient-based method, guided by the partitions of the network, to update the nodes and the parameter vectors. The proposed algorithm is proven to yield an objective function value with a bounded difference to that of the original objective function. The first order moment of the objective difference converges in order of O( 1 ), and the second order moment of the n2 objective difference can be stabilized in order of O(1). Experimental results show that our proposal can significantly reduce the training time while preserving the comparable performance. We also demonstrate the correctness of the theoretical analysis and the practical usefulness of the dynamic network embedding. We perform extensive experiments on multiple real-world large network datasets over multi-label classification and link prediction tasks to evaluate the effectiveness and efficiency of the proposed framework, and up to 22 times speedup has been achieved.", "keywords": ["Dynamic Network Embedding", "Bound and Convergence Analysis", "Multi-label Classification", "Link Prediction"], "reference_count": 45, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Shaosheng Cao, Wei Lu, and Qiongkai Xu. Grarep:learning graph representations with global structural information. In CIKM, 2015."}, {"ref": "[2] Sandro Cavallari, Vincent W Zheng, Hongyun Cai, Chen Chuan Chang, and Erik Cambria. Learning community embedding with community detection and node embedding on graphs. In CIKM, 2017."}, {"ref": "[3] Jifan Chen, Qi Zhang, and Xuanjing Huang. Incorporate group information to enhance network embedding. In CIKM, 2016."}, {"ref": "[4] Peng Cui, Xiao Wang, Jian Pei, and Wenwu Zhu. A survey on network embedding. IEEE Transactions on Knowledge and Data Engineering, 2018."}, {"ref": "[5] Claire Donnat, Marinka Zitnik, David Hallac, and Jure Leskovec. Learning structural node embeddings via diffusion wavelets. In KDD, 2018."}, {"ref": "[6] Lun Du, Yun Wang, Guojie Song, Zhicong Lu, and Junshan Wang. Dynamic network embedding: An extended approach for skip-gram based network embedding. In IJCAI, 2018."}, {"ref": "[7] Rong En Fan, Kai Wei Chang, Cho Jui Hsieh, Xiang Rui Wang, and Chih Jen Lin. Liblinear: A library for large linear classification. JMLR, 2008."}, {"ref": "[8] Palash Goyal and Emilio Ferrara. Graph embedding techniques, applications, and performance: A survey. Knowledge-Based Systems, 2018."}, {"ref": "[9] Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In KDD, 2016."}, {"ref": "[10] Michael Gutmann and Aapo Hyva ̈rinen. Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics. JMLR, 2012."}, {"ref": "[11] Michael U. Gutmann. Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics. JMLR.org, 2012."}, {"ref": "[12] William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In NIPS, 2017."}, {"ref": "[13] William L Hamilton, Rex Ying, and Jure Leskovec. Representation learning on graphs: Methods and applications. In IEEE Data Engineering Bulletin, 2017."}, {"ref": "[14] Renjun Hu, Charu C Aggarwal, Shuai Ma, and Jinpeng Huai. An embedding approach to anomaly detection. In 2016 IEEE 32nd International Conference on Data Engineering (ICDE), pages 385–396. IEEE, 2016."}, {"ref": "[15] Ling Jian, Jundong Li, and Huan Liu. Toward online node classification on streaming networks. DMKD, 2018."}, {"ref": "[16] Nobuhiro Kaji and Hayato Kobayashi. Incremental skip-gram model with negative sampling. In EMNLP, 2017."}, {"ref": "[17] Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. Graph evolution:densification and shrinking diameters. TKDD, 2007."}, {"ref": "[18] O. Levy and Y. Goldberg. Neural word embedding as implicit matrix factorization. 2014."}, {"ref": "[19] Jundong Li, Harsh Dani, Xia Hu, Jiliang Tang, Yi Chang, and Huan Liu. Attributed network embedding for learning in a dynamic environment. In CIKM, 2017."}, {"ref": "[20] Tong Man, Huawei Shen, Shenghua Liu, Xiaolong Jin, and Xueqi Cheng. Predict anchor links across social networks via an embedding approach. In IJCAI, 2016."}, {"ref": "[21] Julian Mcauley and Jure Leskovec. Learning to discover social circles in ego networks. In NIPS, 2012."}, {"ref": "[22] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. Computer Science, 2013."}, {"ref": "[23] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. Distributed representations of words and phrases and their compositionality. In NIPS, 2013."}, {"ref": "[24] Andriy Mnih and Yee Whye Teh. A fast and simple algorithm for training neural probabilistic language models. Computer Science, 2012."}, {"ref": "[25] Frederic Morin and Yoshua Bengio. Hierarchical probabilistic neural network language model. In AISTATS, 2005."}, {"ref": "[26] Hao Peng, Mengjiao Bao, Jianxin Li, Md Zakirul Alam Bhuiyan, Yaopeng Liu, Yu He, and Erica Yang. Incremental term representation learning for social network analysis. Future Generation Computer Systems, 86:1503–1512, 2018."}, {"ref": "[27] Hao Peng, Jianxin Li, Yangqiu Song, and Yaopeng Liu. Incrementally learning the hierarchical softmax function for neural language models. In AAAI, 2017."}, {"ref": "[28] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: online learning of social representations. In KDD, 2014."}, {"ref": "[29] Xiang Ren, Wenqi He, Meng Qu, Clare R. Voss, Heng Ji, and Jiawei Han. Label noise reduction in entity typing by heterogeneous partial-label embedding. In KDD, 2016."}, {"ref": "[30] Zafarani Reza and Liu Huan. Social computing data repository."}, {"ref": "[31] Leonardo F. R Ribeiro, Pedro H. P Saverese, and Daniel R Figueiredo. struc2vec : Learning node representations from structural identity. In KDD, 2017."}, {"ref": "[32] Maja Rudolph and David Blei. Dynamic bernoulli embeddings for language evolution. In WWW, 2018."}, {"ref": "[33] Chuan Shi, Binbin Hu, Wayne Xin Zhao, and S Yu Philip. Heterogeneous information network embedding for recommendation. IEEE Transactions on Knowledge and Data Engineering, 31(2):357–370, 2018."}, {"ref": "[34] Ananthram Swami, Ananthram Swami, and Ananthram Swami. metapath2vec: Scalable representation learning for heterogeneous networks. In KDD, 2017."}, {"ref": "[35] Jian Tang, Meng Qu, and Qiaozhu Mei. Pte: Predictive text embedding through large-scale heterogeneous text networks. In KDD, 2015."}, {"ref": "[36] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. Line: Large-scale information network embedding. In WWW, 2015."}, {"ref": "[37] Lei Tang and Huan Liu. Relational learning via latent social dimensions. In KDD, 2009."}, {"ref": "[38] Rakshit Trivedi, Hanjun Dai, Yichen Wang, and Le Song. Know-evolve: Deep temporal reasoning for dynamic knowledge graphs. In ICML, 2017."}, {"ref": "[39] Daixin Wang, Peng Cui, and Wenwu Zhu. Structural deep network embedding. In KDD, 2016."}, {"ref": "[40] Kevin S. Xu and Alfred O. Hero. Dynamic stochastic blockmodels: Statistical models for time-evolving networks. In SBP-BRiMS, 2013."}, {"ref": "[41] Cheng Yang, Maosong Sun, Zhiyuan Liu, and Cunchao Tu. Fast network embedding enhancement via high order proximity approximation. In IJCAI, 2017."}, {"ref": "[42] Jaewon Yang and J. Leskovec. Defining and evaluating network communities based on ground-truth. In ACM SIGKDD Workshop on Mining Data Semantics, 2012."}, {"ref": "[43] L. Zhou, Y. Yang, X. Ren, F. Wu, and Y. Zhuang. Dynamic Network Embedding by Modelling Triadic Closure Process. In AAAI, 2018."}, {"ref": "[44] Linhong Zhu, Dong Guo, Junming Yin, Greg Ver Steeg, and Aram Galstyan. Scalable temporal latent space inference for link prediction in dynamic social networks. TKDE, 2016."}, {"ref": "[45] Yuan Zuo, Guannan Liu, Hao Lin, Jia Guo, Xiaoqian Hu, and Junjie Wu. Embedding temporal network via neighborhood formation. In KDD, 2018."}]}, {"author": ["Benyun Shi", "Jianan Zhong", "Qing Bao", "Hongjun Qiu", "Jiming Liu"], "title": "EpiRep: Learning Node Representations through Epidemic Dynamics on Networks", "journal": "ACM International Conference on Web Intelligence", "year": 2019, "DOI": "10.1145/3350546.3360738", "month": 10, "citations(google scholar)": 0, "abstract": "Understanding the dynamic properties of epidemic spreading on complex social networks is essential to make effective and efficient public health policies for epidemic prevention and control. In recent years, the concept of network embedding has attracted lots of attention to deal with various network analytic tasks, the purpose of which is to encode relationships or information of networked elements into a low-dimensional vector space. However, most existing embedding methods have focused mainly on preserving static network information, such as structural proximity, node/edge attributes, and labels. On the contrary, in this paper, we focus on the embedding problem of preserving dynamic characteristics of epidemic spreading on social networks. We propose a novel embedding method, namely EpiRep, to learn node representations of a network by maximizing the likelihood of preserving groups of infected nodes due to the epidemics starting from every single node on the network. Specifically, the Susceptible-Infectious model is adopted to simulate the epidemic dynamics on networks, and the Continuous Bag-of-Words model with negative sampling is used to obtain node representations. Experimental results show that the EpiRep method outperforms two benchmark random-walk based embedding methods in terms of node clustering and classification on several synthetic and real-world networks. The proposed method and findings in this paper may offer new insight for source identification and infection prevention in the face of epidemic spreading on social networks.", "keywords": ["Network embedding", "Susceptible-Infectious model", "Random walks", "Continuous Bag-of-Words", "Epidemic dynamics"], "reference_count": 40, "ccfClass": "", "important": true, "references": [{"ref": "[1] Amr Ahmed, Nino Shervashidze, Shravan Narayanamurthy, Vanja Josifovski, and Alexander J Smola. 2013. Distributed large-scale natural graph factorization. In Proceedings of the 22nd International Conference on World Wide Web. ACM, 37–48."}, {"ref": "[2] Réka Albert and Albert-László Barabási. 2002. Statistical mechanics of complex networks. Reviews of Modern Physics 74, 1 (2002), 47."}, {"ref": "[3] Linda J. S. Allen. 1994. Some discrete-time SI, SIR, and SIS epidemic models. Mathematical Biosciences 124, 1 (1994), 83–105."}, {"ref": "[4] Danielle S Bassett and Olaf Sporns. 2017. Network neuroscience. Nature Neuro-science 20, 3 (2017), 353."}, {"ref": "[5] Mikhail Belkin and Partha Niyogi. 2002. Laplacian eigenmaps and spectral techniques for embedding and clustering. In Advances in Neural Information Processing Systems. 585–591."}, {"ref": "[6] Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence 35, 8 (2013), 1798–1828."}, {"ref": "[7] Stefano Boccaletti, Vito Latora, Yamir Moreno, Martin Chavez, and D-U Hwang. 2006. Complex networks: Structure and dynamics. Physics Reports 424, 4-5 (2006), 175–308."}, {"ref": "[8] Stephen P Borgatti, Ajay Mehra, Daniel J Brass, and Giuseppe Labianca. 2009. Network analysis in the social sciences. Science 323, 5916 (2009), 892–895."}, {"ref": "[9] Zhan Bu, Hui-Jia Li, Chengcui Zhang, Jie Cao, Aihua Li, and Yong Shi. 2019. Graph k-means based on leader identification, dynamic game and opinion dynamics. IEEE Transactions on Knowledge and Data Engineering (2019)."}, {"ref": "[10] Jie Cao, Zhan Bu, Yuyao Wang, Huan Yang, Jiuchuan Jiang, and Hui-Jia Li. 2019. Detecting prosumer-community groups in smart grids from the multiagent perspective. IEEE Transactions on Systems, Man, and Cybernetics: Systems (2019)."}, {"ref": "[11] Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2015. GraRep: Learning graph rep- resentations with global structural information. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 891–900."}, {"ref": "[12] Peng Cui, Xiao Wang, Jian Pei, and Wenwu Zhu. 2018. A survey on network embedding. IEEE Transactions on Knowledge and Data Engineering (2018)."}, {"ref": "[13] Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable representation learning for heterogeneous networks. In Proceedings of the 23rd ACM International Conference on Knowledge Discovery and Data Mining. ACM, 135–144."}, {"ref": "[14] Santo Fortunato. 2010. Community detection in graphs. Physics Reports 486, 3-5 (2010), 75–174."}, {"ref": "[15] Daniel T Gillespie. 1977. Exact stochastic simulation of coupled chemical reac- tions. The Journal of Physical Chemistry 81, 25 (1977), 2340–2361."}, {"ref": "[16] Michelle Girvan and Mark EJ Newman. 2002. Community structure in social and biological networks. Proceedings of the National Academy of Sciences 99, 12 (2002), 7821–7826."}, {"ref": "[17] PalashGoyalandEmilioFerrara.2018.Graphembeddingtechniques,applications, and performance: A survey. Knowledge-Based Systems 151 (2018), 78–94."}, {"ref": "[18] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM International Conference on Knowledge Discovery and Data Mining. ACM, 855–864."}, {"ref": "[19] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems. 1024–1034."}, {"ref": "[20] William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Representation learning on graphs: Methods and applications. arXiv preprint arXiv:1709.05584 (2017)."}, {"ref": "[21] Xiao Huang, Jundong Li, and Xia Hu. 2017. Accelerated attributed network embedding. In Proceedings of the 2017 SIAM International Conference on Data Mining. SIAM, 633–641."}, {"ref": "[22] Xiao Huang, Jundong Li, and Xia Hu. 2017. Label informed attributed network embedding. In Proceedings of the 10th ACM International Conference on Web Search and Data Mining. ACM, 731–739."}, {"ref": "[23] Steve Lawrence and C Lee Giles. 1998. Searching the world wide web. Science 280, 5360 (1998), 98–100."}, {"ref": "[24] Tianshu Lyu, Yuan Zhang, and Yan Zhang. 2017. Enhancing the network embed-ding quality with structural similarity. In Proceedings of the ACM Conference on Information and Knowledge Management. ACM, 147–156."}, {"ref": "[25] Víctor Martínez,Fernando Berzal,and Juan-Carlos Cubero. 2017. A survey of link prediction in complex networks. ACM Computing Surveys (CSUR) 49, 4 (2017), 69."}, {"ref": "[26] Naoki Masuda, Mason A Porter, and Renaud Lambiotte. 2017. Random walks and diffusion on networks. Physics Reports 716 (2017), 1–58."}, {"ref": "[27] TomasMikolov,IlyaSutskever,KaiChen,GregSCorrado,andJeffDean.2013. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems. 3111–3119."}, {"ref": "[28] Cameron Nowzari, Victor M Preciado, and George J Pappas. 2016. Analysis and control of epidemics: A survey of spreading processes on complex networks. IEEE Control Systems Magazine 36, 1 (2016), 26–46."}, {"ref": "[29] Romualdo Pastor-Satorras and Alessandro Vespignani. 2001. Epidemic spreading in scale-free networks. Physical Review Letters 86, 14 (2001), 3200."}, {"ref": "[30] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM International Conference on Knowledge Discovery and Data Mining. ACM, 701–710."}, {"ref": "[31] Leonardo FR Ribeiro, Pedro HP Saverese, and Daniel R Figueiredo. 2017. struc2vec: Learning node representations from structural identity. In Proceedings of the 23rd ACM International Conference on Knowledge Discovery and Data Mining. ACM, 385–394."}, {"ref": "[32] Satu Elisa Schaeffer. 2007. Graph clustering. Computer Science Review 1, 1 (2007), 27–64."}, {"ref": "[33] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web. 1067–1077."}, {"ref": "[34] Yang Tang, Feng Qian, Huijun Gao, and Jürgen Kurths. 2014. Synchronization in complex networks and its application–a survey of recent advances and challenges. Annual Reviews in Control 38, 2 (2014), 184–198."}, {"ref": "[35] Athanasios Theocharidis, Stjin Van Dongen, Anton J Enright, and Tom C Freeman. 2009. Network visualization and analysis of gene expression data using BioLayout Express 3D. Nature Protocols 4, 10 (2009), 1535."}, {"ref": "[36] Thomas W Valente. 2012. Network interventions. Science 337, 6090 (2012), 49–53."}, {"ref": "[37] Jacco Wallinga, Michiel van Boven, and Marc Lipsitch. 2010. Optimizing infectious disease interventions during an emerging epidemic. Proceedings of the National Academy of Sciences 107, 2 (2010), 923–928."}, {"ref": "[38] Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural deep network embedding. In Proceedings of the 22nd ACM International Conference on Knowledge Discovery and Data Mining. ACM, 1225–1234."}, {"ref": "[39] Bo Yang, Jin Di, Jiming Liu, and Dayou Liu. 2013. Hierarchical community detection with applications to real-world network analysis. Data & Knowledge Engineering 83 (2013), 20–38."}, {"ref": "[40] Marinka Zitnik and Jure Leskovec. 2017. Predicting multicellular function through multi-layer tissue networks. Bioinformatics 33, 14 (2017), i190–i198."}]}, {"author": ["Sedigheh Mahdavi", "Shima Khoshraftar", "Aijun An"], "title": "dynnode2vec: Scalable Dynamic Network Embedding", "journal": "IEEE International Conference on Big Data", "year": 2018, "DOI": "10.1109/BigData.2018.8621910", "month": 12, "citations(google scholar)": 4, "abstract": "Network representation learning in low dimensional vector space has attracted considerable attention in both academic and industrial domains. Most real-world networks are dynamic with addition/deletion of nodes and edges. The existing graph embedding methods are designed for static networks and they cannot capture evolving patterns in a large dynamic network. In this paper, we propose a dynamic embedding method, dynnode2vec, based on the well-known graph embedding method node2vec. Node2vec is a random walk based embedding method for static networks. Applying static network embedding in dynamic settings has two crucial problems: 1) Generating random walks for every time step is time consuming 2) Embedding vector spaces in each timestamp are different. In order to tackle these challenges, dynnode2vec uses evolving random walks and initializes the current graph embedding with previous embedding vectors. We demonstrate the advantages of the proposed dynamic network embedding by conducting empirical evaluations on several large dynamic network datasets.", "keywords": ["None"], "reference_count": 23, "ccfClass": "C", "important": true, "references": [{"ref": "[1] S. Cao, W. Lu, and Q. Xu, \"Grarep: Learning graph representations with global structural information,\" in Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015, pp. 891–900."}, {"ref": "[2] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei, \"Line: Large-scale information network embedding,\" in Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2015, pp. 1067– 1077."}, {"ref": "[3] A. Grover and J. Leskovec, \"node2vec: Scalable feature learning for networks,\" in Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2016, pp. 855–864."}, {"ref": "[4] B. Perozzi, R. Al-Rfou, and S. Skiena, \"Deepwalk: Online learning of social representations,\" in Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014, pp. 701–710."}, {"ref": "[5] S. Cao, W. Lu, and Q. Xu, \"Deep neural networks for learning graph representations.\" in AAAI, 2016, pp. 1145–1152."}, {"ref": "[6] S. Chang, W. Han, J. Tang, G.-J. Qi, C. C. Aggarwal, and T. S. Huang, \"Heterogeneous network embedding via deep architectures,\" in Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2015, pp. 119–128."}, {"ref": "[7] P. Goyal and E. Ferrara, \"Graph embedding techniques, applications, and performance: A survey,\" Knowledge-Based Systems, vol. 151, pp. 78–94, 2018."}, {"ref": "[8] T. N. Kipf and M. Welling, \"Variational graph auto-encoders,\" arXiv preprint arXiv:1611.07308, 2016."}, {"ref": "[9] L. v. d. Maaten and G. Hinton, \"Visualizing data using t-sne,\" Journal of machine learning research, vol. 9, no. Nov, pp. 2579–2605, 2008."}, {"ref": "[10] S. Bhagat, G. Cormode, and S. Muthukrishnan, \"Node classification in social networks,\" in Social network data analytics. Springer, 2011, pp. 115–148."}, {"ref": "[11] D. Liben-Nowell and J. Kleinberg, \"The link-prediction problem for social networks,\" Journal of the American society for information science and technology, vol. 58, no. 7, pp. 1019–1031, 2007."}, {"ref": "[12] X. Yu, X. Ren, Y. Sun, Q. Gu, B. Sturt, U. Khandelwal, B. Norick, and J. Han, \"Personalized entity recommendation: A heterogeneous information network approach,\" in Proceedings of the 7th ACM international conference on Web search and data mining. ACM, 2014, pp. 283–292."}, {"ref": "[13] R.BamlerandS.Mandt,\"Dynamicwordembeddings,\"arXivpreprint arXiv:1702.08359, 2017."}, {"ref": "[14] Y. Kim, Y.-I. Chiu, K. Hanaki, D. Hegde, and S. Petrov, \"Temporal analysis of language through neural language models,\" arXiv preprint arXiv:1405.3515, 2014."}, {"ref": "[15] N. Kaji and H. Kobayashi, \"Incremental skip-gram model with negative sampling,\" arXiv preprint arXiv:1704.03956, 2017."}, {"ref": "[16] C. May, K. Duh, B. Van Durme, and A. Lall, \"Streaming word embeddings with the space-saving algorithm,\" arXiv preprint arXiv:1704.07463, 2017."}, {"ref": "[17] P. Goyal, N. Kamra, X. He, and Y. Liu, \"Dyngem: Deep embedding method for dynamic graphs,\" arXiv preprint arXiv:1805.11273, 2018."}, {"ref": "[18] Enron network dataset, http://konect.uni-koblenz.de/networks/"}, {"ref": "[19] R. Lippmann, R. K. Cunningham, D. J. Fried, I. Graf, K. R. Kendall, S. E. Webster, and M. A. Zissman, Results of the DARPA 1998 offline intrusion detection evaluation, in Recent Advances in Intrusion Detection, 1999"}, {"ref": "[20] JohannesGehrke,PaulGinsparg,andJonKleinberg.Overviewofthe 2003 kdd cup. ACM SIGKDD Explorations Newsletter, 5(2):149151, 2003."}, {"ref": "[21] Jure Leskovec and Andrej Krevl. SNAP Datasets: Stanford large network dataset collection, 2014"}, {"ref": "[22] Math overflow network dataset, http://snap.stanford.edu/data/sx- mathoverflow.html/"}, {"ref": "[23] Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. ArnetMiner: Extraction and Mining of Academic Social Networks. In Proceedings of the Fourteenth ACM SIGKDD International Confer- ence on Knowledge Discovery and Data Mining (SIGKDD’2008)."}]}, {"author": ["Jundong Li", "Xia Hu", "Ling Jian", "Huan Liu"], "title": "Toward Time-Evolving Feature Selection on Dynamic Networks", "journal": "IEEE International Conference on Data Mining", "year": 2017, "DOI": "10.1109/icdm.2016.0127", "month": 2, "citations(google scholar)": 17, "abstract": "Recent years have witnessed the prevalence of net- worked data in various domains. Among them, a large number of networks are not only topologically structured but also have a rich set of features on nodes. These node features are usually of high dimensionality with noisy, irrelevant and redundant in- formation, which may impede the performance of other learning tasks. Feature selection is useful to alleviate these critical issues. Nonetheless, a vast majority of existing feature selection algorithms are predominantly designed in a static setting. In reality, real-world networks are naturally dynamic, characterized by both topology and content changes. It is desirable to capture these changes to find relevant features tightly hinged with network structure continuously, which is of fundamental importance for many applications such as disaster relief and viral marketing. In this paper, we study a novel problem of time-evolving feature selection for dynamic networks in an unsupervised scenario. Specifically, we propose a TeFS framework by leveraging the temporal evolution property of dynamic networks to update the feature selection results incrementally. Experimental results show the superiority of TeFS over the state-of-the-art batch-mode unsupervised feature selection algorithms.", "keywords": ["unsupervised learning", "feature selection", "dynamic networks"], "reference_count": 23, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Charu Aggarwal and Karthik Subbian. Evolutionary network analysis: A survey. CSUR, 47(1):10, 2014."}, {"ref": "[2] Chen Chen and Hanghang Tong. Fast eigen-functions tracking on dynamic graphs. In SDM, 2015."}, {"ref": "[3] Quanquan Gu and Jiawei Han. Towards feature selection in network. In CIKM, 2011."}, {"ref": "[4] TingGuo,XingquanZhu,JianPei,andChengqiZhang.Snoc:streaming network node classification. In ICDM, 2014."}, {"ref": "[5] Xiaofei He, Deng Cai, and Partha Niyogi. Laplacian score for feature selection. In NIPS, 2005."}, {"ref": "[6] Timothy La Fond and Jennifer Neville. Randomization tests for distinguishing social influence and homophily effects. In WWW, 2010."}, {"ref": "[7] Jundong Li, Kewei Cheng, Suhang Wang, Fred Morstatter, Robert P Trevino, Jiliang Tang, and Huan Liu. Feature selection: A data perspective. arXiv preprint arXiv:1601.07996, 2016."}, {"ref": "[8] Jundong Li, Xia Hu, Jiliang Tang, and Huan Liu. Unsupervised streaming feature selection in social media. In CIKM, 2015."}, {"ref": "[9] Jundong Li, Xia Hu, Liang Wu, and Huan Liu. Robust unsupervised feature selection on networked data. In SDM, 2016."}, {"ref": "[10] Zechao Li, Yi Yang, Jing Liu, Xiaofang Zhou, and Hanqing Lu. Unsupervised feature selection using nonnegative spectral analysis. In AAAI, 2012."}, {"ref": "[11] Chih-Jen Lin. Projected gradient methods for nonnegative matrix factorization. Neural computation, 19(10):2756–2779, 2007."}, {"ref": "[12] Miller McPherson, Lynn Smith-Lovin, and James M Cook. Birds of a feather: Homophily in social networks. Annual review of sociology, pages 415–444, 2001."}, {"ref": "[13] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. Collective classification in network data. AI magazine, 29(3):93, 2008."}, {"ref": "[14] Jiliang Tang and Huan Liu. Feature selection with linked data in social media. In SDM, 2012."}, {"ref": "[15] Jiliang Tang and Huan Liu. Unsupervised feature selection for linked social media data. In KDD, 2012."}, {"ref": "[16] Hanghang Tong, Spiros Papadimitriou, Jimeng Sun, Philip S Yu, and Christos Faloutsos. Colibri: fast mining of large static and dynamic graphs. In KDD, 2008."}, {"ref": "[17] Xin Wang, Roger Donaldson, Christopher Nell, Peter Gorniak, Martin Ester, and Jiajun Bu. Recommending groups to users using user-groupengagement and time-dependent matrix factorization. In AAAI, 2016."}, {"ref": "[18] Xufei Wang, Lei Tang, Huiji Gao, and Huan Liu. Discovering overlap-ping groups in social media. In ICDM, 2010."}, {"ref": "[19] Xiaokai Wei, Sihong Xie, and S Yu Philip. Efficient partial order preserving unsupervised feature selection on networks. In SDM, 2015."}, {"ref": "[20] James D Westaby. Dynamic network theory: How social networks influence goal pursuit. American Psychological Association, 2012."}, {"ref": "[21] Jaewon Yang, Julian McAuley, and Jure Leskovec. Community detection in networks with node attributes. In ICDM, 2013."}, {"ref": "[22] Zheng Zhao and Huan Liu. Spectral feature selection for supervised and unsupervised learning. In ICML, 2007."}, {"ref": "[23] Dawei Zhou, Kangyang Wang, Nan Cao, and Jingrui He. Rare category detection on time-evolving graphs. In ICDM, 2015."}]}, {"author": ["Xiaoyi Li", "Nan Du", "Hui Li", "Kang Li", "Jing Gao", "Aidong Zhang"], "title": "A Deep Learning Approach to Link Prediction in Dynamic Networks", "journal": "SIAM International Conference on Data Mining", "year": 2014, "DOI": "10.1137/1.9781611973440.33", "month": 4, "citations(google scholar)": 55, "abstract": "Time varying problems usually have complex underlying structures represented as dynamic networks where entities and relationships appear and disappear over time. The problem of efficiently performing dynamic link inference is extremely challenging due to the dynamic nature in massive evolving networks especially when there exist sparse connectivities and nonlinear transitional patterns. In this paper, we propose a novel deep learning framework, i.e., Conditional Temporal Restricted Boltzmann Machine (ctRBM), which predicts links based on individual transition variance as well as influence introduced by local neighbors. The proposed model is robust to noise and have the exponential capability to capture nonlinear variance. We tackle the computational challenges by developing an efficient algorithm for learning and inference of the proposed model. To improve the efficiency of the approach, we give a faster approximated implementation based on a proposed Neighbor Influence Clustering algorithm. Extensive experiments on simulated as well as real-world dynamic networks show that the proposed method outperforms existing algorithms in link inference on dynamic networks.", "keywords": ["electrocardiography", "electromyography", "feedback", "force sensors", "fuzzy control", "medical signal processing", "position control", "prosthetics", "sensors", "EEG based position control"], "reference_count": 21, "ccfClass": "B", "important": true, "references": [{"ref": "[1] L. A. Adamic and E. Adar. Friends and neighbors on the web. Social networks, 2003."}, {"ref": "[2] C. C. Aggarwal, Y. Xie, and S. Y. Philip. On dynamic link inference in heterogeneous networks. In SDM, 2012."}, {"ref": "[3] L. E. Baum and T. Petrie. Statistical inference for probabilistic functions of finite state markov chains. The annals of mathematical statistics, 1966."}, {"ref": "[4] M. A. Carreira-Perpinan and G. E. Hinton. On contrastive divergence learning. In AISTATS, 2005."}, {"ref": "[5] R. Caruana and A. Niculescu-Mizil. An empirical comparison of supervised learning algorithms. In ICML, 2006."}, {"ref": "[6] Z. Ghahramani and G. E. Hinton. Variational learning for switching state-space models. Neural computation, 2000."}, {"ref": "[7] G. E. Hinton. Training products of experts by minimiz- ing contrastive divergence. Neural computation, 2002."}, {"ref": "[8] G. E. Hinton and R. R. Salakhutdinov. Reducing the dimensionality of data with neural networks. Science, 2006."}, {"ref": "[9] P. Indyk and R. Motwani. Approximate nearest neigh- bors: towards removing the curse of dimensionality. In STOC, 1998."}, {"ref": "[10] L. Katz. A new status index derived from sociometric analysis. Psychometrika, 1953."}, {"ref": "[11] N. D. Lawrence. Gaussian process latent variable models for visualisation of high dimensional data. NIPS, 2004."}, {"ref": "[12] D. Liben-Nowell and J. Kleinberg. The link-prediction problem for social networks. JASIST, 2007."}, {"ref": "[13] T. C. Mills. Time series techniques for economists. Cambridge University Press, 1991."}, {"ref": "[14] V. Pavlovic, J. M. Rehg, and J. MacCormick. Learning switching linear models of human motion. In NIPS, 2000."}, {"ref": "[15] P. Sarkar, D. Chakrabarti, and M. Jordan. Nonpara-metric link prediction in dynamic networks. arXiv preprint arXiv:1206.6394, 2012."}, {"ref": "[16] U. Sharan and J. Neville. Temporal-relational classifiers for prediction in evolving domains. In ICDM, 2008."}, {"ref": "[17] C. S. Stevenson, C. Docx, R. Webster, C. Battram, D. Hynx, J. Giddings, P. R. Cooper, P. Chakravarty, I. Rahman, J. A. Marwick, et al. Comprehensive gene expression profiling of rat lung reveals distinct acute and chronic responses to cigarette smoke inhalation. AJP-LUNG, 2007."}, {"ref": "[18] I. Sutskever and G. E. Hinton. Learning multilevel distributed representations for high-dimensional sequences. In AISTATS, 2007."}, {"ref": "[19] G. W. Taylor and G. E. Hinton. Factored conditional restricted boltzmann machines for modeling motion style. In ICML, 2009."}, {"ref": "[20] T. Tylenda, R. Angelova, and S. Bedathur. Towards time-aware link prediction in evolving social networks. In SNAKDD, 2009."}, {"ref": "[21] D. Q. Vu, D. Hunter, P. Smyth, and A. U. Asuncion. Continuous-time regression models for longitudinal networks. In NIPS, 2011."}]}, {"author": ["﻿Palash Goyal", "Sujit Rokka Chhetri", "Arquimedes Canedo"], "title": "dyngraph2vec: Capturing Network Dynamics using Dynamic Graph Representation Learning", "journal": "Knowledge-Based Systems", "year": 2019, "DOI": "10.1016/j.knosys.2019.06.024", "month": 7, "citations(google scholar)": 13, "abstract": "Learning graph representations is a fundamental task aimed at capturing various properties of graphs in vector space. The most recent methods learn such representations for static networks. However, real-world networks evolve over time and have varying dynamics. Capturing such evolution is key to predicting the properties of unseen networks. To understand how the network dynamics a\u000bect the prediction performance, we propose an embedding approach which learns the structure of evolution in dynamic graphs and can predict unseen links with higher precision. Our model, dyngraph2vec, learns the temporal transitions in the network using a deep architecture composed of dense and recurrent layers. We motivate the need for capturing dynamics for the prediction on a toy data set created using stochastic block models. We then demonstrate the e\u000ecacy of dyngraph2vec over existing state-ofthe-art methods on two real-world data sets. We observe that learning dynamics can improve the quality of embedding.", "keywords": ["Graph embedding techniques", "Graph embedding applications", "Python Graph Embedding Methods GEM Library"], "reference_count": 39, "ccfClass": "C", "important": true, "references": [{"ref": "[1] J. Gehrke, P. Ginsparg, J. Kleinberg, Overview of the 2003 kdd cup, ACM SIGKDD Explorations 5 (2)."}, {"ref": "[2] L. C. Freeman, Visualizing social networks, Journal of social structure 1 (1) (2000) 4."}, {"ref": "[3] A. Theocharidis, S. Van Dongen, A. Enright, T. Freeman, Network visualization and analysis of gene expression data using biolayout express3d, Nature protocols 4 (2009) 1535–1550."}, {"ref": "[4] P. Goyal, A. Sapienza, E. Ferrara, Recommending teammates with deep neural networks, in: Proceedings of the 29th on Hypertext and Social Media, ACM, 2018, pp. 57–61."}, {"ref": "[5] G. A. Pavlopoulos, A.-L. Wegener, R. Schneider, A survey of visualization tools for biological network analysis, Biodata mining 1 (1) (2008) 12."}, {"ref": "[6] S. Wasserman, K. Faust, Social network analysis: Methods and applications, Vol. 8, Cambridge university press, 1994."}, {"ref": "[7] P. Goyal, E. Ferrara, Graph embedding techniques, applications, and performance: A survey, Knowledge-Based Systems doi:https://doi.org/10.1016/j.knosys.2018.03.022. URL http://www.sciencedirect.com/science/article/pii/ S0950705118301540"}, {"ref": "[8] A. Grover, J. Leskovec, node2vec: Scalable feature learning for networks, in: Proceedings of the 22nd International Conference on Knowledge Discovery and Data Mining, ACM, 2016, pp. 855–864."}, {"ref": "[9] M. Ou, P. Cui, J. Pei, Z. Zhang, W. Zhu, Asymmetric transitivity preserving graph embedding, in: Proc. of ACM SIGKDD, 2016, pp. 1105–1114."}, {"ref": "[10] A. Ahmed, N. Shervashidze, S. Narayanamurthy, V. Josifovski, A. J. Smola, Distributed large-scale natural graph factorization, in: Proceedings of the 22nd international conference on World Wide Web, ACM, 2013, pp. 37–48."}, {"ref": "[11] B. Perozzi, R. Al-Rfou, S. Skiena, Deepwalk: Online learning of social representations, in: Proceedings 20th international conference on Knowledge discovery and data mining, 2014, pp. 701–710."}, {"ref": "[12] S. Cao,W. Lu, Q. Xu, Grarep: Learning graph representations with global structural information, in: KDD15, 2015, pp. 891–900."}, {"ref": "[13] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, Q. Mei, Line: Large-scale information network embedding, in: Proceedings 24th International Conference on World Wide Web, 2015, pp. 1067–1077."}, {"ref": "[14] P. Goyal, H. Hosseinmardi, E. Ferrara, A. Galstyan, Embedding networks with edge attributes, in: Proceedings of the 29th on Hypertext and Social Media, ACM, 2018, pp. 38–42."}, {"ref": "[15] L. Zhou, Y. Yang, X. Ren, F. Wu, Y. Zhuang, Dynamic Network Embedding by Modelling Triadic Closure Process, in: AAAI, 2018."}, {"ref": "[16] P. Goyal, N. Kamra, X. He, Y. Liu, Dyngem: Deep embedding method for dynamic graphs, arXiv preprint arXiv:1805.11273."}, {"ref": "[17] Z. Zhang, P. Cui, J. Pei, X. Wang, W. Zhu, Timers: Error-bounded svd restart on dynamic networks, arXiv preprint arXiv:1711.09541."}, {"ref": "[18] M. Belkin, P. Niyogi, Laplacian eigenmaps and spectral techniques for embedding and clustering, in: NIPS, Vol. 14, 2001, pp. 585–591."}, {"ref": "[19] D. Wang, P. Cui, W. Zhu, Structural deep network embedding, in: Proceedings of the 22nd International Conference on Knowledge Discovery and Data Mining, ACM, 2016, pp. 1225–1234."}, {"ref": "[20] S. Cao, W. Lu, Q. Xu, Deep neural networks for learning graph representations, in: Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI Press, 2016, pp. 1145–1152."}, {"ref": "[21] T. N. Kipf, M. Welling, Variational graph auto-encoders, arXiv preprint arXiv:1611.07308."}, {"ref": "[22] T. N. Kipf, M. Welling, Semi-supervised classification with graph convolutional networks, arXiv preprint arXiv:1609.02907."}, {"ref": "[23] J. Bruna,W. Zaremba, A. Szlam, Y. LeCun, Spectral networks and locally connected networks on graphs, arXiv preprint arXiv:1312.6203."}, {"ref": "[24] M. Hena\u000b, J. Bruna, Y. LeCun, Deep convolutional networks on graphstructured data, arXiv preprint arXiv:1506.05163."}, {"ref": "[25] L. Zhu, D. Guo, J. Yin, G. Ver Steeg, A. Galstyan, Scalable temporal latent space inference for link prediction in dynamic social networks, IEEE Transactions on Knowledge and Data Engineering 28 (10) (2016) 2765– 2777."}, {"ref": "[26] P. Goyal, N. Kamra, X. He, Y. Liu, Dyngem: Deep embedding method for dynamic graphs, in: IJCAI International Workshop on Representation Learning for Graphs, 2017."}, {"ref": "[27] M. Rahman, T. K. Saha, M. A. Hasan, K. S. Xu, C. K. Reddy, Dylink2vec: E\u000bective feature representation for link prediction in dynamic networks, arXiv preprint arXiv:1804.05755."}, {"ref": "[28] P. Sarkar, D. Chakrabarti, M. Jordan, Nonparametric link prediction in dynamic networks, arXiv preprint arXiv:1206.6394."}, {"ref": "[29] S. Yang, T. Khot, K. Kersting, S. Natarajan, Learning continuous-time bayesian networks in relational domains: A non-parametric approach, in: Thirtieth AAAI Conference on Artificial Intelligence, 2016."}, {"ref": "[30] D. M. Dunlavy, T. G. Kolda, E. Acar, Temporal link prediction using matrix and tensor factorizations, ACM Transactions on Knowledge Discovery from Data (TKDD) 5 (2) (2011) 10."}, {"ref": "[31] X. Ma, P. Sun, Y. Wang, Graph regularized nonnegative matrix factorization for temporal link prediction in dynamic networks, Physica A: Statistical mechanics and its applications 496 (2018) 121–136."}, {"ref": "[32] N. Talasu, A. Jonnalagadda, S. S. A. Pillai, J. Rahul, A link prediction based approach for recommendation systems, in: 2017 international conference on advances in computing, communications and informatics (ICACCI), IEEE, 2017, pp. 2059–2062."}, {"ref": "[33] J. Li, K. Cheng, L. Wu, H. Liu, Streaming link prediction on dynamic attributed networks, in: Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, ACM, 2018, pp. 369–377."}, {"ref": "[34] Y. J.Wang, G. Y.Wong, Stochastic blockmodels for directed graphs, Journal of the American Statistical Association 82 (397) (1987) 8–19."}, {"ref": "[35] D. E. Rumelhart, G. E. Hinton, R. J. Williams, Neurocomputing: Foundations of research, JA Anderson and E. Rosenfeld, Eds (1988) 696–699."}, {"ref": "[36] D. Kingma, J. Ba, Adam: A method for stochastic optimization, arXiv preprint arXiv:1412.6980."}, {"ref": "[37] J. Leskovec, J. Kleinberg, C. Faloutsos, Graphs over time: densification laws, shrinking diameters and possible explanations, in: Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining, ACM, 2005, pp. 177–187."}, {"ref": "[38] M. Ou, P. Cui, J. Pei, Z. Zhang, W. Zhu, Asymmetric transitivity preserving graph embedding, in: Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, 2016, pp. 1105–1114."}, {"ref": "[39] M. Brand, Fast low-rank modifications of the thin singular value decomposition, Linear algebra and its applications 415 (1) (2006) 20–30."}]}, {"author": ["﻿Neil Shah", "Danai Koutra", "Tianmin Zou", "Brian Gallagher", "Christos Faloutsos"], "title": "TimeCrunch: Interpretable Dynamic Graph Summarization", "journal": "KDD", "year": 2015, "DOI": "10.1145/2783258.2783321", "month": 8, "citations(google scholar)": 68, "abstract": "How can we describe a large, dynamic graph over time? Is it random? If not, what are the most apparent deviations from randomness -- a dense block of actors that persists over time, or perhaps a star with many satellite nodes that appears with some fixed periodicity? In practice, these deviations indicate patterns -- for example, botnet attackers forming a bipartite core with their victims over the duration of an attack, family members bonding in a clique-like fashion over a difficult period of time, or research collaborations forming and fading away over the years. Which patterns exist in real-world dynamic graphs, and how can we find and rank them in terms of importance? These are exactly the problems we focus on in this work. Our main contributions are (a) formulation: we show how to formalize this problem as minimizing the encoding cost in a data compression paradigm, (b) algorithm: we propose TIMECRUNCH, an effective, scalable and parameter-free method for finding coherent, temporal patterns in dynamic graphs and (c) practicality: we apply our method to several large, diverse real-world datasets with up to 36 million edges and 6.3 million nodes. We show that TIMECRUNCH is able to compress these graphs by summarizing important temporal structures and finds patterns that agree with intuition.", "keywords": ["dynamic graph", "network", "clustering", "summarization", "compression"], "reference_count": 28, "ccfClass": "A", "important": true, "references": [{"ref": "[1] DBLP network dataset. konect.uni-koblenz.de/networks/dblp_coauthor, July 2014."}, {"ref": "[2] C. C. Aggarwal and S. Y. Philip. Online analysis of community evolution in data streams. SIAM."}, {"ref": "[3] C. J. Alpert, A. B. Kahng, and S.-Z. Yao. Spectral partitioning with multiple eigenvectors. Discrete Applied Mathematics, 90(1):3–26, 1999."}, {"ref": "[4] M. Araujo, S. Papadimitriou, S. Günnemann, C. Faloutsos, P. Basu, A. Swami, E. E. Papalexakis, and D. Koutra. Com2: Fast automatic discovery of temporal (\"comet\") communities. In PAKDD, pages 271–283. Springer, 2014."}, {"ref": "[5] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10):P10008, 2008."}, {"ref": "[6] D. Chakrabarti, S. Papadimitriou, D. S. Modha, and C. Faloutsos. Fully automatic cross-associations. In KDD, pages 79–88. ACM, 2004."}, {"ref": "[7] D. J. Cook and L. B. Holder. Substructure discovery using minimum description length and background knowledge. arXiv preprint cs/9402102, 1994."}, {"ref": "[8] T. M. Cover and J. A. Thomas. Elements of information theory. John Wiley & Sons, 2012."}, {"ref": "[9] I. S. Dhillon, S. Mallela, and D. S. Modha. Information-theoretic co-clustering. In Proc. 9th KDD, pages 89–98, 2003."}, {"ref": "[10] J. Ferlez, C. Faloutsos, J. Leskovec, D. Mladenic, and M. Grobelnik. Monitoring network evolution using MDL. ICDE, 2008."}, {"ref": "[11] R. Jin, C. Wang, D. Polshakov, S. Parthasarathy, and G. Agrawal. Discovering frequent topological structures from graph datasets. In KDD, pages 606–611, 2005."}, {"ref": "[12] U. Kang and C. Faloutsos. Beyond’caveman communities’: Hubs and spokes for graph compression and mining. In ICDM, pages 300–309. IEEE, 2011."}, {"ref": "[13] G. Karypis and V. Kumar. Multilevel k-way hypergraph partitioning. VLSI design, 11(3):285–300, 2000."}, {"ref": "[14] J. M. Kleinberg, R. Kumar, P. Raghavan, S. Rajagopalan, and A. S. Tomkins. The web as a graph: measurements, models, and methods. In Computing and combinatorics, pages 1–17. Springer, 1999."}, {"ref": "[15] D. Koutra, U. Kang, J. Vreeken, and C. Faloutsos. Vog: Summarizing and understanding large graphs."}, {"ref": "[16] D. Koutra, T.-Y. Ke, U. Kang, D. H. P. Chau, H.-K. K. Pao, and C. Faloutsos. Unifying guilt-by-association approaches: Theorems and fast algorithms. In ECML/PKDD, pages 245–260. Springer, 2011."}, {"ref": "[17] B. Kulis and Y. Guan. Graclus - efficient graph clustering software for normalized cut and ratio association on undirected graphs, 2008. 2010."}, {"ref": "[18] M. Li and P. M. Vitányi. An introduction to Kolmogorov complexity and its applications. Springer Science & Business Media, 2009."}, {"ref": "[19] M. E. Newman and M. Girvan. Finding and evaluating community structure in networks. Physical review E, 69(2):026113, 2004."}, {"ref": "[20] E. E. Papalexakis, N. D. Sidiropoulos, and R. Bro. From k-means to higher-way co-clustering: Multilinear decomposition with sparse latent factors. IEEE TSP, 61(2):493–506, 2013."}, {"ref": "[21] J. Pei, D. Jiang, and A. Zhang. On mining cross-graph quasi-cliques. In KDD, pages 228–238, 2005."}, {"ref": "[22] J. Rissanen. Modeling by shortest data description. Automatica, 14(5):465–471, 1978."}, {"ref": "[23] N. Shah, A. Beutel, B. Gallagher, and C. Faloutsos. Spotting suspicious link behavior with fbox: An adversarial perspective. In ICDM. 2014."}, {"ref": "[24] J. Shetty and J. Adibi. The enron email dataset database schema and brief statistical report. Inf. sciences inst. TR, USC, 4, 2004."}, {"ref": "[25] J. Sun, C. Faloutsos, S. Papadimitriou, and P. S. Yu. Graphscope: parameter-free mining of large time-evolving graphs. In KDD, pages 687–696. ACM, 2007."}, {"ref": "[26] H. Toivonen, F. Zhou, A. Hartikainen, and A. Hinkka. Compression of weighted graphs. In KDD, pages 965–973. ACM, 2011."}, {"ref": "[27] K. S. Xu, M. Kliger, and A. O. Hero III. Tracking communities in dynamic social networks. In SBP, pages 219–226. Springer, 2011."}, {"ref": "[28] Yahoo! Webscope. webscope.sandbox.yahoo.com."}]}, {"author": ["﻿Taisong Li", "Jiawei Zhang", "Philip S. Yu", "Yan Zhang", "Yonghong Yan"], "title": "Deep Dynamic Network Embedding for Link Prediction", "journal": "IEEE Access", "year": 2018, "DOI": "10.1109/access.2018.2839770", "month": 6, "citations(google scholar)": 14, "abstract": "Network embedding task aims at learning low-dimension latent representations of vertices while preserving the structure of a network simultaneously. Most existing network embedding methods mainly focus on static networks, which extract and condense the network information without temporal information. However, in the real world, networks keep evolving, where the linkage states between the same vertex pairs at consequential timestamps have very close correlations. In this paper, we propose to study the network embedding problem and focus on modeling the linkage evolution in the dynamic network setting. To address this problem, we propose a deep dynamic network embedding method. More specifically, the method utilizes the historical information obtained from the network snapshots at past timestamps to learn latent representations of the future network. In the proposed embedding method, the objective function is carefully designed to incorporate both the network internal and network dynamic transition structures. Extensive empirical experiments prove the effectiveness of the proposed model on various categories of real-world networks, including a human contact network, a bibliographic network, and e-mail networks. Furthermore, the experimental results also demonstrate the significant advantages of the method compared with both the state-of-the-art embedding techniques and several existing baseline methods.", "keywords": ["Social network analysis", "network embedding", "link prediction", "deep learning."], "reference_count": 29, "ccfClass": "", "important": true, "references": [{"ref": "[1] M. Spiliopoulou, ''Evolution in social networks: A survey,'' in Social Network Data Analytics. Boston, MA, USA: Springer, 2011, pp. 149\u0015175."}, {"ref": "[2] J. Leskovec, J. Kleinberg, and C. Faloutsos, ''Graph evolution: Densi\u001ccation and shrinking diameters,'' ACM Trans. Knowl. Discovery Data, vol. 1, no. 1, pp. 1\u001540, 2007."}, {"ref": "[3] X. Li, N. Du, H. Li, K. Li, J. Gao, and A. Zhang, ''Adeep learning approach to link prediction in dynamic networks,'' in Proc. SIAM Int. Conf. Data Mining, 2014, pp. 289\u0015297."}, {"ref": "[4] L. Tang, H. Liu, J. Zhang, and Z. Nazeri, ''Community evolution in dynamic multi-mode networks,'' in Proc. 14th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2008, pp. 677\u0015685."}, {"ref": "[5] J. B. Tenenbaum, V. de Silva, and J. C. Langford, ''A global geometric framework for nonlinear dimensionality reduction,'' Science, vol. 290, no. 5500, pp. 2319\u00152323, Dec. 2000."}, {"ref": "[6] M. Belkin and P. Niyogi, ''Laplacian eigenmaps for dimensionality reduction and data representation,'' Neural Comput., vol. 15, no. 6, pp. 1373\u00151396, 2003."}, {"ref": "[7] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei, ''Line: Large-scale information network embedding,'' in Proc. 24th Int. Conf. World Wide Web Int. World Wide Web Conf. Steering Committee, 2015, pp. 1067\u00151077."}, {"ref": "[8] D. Luo, C. H. Q. Ding, F. Nie, and H. Huang, ''Cauchy graph embedding,'' in Proc. 28th Int. Conf. Mach. Learn. (ICML), 2011, pp. 553\u0015560."}, {"ref": "[9] D. Wang, P. Cui, and W. Zhu, ''Structural deep network embedding,'' in Proc. 22nd ACMSIGKDD Int. Conf. Knowl. Discovery Data Mining, 2016, pp. 1225\u00151234."}, {"ref": "[10] A. Grover and J. Leskovec, ''Node2vec: Scalable feature learning for networks,'' in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2016, pp. 855\u0015864."}, {"ref": "[11] B. Perozzi, R. Al-Rfou, and S. Skiena, ''Deepwalk: Online learning of social representations,'' in Proc. 20th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2014, pp. 701\u0015710."}, {"ref": "[12] G. W. Taylor, G. E. Hinton, and S. T. Roweis, ''Modeling human motion using binary latent variables,'' in Proc. Adv. Neural Inf. Process. Syst., 2007, pp. 1345\u00151352."}, {"ref": "[13] D. Bahdanau, K. Cho, and Y. Bengio. (2014). ''Neural machine translation by jointly learning to align and translate.'' [Online]. Available: https://arxiv.org/abs/1409.0473"}, {"ref": "[14] I. Sutskever, O. Vinyals, and Q. V. Le, ''Sequence to sequence learning with neural networks,'' in Proc. Adv. Neural Inf. Process. Syst., 2014, pp. 3104\u00153112."}, {"ref": "[15] K. Cho et al. (2014). ''Learning phrase representations using RNN encoder-decoder for statistical machine translation.'' [Online]. Available: https://arxiv.org/abs/1406.1078"}, {"ref": "[16] (2015). Understanding LSTM Networks. [Online]. Available: http://colah.github.io/posts/2015-08-Understanding-LSTMs"}, {"ref": "[17] K. Cho, B. van Merri?nboer, D. Bahdanau, and Y. Bengio. (2014). ''On the properties of neural machine translation: Encoder-decoder approaches.'' [Online]. Available:https://arxiv.org/abs/1409.1259"}, {"ref": "[18] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio. (2014). ''Empirical evaluation of gated recurrent neural networks on sequence modeling.'' [Online]. Available: https://arxiv.org/abs/1412.3555"}, {"ref": "[19] M. D. Zeiler. (2012). ''ADADELTA: An adaptive learning rate method.'' [Online]. Available: https://arxiv.org/abs/1212.5701"}, {"ref": "[20] (Oct. 2016). Arxiv Hep-Ph Network Dataset\u0015KONECT. [Online]. Available: http://konect.uni-koblenz.de/networks/ca-cit-HepPh"}, {"ref": "[21] (Oct. 2016). Enron Network Dataset\u0015KONECT. [Online]. Available: http://konect.uni-koblenz.de/networks/enron"}, {"ref": "[22] B. Klimt and Y. Yang, ''The Enron corpus: A new dataset for email classi\u001ccation research,'' in Proc. Eur. Conf. Mach. Learn., 2004, pp. 217\u0015226."}, {"ref": "[23] (Oct. 2016). Manufacturing Emails Network Dataset\u0015KONECT. [Online]. Available: http://konect.uni-koblenz.de/networks/radoslaw_email"}, {"ref": "[24] R. Michalski, S. Palus, and P. Kazienko, ''Matching organizational structure and social network extracted from email communication,'' in Business Information Systems (Lecture Notes in Business Information Processing), vol. 87. Berlin, Germany: Springer, 2011, pp. 197\u0015206."}, {"ref": "[25] (Oct. 2016). Haggle Network Dataset\u0015KONECT. [Online]. Available: http://konect.uni-koblenz.de/networks/contact"}, {"ref": "[26] A. Chaintreau, P. Hui, J. Crowcroft, C. Diot, R. Gass, and J. Scott, ''Impact of human mobility on opportunistic forwarding algorithms,'' IEEE Trans. Mobile Comput., vol. 6, no. 6, pp. 606\u0015620, Jun. 2007."}, {"ref": "[27] L. Katz, ''A new status index derived from sociometric analysis,'' Psychometrika, vol. 18, no. 1, pp. 39\u001543, 1953."}, {"ref": "[28] P. Goyal and E. Ferrara. (2017). ''Graph embedding techniques, applications, and performance: A survey.'' [Online]. Available: https://arxiv.org/abs/1705.02801"}, {"ref": "[29] F. Pedregosa et al., ''Scikit-learn: Machine learning in Python,'' J. Mach. Learn. Res., vol. 12, pp. 2825\u00152830, Oct. 2011."}]}, {"author": ["﻿Srijan Kumar", "Xikun Zhang", "Jure Leskovec"], "title": "Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks", "journal": "KDD : proceedings. International Conference on Knowledge Discovery & Data Mining", "year": 2019, "DOI": "10.1145/3292500.3330895", "month": 8, "citations(google scholar)": 1, "abstract": "Modeling sequential interactions between users and items/products is crucial in domains such as e-commerce, social networking, and education. Representation learning presents an attractive opportunity to model the dynamic evolution of users and items, where each user/item can be embedded in a Euclidean space and its evolution can be modeled by an embedding trajectory in this space. However, existing dynamic embedding methods generate embeddings only when users take actions and do not explicitly model the future trajectory of the user/item in the embedding space. Here we propose JODIE, a coupled recurrent neural network model that learns the embedding trajectories of users and items. JODIE employs two recurrent neural networks to update the embedding of a user and an item at every interaction. Crucially, JODIE also models the future embedding trajectory of a user/item. To this end, it introduces a novel projection operator that learns to estimate the embedding of the user at any time in the future. These estimated embeddings are then used to predict future user-item interactions. To make the method scalable, we develop a t-Batch algorithm that creates time-consistent batches and leads to 9x faster training. We conduct six experiments to validate JODIE on two prediction tasks---future interaction prediction and state change prediction---using four real-world datasets. We show that JODIE outperforms six state-of-the-art algorithms in these tasks by at least 20% in predicting future interactions and 12% in state change prediction.", "keywords": ["Dynamic Embedding", "Temporal Interaction Networks"], "reference_count": 52, "ccfClass": "", "important": true, "references": [{"ref": "[1] Kdd cup 2015. https://biendata.com/competition/kddcup2015/data/."}, {"ref": "[2] Reddit data dump. http://files.pushshift.io/reddit/."}, {"ref": "[3] Wikipedia edit history dump. https://meta.wikimedia.org/wiki/Data_dumps."}, {"ref": "[4] D. Agrawal, C. Budak, A. El Abbadi, T. Georgiou, and X. Yan. Big data in online social networks: user interaction analysis to model user behavior in social networks. In DNIS, 2014."}, {"ref": "[5] T. Arnoux, L. Tabourier, and M. Latapy. Combining structural and dynamic information to predict activity in link streams. In ASONAM, 2017."}, {"ref": "[6] T. Arnoux, L. Tabourier, and M. Latapy. Predicting interactions between individuals with structural and dynamical information. CoRR, 2018."}, {"ref": "[7] I. M. Baytas, C. Xiao, X. Zhang, F.Wang, A. K. Jain, and J. Zhou. Patient subtyping via time-aware lstm networks. In KDD, 2017."}, {"ref": "[8] A. Beutel, P. Covington, S. Jain, C. Xu, J. Li, V. Gatto, and E. H. Chi. Latent cross: Making use of context in recurrent recommender systems. In WSDM, 2018."}, {"ref": "[9] J. Cheng, M. Bernstein, C. Danescu-Niculescu-Mizil, and J. Leskovec. Anyone can become a troll: Causes of trolling behavior in online discussions. In CSCW, 2017."}, {"ref": "[10] J. Cheng, C. Lo, and J. Leskovec. Predicting intent using activity logs: How goal specificity and temporal range affect user behavior. In WWW, 2017."}, {"ref": "[11] H. Dai, Y. Wang, R. Trivedi, and L. Song. Deep coevolutionary network: Embedding user and item features for recommendation. arXiv:1609.03675, 2016."}, {"ref": "[12] N. Du, H. Dai, R. Trivedi, U. Upadhyay, M. Gomez-Rodriguez, and L. Song. Recurrent marked temporal point processes: Embedding event history to vector. In KDD, 2016."}, {"ref": "[13] M. Farajtabar, Y. Wang, M. Gomez-Rodriguez, S. Li, H. Zha, and L. Song. COEVOLVE: A joint point process model for information diffusion and network co-evolution. In NeurIPS, 2015."}, {"ref": "[14] P. Goyal and E. Ferrara. Graph embedding techniques, applications, and performance: A survey. Knowledge Based Systems, 151:78–94, 2018."}, {"ref": "[15] P. Goyal, N. Kamra, X. He, and Y. Liu. Dyngem: Deep embedding method for dynamic graphs. arXiv:1805.11273, 2018."}, {"ref": "[16] A. Grover and J. Leskovec. node2vec: Scalable feature learning for networks. In KDD, 2016."}, {"ref": "[17] W. L. Hamilton, R. Ying, and J. Leskovec. Representation learning on graphs: Methods and applications. IEEE Data Engineering Bulletin, 40(3):52–74, 2017."}, {"ref": "[18] B. Hidasi and D. Tikk. Fast als-based tensor factorization for context-aware recommendation from implicit feedback. In ECML, 2012."}, {"ref": "[19] T. Iba, K. Nemoto, B. Peters, and P. A. Gloor. Analyzing the creative editing behavior of wikipedia editors: Through dynamic social network analysis. Procedia- Social and Behavioral Sciences, 2(4):6441–6456, 2010."}, {"ref": "[20] S. J. Julier and J. K. Uhlmann. New extension of the kalman filter to nonlinear systems. In Signal processing, sensor fusion, and target recognition VI, volume 3068, pages 182–194, 1997."}, {"ref": "[21] R. R. Junuthula, M. Haghdan, K. S. Xu, and V. K. Devabhaktuni. The block point process model for continuous-time event-based dynamic networks. CoRR, 2017."}, {"ref": "[22] R. R. Junuthula, K. S. Xu, and V. K. Devabhaktuni. Leveraging friendship networks for dynamic link prediction in social interaction networks. In ICWSM, 2018."}, {"ref": "[23] M. Kloft, F. Stiehler, Z. Zheng, and N. Pinkwart. Predicting mooc dropout over weeks using machine learning methods. In EMNLP, 2014."}, {"ref": "[24] S. Kumar, W. L. Hamilton, J. Leskovec, and D. Jurafsky. Community interaction and conflict on the web. In The World Wide Web Conference, 2018."}, {"ref": "[25] S. Kumar, B. Hooi, D. Makhija, M. Kumar, C. Faloutsos, and V. Subrahmanian. Rev2: Fraudulent user prediction in rating platforms. In WSDM, 2018."}, {"ref": "[26] S. Kumar, F. Spezzano, and V. Subrahmanian. Vews: A wikipedia vandal early warning system. In KDD, 2015."}, {"ref": "[27] J. Leskovec, A. Rajaraman, and J. D. Ullman. Mining of massive datasets. Cambridge university press, 2014."}, {"ref": "[28] J. Li, H. Dani, X. Hu, J. Tang, Y. Chang, and H. Liu. Attributed network embedding for learning in a dynamic environment. In CIKM, 2017."}, {"ref": "[29] T. Li, J. Zhang, P. S. Yu, Y. Zhang, and Y. Yan. Deep dynamic network embedding for link prediction. IEEE Access, 6:29219–29230, 2018."}, {"ref": "[30] X. Li, N. Du, H. Li, K. Li, J. Gao, and A. Zhang. A deep learning approach to link prediction in dynamic networks. In SDM, 2014."}, {"ref": "[31] T. R. Liyanagunawardena, A. A. Adams, and S. A. Williams. Moocs: A systematic study of the published literature 2008-2012. The International Review of Research in Open and Distributed Learning, 14(3):202–227, 2013."}, {"ref": "[32] Y. Ma, Z. Guo, Z. Ren, Y. E. Zhao, J. Tang, and D. Yin. Dynamic graph neural networks. CoRR, abs/1810.10627, 2018."}, {"ref": "[33] G. H. Nguyen, J. B. Lee, R. A. Rossi, N. K. Ahmed, E. Koh, and S. Kim. Continuoustime dynamic network embeddings. In WWW BigNet workshop, 2018."}, {"ref": "[34] R. Pálovics, A. A. Benczúr, L. Kocsis, T. Kiss, and E. Frigó. Exploiting temporal influence in online recommendation. In RecSys, 2014."}, {"ref": "[35] J. W. Pennebaker, M. E. Francis, and R. J. Booth. Linguistic inquiry and word count: Liwc 2001. Mahway: Lawrence Erlbaum Associates, 71(2001):2001, 2001."}, {"ref": "[36] J. Qiu, Y. Dong, H. Ma, J. Li, K. Wang, and J. Tang. Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec. In WSDM, 2018."}, {"ref": "[37] V. Raghavan, G. Ver Steeg, A. Galstyan, and A. G. Tartakovsky. Modeling temporal activity patterns in dynamic social networks. IEEE TCSS, 1(1):89–107, 2014."}, {"ref": "[38] M. Rahman, T. K. Saha, M. A. Hasan, K. S. Xu, and C. K. Reddy. Dylink2vec: Effective feature representation for link prediction in dynamic networks. CoRR, 2018."}, {"ref": "[39] S. Sajadmanesh, J. Zhang, and H. R. Rabiee. Continuous-time relationship prediction in dynamic heterogeneous information networks. CoRR, 2017."}, {"ref": "[40] S. Sedhain, S. Sanner, L. Xie, R. Kidd, K. Tran, and P. Christen. Social affinity filtering: recommendation through fine-grained analysis of user interactions and activities. In COSN, 2013."}, {"ref": "[41] R. Trivedi, H. Dai, Y. Wang, and L. Song. Know-evolve: Deep temporal reasoning for dynamic knowledge graphs. In ICML, 2017."}, {"ref": "[42] R. Trivedi, M. Farajtbar, P. Biswal, and H. Zha. Representation learning over dynamic graphs. arXiv:1803.04051, 2018."}, {"ref": "[43] P. B. Walker, S. G. Fooshee, and I. Davidson. Complex interactions in social and event network analysis. In SBP-BRiMS, 2015."}, {"ref": "[44] Y. Wang, N. Du, R. Trivedi, and L. Song. Coevolutionary latent feature processes for continuous-time user-item interactions. In NeurIPS, 2016."}, {"ref": "[45] C.-Y. Wu, A. Ahmed, A. Beutel, A. J. Smola, and H. Jing. Recurrent recommender networks. In WSDM, 2017."}, {"ref": "[46] D. Yang, T. Sinha, D. Adamson, and C. P. Rosé. Turn on, tune in, drop out: Anticipating student dropouts in massive open online courses. In NeurIPS Datadriven education workshop, 2013."}, {"ref": "[47] J. You, Y. Wang, A. Pal, P. Eksombatchai, C. Rosenburg, and J. Leskovec. Hierarchical temporal convolutional networks for dynamic recommender systems. In The World Wide Web Conference, 2019."}, {"ref": "[48] S. Zhang, L. Yao, and A. Sun. Deep learning based recommender system: A survey and new perspectives. arXiv:1707.07435, 2017."}, {"ref": "[49] Y. Zhang, Y. Xiong, X. Kong, and Y. Zhu. Learning node embeddings in interaction graphs. In CIKM, 2017."}, {"ref": "[50] L.-k. Zhou, Y. Yang, X. Ren, F. Wu, and Y. Zhuang. Dynamic network embedding by modeling triadic closure process. In AAAI, 2018."}, {"ref": "[51] L. Zhu, D. Guo, J. Yin, G. Ver Steeg, and A. Galstyan. Scalable temporal latent space inference for link prediction in dynamic social networks. IEEE TKDE, 28(10):2765–2777, 2016."}, {"ref": "[52] Y. Zhu, H. Li, Y. Liao, B. Wang, Z. Guan, H. Liu, and D. Cai. What to do next: modeling user behaviors by time-lstm. In IJCAI, 2017."}]}, {"author": ["﻿Jundong Li", "Kewei Cheng", "Liang Wu", "Huan Liu"], "title": "Streaming Link Prediction on Dynamic Attributed Networks", "journal": "WSDM", "year": 2018, "DOI": "10.1145/3159652.3159674", "month": 2, "citations(google scholar)": 17, "abstract": "Link prediction targets to predict the future node interactions mainly based on the current network snapshot. It is a key step in understanding the formation and evolution of the underlying networks; and has practical implications in many real-world applications, ranging from friendship recommendation, click through prediction to targeted advertising. Most existing efforts are devoted to plain networks and assume the availability of network structure in memory before link prediction takes place. However, this assumption is untenable as many real-world networks are affiliated with rich node attributes, and often, the network structure and node attributes are both dynamically evolving at an unprecedented rate. Even though recent studies show that node attributes have an added value to network structure for accurate link prediction, it still remains a daunting task to support link prediction in an online fashion on such dynamic attributed networks. As changes in the dynamic attributed networks are often transient and can be endless, link prediction algorithms need to be efficient by making only one pass of the data with limited memory overhead. To tackle these challenges, we study a novel problem of streaming link prediction on dynamic attributed networks and present a novel framework - SLIDE. Methodologically, SLIDE maintains and updates a low-rank sketching matrix to summarize all observed data, and we further leverage the sketching matrix to infer missing links on the fly. The whole procedure is theoretically guaranteed, and empirical experiments on real-world dynamic attributed networks validate the effectiveness and efficiency of the proposed framework.", "keywords": ["Dynamic Attributed Networks，Link Prediction"], "reference_count": 57, "ccfClass": "B", "important": true, "references": [{"ref": "[1] Charu Aggarwal and Karthik Subbian. 2014. Evolutionary network analysis: A survey. CSUR (2014)."}, {"ref": "[2] Charu C Aggarwal. 2011. On Classification of Graph Streams. In SDM."}, {"ref": "[3] Charu C Aggarwal, Yuchen Zhao, and S Yu Philip. 2011. Outlier Detection in Graph Streams. In ICDE."}, {"ref": "[4] Charu C Aggarwal, Yuchen Zhao, and Philip S Yu. 2010. On Clustering Graph Streams. In SDM."}, {"ref": "[5] Mohammad Al Hasan and Mohammed J Zaki. 2011. A Survey of Link Prediction in Social Networks. In Social Network Data Analytics."}, {"ref": "[6] Lars Backstrom and Jure Leskovec. 2011. Supervised Random Walks: Predicting and Recommending Links in Social Networks. In WSDM."}, {"ref": "[7] Nicola Barbieri, Francesco Bonchi, and Giuseppe Manco. 2014. Who to Follow and Why: Link Prediction with Explanations. In KDD."}, {"ref": "[8] Shiyu Chang, Guo-Jun Qi, Charu C Aggarwal, Jiayu Zhou, Meng Wang, and Thomas S Huang. 2014. Factorized Similarity Learning in Networks. In ICDM."}, {"ref": "[9] Shiyu Chang, Yang Zhang, Jiliang Tang, Dawei Yin, Yi Chang, Mark A Hasegawa- Johnson, and Thomas S Huang. 2016. Positive-Unlabeled Learning in Streaming Networks. In KDD."}, {"ref": "[10] Chen Chen and Hanghang Tong. 2015. Fast Eigen-Functions Tracking on Dynamic Graphs. In SDM."}, {"ref": "[11] Chen Chen, Hanghang Tong, Lei Xie, Lei Ying, and Qing He. 2016. FASCINATE: Fast Cross-Layer Dependency Inference on Multi-Layered Networks. In KDD."}, {"ref": "[12] Lorenzo De Stefani, Alessandro Epasto, Matteo Riondato, and Eli Upfal. 2016. TRIèST: Counting Local and Global Triangles in Fully-Dynamic Streams with Fixed Memory Size. In KDD."}, {"ref": "[13] Liang Duan, Charu Aggarwal, Shuai Ma, Renjun Hu, and Jinpeng Huai. 2016. Scaling up Link Prediction with Ensembles. In WSDM."}, {"ref": "[14] Daniel M Dunlavy, Tamara G Kolda, and Evrim Acar. 2011. Temporal Link Prediction using Matrix and Tensor Factorizations. TKDD (2011)."}, {"ref": "[15] Joan Feigenbaum, Sampath Kannan, Andrew McGregor, Siddharth Suri, and Jian Zhang. 2005. On Graph Problems in a Semi-Streaming Model. TCS (2005)."}, {"ref": "[16] Huiji Gao, Xufei Wang, Jiliang Tang, and Huan Liu. 2013. Network Denoising in Social Media. In ASONAM."}, {"ref": "[17] Lise Getoor and Christopher P Diehl. 2005. Link Mining: A Survey. SIGKDD Explorations (2005)."}, {"ref": "[18] Mina Ghashami, Amey Desai, and JeffMPhillips. 2014. Improved Practical Matrix Sketching with Guarantees. In ESA."}, {"ref": "[19] Mina Ghashami and Jeff M Phillips. 2014. Relative Errors for Deterministic Low-Rank Matrix Approximations. In SODA."}, {"ref": "[20] Neil Zhenqiang Gong, Ameet Talwalkar, Lester Mackey, Ling Huang, Eui Chul Richard Shin, Emil Stefanov, Elaine Runting Shi, and Dawn Song. 2014. Joint Link Prediction and Attribute Inference using a Social-Attribute Network. TIST (2014)."}, {"ref": "[21] Ting Guo, Lianhua Chi, and Xingquan Zhu. 2013. Graph Hashing and Factorization for Fast Graph Stream Classification. In CIKM."}, {"ref": "[22] Chin-Chi Hsu, Yi-An Lai, Wen-Hao Chen, Ming-Han Feng, and Shou-De Lin. 2017. Unsupervised Ranking using Graph Structures and Node Attributes. In WSDM."}, {"ref": "[23] Hao Huang and Shiva Prasad Kasiviswanathan. 2015. Streaming Anomaly Detection Using Randomized Matrix Sketching. VLDB (2015)."}, {"ref": "[24] Hao Huang, Shinjae Yoo, and Shiva Prasad Kasiviswanathan. 2015. Unsupervised Feature Selection on Data Streams. In CIKM."}, {"ref": "[25] Ling Jian, Jundong Li, and Huan Liu. 2017. Toward Online Node Classification on Streaming Networks. DMKD (2017)."}, {"ref": "[26] Takuya Kitazawa. 2017. Sketching Dynamic User-Item Interactions for Online Item Recommendation. In CHIIR."}, {"ref": "[27] Jér?me Kunegis and Andreas Lommatzsch. 2009. Learning Spectral Graph Transformations for Link Prediction. In ICML."}, {"ref": "[28] Timothy La Fond and Jennifer Neville. 2010. Randomization Tests for Distinguishing Social Influence and Homophily Effects. In WWW."}, {"ref": "[29] Jundong Li, Harsh Dani, Xia Hu, and Huan Liu. 2017. Radar: Residual Analysis for Anomaly Detection in Attributed Networks. IJCAI (2017)."}, {"ref": "[30] Jundong Li, Harsh Dani, Xia Hu, Jiliang Tang, Yi Chang, and Huan Liu. 2017. Attributed Network Embedding for Learning in a Dynamic Environment. In CIKM."}, {"ref": "[31] Jundong Li, Xia Hu, Ling Jian, and Huan Liu. 2016. Toward Time-Evolving Feature Selection on Dynamic Networks. In ICDM."}, {"ref": "[32] Jundong Li, Xia Hu, LiangWu, and Huan Liu. 2016. Robust Unsupervised Feature Selection on Networked Data. In SDM."}, {"ref": "[33] Jundong Li, Jiliang Tang, Yilin Wang, Yali Wan, Yi Chang, and Huan Liu. 2017. Understanding and Predicting Delay in Reciprocal Relations. arXiv preprint arXiv:1703.01393 (2017)."}, {"ref": "[34] Jundong Li, LiangWu, Osmar R Za?ane, and Huan Liu. 2017. Toward Personalized Relational Learning. In SDM."}, {"ref": "[35] Lihong Li, Wei Chu, John Langford, and Robert E Schapire. 2010. A Contextual- Bandit Approach to Personalized News Article Recommendation. In WWW."}, {"ref": "[36] Yanen Li, Jia Hu, ChengXiang Zhai, and Ye Chen. 2010. Improving One-Class Collaborative Filtering by Incorporating Rich User Information. In CIKM."}, {"ref": "[37] David Liben-Nowell and Jon Kleinberg. 2007. The Link Prediction Problem for Social Networks. JASIST (2007)."}, {"ref": "[38] Edo Liberty. 2013. Simple and Deterministic Matrix Sketching. In KDD."}, {"ref": "[39] Ryan N Lichtenwalter, Jake T Lussier, and Nitesh V Chawla. 2010. New Perspectives and Methods in Link Prediction. In KDD."}, {"ref": "[40] Chih-Jen Lin. 2007. Projected Gradient Methods for Nonnegative Matrix Factorization. Neural Computation (2007)."}, {"ref": "[41] Andrew McGregor. 2005. Finding Graph Matchings in Data Streams. In APPROXRANDOM."}, {"ref": "[42] Andrew McGregor. 2014. Graph Stream Algorithms: A Survey. ACM SIGMOD Record (2014)."}, {"ref": "[43] Miller McPherson, Lynn Smith-Lovin, and JamesMCook. 2001. Birds of a Feather: Homophily in Social Networks. Annual Review of Sociology (2001)."}, {"ref": "[44] Aditya Menon and Charles Elkan. 2011. Link Prediction via Matrix Factorization. ECMLPKDD (2011)."}, {"ref": "[45] Rong Pan, Yunhong Zhou, Bin Cao, Nathan N Liu, Rajan Lukose, Martin Scholz, and Qiang Yang. 2008. One-class Collaborative Filtering. In ICDM."}, {"ref": "[46] Steffen Rendle. 2010. Factorization Machines. In ICDM."}, {"ref": "[47] Gilbert W Stewart. 1990. Matrix Perturbation Theory. (1990)."}, {"ref": "[48] Yizhou Sun, Jiawei Han, Charu C Aggarwal, and Nitesh V Chawla. 2012. When Will It Happen?: Relationship Prediction in Heterogeneous Information Networks. In WWW."}, {"ref": "[49] Hanghang Tong, Christos Faloutsos, and Jia-yu Pan. 2006. Fast Random Walk with Restart and Its Applications. In ICDM."}, {"ref": "[50] Alexey Tsymbal. 2004. The Problem of Concept Drift: Definitions and Related Work. Computer Science Department, Trinity College Dublin (2004)."}, {"ref": "[51] Xiaokai Wei, Linchuan Xu, Bokai Cao, and Philip S Yu. 2017. Cross View Link Prediction by Learning Noise-resilient Representation Consensus. In WWW."}, {"ref": "[52] Qingyun Wu, Huazheng Wang, Quanquan Gu, and Hongning Wang. 2016. Contextual Bandits in A Collaborative Environment. In SIGIR."}, {"ref": "[53] Zhijun Yin, Manish Gupta, Tim Weninger, and Jiawei Han. 2010. A Unified Framework for Link Recommendation Using Random Walks. In ASONAM."}, {"ref": "[54] Peixiang Zhao, Charu Aggarwal, and Gewen He. 2016. Link Prediction in Graph Streams. In ICDE."}, {"ref": "[55] Tong Zhao, H Vicky Zhao, and Irwin King. 2015. Exploiting Game Theoretic Analysis for Link Recommendation in Social Networks. In CIKM."}, {"ref": "[56] Yuchen Zhao and Philip S Yu. 2013. On Graph Stream Clustering with Side Information. In SDM."}, {"ref": "[57] Linhong Zhu, Dong Guo, Junming Yin, Greg Ver Steeg, and Aram Galstyan. 2016. Scalable Temporal Latent Space Inference for Link Prediction in Dynamic Social Networks. TKDE (2016)."}]}, {"author": ["﻿Taisong Li", "Bing Wang", "Yasong Jiang", "Yan Zhang", "Yonghong Yan"], "title": "Restricted Boltzmann Machine-Based Approaches for Link Prediction in Dynamic Networks", "journal": "IEEE Access", "year": 2018, "DOI": "10.1109/access.2018.2840054", "month": 5, "citations(google scholar)": 3, "abstract": "Link prediction in dynamic networks aims to predict edges according to historical linkage status. It is inherently difficult because of the linear/non-linear transformation of underlying structures. The problem of efficiently performing dynamic link inference is extremely challenging due to the scale of networks and different evolving patterns. Most previous approaches for link prediction are based on members’ similarity and supervised learning methods. However, research work on investigating hidden patterns of dynamic social networks is rarely conducted. In this paper, we propose a novel framework that incorporates a deep learning method, i.e., temporal restricted Boltzmann machine, and a machine learning approach, i.e., gradient boosting decision tree. The proposed model is capable of modeling each link’s evolving patterns. We also propose a novel transformation for input matrix, which significantly reduces the computational complexity and makes our algorithm scalable to large networks. Extensive experiments demonstrate that the proposed method outperforms the existing state-of-the-art algorithms on real-world dynamic networks.", "keywords": ["Link prediction", "social network analysis", "deep learning"], "reference_count": 38, "ccfClass": "", "important": true, "references": [{"ref": "[1] D. Liben-Nowell J. Kleinberg \"The link-prediction problem for social networks\" J. Amer. Soc. Inf. Sci. Technol. vol. 58 pp. 1019-1031 2007."}, {"ref": "[2] P. Wang B. Xu Y. Wu X. Zhou \"Link prediction in social networks: The state-of-the-art\" Sci. China Inf. Sci. vol. 58 no. 1 pp. 1-38 2015."}, {"ref": "[3] M. E. J. Newman \"Clustering and preferential attachment in growing networks\" Phys. Rev. E Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top. vol. 64 no. 2 pp. 025102 2001."}, {"ref": "[4] L. Katz \"A new status index derived from sociometric analysis\" Psychometrika vol. 18 no. 1 pp. 39-43 1953."}, {"ref": "[5] A.-L. Barabási H. Jeong Z. Néda E. Ravasz A. Schubert T. Vicsek \"Evolution of the social network of scientific collaborations\" Phys. A Stat. Mech. Appl. vol. 311 no. 3 pp. 590-614 2002."}, {"ref": "[6] Y. Sun J. Han C. C. Aggarwal N. V. Chawla \"When will it happen?: Relationship prediction in heterogeneous information networks\" Proc. 5th ACM Int. Conf. Web Search Data Mining pp. 663-672 2012."}, {"ref": "[7] Z. Lu B. Savas W. Tang I. S. Dhillon \"Supervised link prediction using multiple sources\" Proc. IEEE 10th Int. Conf. Data Mining (ICDM) pp. 923-928 Dec. 2010."}, {"ref": "[8] M. Rowe M. Stankovic H. Alani \"Who will follow whom? Exploiting semantics for link prediction in attention-information networks\" Proc. Int. Semantic Web Conf. pp. 476-491 2012."}, {"ref": "[9] F. Liu B. Liu C. Sun M. Liu X. Wang \"Deep learning approaches for link prediction in social network services\" Proc. Int. Conf. Neural Inf. Process. pp. 425-432 2013."}, {"ref": "[10] X. Li N. Du H. Li K. Li J. Gao A. Zhang \"A deep learning approach to link prediction in dynamic networks\" Proc. SIAM Int. Conf. Data Mining pp. 289-297 2013."}, {"ref": "[11] A. Clauset C. Moore M. E. Newman \"Hierarchical structure and the prediction of missing links in networks\" Nature vol. 453 no. 7191 pp. 98-101 2008."}, {"ref": "[12] R. Guimerà M. Sales-Pardo \"Missing and spurious interactions and the reconstruction of complex networks\" Proc. Nat. Acad. Sci. USA vol. 106 no. 52 pp. 22073-22078 2009."}, {"ref": "[13] C. Wang V. Satuluri S. Parthasarathy \"Local probabilistic models for link prediction\" Proc. 7th IEEE Int. Conf. Data Mining (ICDM) pp. 322-331 Oct. 2007."}, {"ref": "[14] N. M. Ahmed L. Chen \"An efficient algorithm for link prediction in temporal uncertain social networks\" Inf. Sci. vol. 331 pp. 120-136 Apr. 2016."}, {"ref": "[15] C. A. Bliss M. R. Frank C. M. Danforth P. S. Dodds \"An evolutionary algorithm approach to link prediction in dynamic social networks\" J. Comput. Sci. vol. 5 no. 5 pp. 750-764 2014."}, {"ref": "[16] L. Zhu D. Guo J. Yin G. Ver Steeg A. Galstyan \"Scalable temporal latent space inference for link prediction in dynamic social networks\" IEEE Trans. Knowl. Data Eng. vol. 28 no. 10 pp. 2765-2777 Oct. 2016."}, {"ref": "[17] M. W. Berry M. Browne A. N. Langville V. P. Pauca R. J. Plemmons \"Algorithms and applications for approximate nonnegative matrix factorization\" Comput. Statist. Data Anal. vol. 52 no. 1 pp. 155-173 2007."}, {"ref": "[18] P. Tseng S. Yun \"A coordinate gradient descent method for nonsmooth separable minimization\" Math. Program. vol. 117 no. 1 pp. 387-423 2009."}, {"ref": "[19] G. E. Hinton R. R. Salakhutdinov \"Reducing the dimensionality of data with neural networks\" Science vol. 313 no. 5786 pp. 504-507 2006."}, {"ref": "[20] G. E. Hinton \"Training products of experts by minimizing contrastive divergence\" Neural Comput. vol. 14 no. 8 pp. 1771-1800 2002."}, {"ref": "[21] G. W. Taylor G. E. Hinton S. T. Roweis \"Modeling human motion using binary latent variables\" Proc. Adv. Neural Inf. Process. Syst. pp. 1345-1352 2006."}, {"ref": "[22] T. Li J. Wang M. Tu Y. Zhang Y. Yan \"Enhancing link prediction using gradient boosting features\" Proc. Int. Conf. Intell. Comput. pp. 81-92 2016."}, {"ref": "[23] C. D. Manning P. Raghavan H. Schütze Introduction to Information Retrieval Cambridge U.K.:Cambridge Univ. Press vol. 1 pp. 496 2008."}, {"ref": "[24] L. A. Adamic E. Adar \"Friends and neighbors on the Web\" Soc. Netw. vol. 25 no. 3 pp. 211-230 2003."}, {"ref": "[25] T. Zhou L. Lü Y.-C. Zhang \"Predicting missing links via local information\" Eur. Phys. J. B vol. 71 no. 4 pp. 623-630 2009."}, {"ref": "[26] E. A. Leicht P. Holme M. E. J. Newman \"Vertex similarity in networks\" Phys. Rev. E Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top. vol. 73 no. 2 pp. 026120 2006."}, {"ref": "[27] J. H. Friedman \"Greedy function approximation: A gradient boosting machine\" Ann. Statist. vol. 29 no. 5 pp. 1189-1232 2001."}, {"ref": "[28] T. K. Ho \"Random decision forests\" Proc. 3rd Int. Conf. Document Anal. Recognit. vol. 1 pp. 278-282 Aug. 1995."}, {"ref": "[29] D. Yin L. Hong B. D. Davison \"Structural link analysis and prediction in microblogs\" Proc. 20th ACM Int. Conf. Inf. Knowl. Manage. pp. 1163-1168 2011."}, {"ref": "[30] Arxiv Hep-Ph Network Dataset—KONECT Oct. 2016 [online] Available: http://konect.uni-koblenz.de/networks/ca-cit-HepPh."}, {"ref": "[31] J. Leskovec J. Kleinberg C. Faloutsos \"Graph evolution: Densification and shrinking diameters\" ACM Trans. Knowl. Discovery Data vol. 1 no. 1 2007."}, {"ref": "[32] Enron Network Dataset—KONECT Oct. 2016 [online] Available: http://konect.uni-koblenz.de/networks/enron."}, {"ref": "[33] B. Klimt Y. Yang \"The enron corpus: A new dataset for email classification research\" Proc. Eur. Conf. Mach. Learn. pp. 217-226 2004."}, {"ref": "[34] Manufacturing Emails Network Dataset—KONECT Oct. 2016 [online] Available: http://konect.uni-koblenz.de/networks/radoslaw_email."}, {"ref": "[35] R. Michalski S. Palus P. Kazienko \"Matching organizational structure and social network extracted from email communication\" Proc. Int. Conf. Bus. Inf. Syst. vol. 87 pp. 197-206 2011."}, {"ref": "[36] Haggle Network Dataset—KONECT Oct. 2016 [online] Available: http://konect.uni-koblenz.de/networks/contact."}, {"ref": "[37] A. Chaintreau P. Hui J. Crowcroft C. Diot R. Gass J. Scott \"Impact of human mobility on opportunistic forwarding algorithms\" IEEE Trans. Mobile Comput. vol. 6 no. 6 pp. 606-620 Jun. 2007."}, {"ref": "[38] H. R. De Sá R. B. Prudêncio \"Supervised link prediction in weighted networks\" Proc. Int. Joint Conf. Neural Netw. (IJCNN) pp. 2281-2288 Jul./Aug. 2011."}]}, {"author": ["﻿Yujing Zhou", "Weile Liu", "Yang Pei", "Lei Wang", "Daren Zha", "Tianshu Fu"], "title": "Dynamic Network Embedding by Semantic Evolution", "journal": "2019 International Joint Conference on Neural Networks (IJCNN)", "year": 2019, "DOI": "10.1109/IJCNN.2019.8852247", "month": 7, "citations(google scholar)": 27, "abstract": "Network embedding, which aims to learn the low-dimensional representations of nodes, has attracted increasing attention in various fields such as social networks, paper citation networks and knowledge graphs. At present, most of the network embedding works are based on static networks, that is, the evolution of networks over time is not taken into account. It is more realistic to consider temporal information in network embedding and it could also make the embedding get more abundant information. In this paper, we propose a dynamic network embedding model DynSEM with semantic evolution, to train node embeddings in a sequence of networks over time. The advantage of our method is that it presents an effective inheritance of historical information. Our method uses nonrandom initialization and orthogonal procrustes method to align the node embeddings into common space which makes node embedding able to inheritance information. In particular, in the common space, we train a model to capture the dynamics information of the networks and smooth temporal node embeddings. We evaluate our method comparing it with other methods on three real-world datasets. The experimental results prove the effectiveness of dynamic network embeddings generated by DynSEM model.", "keywords": ["Dynamic Network", "Semantic Evolution", "Nonrandom Initialization", "Network Embedding"], "reference_count": 34, "ccfClass": "C", "important": true, "references": [{"ref": "[1] Le-kui Zhou Yang Yang Xiang Ren Fei Wu Yueting Zhuang Dynamic Network Embedding by Modeling Triadic Closure Process AAAI pp. 571-578 2018."}, {"ref": "[2] B Perozzi R Alrfou S Skiena DeepWalk: online learning of social representations[J] pp. 701-710 2014."}, {"ref": "[3] A Grover J Leskovec node2vec: Scalable Feature Learning for Networks[J] vol. 2016 pp. 855-864 2016."}, {"ref": "[4] D Wang P Cui W Zhu \"Structural Deep Network Embedding[C]\" Acm Sigkdd International Conference on Knowledge Discovery &amp; Data Mining 2016."}, {"ref": "[5] Li J Dani H Hu X et al. \"Attributed network embedding for learning in a dynamic environment[C]\" Proceedings of the 2017 ACM on Conference on Information and Knowledge Management pp. 387-396 2017."}, {"ref": "[6] D Zhu P Cui Z Zhang et al. \"High-order Proximity Preserved Embedding For Dynamic Networks[J]\" IEEE Transactions on Knowledge &amp; Data Engineering vol. PP no. 99 pp. 1-1 2018."}, {"ref": "[7] Lun Du et al. Dynamic Network Embedding: An Extended Approach for Skip-gram based Network Embedding IJCAI 2018."}, {"ref": "[8] P Goyal N Kamra X He et al. \"DynGEM: Deep Embedding Method for Dynamic Graphs[J]\" arXiv preprint arXiv:1805.11273 2018."}, {"ref": "[9] Palash Goyal Sujit Rokka Chhetri Arquimedes Canedo \"dyngraph2vec: Capturing Network Dynamics using Dynamic Graph Representation Learning\" arXiv preprint arXiv:1809.02657 2018."}, {"ref": "[10] GD Rosin K Radinsky E Adar Learning Word Relatedness over Time[J] 2017."}, {"ref": "[11] Z Yao Y Sun W Ding et al. Dynamic Word Embeddings for Evolving Semantic Discovery[J] 2017."}, {"ref": "[12] R Bamler S Mandt Dynamic Word Embeddings[J] 2017."}, {"ref": "[13] Y Bengio JS Senecal \"Adaptive importance sampling to accelerate training of a neural probabilistic language model.[J]\" IEEE Transactions on Neural Networks vol. 19 no. 4 pp. 713 2008."}, {"ref": "[14] Mikolov T Chen K Corrado G et al. \"Efficient Estimation of Word Representations in Vector Space[J]\" Computer Science 2013."}, {"ref": "[15] J Pennington R Socher C Manning \"Glove: Global Vectors for Word Representation[C]\" Conference on Empirical Methods in Natural Language Processing pp. 1532-1543 2014."}, {"ref": "[16] O Levy Y Goldberg \"Neural word embedding as implicit matrix factorization[J]\" Advances in Neural Information Processing Systems vol. 3 pp. 2177-2185 2014."}, {"ref": "[17] S.T. Roweis \"Nonlinear Dimensionality Reduction by Locally Linear Embedding[J]\" Science vol. 290 no. 5500 pp. 2323-2326 2000."}, {"ref": "[18] M Belkin P Niyogi TG Dietterich et al. \"Laplacian eigenmaps and spectral techniques for embedding and clustering.[J]\" Advances in Neural Information Processing Systems vol. 14 no. 6 pp. 585-591 2001."}, {"ref": "[19] L Tang H Liu \"Leveraging social media networks for classification[J]\" Data Mining and Knowledge Discovery vol. 23 no. 3 pp. 447-478 2011."}, {"ref": "[20] T Chen Q Yang X Tang et al. \"Directed graph embedding[C]\" International Joint Conference on Artifical Intelligence 2007."}, {"ref": "[21] L Tang H Liu \"Relational learning via latent social dimensions[C]\" Acm Sigkdd International Conference on Knowledge Discovery &amp; Data Mining. DBLP 2009."}, {"ref": "[22] Zhang M Tang J Qu M et al. LINE: Large-scale Information Network Embedding[J] vol. 2 no. 2 pp. 1067-1077 2015."}, {"ref": "[23] D Wang P Cui W Zhu \"Structural Deep Network Embedding[C]\" ACM SIGKDD International Conference on Knowledge Discovery and Data Mining pp. 2016-1234."}, {"ref": "[24] C Yang Z Liu D Zhao et al. \"Network Representation Learning with Rich Text Information[C]\" International Conference on Artificial Intelligence 2015."}, {"ref": "[25] CC Tu WC Zhang ZY Liu et al. \"Max-Margin DeepWalk: discriminative learning of network representation\" Proceedings of International Joint Conference on Artificial Intelligence (IJCAI) 2016."}, {"ref": "[26] S Cao W Lu Q Xu \"GraRep: Learning Graph Representations with Global Structural Information[C]\" Acm International on Conference on Information &amp; Knowledge Management 2015."}, {"ref": "[27] V Kulkarni R Alrfou B Perozzi et al. Statistically Significant Detection of Linguistic Change[J] 2014."}, {"ref": "[28] Terrence Szymanski \"Temporal Word Analogies: Identifying Lexical Replacement with Diachronic Word Embeddings\" ACL no. 2 pp. 448-453 2017."}, {"ref": "[29] M Rudolph D Blei Dynamic Bernoulli Embeddings for Language Evolution[J] 2017."}, {"ref": "[30] T Mikolov I Sutskever K Chen et al. \"Distributed Representations of Words and Phrases and their Compositionality[J]\" Advances in Neural Information Processing Systems vol. 26 pp. 3111-3119 2013."}, {"ref": "[31] Y Kim Y Chiu K Hanaki et al. \"Temporal Analysis of Language through Neural Language Models[J]\" Computer Science vol. 6 no. 3 pp. 153-178 2014."}, {"ref": "[32] LVD Maaten G Hinton \"Visualizing Data using t-SNE[J]\" Journal of Machine Learning Research vol. 9 no. 2605 pp. 2579-2605 2008."}, {"ref": "[33] L Zhu D Guo J Yin et al. \"Scalable Temporal Latent Space Inference for Link Prediction in Dynamic Social Networks[J]\" IEEE Transactions on Knowledge &amp; Data Engineering vol. 28 no. 10 pp. 2765-2777 2016."}, {"ref": "[34] J Tang J Zhang L Yao et al. \"ArnetMiner: extraction and mining of academic social networks[C]\" Acm Sigkdd International Conference on Knowledge Discovery &amp; Data Mining. DBLP 2008."}]}, {"author": ["﻿Jianxin Ma", "Peng Cui", "Wenwu Zhu"], "title": "DepthLGP: Learning Embeddings of Out-of-Sample Nodes in Dynamic Networks", "journal": "AAAI", "year": 2018, "DOI": "CannotFind", "month": 2, "citations(google scholar)": 29, "abstract": "Network embedding algorithms to date are primarily designed for static networks, where all nodes are known before learning. How to infer embeddings for out-of-sample nodes, i.e. nodes that arrive after learning, remains an open problem. The problem poses great challenges to existing methods, since the inferred embeddings should preserve intricate network properties such as high-order proximity, share similar characteristics (i.e. be of a homogeneous space) with in-sample node embeddings, and be of low computational cost. To overcome these challenges, we propose a Deeply Transformed High-order Laplacian Gaussian Process (DepthLGP) method to infer embeddings for out-of-sample nodes. DepthLGP combines the strength of nonparametric probabilistic modeling and deep learning. In particular, we design a high-order Laplacian Gaussian process (hLGP) to encode network properties, which permits fast and scalable inference. In order to further ensure homogeneity, we then employ a deep neural network to learn a nonlinear transformation from latent states of the hLGP to node embeddings. DepthLGP is general, in that it is applicable to embeddings learned by any network embedding algorithms. We theoretically prove the expressive power of DepthLGP, and conduct extensive experiments on real-world networks. Empirical results demonstrate that our approach can achieve significant performance gain over existing approaches.", "keywords": ["None"], "reference_count": 40, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Belkin, M.; Niyogi, P.; and Sindhwani, V. 2006. Manifold regularization: A geometric framework for learning from labeled and unlabeled examples. JMLR."}, {"ref": "[2] Breitkreutz, B.-J.; Stark, C.; Reguly, T.; Boucher, L.; Breitkreutz, A.; Livstone, M.; Oughtred, R.; Lackner, D. H.;"}, {"ref": "[3] Bhler, J.; Wood, V.; Dolinski, K.; and Tyers, M. 2008. The biogrid interaction database: 2008 update. Nucleic Acids Research."}, {"ref": "[4] Cao, S.; Lu, W.; and Xu, Q. 2015. Grarep: Learning graph representations with global structural information. In Proceedings of CIKM 2015."}, {"ref": "[5] Chapelle, O.; Schlkopf, B.; and Zien, A. 2010. SemiSupervised Learning. The MIT Press."}, {"ref": "[6] Chen, L.; Tsang, I. W.; and Xu, D. 2012. Laplacian embedded regression for scalable manifold regularization. IEEE Transactions on Neural Networks and Learning Systems."}, {"ref": "[7] Chu, W.; Sindhwani, V.; Ghahramani, Z.; and Keerthi, S. S. 2006. Relational learning with gaussian processes. In Proceedings of NIPS 2006."}, {"ref": "[8] Cybenko, G. 1989. Approximation by superpositions of a sigmoidal function. Mathematics of Control, Signals and Systems."}, {"ref": "[9] Delalleau, O.; Bengio, Y.; and Roux, N. L. 2005. Efficient non-parametric function induction in semi-supervised learning. In Proceedings of AISTATS 2005."}, {"ref": "[10] Dong, Y.; Chawla, N. V.; and Swami, A. 2017. Metapath2vec: Scalable representation learning for heterogeneous networks. In Proceedings of KDD 2017."}, {"ref": "[11] Dreyfus, S. 1962. The numerical solution of variational problems. Journal of Mathematical Analysis and Applications."}, {"ref": "[12] Grover, A., and Leskovec, J. 2016. Node2vec: Scalable feature learning for networks. In Proceedings of KDD 2016."}, {"ref": "[13] He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep residual learning for image recognition. In Proceedings of CVPR 2016."}, {"ref": "[14] Hornik, K. 1991. Approximation capabilities of multilayer feedforward networks. Neural Networks."}, {"ref": "[15] Joachims, T. 2003. Transductive learning via spectral graph partitioning. In Proceedings of ICML 2003."}, {"ref": "[16] Karlen, M.; Weston, J.; Erkan, A.; and Collobert, R. 2008. Large scale manifold transduction. In Proceedings of ICML 2008."}, {"ref": "[17] Kingma, D., and Ba, J. 2015. Adam: A method for stochastic optimization. In Proceedings of ICLR 2015."}, {"ref": "[18] Ou, M.; Cui, P.; Wang, F.; Wang, J.; and Zhu, W. 2015. Non-transitive hashing with latent similarity components. In Proceedings of KDD 2015."}, {"ref": "[19] Ou, M.; Cui, P.; Pei, J.; Zhang, Z.; and Zhu, W. 2016. Asymmetric transitivity preserving graph embedding. In Proceedings of KDD 2016."}, {"ref": "[20] Perozzi, B.; Al-Rfou, R.; and Skiena, S. 2014. Deepwalk: Online learning of social representations. In Proceedings of  KDD 2014."}, {"ref": "[21] Rasmussen, C. E., and Williams, C. K. I. 2005. Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning). The MIT Press."}, {"ref": "[22] Rumelhart, D. E.; Hinton, G. E.; and Williams, R. J. 1988. Learning representations by back-propagating errors. In Neurocomputing: Foundations of Research. The MIT Press."}, {"ref": "[23] Silva, R.; Chu, W.; and Ghahramani, Z. 2007. Hidden common cause relations in relational learning. In Proceedings of NIPS 2007."}, {"ref": "[24] Smola, A. J., and Kondor, R. 2003. Kernels and regularization on graphs. In Proceedings of COLT 2003."}, {"ref": "[25] Stoyanov, V.; Ropson, A.; and Eisner, J. 2011. Empirical risk minimization of graphical model parameters given approximate inference, decoding, and model structure. In Proceedings of AISTATS 2011."}, {"ref": "[26] Subramanya, A., and Bilmes, J. 2008. Soft-supervised learning for text classification. In Proceedings of EMNLP 2008."}, {"ref": "[27] Szummer, M., and Jaakkola, T. 2001. Partially labeled classification with markov random walks. In Proceedings of NIPS 2001."}, {"ref": "[28] Tang, L., and Liu, H. 2009. Relational learning via latent social dimensions. In Proceedings of KDD 2009."}, {"ref": "[29] Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, Q. 2015. Line: Large-scale information network embedding. In Proceedings of WWW 2015."}, {"ref": "[30] Tomar, V. S., and Rose, R. C. 2014. Manifold regularized deep neural networks. In Proceedings of INTERSPEECH 2014."}, {"ref": "[31] Wang, S.; Tang, J.; Aggarwal, C.; Chang, Y.; and Liu, H. 2017a. Signed network embedding in social media. In Proceedings of SDM 2017."}, {"ref": "[32] Wang, X.; Cui, P.; Wang, J.; Pei, J.; Zhu, W.; and Yang, S. 2017b. Community preserving network embedding. In Proceedings of AAAI 2017."}, {"ref": "[33] Wang, D.; Cui, P.; and Zhu, W. 2016. Structural deep network embedding. In Proceedings of KDD 2016."}, {"ref": "[34] Yang, C.; Liu, Z.; Zhao, D.; Sun, M.; and Chang, E. Y. 2015. Network representation learning with rich text information. In Proceedings of IJCAI 2015."}, {"ref": "[35] Yu, K., and Chu, W. 2007. Gaussian process models for link analysis and transfer learning. In Proceedings of NIPS 2007."}, {"ref": "[36] Yu, K.; Chu, W.; Yu, S.; Tresp, V.; and Xu, Z. 2006. Stochastic relational models for discriminative link prediction. In Proceedings of NIPS 2006."}, {"ref": "[37] Zheng, Q., and Skillicorn, D. 2015. Spectral embedding of signed networks. In Proceedings of SDM 2015."}, {"ref": "[38] Zhu, X., and Ghahramani, Z. 2002. Learning from labeled and unlabeled data with label propagation. Technical report, Carnegie Mellon University."}, {"ref": "[39] Zhu, X.; Ghahramani, Z.; and Lafferty, J. 2003. Semisupervised learning using gaussian fields and harmonic functions. In Proceedings of ICML 2003."}, {"ref": "[40] Zhu, X. 2005. Semi-supervised Learning with Graphs.Ph.D. Dissertation, Carnegie Mellon University."}]}, {"author": ["﻿Uriel Singer", "Ido Guy", "Kira Radinsky"], "title": "Node Embedding over Temporal Graphs", "journal": "IJCAI", "year": 2019, "DOI": "10.24963/ijcai.2019/640", "month": 4, "citations(google scholar)": 1, "abstract": "In this work, we present a method for node embedding in temporal graphs. We propose an algorithm that learns the evolution of a temporal graph's nodes and edges over time and incorporates this dynamics in a temporal node embedding framework for different graph prediction tasks. We present a joint loss function that creates a temporal embedding of a node by learning to combine its historical temporal embeddings, such that it optimizes per given task (e.g., link prediction). The algorithm is initialized using static node embeddings, which are then aligned over the representations of a node at different time points, and eventually adapted for the given task in a joint optimization. We evaluate the effectiveness of our approach over a variety of temporal graphs for the two fundamental tasks of temporal link prediction and multi-label node classification, comparing to competitive baselines and algorithmic alternatives. Our algorithm shows performance improvements across many of the datasets and baselines and is found particularly effective for graphs that are less cohesive, with a lower clustering coefficient.", "keywords": ["Node Embedding", "Temporal Graphs"], "reference_count": 59, "ccfClass": "A", "important": true, "references": [{"ref": "[1] Leman Akoglu, Hanghang Tong, and Danai Koutra. 2015. Graph based anomaly detection and description: a survey. Data Mining and Knowledge Discovery 29, 3 (2015), 626–688."}, {"ref": "[2] Mohammad Al Hasan, Vineet Chaoji, Saeed Salem, and Mohammed Zaki. 2006. Link prediction using supervised learning. In Proc. of SDM06: workshop on link analysis, counter-terrorism and security."}, {"ref": "[3] Albert-Laszlo Barabasi and Reka Albert. 1999. Emergence of Scaling in Random Networks. Science 286, 5439 (1999), 509–512."}, {"ref": "[4] Mikhail Belkin and Partha Niyogi. 2002. Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering. In Advances in Neural Information Processing Systems 14. 585–591."}, {"ref": "[5] Paul J Besl and Neil D McKay. 1992. Method for registration of 3-D shapes. In Sensor Fusion IV: Control Paradigms and Data Structures, Vol. 1611. 586–607."}, {"ref": "[6] Justin Cheng, Lada Adamic, P. Alex Dow, Jon Michael Kleinberg, and Jure Leskovec. 2014. Can Cascades Be Predicted?. In Proc. of WWW. 925–936."}, {"ref": "[7] Peng Cui, Xiao Wang, Jian Pei, and Wenwu Zhu. 2018. A survey on network embedding. IEEE Transactions on Knowledge and Data Engineering (2018)."}, {"ref": "[8] Zhiyong Cui, Kristian Henrickson, Ruimin Ke, and Yinhai Wang. 2018. HighOrder Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting. arXiv preprint abs/1802.07007 (2018)."}, {"ref": "[9] Lun Du, Yun Wang, Guojie Song, Zhicong Lu, and Junshan Wang. 2018. Dynamic Network Embedding: An Extended Approach for Skip-gram based Network Embedding.. In IJCAI. 2086–2092."}, {"ref": "[10] Daniel M Dunlavy, Tamara G Kolda, and Evrim Acar. 2011. Temporal link prediction using matrix and tensor factorizations. ACM Transactions on Knowledge Discovery from Data (TKDD) 5, 2 (2011), 10."}, {"ref": "[11] Jie Feng, Yong Li, Chao Zhang, Funing Sun, Fanchao Meng, Ang Guo, and Depeng Jin. 2018. DeepMove: Predicting Human Mobility with Attentional Recurrent Networks. In Proc. of WWW. 1459–1468."}, {"ref": "[12] Palash Goyal and Emilio Ferrara. 2018. Graph embedding techniques, applications, and performance: A survey. Knowledge-Based Systems 151 (2018), 78–94."}, {"ref": "[13] Palash Goyal, Nitin Kamra, Xinran He, and Yan Liu. 2017. DynGEM: Deep Embedding Method for Dynamic Graphs. arXiv preprint abs/1805.11273 (2017)."}, {"ref": "[14] Aditya Grover and Jure Leskovec. 2016. Node2Vec: Scalable Feature Learning for Networks. In Proc. of KDD. 855–864."}, {"ref": "[15] William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Representation learning on graphs: Methods and applications. arXiv preprint abs/1709.05584 (2017)."}, {"ref": "[16] Alan G Hawkes. 1971. Spectra of some self-exciting and mutually exciting point processes. Biometrika 58, 1 (1971), 83–90."}, {"ref": "[17] Derek LG Hill, Philipp G Batchelor, Mark Holden, and David J Hawkes. 2001. Medical image registration. Physics in medicine & biology 46, 3 (2001), R1."}, {"ref": "[18] Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735–1780."}, {"ref": "[19] John R Hurley and Raymond B Cattell. 1962. The Procrustes program: Producing direct rotation to test a hypothesized factor structure. Systems Research and Behavioral Science 7, 2 (1962), 258–262."}, {"ref": "[20] Ashesh Jain, Amir R Zamir, Silvio Savarese, and Ashutosh Saxena. 2016. Structural-RNN: Deep learning on spatio-temporal graphs. In Proc. of CVPR. 5308–5317."}, {"ref": "[21] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint abs/1412.6980 (2014)."}, {"ref": "[22] Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint abs/1609.02907 (2016)."}, {"ref": "[23] Andrey Kupavskii, Liudmila Ostroumova, Alexey Umnov, Svyatoslav Usachev, Pavel Serdyukov, Gleb Gusev, and Andrey Kustarev. 2012. Prediction of Retweet Cascade Size over Time. In Proc. of CIKM. 2335–2338."}, {"ref": "[24] Jure Leskovec, Lars Backstrom, Ravi Kumar, and Andrew Tomkins. 2008. Microscopic Evolution of Social Networks. In Proc. of KDD. 462–470."}, {"ref": "[25] Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. 2005. Graphs over Time: Densification Laws, Shrinking Diameters and Possible Explanations. In Proc. of KDD. 177–187."}, {"ref": "[26] Jundong Li, Harsh Dani, Xia Hu, Jiliang Tang, Yi Chang, and Huan Liu. 2017. Attributed network embedding for learning in a dynamic environment. In Proc. of CIKM. 387–396."}, {"ref": "[27] Taisong Li, Jiawei Zhang, S Yu Philip, Yan Zhang, and Yonghong Yan. 2018. Deep Dynamic Network Embedding for Link Prediction. IEEE Access (2018)."}, {"ref": "[28] Xiaoyi Li, Nan Du, Hui Li, Kang Li, Jing Gao, and Aidong Zhang. 2014. A Deep Learning Approach to Link Prediction in Dynamic Networks. In Proc. of SDM. 289–297."}, {"ref": "[29] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. 2015. Gated graph sequence neural networks. arXiv preprint abs/1511.05493 (2015)."}, {"ref": "[30] David Liben-Nowell and Jon Kleinberg. 2007. The Link-prediction Problem for Social Networks. J. Am. Soc. Inf. Sci. Technol. 58, 7 (May 2007), 1019–1031."}, {"ref": "[31] Linyuan Lü and Tao Zhou. 2011. Link prediction in complex networks: A survey. Physica A: statistical mechanics and its applications 390, 6 (2011), 1150–1170."}, {"ref": "[32] Aditya Krishna Menon and Charles Elkan. 2011. Link prediction via matrix factorization. In Proc. of ECML PKDD. 437–452."}, {"ref": "[33] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. arXiv preprint abs/1301.3781 (2013)."}, {"ref": "[34] Giang Hoang Nguyen, John Boaz Lee, Ryan A Rossi, Nesreen K Ahmed, Eunyee Koh, and Sungchul Kim. 2018. Continuous-time dynamic network embeddings. In Proc. of WWW Companion. 969–976."}, {"ref": "[35] Hamid Palangi, Li Deng, Yelong Shen, Jianfeng Gao, Xiaodong He, Jianshu Chen, Xinying Song, and Rabab K. Ward. 2015. Deep Sentence Embedding Using the Long Short Term Memory Network: Analysis and Application to Information Retrieval. (2015)."}, {"ref": "[36] Gergely Palla, Imre Der??nyi, Ill??s Farkas, and Tam??s Vicsek. 2005. Uncovering the overlapping community structure of complex networks in nature and society. Nature 435, 7043 (June 2005), 814–818."}, {"ref": "[37] Ashwini Patil and Haruki Nakamura. 2005. HINT: a database of annotated protein-protein interactions and their homologs. Biophysics 1 (2005), 21–24."}, {"ref": "[38] Yulong Pei, Jianpeng Zhang, George HL Fletcher, and Mykola Pechenizkiy. 2016. Node classification in dynamic social networks. In Proc. of AALTD (ECML/PKDD Workshop). 8."}, {"ref": "[39] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: Online Learning of Social Representations. In Proc. of KDD. 701–710."}, {"ref": "[40] F. Radicchi, C. Castellano, F. Cecconi, V. Loreto, and D. Parisi. 2004. Defining and identifying communities in networks. Proceedings of the National Academy of Sciences 101, 9 (2004), 2658."}, {"ref": "[41] Ryan A. Rossi and Nesreen K. Ahmed. 2015. Role Discovery in Networks. IEEE Trans. Knowl. Data Eng. 27, 4 (2015), 1112–1131."}, {"ref": "[42] Sam T. Roweis and Lawrence K. Saul. 2000. Nonlinear dimensionality reduction by locally linear embedding. SCIENCE 290 (2000), 2323–2326."}, {"ref": "[43] Peter H Sch?nemann. 1966. A generalized solution of the orthogonal procrustes problem. Psychometrika 31, 1 (1966), 1–10."}, {"ref": "[44] Peter H Sch?nemann and Robert M Carroll. 1970. Fitting one matrix to another under choice of a central dilation and a rigid motion. Psychometrika 35, 2 (1970), 245–255."}, {"ref": "[45] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale Information Network Embedding. In Proc. of WWW. 1067–1077."}, {"ref": "[46] Joshua B. Tenenbaum, Vin de Silva, and John C. Langford. 2000. A Global Geometric Framework for Nonlinear Dimensionality Reduction. Science 290 (2000), 2319."}, {"ref": "[47] Rakshit Trivedi, Hanjun Dai, Yichen Wang, and Le Song. 2017. Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs. In Proc. of ICML. 3462–3471."}, {"ref": "[48] Rakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, and Hongyuan Zha. 2018. Representation Learning over Dynamic Graphs. arXiv preprint abs/1803.04051 (2018)."}, {"ref": "[49] Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural Deep Network Embedding. In Proc. of KDD. 1225–1234."}, {"ref": "[50] Hongjian Wang and Zhenhui Li. 2017. Region Representation Learning via Mobility Flow. In Proc. of CIKM. 237–246."}, {"ref": "[51] Stanley Wasserman and Katherine Faust. 1994. Social network analysis: Methods and applications. Vol. 8. Cambridge university press."}, {"ref": "[52] Sijie Yan, Yuanjun Xiong, and Dahua Lin. 2018. Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition. In Proc. of AAAI. 3482–3489."}, {"ref": "[53] Shuicheng Yan, Dong Xu, Benyu Zhang, Hong-Jiang Zhang, Qiang Yang, and Stephen Lin. 2007. Graph Embedding and Extensions: A General Framework for Dimensionality Reduction. IEEE Trans. Pattern Anal. Mach. Intell. 29, 1 (2007), 40–51."}, {"ref": "[54] Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2017. Spatio-temporal Graph Convolutional Neural Network: A Deep Learning Framework for Traffic Forecasting. arXiv preprint abs/1709.04875 (2017)."}, {"ref": "[55] Wenchao Yu, Charu C. Aggarwal, and Wei Wang. 2017. Temporally Factorized Network Modeling for Evolutionary Network Analysis. In Proc. of WSDM (WSDM ’17). 455–464."}, {"ref": "[56] Le-kui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. 2018. Dynamic Network Embedding by Modeling Triadic Closure Process. In Proc. of AAAI. 571–578."}, {"ref": "[57] Dingyuan Zhu, Peng Cui, Ziwei Zhang, Jian Pei, and Wenwu Zhu. 2018. Highorder Proximity Preserved Embedding For Dynamic Networks. IEEE Transactions on Knowledge and Data Engineering (2018), 2134–2144."}, {"ref": "[58] Linhong Zhu, Dong Guo, Junming Yin, Greg Ver Steeg, and Aram Galstyan. 2016. Scalable temporal latent space inference for link prediction in dynamic social networks. IEEE Transactions on Knowledge and Data Engineering 28, 10 (2016), 2765–2777."}, {"ref": "[59] Yuan Zuo, Guannan Liu, Hao Lin, Jia Guo, Xiaoqian Hu, and Junjie Wu. 2018. Embedding Temporal Network via Neighborhood Formation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 2857–2866."}]}, {"author": ["﻿Carter Chiu", "Justin Zhan"], "title": "Deep Learning for Link Prediction in Dynamic Networks Using Weak Estimators", "journal": "IEEE Access", "year": 2018, "DOI": "10.1109/access.2018.2845876", "month": 6, "citations(google scholar)": 12, "abstract": "Link prediction is the task of evaluating the probability that an edge exists in a network, and it has useful applications in many domains. Traditional approaches rely on measuring the similarity between two nodes in a static context. Recent research has focused on extending link prediction to a dynamic setting, predicting the creation and destruction of links in networks that evolve over time. Though a difficult task, the employment of deep learning techniques has shown to make notable improvements to the accuracy of predictions. To this end, we propose the novel application of weak estimators in addition to the utilization of traditional similarity metrics to inexpensively build an effective feature vector for a deep neural network. Weak estimators have been used in a variety of machine learning algorithms to improve model accuracy, owing to their capacity to estimate the changing probabilities in dynamic systems. Experiments indicate that our approach results in increased prediction accuracy on several real-world dynamic networks.", "keywords": ["Deep learning", "link prediction", "dynamic networks", "weak estimators", "similarity metrics"], "reference_count": 52, "ccfClass": "", "important": true, "references": [{"ref": "[1] D. Liben-Nowell and J. Kleinberg, \"The link-prediction problem for social networks,\" J. Am. Soc. Inf. Sci. Technol., vol. 58, no. 7, pp. 1019–1031, May 2007."}, {"ref": "[2] L. A. Adamic and E. Adar, \"Friends and neighbors on the web,\" Social Networks, vol. 25, no. 3, pp. 211–230, 2003."}, {"ref": "[3] L. Katz, \"A new status index derived from sociometric analysis,\" Psychometrika, vol. 18, no. 1, pp. 39–43, Mar 1953."}, {"ref": "[4] L. Yao, L. Wang, L. Pan, and K. Yao, \"Link prediction based on common-neighbors for dynamic social network,\" Procedia Computer Science, vol. 83, no. Supplement C, pp. 82 – 89, 2016, Workshops."}, {"ref": "[5] M. Kaya, M. Jawed, E. But¨ un, and R. Alhajj, ¨ Unsupervised Link Prediction Based on Time Frames in Weighted–Directed Citation Networks. Cham: Springer International Publishing, 2017, pp. 189–205."}, {"ref": "[6] H. Wang, W. Hu, Z. Qiu, and B. Du, \"Nodes’ evolution diversity and link prediction in social networks,\" IEEE Transactions on Knowledge and Data Engineering, vol. 29, no. 10, pp. 2263–2274, Oct 2017."}, {"ref": "[7] H. A. Deylami and M. Asadpour, \"Link prediction in social networks using hierarchical community detection,\" in 2015 7th Conference on Information and Knowledge Technology (IKT), May 2015, pp. 1–5."}, {"ref": "[8] W. Hu, H. Wang, C. Peng, H. Liang, and B. Du, \"An event detection method for social networks based on link prediction,\" Information Systems, vol. 71, pp. 16 – 26, 2017. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0306437917303976"}, {"ref": "[9] W. Hu, H. Wang, Z. Qiu, C. Nie, L. Yan, and B. Du, \"An event detection method for social networks based on hybrid link prediction and quantum swarm intelligent,\" World Wide Web, vol. 20, no. 4, pp. 775–795, Jul 2017. [Online]. Available: https://doi.org/10.1007/s11280-016-0416-y"}, {"ref": "[10] L. Zhang, F. Zhuo, C. Bai, and H. Xu, \"Analytical model for predictable contact in intermittently connected cognitive radio ad hoc networks,\" International Journal of Distributed Sensor Networks,  vol. 12, no. 7, p. 1550147716659426, 2016. [Online]. Available: https://doi.org/10.1177/1550147716659426"}, {"ref": "[11] M. A. Hasan, V. Chaoji, S. Salem, and M. Zaki, \"Link prediction using supervised learning,\" in In Proc. of SDM 06 workshop on Link Analysis, Counterterrorism and Security, 2006."}, {"ref": "[12] N. Benchettara, R. Kanawati, and C. Rouveirol, \"Supervised machine learning applied to link prediction in bipartite social networks,\" in 2010 International Conference on Advances in Social Networks Analysis and Mining, Aug 2010, pp. 326–330."}, {"ref": "[13] J. R. Doppa, J. Yu, P. Tadepalli, and L. Getoor, Learning Algorithms for Link Prediction Based on Chance Constraints. Berlin, Heidelberg: Springer Berlin Heidelberg, 2010, pp. 344–360."}, {"ref": "[14] X. Li, N. Du, H. Li, K. Li, J. Gao, and A. Zhang, A Deep Learning Approach to Link Prediction in Dynamic Networks, pp. 289–297."}, {"ref": "[15] C. Zhang, H. Zhang, D. Yuan, and M. Zhang, \"Deep learning based link prediction with social pattern and external attribute knowledge in bibliographic networks,\" in 2016 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData), Dec 2016, pp. 815–821."}, {"ref": "[16] M. Rahman and M. A. Hasan, Link Prediction in Dynamic Networks Using Graphlet. Cham: Springer International Publishing, 2016, pp. 394–409."}, {"ref": "[17] T. D. Bui, S. Ravi, and V. Ramavajjala, \"Neural graph machines: Learning neural networks using graphs,\" CoRR, vol. abs/1703.04818, 2017."}, {"ref": "[18] R. A. Rossi, R. Zhou, and N. K. Ahmed, \"Deep feature learning for graphs,\" in arXiv:1704.08829, 2017, pp. 1–11."}, {"ref": "[19] I. Fras-Blanco, J. d. Campo-vila, G. Ramos-Jimnez, R. MoralesBueno, A. Ortiz-Daz, and Y. Caballero-Mota, \"Online and nonparametric drift detection methods based on hoeffding’s bounds,\" IEEE Transactions on Knowledge and Data Engineering, vol. 27, no. 3, pp. 810–823, March 2015."}, {"ref": "[20] M. Bhaduri, J. Zhan, C. Chiu, and F. Zhan, \"A novel online and non-parametric approach for drift detection in big data,\" IEEE Access, vol. 5, pp. 15 883–15 892, 2017."}, {"ref": "[21] H. Wang and Z. Abraham, \"Concept drift detection for streaming data,\" in 2015 International Joint Conference on Neural Networks (IJCNN), 07 2015, pp. 1–9."}, {"ref": "[22] H.-K. Song, \"A channel estimation using sliding window approach and tuning algorithm for mlse,\" IEEE Communications Letters, vol. 3, no. 7, pp. 211–213, July 1999."}, {"ref": "[23] M. M. Lazarescu, S. Venkatesh, and H. H. Bui, \"Using multiple windows to track concept drift,\" Intell. Data Anal., vol. 8, no. 1, pp. 29–59, Jan. 2004."}, {"ref": "[24] B. J. Oommen and L. Rueda, On Utilizing Stochastic Learning Weak Estimators for Training and Classification of Patterns with Nonstationary Distributions. Berlin, Heidelberg: Springer Berlin Heidelberg, 2005, pp. 107–120."}, {"ref": "[25] ——, \"Stochastic learning-based weak estimation of multinomial random variables and its applications to pattern recognition in non-stationary environments,\" Pattern Recognition, vol. 39, no. 3, pp. 328 – 341, 2006."}, {"ref": "[26] J. Zhan, B. J. Oommen, and J. Crisostomo, \"Anomaly detection in dynamic systems using weak estimators,\" ACM Trans. Internet Technol., vol. 11, no. 1, pp. 3:1–3:16, Jul. 2011."}, {"ref": "[27] M. Bhaduri, J. Zhan, and C. Chiu, \"A novel weak estimator for dynamic systems,\" IEEE Access, vol. PP, no. 99, pp. 1–1, 2017."}, {"ref": "[28] N. B. Silva, I. R. Tsang, G. D. C. Cavalcanti, and I. J. Tsang, \"A graph-based friend recommendation system using genetic algorithm,\" in IEEE Congress on Evolutionary Computation, July 2010, pp. 1–7."}, {"ref": "[29] P. Wang, B. Xu, Y. Wu, and X. Zhou, \"Link prediction in social networks: the state-of-the-art,\" CoRR, vol. abs/1411.5118, 2014."}, {"ref": "[30] A. Lebedev, J. Lee, V. Rivera, and M. Mazzara, \"Link prediction using top-k shortest distances,\" CoRR, vol. abs/1705.02936, 2017."}, {"ref": "[31] J. Leskovec and A. Krevl, \"SNAP Datasets: Stanford large network dataset collection,\" http://snap.stanford.edu/data, Jun. 2014."}, {"ref": "[32] D. P. Kingma and J. Ba, \"Adam: A method for stochastic optimization,\" CoRR, vol. abs/1412.6980, 2014."}, {"ref": "[33] P. Ezatpoor, J. Zhan, J. Wu, and C. Chiu, \"Finding top-k dominance on incomplete big data using mapreduce framework,\" IEEE Access, vol. 6, pp. 7872–7887, 2018."}, {"ref": "[34] P. Chopade and J. Zhan, \"Towards a framework for community detection in large networks using game-theoretic modeling,\" IEEE Transaction on Big Data, vol. 3, no. 3, pp. 276–288, 2017."}, {"ref": "[35] M. Bhaduri, J. Zhan, and C. Chiu, \"A weak estimator for dynamic systems,\" IEEE Access, vol. 5, no. 1, pp. 27 354–27 365, 2017."}, {"ref": "[36] M. Bhaduri, J. Zhan, C. Chiu, and F. Zhan, \"A novel online and non-parametric approach for drift detection in big data,\" IEEE Access, vol. 5, no. 1, pp. 15 883–15 892, 2017."}, {"ref": "[37] C. Chiu, J. Zhan, and F. Zhan, \"Uncovering suspicious activity from partially paired and incomplete multimodal data,\" IEEE Access, vol. 5, no. 1, pp. 13 689 – 13 698, 2017."}, {"ref": "[38] R. Ahn and J. Zhan, \"Using proxies for node immunization identification on large graphs,\" IEEE Access, vol. 5, no. 1, pp. 13 046– 13 053, 2017."}, {"ref": "[39] M. Wu, J. Zhan, and J. Lin, \"Ant colony system sanitization approach to hiding sensitive itemsets,\" IEEE Access, vol. 14, no. 8, 2017."}, {"ref": "[40] J. Zhan and B. Dahal, \"Using deep learning for short text understanding,\" Journal of Big Data, vol. 4, no. 34, pp. 1–15, 2017."}, {"ref": "[41] W. Gan, J. Lin, P. Fournier-Viger, H. Chao, J. Zhan, and J. Zhang, \"Exploiting highly qualified pattern with frequency and weight occupancy,\" Knowledge and Information Systems, In Press, 3 October 2017."}, {"ref": "[42] J. Lin, T.-P. Hong, P. Fournier-Viger, Q. Liu, J.-W. Wong, and J. Zhan, \"Efficient hiding of confidential high-utility itemsets with minimal side effects,\" Journal of Experimental and Theoretical Artificial Intelligence, vol. 0, no. 0, pp. 1–21, 2017."}, {"ref": "[43] J. Zhan, S. Gurung, and S. P. K. Parsa, \"Identification of top-k nodes in large networks using katz centrality,\" Journal of Big Data, vol. 4, no. 16, 2017."}, {"ref": "[44] J. C.-W. Lin, W. Gan, P. Fournier-Viger, H.-C. Chao, J. M.-T. Wu, and J. Zhan, \"Extracting recent weighted-based patterns from uncertain temporal databases,\" International Scientific Journal Engineering Applications of Artificial Intelligence, vol. 61, pp. 161–172, 2017."}, {"ref": "[45] J. Zhan, T. Rafalski, G. Stashkevich, and E. Verenich, \"Vaccination allocation in large dynamic networks,\" Journal of Big Data, vol. 4, no. 2, 2017."}, {"ref": "[46] W. Gan, C.-W. Lin, H.-C. Chao, and Z. Justin, \"Data mining in distributed environment: A survey, wires data mining and knowledge discovery,\" 2017 (accepted)."}, {"ref": "[47] W. Gan, J. C.-W. Lin, P. Fournier-Viger, H. C. Chao, and J. Zhan, \"Mining of frequent patterns with multiple minimum supports,\" Engineering Applications of Artificial Intelligence, 2017."}, {"ref": "[48] J. M.-T. Wu, J. Zhan, and J. C.-W. Lin, \"An aco-based approach to mine high-utility itemsets,\" Knowledge-Based Systems, vol. 116, pp. 102–113, 2017."}, {"ref": "[49] M. Pirouz, J. Zhan, and S. Tayeb, \"An optimized approach for community detection and ranking,\" Journal of Big Data, vol. 3, no. 22, 2016."}, {"ref": "[50] J. C.-W. Lin, W. Gan, P. Fournier-Viger, T.-P. Hong, and J. Zhan, \"Efficient mining of high-utility itemsets using multiple minimum utility thresholds,\" Knowledge-Based Systems, vol. 113, pp. 100–115, 2016."}, {"ref": "[51] J. C.-W. Lin, T. Li, P. Fournier-Viger, T.-P. Hong, J. M.-T. Wu, and J. Zhan, \"Efficient mining of multiple fuzzy frequent itemsets,\" International Journal of Fuzzy Systems, pp. 1–9, 2016."}]}]}